{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acd0e3de",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4199b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentations_to_test = [\n",
    "#     # \"none\",\n",
    "#     # \"light\",\n",
    "#     # \"medium\",\n",
    "#     # \"heavy\",\n",
    "#     # \"grayscale\",\n",
    "#     # \"randaugment\",\n",
    "#     \"mixup\",\n",
    "#     \"cutmix\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813e37b4",
   "metadata": {},
   "source": [
    "<!-- ##### Simple model do test augmentations -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d78069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model(num_classes):\n",
    "#     base = keras.applications.EfficientNetB0(\n",
    "#         input_shape=(224, 224, 3),\n",
    "#         include_top=False,\n",
    "#         weights=\"imagenet\",\n",
    "#         pooling=\"avg\"\n",
    "#     )\n",
    "#     base.trainable = False  # You can fine-tune later\n",
    "\n",
    "#     inputs = keras.Input(shape=(224, 224, 3))\n",
    "#     x = base(inputs, training=False)\n",
    "#     x = keras.layers.Dropout(0.2)(x)\n",
    "#     outputs = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "#     return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f7ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample_dataset(dataset, fraction=None, num_batches=None, seed=42):\n",
    "#     \"\"\"Return a sampled subset of the dataset.\"\"\"\n",
    "#     if fraction:\n",
    "#         dataset = dataset.shuffle(1000, seed=seed)\n",
    "#         dataset = dataset.take(int(fraction * tf.data.experimental.cardinality(dataset).numpy()))\n",
    "#     elif num_batches:\n",
    "#         dataset = dataset.take(num_batches)\n",
    "#     return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca4e98c",
   "metadata": {},
   "source": [
    "<!-- ##### Loop -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf91ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the preprocessor\n",
    "# pre = Preprocessor(image_size=(224, 224), batch_size=32)\n",
    "\n",
    "# # Store results\n",
    "# results = {}\n",
    "\n",
    "# # Loop through each augmentation\n",
    "# for aug in augmentations_to_test:\n",
    "#     print(f\"\\nTraining with augmentation: {aug}\")\n",
    "\n",
    "#     # Load datasets\n",
    "#     train_ds, class_names = pre.load_img(\n",
    "#         data_dir=\"../data/rare_species/train\",\n",
    "#         augment=aug\n",
    "#     )\n",
    "\n",
    "#     val_ds, _ = pre.load_img(\n",
    "#         data_dir=\"../data/rare_species/val\",\n",
    "#         augment=None\n",
    "#     )\n",
    "\n",
    "#     # Sample a subset of training data\n",
    "#     train_ds = sample_dataset(train_ds, fraction=0.5)\n",
    "\n",
    "#     # Build a fresh model (you should define this function)\n",
    "#     model = build_sequential_model(list_of_layers=layers)\n",
    "\n",
    "#     # Compile\n",
    "#     model.compile(\n",
    "#         optimizer=\"adam\",\n",
    "#         loss=\"categorical_crossentropy\",\n",
    "#         metrics=[\"accuracy\"]\n",
    "#     )\n",
    "\n",
    "#     # Train\n",
    "#     history = model.fit(\n",
    "#         train_ds,\n",
    "#         validation_data=val_ds,\n",
    "#         epochs=5,\n",
    "#         verbose=1\n",
    "#     )\n",
    "\n",
    "#     # Predict entire validation set at once\n",
    "#     preds = model.predict(val_ds)\n",
    "#     y_pred = np.argmax(preds, axis=1)\n",
    "\n",
    "#     # Extract true labels in order\n",
    "#     y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
    "\n",
    "#     # Compute metrics\n",
    "#     f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "#     f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "#     precision = precision_score(y_true, y_pred, average='weighted')\n",
    "#     recall = recall_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "#     # Store in results\n",
    "#     results[aug] = {\n",
    "#         \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "#         \"f1_macro\": f1_macro,\n",
    "#         \"f1_weighted\": f1_weighted,\n",
    "#         \"precision\": precision,\n",
    "#         \"recall\": recall\n",
    "#     }\n",
    "\n",
    "#     print(f\"Finished '{aug}'\")\n",
    "#     print(f\"  Accuracy:      {results[aug]['val_accuracy']:.4f}\")\n",
    "#     print(f\"  F1 (macro):    {results[aug]['f1_macro']:.4f}\")\n",
    "#     print(f\"  F1 (weighted): {results[aug]['f1_weighted']:.4f}\")\n",
    "#     print(f\"  Precision:     {results[aug]['precision']:.4f}\")\n",
    "#     print(f\"  Recall:        {results[aug]['recall']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07b6e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentations_to_test = [\n",
    "#     \"none\",\n",
    "#     \"light\",\n",
    "#     \"medium\",\n",
    "#     \"heavy\",\n",
    "#     \"grayscale\",\n",
    "#     \"randaugment\",\n",
    "#     \"mixup\",\n",
    "#     \"cutmix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d6be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the preprocessor\n",
    "# pre = Preprocessor(image_size=(224, 224), batch_size=32)\n",
    "\n",
    "# # Store results\n",
    "# results = {}\n",
    "\n",
    "# # Loop through each augmentation\n",
    "# for aug in augmentations_to_test:\n",
    "#     print(f\"\\nTraining with augmentation: {aug}\")\n",
    "\n",
    "#     # Load datasets\n",
    "#     train_ds, class_names = pre.load_img(\n",
    "#         data_dir=\"../data/rare_species/train\",\n",
    "#         augment=aug\n",
    "#     )\n",
    "\n",
    "#     val_ds, _ = pre.load_img(\n",
    "#         data_dir=\"../data/rare_species/val\",\n",
    "#         augment=None\n",
    "#     )\n",
    "\n",
    "#     # Sample a subset of training data\n",
    "#     train_ds = sample_dataset(train_ds, fraction=0.5)\n",
    "\n",
    "#     # Build a fresh model (you should define this function)\n",
    "#     model = build_sequential_model(list_of_layers=layers)\n",
    "\n",
    "#     # Compile\n",
    "#     model.compile(\n",
    "#         optimizer=\"adam\",\n",
    "#         loss=\"categorical_crossentropy\",\n",
    "#         metrics=[\"accuracy\"]\n",
    "#     )\n",
    "\n",
    "#     # Train\n",
    "#     history = model.fit(\n",
    "#         train_ds,\n",
    "#         validation_data=val_ds,\n",
    "#         epochs=15,\n",
    "#         verbose=1\n",
    "#     )\n",
    "\n",
    "#     # Predict entire validation set at once\n",
    "#     preds = model.predict(val_ds)\n",
    "#     y_pred = np.argmax(preds, axis=1)\n",
    "\n",
    "#     # Extract true labels in order\n",
    "#     y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
    "\n",
    "#     # Compute metrics\n",
    "#     f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "#     f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "#     precision = precision_score(y_true, y_pred, average='weighted')\n",
    "#     recall = recall_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "#     # Store in results\n",
    "#     results[aug] = {\n",
    "#         \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "#         \"f1_macro\": f1_macro,\n",
    "#         \"f1_weighted\": f1_weighted,\n",
    "#         \"precision\": precision,\n",
    "#         \"recall\": recall\n",
    "#     }\n",
    "\n",
    "#     print(f\"Finished '{aug}'\")\n",
    "#     print(f\"  Accuracy:      {results[aug]['val_accuracy']:.4f}\")\n",
    "#     print(f\"  F1 (macro):    {results[aug]['f1_macro']:.4f}\")\n",
    "#     print(f\"  F1 (weighted): {results[aug]['f1_weighted']:.4f}\")\n",
    "#     print(f\"  Precision:     {results[aug]['precision']:.4f}\")\n",
    "#     print(f\"  Recall:        {results[aug]['recall']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
