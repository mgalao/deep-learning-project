{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02e283f2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# **1.** Environment Setup\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d815d3b",
   "metadata": {},
   "source": [
    "## 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ef556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import regularizers\n",
    "from classes import *\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55268a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Dropout, Input, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.metrics import AUC, F1Score, CategoricalAccuracy, TopKCategoricalAccuracy\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803176e3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# **2.** Preprocessing\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab5ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/train_df.pkl\", \"rb\") as f:\n",
    "     train_df = pickle.load(f)\n",
    "\n",
    "with open(\"../data/val_df.pkl\", \"rb\") as f:\n",
    "     val_df = pickle.load(f)\n",
    "\n",
    "with open(\"../data/test_df.pkl\", \"rb\") as f:\n",
    "     test_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc100d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('family_encoder.pkl', 'rb') as f:\n",
    "    family_encoder = pickle.load(f)\n",
    "\n",
    "# Load class names\n",
    "class_names = family_encoder.classes_\n",
    "\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ca1ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_class = train_df['family'].value_counts()[train_df['family'].value_counts() < 25].index\n",
    "minority_class=minority_class.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9020e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
    "image_size = (224, 224)\n",
    "\n",
    "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bae18c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# **3.** Results Analysis\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51bd5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model keras\n",
    "model = load_model(\"efficient_net_finetuned_final.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9376929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets with efficientnets preprocessing\n",
    "train_ds, _ = preprocess.load_img(\n",
    "    data_dir=\"../data/rare_species/train\",\n",
    "    minority_class=minority_class,\n",
    "    augment=\"mixup\",\n",
    "    oversampling=True,\n",
    "    shuffle= True,\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds, _ = preprocess.load_img(\n",
    "    data_dir=\"../data/rare_species/val\",\n",
    "    minority_class=[],\n",
    "    augment=None,\n",
    "    shuffle= False,\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "test_ds, _ = preprocess.load_img(\n",
    "    data_dir=\"../data/rare_species/test\",\n",
    "    minority_class=[],\n",
    "    augment=None,\n",
    "    shuffle= False,\n",
    "    preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d22e293",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28abc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaecb56d",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7f0f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metric(train_ds, \"efficient_net_finetuned_final.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7452f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metric(val_ds, \"efficient_net_finetuned_final.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f844d1fa",
   "metadata": {},
   "source": [
    "### Visualize no confidence images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94972250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unbatch train_ds into list\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "for img, label in train_ds.unbatch():\n",
    "    train_images.append(img.numpy())\n",
    "    train_labels.append(label.numpy())\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Predict all train images\n",
    "pred_probs_all = model.predict(train_images, verbose=1)\n",
    "y_pred = np.argmax(pred_probs_all, axis=1)\n",
    "y_true = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76289de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aff2142",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8843f90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319eaf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(pred_probs_all, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac587bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of certainties\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(np.max(pred_probs_all, axis=1), bins=30, edgecolor='black')\n",
    "plt.xlabel('Model Certainty (Max Softmax Probability)')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Distribution of Model Certainty')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dade6ad",
   "metadata": {},
   "source": [
    "#### Histogram of model confidence, divided by correctly and incorrectly classified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb232c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- assume pred_probs_all and train_labels are already defined ---\n",
    "\n",
    "# 1) prepare labels\n",
    "labels = train_labels\n",
    "if labels.ndim > 1:\n",
    "    labels = np.argmax(labels, axis=1)\n",
    "\n",
    "# 2) get preds and confidences\n",
    "preds = np.argmax(pred_probs_all, axis=1)\n",
    "confidences = np.max(pred_probs_all, axis=1)\n",
    "\n",
    "# 3) split confidences by correctness\n",
    "correct_conf = confidences[preds == labels]\n",
    "incorrect_conf = confidences[preds != labels]\n",
    "\n",
    "# 4) define bins\n",
    "bins = np.linspace(0, 1, 21)  # 20 bins\n",
    "\n",
    "# 5) histogram counts for each bin\n",
    "correct_counts, _   = np.histogram(correct_conf,   bins=bins)\n",
    "incorrect_counts, _ = np.histogram(incorrect_conf, bins=bins)\n",
    "total_counts = correct_counts + incorrect_counts\n",
    "\n",
    "# 6) misclassification rate per bin (in %), guard against zero-division\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    misclass_rate = 100 * incorrect_counts / total_counts\n",
    "misclass_rate = np.nan_to_num(misclass_rate)  # zero where total_counts==0\n",
    "\n",
    "# 7) bin centers for plotting the line\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "# 8) plot\n",
    "fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# stacked histogram\n",
    "ax1.hist(\n",
    "    [correct_conf, incorrect_conf],\n",
    "    bins=bins,\n",
    "    stacked=True,\n",
    "    color=['green', 'red'],\n",
    "    label=['Correct classification', 'Incorrect classification'],\n",
    "    edgecolor=\"black\"\n",
    ")\n",
    "ax1.set_xlabel('Model Confidence (Max Softmax Probability)')\n",
    "ax1.set_ylabel('Number of Samples')\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "# secondary axis for misclassification %\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(\n",
    "    bin_centers,\n",
    "    misclass_rate,\n",
    "    marker='o',\n",
    "    linestyle='-',\n",
    "    color='blue',\n",
    "    label='Misclassification rate (%)'\n",
    ")\n",
    "ax2.set_ylabel('Misclassification Rate (%)')\n",
    "ax2.set_ylim(0, 100)\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.title('Distribution of Model Confidence')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d20e6c8",
   "metadata": {},
   "source": [
    "#### Trying to incorporate phylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51884f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unbatch train_ds into list\n",
    "val_images = []\n",
    "val_labels = []\n",
    "\n",
    "for img, label in val_ds.unbatch():\n",
    "    val_images.append(img.numpy())\n",
    "    val_labels.append(label.numpy())\n",
    "\n",
    "val_images = np.array(val_images)\n",
    "val_labels = np.array(val_labels)\n",
    "\n",
    "# Predict all val images\n",
    "pred_probs_all_val = model.predict(val_images, verbose=1)\n",
    "y_pred = np.argmax(pred_probs_all, axis=1)\n",
    "y_true = val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3182fc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# create family:phylum dicionary\n",
    "meta = pd.read_csv('../data/rare_species/metadata.csv')\n",
    "dup = meta.groupby('family')['phylum'].nunique()\n",
    "family_to_phylum = dict(zip(meta['family'], meta['phylum']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c182f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2) Prepare true labels & names ---\n",
    "# train_labels: your true labels, shape (11200,) or one-hot (11200,202)\n",
    "# class_names: list of length 202 mapping index→family string\n",
    "labels = np.argmax(val_labels, axis=1) # family# prediction, not one-hot-encoded\n",
    "y_true_fam   = np.array([class_names[i] for i in labels])\n",
    "y_true_phyl  = np.array([family_to_phylum[f] for f in y_true_fam])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3) Baseline predictions & phylum check ---\n",
    "y_pred       = np.argmax(pred_probs_all_val, axis=1)\n",
    "y_pred_fam   = np.array([class_names[i] for i in y_pred])\n",
    "y_pred_phyl  = np.array([family_to_phylum[f] for f in y_pred_fam])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c97d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary phylum:[list of indices of classes that belong to that phylum]\n",
    "phylum_to_inds = {}\n",
    "for idx, fam in enumerate(class_names):\n",
    "    ph = family_to_phylum[fam]\n",
    "    phylum_to_inds.setdefault(ph, []).append(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a924cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4) Hierarchical override logic ---\n",
    "y_pred_hier = y_pred.copy()\n",
    "for i, probs in enumerate(pred_probs_all_val):\n",
    "    # if predicted phylum ≠ true phylum, force to best within true phylum\n",
    "    if y_pred_phyl[i] != y_true_phyl[i]:\n",
    "        valid_idx = phylum_to_inds[y_true_phyl[i]]\n",
    "        y_pred_hier[i] = valid_idx[np.argmax(probs[valid_idx])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6535eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5) Overall accuracy comparison ---\n",
    "acc_base  = accuracy_score(labels, y_pred)\n",
    "acc_hier  = accuracy_score(labels, y_pred_hier)\n",
    "print(f\"Baseline overall accuracy:     {acc_base:.4f}\")\n",
    "print(f\"Hierarchical override accuracy:{acc_hier:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd706552",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification report with original predictions:\")\n",
    "print(classification_report(labels,y_pred))\n",
    "print(\"Classification report with original predictions:\")\n",
    "print(classification_report(labels,y_pred_hier,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209f9b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6) Per-phylum accuracy improvement ---\n",
    "phyla = np.unique(y_true_phyl)\n",
    "base_scores = []\n",
    "hier_scores = []\n",
    "for ph in phyla:\n",
    "    idxs = np.where(y_true_phyl == ph)[0]\n",
    "    base_scores.append( accuracy_score(labels[idxs], y_pred[idxs]) )\n",
    "    hier_scores.append( accuracy_score(labels[idxs], y_pred_hier[idxs]) )\n",
    "\n",
    "x = np.arange(len(phyla))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(x - width/2, base_scores, width, label='Baseline')\n",
    "plt.bar(x + width/2, hier_scores, width, label='Hierarchical')\n",
    "plt.xticks(x, phyla, rotation=45, ha='right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy by Phylum')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15927509",
   "metadata": {},
   "source": [
    "#### No certainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8003e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_true to class labels\n",
    "y_true_labels = np.argmax(y_true, axis=1)\n",
    "\n",
    "# Get misclassified indices\n",
    "misclassified_indices = np.where(y_true_labels != y_pred)[0]\n",
    "\n",
    "# For each misclassified, get model confidence (highest softmax probability)\n",
    "confidences = np.max(pred_probs_all[misclassified_indices], axis=1)\n",
    "\n",
    "# Sort misclassified examples by descending confidence\n",
    "sorted_indices = np.argsort(confidences)  # Sort ascending\n",
    "selected_indices = misclassified_indices[sorted_indices[:12]]  # Take top 6\n",
    "\n",
    "# Prepare images to show (selected misclassified ones)\n",
    "images_to_show = []\n",
    "\n",
    "for idx in selected_indices:\n",
    "    img = train_images[idx]\n",
    "    true_label = y_true_labels[idx]\n",
    "    pred_label = y_pred[idx]\n",
    "    confidence = confidences[np.where(misclassified_indices == idx)][0]  # Get confidence for the current misclassified image\n",
    "    images_to_show.append((img, true_label, pred_label, confidence))\n",
    "\n",
    "# Save the misclassified data\n",
    "misclassified_data = {\n",
    "    \"True Label\": [class_names[true_label] for _, true_label, _, _ in images_to_show],\n",
    "    \"Predicted Label\": [class_names[pred_label] for _, _, pred_label, _ in images_to_show],\n",
    "    \"Confidence\": [confidence for _, _, _, confidence in images_to_show]\n",
    "}\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "for i, (img, true_label, pred_label, confidence) in enumerate(images_to_show):\n",
    "    plt.subplot(4, 3, i + 1)\n",
    "    plt.imshow(img.astype(\"uint8\"))\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"True: {class_names[true_label]}\\nPred: {class_names[pred_label]}\\nConf: {confidence:.2f}\", \n",
    "              color='red', fontsize=10)\n",
    "\n",
    "plt.suptitle(\"Less Confident Misclassifications\", fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e726e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of certainties\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(confidences, bins=30, edgecolor='black')\n",
    "plt.xlabel('Model Certainty (Max Softmax Probability)')\n",
    "plt.ylabel('Number of Misclassified Samples')\n",
    "plt.title('Distribution of Model Certainty for Misclassified Samples')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dcfddc",
   "metadata": {},
   "source": [
    "Since you have 202 classes, a model that is completely uncertain (i.e., guessing randomly) would have maximum softmax probability 0.004. But models aren't truly random even when uncertain — usually, even bad predictions are around 0.02–0.1 certainty (depends on how the softmax behaves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f75238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, compute the maximum probability for ALL predictions\n",
    "all_confidences = np.max(pred_probs_all, axis=1)  # Shape: (num_val_samples,)\n",
    "\n",
    "# Total number of validation images\n",
    "total_val_images = len(train_images)\n",
    "\n",
    "# Number of predictions where certainty < 0.1\n",
    "num_uncertain_predictions = np.sum(all_confidences < 0.019)\n",
    "\n",
    "print(f\"Total validation images: {total_val_images}\")\n",
    "print(f\"Number of predictions with certainty < 0.1: {num_uncertain_predictions}\")\n",
    "print(f\"Percentage: {100 * num_uncertain_predictions / total_val_images:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c8f26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab43070",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc372ac",
   "metadata": {},
   "source": [
    "#### Top Correctly Classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d425d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_true to class labels\n",
    "y_true_labels = np.argmax(y_true, axis=1)\n",
    "\n",
    "# Get indices of correctly classified images\n",
    "correct_indices = np.where(y_true_labels == y_pred)[0]\n",
    "\n",
    "# For each correctly classified image, get model confidence (highest softmax probability)\n",
    "confidences = np.max(pred_probs_all[correct_indices], axis=1)\n",
    "\n",
    "# Sort correctly classified examples by descending confidence\n",
    "sorted_indices = np.argsort(confidences)[::-1]  # Sort descending\n",
    "selected_indices = correct_indices[sorted_indices[:6]]  # Take top 6 with highest confidence\n",
    "\n",
    "# Prepare images to show (selected correctly classified ones)\n",
    "images_to_show = []\n",
    "\n",
    "for idx in selected_indices:\n",
    "    img = test_images[idx]\n",
    "    true_label = y_true_labels[idx]\n",
    "    pred_label = y_pred[idx]\n",
    "    confidence = confidences[np.where(correct_indices == idx)][0]  # Get confidence for the current correctly classified image\n",
    "    images_to_show.append((img, true_label, pred_label, confidence))\n",
    "\n",
    "# Save the misclassified data\n",
    "correctly_classified_data = {\n",
    "    \"True Label\": [class_names[true_label] for _, true_label, _, _ in images_to_show],\n",
    "    \"Predicted Label\": [class_names[pred_label] for _, _, pred_label, _ in images_to_show],\n",
    "    \"Confidence\": [confidence for _, _, _, confidence in images_to_show]\n",
    "}\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "for i, (img, true_label, pred_label, confidence) in enumerate(images_to_show):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.imshow(img.astype(\"uint8\"))\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"True: {class_names[true_label]}\\nPred: {class_names[pred_label]}\\nConf: {confidence:.2f}\", \n",
    "              color='green', fontsize=10)\n",
    "\n",
    "plt.suptitle(\"Most Confident Correct Classifications\", fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011c201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "correctly_classified_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16268a15",
   "metadata": {},
   "source": [
    "#### Correctly Classified for Specific Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc6e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e9b4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for family in misclassified_data[\"True Label\"]:\n",
    "    show_correct_predictions_for_family(y_true, y_pred, pred_probs_all, test_images, class_names, family_name=family, num_images=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for family in misclassified_data[\"Predicted Label\"]:\n",
    "    show_correct_predictions_for_family(y_true, y_pred, pred_probs_all, test_images, class_names, family_name=family, num_images=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e2ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "correctly_classified_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for family in correctly_classified_data[\"True Label\"]:\n",
    "    show_correct_predictions_for_family(y_true, y_pred, pred_probs_all, test_images, class_names, family_name=family, num_images=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2841d5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# **4.** More\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d6716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    \"VGG16\": \"vgg_history_train_until_opt.csv\",\n",
    "    \"ResNet50\": \"resnet50_final_train_history.csv\",\n",
    "    \"EfficientNet Baseline 1\": \"efficient_net_baseline1_history.csv\",\n",
    "    \"EfficientNet Baseline 2\": \"efficient_net_baseline2_history.csv\",\n",
    "    \"EfficientNet Final\": \"efficient_net_final_train_history.csv\",\n",
    "    \"EfficientNet Fine-Tuned\": \"efficient_net_final_finetune_history.csv\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f2994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_history(path):\n",
    "    df = pd.read_csv(path)\n",
    "    if 'acc' in df.columns:\n",
    "        df = df.rename(columns={'acc': 'accuracy'})\n",
    "    if 'val_acc' in df.columns:\n",
    "        df = df.rename(columns={'val_acc': 'val_accuracy'})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c69abdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = {label: load_history(path) for label, path in files.items()}\n",
    "\n",
    "summary_list = []\n",
    "for label, df in histories.items():\n",
    "    last_epoch = df.iloc[-1]\n",
    "    # Para cada métrica, tenta pegar 'accuracy' e 'f1_score'\n",
    "    summary_list.append({\n",
    "        \"Model\": label,\n",
    "        \"Train Set Accuracy\": last_epoch.get(\"accuracy\", last_epoch.get(\"accuracy\", None)),\n",
    "        \"Validation Set Accuracy\": last_epoch.get(\"val_accuracy\", last_epoch.get(\"val_accuracy\", None)),\n",
    "        \"Train Set F1-Score\": last_epoch.get(\"f1_score\", last_epoch.get(\"f1_score\", None)),\n",
    "        \"Validation Set F1-Score\": last_epoch.get(\"val_f1_score\", last_epoch.get(\"val_f1_score\", None)),\n",
    "        \"Train Set Loss\": last_epoch.get(\"loss\", last_epoch.get(\"loss\", None)),\n",
    "        \"Validation Set Loss\": last_epoch.get(\"val_loss\", last_epoch.get(\"val_loss\", None))\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_list)\n",
    "summary_df = summary_df.set_index(\"Model\")\n",
    "summary_df = summary_df.sort_values(by=\"Validation Set F1-Score\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02ad7bf",
   "metadata": {},
   "source": [
    "### Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e482b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = summary_df.sort_values(by=\"Validation Set F1-Score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a745392",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de018a27",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fd2996",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Aptos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1606c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(8, 10))\n",
    "ax = summary_df[['Train Set Accuracy', 'Validation Set Accuracy']].plot(kind='bar', color=['navy', 'maroon'], legend=False)\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9753727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(8, 10))\n",
    "ax = summary_df[['Train Set Loss', 'Validation Set Loss']].plot(kind='bar', color=['navy', 'maroon'], legend=False)\n",
    "ax.legend(loc='upper left', fontsize=10)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim(0, 2.5)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(8, 10))\n",
    "ax = summary_df[['Train Set F1-Score', 'Validation Set F1-Score']].plot(kind='bar', color=['navy', 'maroon'], legend=False)\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "plt.ylabel(\"F1-Score\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5416e338",
   "metadata": {},
   "source": [
    "### Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d80618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a8c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds, _ = preprocess.load_img(\n",
    "    data_dir=\"../data/rare_species/test\",\n",
    "    minority_class=[],\n",
    "    augment=None,\n",
    "    shuffle= False,\n",
    "    preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc649597",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metric(test_ds, \"efficient_net_finetuned_final.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
