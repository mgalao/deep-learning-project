{"cells":[{"cell_type":"markdown","metadata":{"id":"IarMyf8tHE9O"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","# **1.** Environment Setup\n","\n","<div>"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":157,"status":"ok","timestamp":1745634441206,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"},"user_tz":-60},"id":"XxCNHXvYIxsc","outputId":"4dcf9bf7-a2b3-4947-9438-8438ec4cace6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Apr 26 02:27:20 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   56C    P8             12W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1745634441209,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"},"user_tz":-60},"id":"1Im046xxIzgM","outputId":"a3fbf2f1-3724-4e3d-dbf1-cea656ef328f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 54.8 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"markdown","metadata":{"id":"BFzFY6OAHE9S"},"source":["## 1.1 Connect Google Drive"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1730,"status":"ok","timestamp":1745634442939,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"},"user_tz":-60},"id":"QxFPtRX_HE9S","outputId":"3c6e7ef5-577e-4c1f-e47e-86e6f7bc03c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1745634442943,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"},"user_tz":-60},"id":"9MXJsXNQHE9T","outputId":"743f5c68-29c1-4f34-a355-364aac6ec3d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Changed directory to: /content/drive/MyDrive/College/MSc/2nd Semester/Deep Learning/project\n"]}],"source":["import os\n","\n","# Change to the directory where project is located\n","os.chdir('/content/drive/MyDrive/College/MSc/2nd Semester/Deep Learning/project')\n","\n","# Verify that we changed the directory\n","print(\"Changed directory to:\", os.getcwd())"]},{"cell_type":"markdown","metadata":{"id":"KqYUDYg3HE9U"},"source":["## 1.2 Import Libraries"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2507,"status":"ok","timestamp":1745634445451,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"},"user_tz":-60},"id":"lbdGTrRLHE9U","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f24d0b28-8e8e-44d5-bff3-c99e479b1e2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: keras_cv in /usr/local/lib/python3.11/dist-packages (0.9.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras_cv) (24.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras_cv) (1.4.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from keras_cv) (2024.11.6)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (from keras_cv) (4.9.8)\n","Requirement already satisfied: keras-core in /usr/local/lib/python3.11/dist-packages (from keras_cv) (0.1.7)\n","Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from keras_cv) (0.3.11)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras_cv) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras_cv) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras_cv) (4.67.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras-core->keras_cv) (2.0.2)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras-core->keras_cv) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras-core->keras_cv) (0.0.9)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras-core->keras_cv) (3.13.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from keras-core->keras_cv) (0.1.9)\n","Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (0.7.1)\n","Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (1.12.2)\n","Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (4.2.1)\n","Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (2.3)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (5.29.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (5.9.5)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (18.1.0)\n","Requirement already satisfied: simple_parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (0.1.7)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (1.17.1)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (3.0.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (0.10.2)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (1.17.2)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (0.8.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (2025.3.2)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (6.5.2)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (4.13.2)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (3.21.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_cv) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_cv) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_cv) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_cv) (2025.1.31)\n","Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->keras-core->keras_cv) (25.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from promise->tensorflow-datasets->keras_cv) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-core->keras_cv) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-core->keras_cv) (2.18.0)\n","Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple_parsing->tensorflow-datasets->keras_cv) (0.16)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras_cv) (1.70.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras_cv) (0.1.2)\n"]}],"source":["# Google Colab\n","!pip install keras_cv"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"CMD7vSkiHE9U","executionInfo":{"status":"ok","timestamp":1745634460420,"user_tz":-60,"elapsed":14952,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"}}},"outputs":[],"source":["import pandas as pd\n","import zipfile\n","import pickle\n","from sklearn.preprocessing import LabelEncoder\n","from pathlib import Path\n","from sklearn.model_selection import train_test_split\n","from tensorflow import keras\n","from keras import regularizers\n","from classes import *\n","from functions import *"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"KDUcMRkgHE9V","executionInfo":{"status":"ok","timestamp":1745634460433,"user_tz":-60,"elapsed":2,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Dropout, Input, Conv2D, MaxPooling2D, Flatten\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n","from keras.metrics import AUC, F1Score, CategoricalAccuracy, TopKCategoricalAccuracy\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","from keras import optimizers"]},{"cell_type":"markdown","metadata":{"id":"9aODyFOSHE9W"},"source":["## 1.3 Import Dataset"]},{"cell_type":"markdown","metadata":{"id":"EuHifv_JHE9W"},"source":["The amount of data we have is not supported by GitHub (where we have our project stored). The solution is: create a folder named data and allocate the rare_species file inside it. The gitignore file makes sure this folder is not used when we are pulling or pushing changes but everyone needs to have it on their machines locally. A random seed was used to ensure that the splits stay the same."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":98,"status":"ok","timestamp":1745634460532,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"},"user_tz":-60},"id":"H2tnyOH7HE9W","outputId":"461e6bc7-1b6c-4846-d072-07ad25f2c633"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                        rare_species_id  eol_content_id  eol_page_id  \\\n","0  75fd91cb-2881-41cd-88e6-de451e8b60e2        12853737       449393   \n","1  28c508bc-63ff-4e60-9c8f-1934367e1528        20969394       793083   \n","2  00372441-588c-4af8-9665-29bee20822c0        28895411       319982   \n","3  29cc6040-6af2-49ee-86ec-ab7d89793828        29658536     45510188   \n","4  94004bff-3a33-4758-8125-bf72e6e57eab        21252576      7250886   \n","\n","    kingdom    phylum            family  \\\n","0  animalia  mollusca         unionidae   \n","1  animalia  chordata       geoemydidae   \n","2  animalia  chordata  cryptobranchidae   \n","3  animalia  chordata          turdidae   \n","4  animalia  chordata         indriidae   \n","\n","                                           file_path  \n","0  mollusca_unionidae/12853737_449393_eol-full-si...  \n","1  chordata_geoemydidae/20969394_793083_eol-full-...  \n","2  chordata_cryptobranchidae/28895411_319982_eol-...  \n","3  chordata_turdidae/29658536_45510188_eol-full-s...  \n","4  chordata_indriidae/21252576_7250886_eol-full-s...  "],"text/html":["\n","  <div id=\"df-2b017ecc-1b4d-480b-9535-c5076dd5a8c1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rare_species_id</th>\n","      <th>eol_content_id</th>\n","      <th>eol_page_id</th>\n","      <th>kingdom</th>\n","      <th>phylum</th>\n","      <th>family</th>\n","      <th>file_path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>75fd91cb-2881-41cd-88e6-de451e8b60e2</td>\n","      <td>12853737</td>\n","      <td>449393</td>\n","      <td>animalia</td>\n","      <td>mollusca</td>\n","      <td>unionidae</td>\n","      <td>mollusca_unionidae/12853737_449393_eol-full-si...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>28c508bc-63ff-4e60-9c8f-1934367e1528</td>\n","      <td>20969394</td>\n","      <td>793083</td>\n","      <td>animalia</td>\n","      <td>chordata</td>\n","      <td>geoemydidae</td>\n","      <td>chordata_geoemydidae/20969394_793083_eol-full-...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00372441-588c-4af8-9665-29bee20822c0</td>\n","      <td>28895411</td>\n","      <td>319982</td>\n","      <td>animalia</td>\n","      <td>chordata</td>\n","      <td>cryptobranchidae</td>\n","      <td>chordata_cryptobranchidae/28895411_319982_eol-...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>29cc6040-6af2-49ee-86ec-ab7d89793828</td>\n","      <td>29658536</td>\n","      <td>45510188</td>\n","      <td>animalia</td>\n","      <td>chordata</td>\n","      <td>turdidae</td>\n","      <td>chordata_turdidae/29658536_45510188_eol-full-s...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>94004bff-3a33-4758-8125-bf72e6e57eab</td>\n","      <td>21252576</td>\n","      <td>7250886</td>\n","      <td>animalia</td>\n","      <td>chordata</td>\n","      <td>indriidae</td>\n","      <td>chordata_indriidae/21252576_7250886_eol-full-s...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b017ecc-1b4d-480b-9535-c5076dd5a8c1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2b017ecc-1b4d-480b-9535-c5076dd5a8c1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2b017ecc-1b4d-480b-9535-c5076dd5a8c1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-a3564d84-59ee-4998-979c-9f094e20e8ed\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3564d84-59ee-4998-979c-9f094e20e8ed')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-a3564d84-59ee-4998-979c-9f094e20e8ed button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 11983,\n  \"fields\": [\n    {\n      \"column\": \"rare_species_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11983,\n        \"samples\": [\n          \"1fe30955-851a-4330-8e3e-899f852b7394\",\n          \"f181063f-8b62-4973-b87a-9953f50afe57\",\n          \"a61542c5-66ae-425e-ae1a-a8dfba86209e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eol_content_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6999288,\n        \"min\": 475,\n        \"max\": 30619463,\n        \"num_unique_values\": 11983,\n        \"samples\": [\n          21632363,\n          14020535,\n          24592257\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eol_page_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22413190,\n        \"min\": 118008,\n        \"max\": 52691998,\n        \"num_unique_values\": 400,\n        \"samples\": [\n          46560360,\n          46394217,\n          791461\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kingdom\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"animalia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phylum\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"chordata\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"family\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 202,\n        \"samples\": [\n          \"ambystomatidae\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11983,\n        \"samples\": [\n          \"chordata_squalidae/21632363_46560201_eol-full-size-copy.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":8}],"source":["# Import Metadata\n","metadata_path = Path(\"../data/rare_species/metadata.csv\")\n","df = pd.read_csv(metadata_path)\n","df.head()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1745634460539,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"},"user_tz":-60},"id":"bPX86TODHE9X","outputId":"8dc6b120-004f-4270-9aeb-35be998e5514"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11983, 7)"]},"metadata":{},"execution_count":9}],"source":["df.shape # 11983 images"]},{"cell_type":"markdown","metadata":{"id":"dXv1c3MsHE9X"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","# **2.** Preprocessing\n","\n","<div>"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"HYdDcJNrHE9X","executionInfo":{"status":"ok","timestamp":1745634460683,"user_tz":-60,"elapsed":143,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"}}},"outputs":[],"source":["#Load the DataFrames from the .pkl files\n","with open(\"../data/train_df.pkl\", \"rb\") as f:\n","     train_df = pickle.load(f)\n","\n","with open(\"../data/valid_df.pkl\", \"rb\") as f:\n","     val_df = pickle.load(f)\n","\n","with open(\"../data/test_df.pkl\", \"rb\") as f:\n","     test_df = pickle.load(f)\n","\n","with open(\"family_encoder.pkl\", \"rb\") as f:\n","     family_encoder = pickle.load(f)\n","\n","with open(\"phylum_encoder.pkl\", \"rb\") as f:\n","     phylum_encoder = pickle.load(f)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"V412ROvmop66","executionInfo":{"status":"ok","timestamp":1745634460686,"user_tz":-60,"elapsed":1,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"}}},"outputs":[],"source":["# identify the minority class\n","minority_class = train_df['family'].value_counts()[train_df['family'].value_counts() < 25].index\n","minority_class = minority_class.to_list()"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"O-dgw1jcHE9X","executionInfo":{"status":"ok","timestamp":1745634461075,"user_tz":-60,"elapsed":388,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"}}},"outputs":[],"source":["batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n","image_size = (224, 224)\n","\n","preprocess = Preprocessor_with_phylum(image_size=image_size, batch_size=batch_size)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Zx4qLcAuHE9X","executionInfo":{"status":"ok","timestamp":1745634461079,"user_tz":-60,"elapsed":2,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"}}},"outputs":[],"source":["# num_images = 16 ##\n","# rows, cols = 4, 4 ##\n","\n","# plot_batch(train_ds, class_names=class_names, num_images=num_images, rows=rows, cols=cols)"]},{"cell_type":"markdown","metadata":{"id":"pnYT4oJ4HE9Y"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","# **3.** Models\n","\n","<div>"]},{"cell_type":"markdown","metadata":{"id":"W0bSA5ZmHE9Y"},"source":["## EfficientNet"]},{"cell_type":"markdown","metadata":{"id":"VuWxQleZop66"},"source":["### Base line 1 (without preprocessing and without regularization)"]},{"cell_type":"markdown","metadata":{"id":"XbVPhM7gop66"},"source":["#### Set-up"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O5ZNyE07op66"},"outputs":[],"source":["from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1q7jWoOBsbVK"},"outputs":[],"source":["# Compile with metrics\n","verbose = 1\n","metrics = [\n","    CategoricalAccuracy(name=\"accuracy\"),\n","    AUC(name=\"auc\"),\n","    F1Score(average=\"macro\", name=\"f1_macro\"),\n","    F1Score(average=\"weighted\", name=\"f1_weighted\"),\n","    TopKCategoricalAccuracy(k=5, name=\"top5_accuracy\")\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJC_i-x9op66"},"outputs":[],"source":["# Load datasets\n","train_ds_en_no_proc_no_reg, family_class_names, phylum_class_names = preprocess.load_img(\n","    train_df,\n","    minority_class=[],\n","    augment=None,\n","    oversampling=False,\n","    shuffle=True,\n","    preprocessing_function=preprocess_input,\n","    family_encoder=family_encoder,\n","    phylum_encoder=phylum_encoder,\n",")\n","\n","val_ds_en_no_proc_no_reg, _, _ = preprocess.load_img(\n","    val_df,\n","    minority_class=[],\n","    augment=None,\n","    oversampling=False,\n","    shuffle=False,\n","    preprocessing_function=preprocess_input,\n","    family_encoder=family_encoder,\n","    phylum_encoder=phylum_encoder,\n",")"]},{"cell_type":"markdown","metadata":{"id":"4XH3CS6uop66"},"source":["#### Run"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y40z53qWHE9Y"},"outputs":[],"source":["# Image input pipeline\n","image_input = Input(shape=(224, 224, 3), name=\"image_input\")  # Input for RGB image\n","base_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_tensor=image_input)  # Pretrained EfficientNet without final dense layers\n","\n","# Freeze the base model layers\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Add a global average pooling layer\n","x = GlobalAveragePooling2D()(base_model.output)  # Convert 4D feature map to 2D vector (batch_size, 2048)\n","\n","# Phylum input (one-hot or multi-class vector with 5 classes)\n","phylum_input = Input(shape=(5,), name=\"phylum_input\")  # Input for phylum-level info\n","\n","# Combine image and phylum features\n","combined = Concatenate()([x, phylum_input])  # Concatenate the two inputs: (batch_size, 2048 + 5)\n","combined = Dense(256, activation='relu')(combined)  # Fully connected layer\n","output = Dense(202, activation='softmax')(combined)  # Final classification layer (202 family classes)\n","\n","# Define the model\n","model_en_no_proc_no_reg = Model(inputs=[image_input, phylum_input], outputs=output)\n","\n","# Compile the model\n","model_en_no_proc_no_reg.compile(\n","    optimizer=optimizers.RMSprop(learning_rate=1e-4),\n","    loss=keras.losses.CategoricalCrossentropy(),\n","    metrics=metrics\n",")\n","\n","# Print the model summary\n","# model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w8O73XQaHE9Y","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ba310a89-9d43-4265-eb29-a5ae0cb40378"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 573ms/step - accuracy: 0.0784 - auc: 0.6456 - f1_macro: 0.0171 - f1_weighted: 0.0509 - loss: 5.0572 - top5_accuracy: 0.1751 - val_accuracy: 0.2209 - val_auc: 0.8292 - val_f1_macro: 0.0566 - val_f1_weighted: 0.1354 - val_loss: 4.2321 - val_top5_accuracy: 0.4302\n","Epoch 2/25\n","\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 279ms/step - accuracy: 0.2572 - auc: 0.8644 - f1_macro: 0.0765 - f1_weighted: 0.1690 - loss: 3.9565 - top5_accuracy: 0.4763 - val_accuracy: 0.3239 - val_auc: 0.8992 - val_f1_macro: 0.1160 - val_f1_weighted: 0.2217 - val_loss: 3.4231 - val_top5_accuracy: 0.5765\n","Epoch 3/25\n","\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 272ms/step - accuracy: 0.3573 - auc: 0.9292 - f1_macro: 0.1519 - f1_weighted: 0.2662 - loss: 3.1592 - top5_accuracy: 0.6351 - val_accuracy: 0.4062 - val_auc: 0.9401 - val_f1_macro: 0.2043 - val_f1_weighted: 0.3214 - val_loss: 2.8550 - val_top5_accuracy: 0.6656\n","Epoch 4/25\n","\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 266ms/step - accuracy: 0.4559 - auc: 0.9630 - f1_macro: 0.2496 - f1_weighted: 0.3781 - loss: 2.5689 - top5_accuracy: 0.7336 - val_accuracy: 0.4769 - val_auc: 0.9582 - val_f1_macro: 0.2900 - val_f1_weighted: 0.4059 - val_loss: 2.4328 - val_top5_accuracy: 0.7407\n","Epoch 5/25\n","\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 269ms/step - accuracy: 0.5274 - auc: 0.9757 - f1_macro: 0.3548 - f1_weighted: 0.4642 - loss: 2.1723 - top5_accuracy: 0.8004 - val_accuracy: 0.5248 - val_auc: 0.9682 - val_f1_macro: 0.3642 - val_f1_weighted: 0.4615 - val_loss: 2.1235 - val_top5_accuracy: 0.7869\n","Epoch 6/25\n","\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 264ms/step - accuracy: 0.6003 - auc: 0.9831 - f1_macro: 0.4521 - f1_weighted: 0.5541 - loss: 1.8169 - top5_accuracy: 0.8603 - val_accuracy: 0.5559 - val_auc: 0.9714 - val_f1_macro: 0.4231 - val_f1_weighted: 0.5068 - val_loss: 1.8960 - val_top5_accuracy: 0.8292\n","Epoch 7/25\n","\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 269ms/step - accuracy: 0.6552 - auc: 0.9883 - f1_macro: 0.5478 - f1_weighted: 0.6234 - loss: 1.5702 - top5_accuracy: 0.8946 - val_accuracy: 0.5876 - val_auc: 0.9743 - val_f1_macro: 0.4810 - val_f1_weighted: 0.5499 - val_loss: 1.7336 - val_top5_accuracy: 0.8459\n","Epoch 8/25\n","\u001b[1m124/263\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 321ms/step - accuracy: 0.6981 - auc: 0.9902 - f1_macro: 0.5691 - f1_weighted: 0.6713 - loss: 1.3702 - top5_accuracy: 0.9140"]}],"source":["# Initialize the experiment\n","experiment_en_no_proc_no_reg = Experiment(\n","    model=model_en_no_proc_no_reg,\n","    train_ds=train_ds_en_no_proc_no_reg,\n","    val_ds=val_ds_en_no_proc_no_reg,\n","    experiment_name=\"eff-net_with_phylum_no_proc_no_reg\",\n","    resume=False,\n","    steps_per_epoch=263\n",")\n","\n","# Run the experiment\n","history_en_no_proc_no_reg = experiment_en_no_proc_no_reg.run_experiment(callbacks=None, epochs=25)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SY_6hXgXmy6P","colab":{"base_uri":"https://localhost:8080/","height":410},"executionInfo":{"status":"ok","timestamp":1745602405764,"user_tz":-60,"elapsed":81,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"}},"outputId":"c561b353-489c-4459-9506-ef9d12ea0306"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     id                     experiment_name  epoch  train_accuracy  \\\n","365  15  eff-net_with_phylum_no_proc_no_reg      1          0.1368   \n","366  15  eff-net_with_phylum_no_proc_no_reg      2          0.2810   \n","367  15  eff-net_with_phylum_no_proc_no_reg      3          0.3770   \n","368  15  eff-net_with_phylum_no_proc_no_reg      4          0.4690   \n","369  15  eff-net_with_phylum_no_proc_no_reg      5          0.5427   \n","370  15  eff-net_with_phylum_no_proc_no_reg      6          0.6067   \n","371  15  eff-net_with_phylum_no_proc_no_reg      7          0.6611   \n","\n","     val_accuracy  train_loss  val_loss  f1_train_macro  f1_val_macro  \\\n","365        0.2209      4.7950    4.2321          0.0312        0.0566   \n","366        0.3239      3.7621    3.4231          0.0948        0.1160   \n","367        0.4062      3.0345    2.8550          0.1728        0.2043   \n","368        0.4769      2.4912    2.4328          0.2876        0.2900   \n","369        0.5248      2.0781    2.1235          0.3900        0.3642   \n","370        0.5559      1.7702    1.8960          0.5009        0.4231   \n","371        0.5876      1.5308    1.7336          0.5934        0.4810   \n","\n","     f1_train_weighted  f1_val_weighted  top5_train_accuracy  \\\n","365             0.0855           0.1354               0.2776   \n","366             0.1914           0.2217               0.5108   \n","367             0.2890           0.3214               0.6535   \n","368             0.3974           0.4059               0.7470   \n","369             0.4865           0.4615               0.8189   \n","370             0.5675           0.5068               0.8634   \n","371             0.6355           0.5499               0.8952   \n","\n","     top5_val_accuracy            timestamp  \n","365             0.4302  2025-04-25 17:23:10  \n","366             0.5765  2025-04-25 17:24:24  \n","367             0.6656  2025-04-25 17:25:35  \n","368             0.7407  2025-04-25 17:26:45  \n","369             0.7869  2025-04-25 17:27:55  \n","370             0.8292  2025-04-25 17:29:04  \n","371             0.8459  2025-04-25 17:30:15  "],"text/html":["\n","  <div id=\"df-5c6fae49-e6bd-49f2-98e0-9ea6b99885b6\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>experiment_name</th>\n","      <th>epoch</th>\n","      <th>train_accuracy</th>\n","      <th>val_accuracy</th>\n","      <th>train_loss</th>\n","      <th>val_loss</th>\n","      <th>f1_train_macro</th>\n","      <th>f1_val_macro</th>\n","      <th>f1_train_weighted</th>\n","      <th>f1_val_weighted</th>\n","      <th>top5_train_accuracy</th>\n","      <th>top5_val_accuracy</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>365</th>\n","      <td>15</td>\n","      <td>eff-net_with_phylum_no_proc_no_reg</td>\n","      <td>1</td>\n","      <td>0.1368</td>\n","      <td>0.2209</td>\n","      <td>4.7950</td>\n","      <td>4.2321</td>\n","      <td>0.0312</td>\n","      <td>0.0566</td>\n","      <td>0.0855</td>\n","      <td>0.1354</td>\n","      <td>0.2776</td>\n","      <td>0.4302</td>\n","      <td>2025-04-25 17:23:10</td>\n","    </tr>\n","    <tr>\n","      <th>366</th>\n","      <td>15</td>\n","      <td>eff-net_with_phylum_no_proc_no_reg</td>\n","      <td>2</td>\n","      <td>0.2810</td>\n","      <td>0.3239</td>\n","      <td>3.7621</td>\n","      <td>3.4231</td>\n","      <td>0.0948</td>\n","      <td>0.1160</td>\n","      <td>0.1914</td>\n","      <td>0.2217</td>\n","      <td>0.5108</td>\n","      <td>0.5765</td>\n","      <td>2025-04-25 17:24:24</td>\n","    </tr>\n","    <tr>\n","      <th>367</th>\n","      <td>15</td>\n","      <td>eff-net_with_phylum_no_proc_no_reg</td>\n","      <td>3</td>\n","      <td>0.3770</td>\n","      <td>0.4062</td>\n","      <td>3.0345</td>\n","      <td>2.8550</td>\n","      <td>0.1728</td>\n","      <td>0.2043</td>\n","      <td>0.2890</td>\n","      <td>0.3214</td>\n","      <td>0.6535</td>\n","      <td>0.6656</td>\n","      <td>2025-04-25 17:25:35</td>\n","    </tr>\n","    <tr>\n","      <th>368</th>\n","      <td>15</td>\n","      <td>eff-net_with_phylum_no_proc_no_reg</td>\n","      <td>4</td>\n","      <td>0.4690</td>\n","      <td>0.4769</td>\n","      <td>2.4912</td>\n","      <td>2.4328</td>\n","      <td>0.2876</td>\n","      <td>0.2900</td>\n","      <td>0.3974</td>\n","      <td>0.4059</td>\n","      <td>0.7470</td>\n","      <td>0.7407</td>\n","      <td>2025-04-25 17:26:45</td>\n","    </tr>\n","    <tr>\n","      <th>369</th>\n","      <td>15</td>\n","      <td>eff-net_with_phylum_no_proc_no_reg</td>\n","      <td>5</td>\n","      <td>0.5427</td>\n","      <td>0.5248</td>\n","      <td>2.0781</td>\n","      <td>2.1235</td>\n","      <td>0.3900</td>\n","      <td>0.3642</td>\n","      <td>0.4865</td>\n","      <td>0.4615</td>\n","      <td>0.8189</td>\n","      <td>0.7869</td>\n","      <td>2025-04-25 17:27:55</td>\n","    </tr>\n","    <tr>\n","      <th>370</th>\n","      <td>15</td>\n","      <td>eff-net_with_phylum_no_proc_no_reg</td>\n","      <td>6</td>\n","      <td>0.6067</td>\n","      <td>0.5559</td>\n","      <td>1.7702</td>\n","      <td>1.8960</td>\n","      <td>0.5009</td>\n","      <td>0.4231</td>\n","      <td>0.5675</td>\n","      <td>0.5068</td>\n","      <td>0.8634</td>\n","      <td>0.8292</td>\n","      <td>2025-04-25 17:29:04</td>\n","    </tr>\n","    <tr>\n","      <th>371</th>\n","      <td>15</td>\n","      <td>eff-net_with_phylum_no_proc_no_reg</td>\n","      <td>7</td>\n","      <td>0.6611</td>\n","      <td>0.5876</td>\n","      <td>1.5308</td>\n","      <td>1.7336</td>\n","      <td>0.5934</td>\n","      <td>0.4810</td>\n","      <td>0.6355</td>\n","      <td>0.5499</td>\n","      <td>0.8952</td>\n","      <td>0.8459</td>\n","      <td>2025-04-25 17:30:15</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c6fae49-e6bd-49f2-98e0-9ea6b99885b6')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5c6fae49-e6bd-49f2-98e0-9ea6b99885b6 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5c6fae49-e6bd-49f2-98e0-9ea6b99885b6');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9859c5a1-dfef-40e3-9f7b-32f0cb8e437d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9859c5a1-dfef-40e3-9f7b-32f0cb8e437d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9859c5a1-dfef-40e3-9f7b-32f0cb8e437d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_23e173fd-39f4-4039-99f0-069e55631cad\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_latest_experiment')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_23e173fd-39f4-4039-99f0-069e55631cad button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df_latest_experiment');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_latest_experiment","repr_error":"0"}},"metadata":{},"execution_count":15}],"source":["# Load the experiment log\n","df = pd.read_csv('experiment_log.csv')\n","\n","# Identify the latest experiment\n","max_id = df['id'].max()\n","\n","# Filter the DataFrame to get the latest experiment\n","df_latest_experiment = df[df['id'] == max_id]\n","\n","# Save the latest experiment log to a CSV file\n","df_latest_experiment.to_csv('phylum_models_results/efficient_net_phylum_1_no_proc_no_reg_history.csv', index=False)\n","\n","df_latest_experiment"]},{"cell_type":"markdown","metadata":{"id":"suwOvIdOyiqf"},"source":["### Base line 2 (without preprocessing and with regularization)"]},{"cell_type":"markdown","metadata":{"id":"LAl_TVzAyiqf"},"source":["#### Set-up"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"0ttlTihlyiqf","executionInfo":{"status":"ok","timestamp":1745625852847,"user_tz":-60,"elapsed":8,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"}}},"outputs":[],"source":["from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"kOS80O1QsbVK","executionInfo":{"status":"ok","timestamp":1745625852848,"user_tz":-60,"elapsed":7,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"}}},"outputs":[],"source":["# Compile with metrics\n","verbose = 1\n","metrics = [\n","    CategoricalAccuracy(name=\"accuracy\"),\n","    AUC(name=\"auc\"),\n","    F1Score(average=\"macro\", name=\"f1_macro\"),\n","    F1Score(average=\"weighted\", name=\"f1_weighted\"),\n","    TopKCategoricalAccuracy(k=5, name=\"top5_accuracy\")\n","]"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"oJpxsqroyiqf","executionInfo":{"status":"ok","timestamp":1745625854473,"user_tz":-60,"elapsed":1624,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"}}},"outputs":[],"source":["# Load datasets\n","train_ds_en_no_proc_reg, family_class_names, phylum_class_names = preprocess.load_img(\n","    train_df,\n","    minority_class=[],\n","    augment=None,\n","    oversampling=False,\n","    shuffle=True,\n","    preprocessing_function=preprocess_input,\n","    family_encoder=family_encoder,\n","    phylum_encoder=phylum_encoder,\n",")\n","\n","val_ds_en_no_proc_reg, _, _ = preprocess.load_img(\n","    val_df,\n","    minority_class=[],\n","    augment=None,\n","    oversampling=False,\n","    shuffle=False,\n","    preprocessing_function=preprocess_input,\n","    family_encoder=family_encoder,\n","    phylum_encoder=phylum_encoder,\n",")"]},{"cell_type":"markdown","metadata":{"id":"ZO4ln1fYyiqf"},"source":["#### Run"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"VgR9dGN3yiqf","executionInfo":{"status":"ok","timestamp":1745625856659,"user_tz":-60,"elapsed":2182,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"}}},"outputs":[],"source":["# Image input pipeline\n","image_input = Input(shape=(224, 224, 3), name=\"image_input\")  # Input for RGB image\n","base_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_tensor=image_input)  # Pretrained EfficientNet without final dense layers\n","\n","# Freeze the base model layers\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Add a global average pooling layer\n","x = GlobalAveragePooling2D()(base_model.output)  # Convert 4D feature map to 2D vector (batch_size, 2048)\n","\n","# Phylum input (one-hot or multi-class vector with 5 classes)\n","phylum_input = Input(shape=(5,), name=\"phylum_input\")  # Input for phylum-level info\n","\n","# Combine image and phylum features\n","combined = Concatenate()([x, phylum_input])  # Concatenate the two inputs: (batch_size, 2048 + 5)\n","combined = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(combined)  # regularization parameter\n","combined = layers.Dropout(0.5)(combined) # regularization layer\n","output = Dense(202, activation='softmax', kernel_regularizer=regularizers.l2(1e-4))(combined)  # Final classification layer (202 family classes)\n","\n","# Define the model\n","model_en_no_proc_reg = Model(inputs=[image_input, phylum_input], outputs=output)\n","\n","# Compile the model\n","model_en_no_proc_reg.compile(\n","    optimizer=optimizers.RMSprop(learning_rate=1e-4),\n","    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.01), # regularization parameter\n","    metrics=metrics\n",")\n","\n","# Print the model summary\n","# model.summary()"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"DmrIM1Moyiqf","executionInfo":{"status":"ok","timestamp":1745625856669,"user_tz":-60,"elapsed":3,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"}}},"outputs":[],"source":["callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j01e77Mvyiqf","outputId":"f4399796-50de-4621-f6c5-707b67375d83"},"outputs":[{"output_type":"stream","name":"stdout","text":["Resuming training from epoch 14 (timestamp 20250425-231537)\n","Epoch 15/50\n","\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 344ms/step - accuracy: 0.6226 - auc: 0.9826 - f1_macro: 0.5276 - f1_weighted: 0.5979 - loss: 1.7101 - top5_accuracy: 0.8769 - val_accuracy: 0.6060 - val_auc: 0.9775 - val_f1_macro: 0.5072 - val_f1_weighted: 0.5677 - val_loss: 1.7790 - val_top5_accuracy: 0.8598\n","Epoch 16/50\n","\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 271ms/step - accuracy: 0.6267 - auc: 0.9844 - f1_macro: 0.5363 - f1_weighted: 0.6039 - loss: 1.6691 - top5_accuracy: 0.8818 - val_accuracy: 0.6194 - val_auc: 0.9790 - val_f1_macro: 0.5340 - val_f1_weighted: 0.5850 - val_loss: 1.7449 - val_top5_accuracy: 0.8625\n","Epoch 17/50\n","\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 267ms/step - accuracy: 0.6429 - auc: 0.9862 - f1_macro: 0.5531 - f1_weighted: 0.6223 - loss: 1.6024 - top5_accuracy: 0.8927 - val_accuracy: 0.6288 - val_auc: 0.9793 - val_f1_macro: 0.5437 - val_f1_weighted: 0.5951 - val_loss: 1.7162 - val_top5_accuracy: 0.8648\n","Epoch 18/50\n","\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 263ms/step - accuracy: 0.6630 - auc: 0.9883 - f1_macro: 0.5829 - f1_weighted: 0.6450 - loss: 1.5680 - top5_accuracy: 0.8973 - val_accuracy: 0.6355 - val_auc: 0.9794 - val_f1_macro: 0.5542 - val_f1_weighted: 0.6047 - val_loss: 1.6893 - val_top5_accuracy: 0.8653\n","Epoch 19/50\n","\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 262ms/step - accuracy: 0.6586 - auc: 0.9883 - f1_macro: 0.5839 - f1_weighted: 0.6410 - loss: 1.5446 - top5_accuracy: 0.8991 - val_accuracy: 0.6422 - val_auc: 0.9799 - val_f1_macro: 0.5620 - val_f1_weighted: 0.6109 - val_loss: 1.6695 - val_top5_accuracy: 0.8692\n","Epoch 20/50\n","\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 263ms/step - accuracy: 0.6787 - auc: 0.9872 - f1_macro: 0.6004 - f1_weighted: 0.6628 - loss: 1.5091 - top5_accuracy: 0.9102 - val_accuracy: 0.6455 - val_auc: 0.9803 - val_f1_macro: 0.5689 - val_f1_weighted: 0.6166 - val_loss: 1.6495 - val_top5_accuracy: 0.8726\n","Epoch 21/50\n","\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 272ms/step - accuracy: 0.6778 - auc: 0.9903 - f1_macro: 0.6082 - f1_weighted: 0.6651 - loss: 1.4700 - top5_accuracy: 0.9176 - val_accuracy: 0.6561 - val_auc: 0.9792 - val_f1_macro: 0.5874 - val_f1_weighted: 0.6313 - val_loss: 1.6339 - val_top5_accuracy: 0.8765\n","Epoch 22/50\n","\u001b[1m104/263\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 297ms/step - accuracy: 0.7034 - auc: 0.9910 - f1_macro: 0.5878 - f1_weighted: 0.6887 - loss: 1.4201 - top5_accuracy: 0.9246"]}],"source":["# Initialize the experiment\n","experiment_en_no_proc_reg = Experiment(\n","    model=model_en_no_proc_reg,\n","    train_ds=train_ds_en_no_proc_reg,\n","    val_ds=val_ds_en_no_proc_reg,\n","    experiment_name=\"eff-net_with_phylum_no_proc_reg\",\n","    resume=True,\n","    steps_per_epoch=263,\n",")\n","\n","# Run the experiment\n","history_en_no_proc_reg = experiment_en_no_proc_reg.run_experiment(callbacks=callbacks, epochs=50)"]},{"cell_type":"markdown","metadata":{"id":"PSeuO9VPsbVQ"},"source":["### Set-up"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"XG_OvmWysbVQ","executionInfo":{"status":"ok","timestamp":1745634461135,"user_tz":-60,"elapsed":42,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"}}},"outputs":[],"source":["from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"JoNBxkEEsbVQ","executionInfo":{"status":"ok","timestamp":1745634461138,"user_tz":-60,"elapsed":2,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"}}},"outputs":[],"source":["verbose = 1\n","metrics = [\n","    CategoricalAccuracy(name=\"accuracy\"),\n","    AUC(name=\"auc\"),\n","    F1Score(average=\"macro\", name=\"f1_macro\"),\n","    F1Score(average=\"weighted\", name=\"f1_weighted\"),\n","    TopKCategoricalAccuracy(k=5, name=\"top5_accuracy\")\n","]\n","\n","initial_lr = 1e-4\n","final_lr = 1e-5\n","n_epochs = 50\n","my_scheduler_fn = lr_scheduler(initial_lr, final_lr, n_epochs)\n","lr_callback = LearningRateScheduler(my_scheduler_fn)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"TrxBDwMGsbVQ","executionInfo":{"status":"ok","timestamp":1745634463475,"user_tz":-60,"elapsed":2336,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"}}},"outputs":[],"source":["# Load datasets\n","train_ds_en_pre_ft, family_class_names, phylum_class_names = preprocess.load_img(\n","    train_df,\n","    minority_class=minority_class,\n","    augment='mixup',\n","    oversampling=True,\n","    shuffle=True,\n","    preprocessing_function=preprocess_input,\n","    family_encoder=family_encoder,\n","    phylum_encoder=phylum_encoder,\n",")\n","\n","val_ds_en_pre_ft, _, _ = preprocess.load_img(\n","    val_df,\n","    minority_class=[],\n","    augment=None,\n","    oversampling=False,\n","    shuffle=False,\n","    preprocessing_function=preprocess_input,\n","    family_encoder=family_encoder,\n","    phylum_encoder=phylum_encoder,\n",")"]},{"cell_type":"markdown","metadata":{"id":"2YP5_njOsbVQ"},"source":["### Head Train"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"0ReT_sOMsbVQ","executionInfo":{"status":"ok","timestamp":1745634465628,"user_tz":-60,"elapsed":2147,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"}}},"outputs":[],"source":["# Image input pipeline\n","image_input = Input(shape=(224, 224, 3), name=\"image_input\")  # Input for RGB image\n","base_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_tensor=image_input)  # Pretrained EfficientNet without final dense layers\n","\n","# Freeze the base model layers\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Add a global average pooling layer\n","x = GlobalAveragePooling2D()(base_model.output)  # Convert 4D feature map to 2D vector (batch_size, 2048)\n","\n","# Phylum input (one-hot or multi-class vector with 5 classes)\n","phylum_input = Input(shape=(5,), name=\"phylum_input\")  # Input for phylum-level info\n","\n","# Combine image and phylum features\n","combined = Concatenate()([x, phylum_input])  # Concatenate the two inputs: (batch_size, 2048 + 5)\n","combined = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(combined)  # regularization parameter\n","combined = layers.Dropout(0.5)(combined) # regularization layer\n","output = Dense(202, activation='softmax', kernel_regularizer=regularizers.l2(1e-4))(combined)  # Final classification layer (202 family classes)\n","\n","# Define the model\n","model_en_pre_ft = Model(inputs=[image_input, phylum_input], outputs=output)\n","\n","# Compile the model\n","model_en_pre_ft.compile(\n","    optimizer=optimizers.RMSprop(learning_rate=1e-4),\n","    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.01), # regularization parameter\n","    metrics=metrics\n",")\n","\n","# Print the model summary\n","# model.summary()"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"1DaAHdBIsbVQ","executionInfo":{"status":"ok","timestamp":1745634465636,"user_tz":-60,"elapsed":4,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"}}},"outputs":[],"source":["callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n","    lr_callback\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ImJ6t1mTsbVR","outputId":"dd4119c4-b6f4-412c-9410-c4cc8a8c2c9e","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Resuming training from epoch 28 (timestamp 20250426-021318)\n","Epoch 29/50\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 257ms/step - accuracy: 0.7044 - auc: 0.9896 - f1_macro: 0.6684 - f1_weighted: 0.6979 - loss: 1.4654 - top5_accuracy: 0.9143 - val_accuracy: 0.6711 - val_auc: 0.9819 - val_f1_macro: 0.6225 - val_f1_weighted: 0.6520 - val_loss: 1.6119 - val_top5_accuracy: 0.8815 - learning_rate: 2.6303e-05\n","Epoch 30/50\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 200ms/step - accuracy: 0.6930 - auc: 0.9893 - f1_macro: 0.6584 - f1_weighted: 0.6870 - loss: 1.4813 - top5_accuracy: 0.9156 - val_accuracy: 0.6745 - val_auc: 0.9819 - val_f1_macro: 0.6298 - val_f1_weighted: 0.6565 - val_loss: 1.6084 - val_top5_accuracy: 0.8843 - learning_rate: 2.5119e-05\n","Epoch 31/50\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 202ms/step - accuracy: 0.7052 - auc: 0.9888 - f1_macro: 0.6710 - f1_weighted: 0.6999 - loss: 1.4603 - top5_accuracy: 0.9149 - val_accuracy: 0.6767 - val_auc: 0.9820 - val_f1_macro: 0.6334 - val_f1_weighted: 0.6585 - val_loss: 1.6036 - val_top5_accuracy: 0.8843 - learning_rate: 2.3988e-05\n","Epoch 32/50\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 212ms/step - accuracy: 0.6965 - auc: 0.9903 - f1_macro: 0.6594 - f1_weighted: 0.6924 - loss: 1.4576 - top5_accuracy: 0.9153 - val_accuracy: 0.6789 - val_auc: 0.9820 - val_f1_macro: 0.6362 - val_f1_weighted: 0.6611 - val_loss: 1.5997 - val_top5_accuracy: 0.8837 - learning_rate: 2.2909e-05\n","Epoch 33/50\n","\u001b[1m 34/350\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 173ms/step - accuracy: 0.6661 - auc: 0.9891 - f1_macro: 0.4428 - f1_weighted: 0.6597 - loss: 1.5872 - top5_accuracy: 0.8915"]}],"source":["# Initialize the experiment\n","experiment_en_pre_ft = Experiment(\n","    model=model_en_pre_ft,\n","    train_ds=train_ds_en_pre_ft,\n","    val_ds=val_ds_en_pre_ft,\n","    experiment_name=\"eff-net_with_phylum_pre-ft\",\n","    resume=True,\n","    steps_per_epoch=350,\n",")\n","\n","# Run the experiment\n","history_en_pre_ft = experiment_en_pre_ft.run_experiment(callbacks=callbacks, epochs=50)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"46Q71mMVsbVR","outputId":"61a76eee-e149-4499-fd60-f865a3c5bbf3","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1745634530310,"user_tz":-60,"elapsed":86,"user":{"displayName":"Marco Galão","userId":"08018044528075081454"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     id             experiment_name  epoch  train_accuracy  val_accuracy  \\\n","400  18  eff-net_with_phylum_pre-ft      1          0.0672        0.2026   \n","401  18  eff-net_with_phylum_pre-ft      2          0.1718        0.2627   \n","402  18  eff-net_with_phylum_pre-ft      3          0.2352        0.3306   \n","403  18  eff-net_with_phylum_pre-ft      4          0.2933        0.3934   \n","404  18  eff-net_with_phylum_pre-ft      5          0.3582        0.4591   \n","405  18  eff-net_with_phylum_pre-ft      6          0.4065        0.5019   \n","406  18  eff-net_with_phylum_pre-ft      7          0.4481        0.5337   \n","407  18  eff-net_with_phylum_pre-ft      8          0.4816        0.5548   \n","408  18  eff-net_with_phylum_pre-ft      9          0.5068        0.5743   \n","409  18  eff-net_with_phylum_pre-ft     10          0.5304        0.5871   \n","410  18  eff-net_with_phylum_pre-ft     11          0.5571        0.6004   \n","411  18  eff-net_with_phylum_pre-ft     12          0.5684        0.6093   \n","412  18  eff-net_with_phylum_pre-ft     13          0.5821        0.6110   \n","413  18  eff-net_with_phylum_pre-ft     14          0.5904        0.6188   \n","414  18  eff-net_with_phylum_pre-ft     15          0.6074        0.6227   \n","415  18  eff-net_with_phylum_pre-ft     16          0.6158        0.6294   \n","416  18  eff-net_with_phylum_pre-ft     17          0.6190        0.6322   \n","417  18  eff-net_with_phylum_pre-ft     18          0.6288        0.6377   \n","418  18  eff-net_with_phylum_pre-ft     19          0.6358        0.6427   \n","419  18  eff-net_with_phylum_pre-ft     20          0.6404        0.6444   \n","420  18  eff-net_with_phylum_pre-ft     21          0.6534        0.6528   \n","421  18  eff-net_with_phylum_pre-ft     22          0.6571        0.6572   \n","422  18  eff-net_with_phylum_pre-ft     23          0.6604        0.6578   \n","423  18  eff-net_with_phylum_pre-ft     24          0.6651        0.6617   \n","424  18  eff-net_with_phylum_pre-ft     25          0.6734        0.6672   \n","425  18  eff-net_with_phylum_pre-ft     26          0.6766        0.6678   \n","426  18  eff-net_with_phylum_pre-ft     27          0.6781        0.6683   \n","427  18  eff-net_with_phylum_pre-ft     28          0.6796        0.6706   \n","428  18  eff-net_with_phylum_pre-ft     29          0.6930        0.6711   \n","429  18  eff-net_with_phylum_pre-ft     30          0.6923        0.6745   \n","430  18  eff-net_with_phylum_pre-ft     31          0.7001        0.6767   \n","431  18  eff-net_with_phylum_pre-ft     32          0.6969        0.6789   \n","\n","     train_loss  val_loss  f1_train_macro  f1_val_macro  f1_train_weighted  \\\n","400      5.1371    4.6038          0.0261        0.0572             0.0490   \n","401      4.4422    3.8899          0.0696        0.0926             0.1050   \n","402      3.8712    3.3727          0.1263        0.1675             0.1637   \n","403      3.4293    2.9754          0.1982        0.2441             0.2310   \n","404      3.0522    2.6714          0.2791        0.3383             0.3077   \n","405      2.7715    2.4426          0.3478        0.3976             0.3684   \n","406      2.5524    2.2706          0.4034        0.4404             0.4191   \n","407      2.3701    2.1388          0.4432        0.4734             0.4558   \n","408      2.2208    2.0428          0.4719        0.5005             0.4837   \n","409      2.1190    1.9668          0.5054        0.5188             0.5129   \n","410      2.0225    1.9070          0.5345        0.5330             0.5413   \n","411      1.9659    1.8614          0.5460        0.5478             0.5531   \n","412      1.8907    1.8233          0.5656        0.5501             0.5701   \n","413      1.8550    1.7917          0.5732        0.5590             0.5786   \n","414      1.8025    1.7637          0.5908        0.5648             0.5959   \n","415      1.7640    1.7420          0.6033        0.5696             0.6057   \n","416      1.7323    1.7220          0.6077        0.5736             0.6099   \n","417      1.6908    1.7056          0.6180        0.5838             0.6204   \n","418      1.6648    1.6908          0.6269        0.5881             0.6283   \n","419      1.6488    1.6795          0.6323        0.5909             0.6320   \n","420      1.6160    1.6675          0.6465        0.6017             0.6463   \n","421      1.6022    1.6573          0.6512        0.6056             0.6508   \n","422      1.5757    1.6477          0.6549        0.6079             0.6541   \n","423      1.5649    1.6399          0.6596        0.6124             0.6589   \n","424      1.5400    1.6338          0.6674        0.6191             0.6681   \n","425      1.5390    1.6280          0.6700        0.6216             0.6704   \n","426      1.5208    1.6213          0.6767        0.6213             0.6720   \n","427      1.5122    1.6168          0.6757        0.6234             0.6749   \n","428      1.4941    1.6119          0.6882        0.6225             0.6868   \n","429      1.4902    1.6084          0.6894        0.6298             0.6870   \n","430      1.4634    1.6036          0.6978        0.6334             0.6954   \n","431      1.4695    1.5997          0.6948        0.6362             0.6927   \n","\n","     f1_val_weighted  top5_train_accuracy  top5_val_accuracy  \\\n","400           0.1212               0.1567             0.3728   \n","401           0.1650               0.3427             0.5109   \n","402           0.2395               0.4771             0.6388   \n","403           0.3128               0.5908             0.7201   \n","404           0.3946               0.6635             0.7702   \n","405           0.4444               0.7187             0.7963   \n","406           0.4830               0.7552             0.8152   \n","407           0.5108               0.7865             0.8253   \n","408           0.5333               0.8090             0.8325   \n","409           0.5517               0.8233             0.8381   \n","410           0.5677               0.8361             0.8475   \n","411           0.5788               0.8461             0.8509   \n","412           0.5807               0.8557             0.8536   \n","413           0.5898               0.8587             0.8575   \n","414           0.5951               0.8628             0.8637   \n","415           0.6015               0.8744             0.8676   \n","416           0.6060               0.8763             0.8687   \n","417           0.6136               0.8843             0.8698   \n","418           0.6186               0.8871             0.8742   \n","419           0.6206               0.8918             0.8748   \n","420           0.6310               0.8966             0.8753   \n","421           0.6347               0.8959             0.8792   \n","422           0.6359               0.9025             0.8809   \n","423           0.6403               0.9031             0.8820   \n","424           0.6466               0.9057             0.8809   \n","425           0.6482               0.9059             0.8815   \n","426           0.6489               0.9105             0.8804   \n","427           0.6514               0.9104             0.8804   \n","428           0.6520               0.9137             0.8815   \n","429           0.6565               0.9142             0.8843   \n","430           0.6585               0.9161             0.8843   \n","431           0.6611               0.9140             0.8837   \n","\n","               timestamp  \n","400  2025-04-26 00:13:07  \n","401  2025-04-26 00:14:19  \n","402  2025-04-26 00:15:30  \n","403  2025-04-26 00:16:45  \n","404  2025-04-26 00:26:13  \n","405  2025-04-26 00:27:25  \n","406  2025-04-26 00:28:36  \n","407  2025-04-26 00:29:51  \n","408  2025-04-26 00:36:55  \n","409  2025-04-26 00:38:07  \n","410  2025-04-26 00:39:18  \n","411  2025-04-26 00:40:33  \n","412  2025-04-26 00:46:46  \n","413  2025-04-26 00:47:56  \n","414  2025-04-26 00:49:06  \n","415  2025-04-26 00:50:19  \n","416  2025-04-26 00:55:00  \n","417  2025-04-26 00:56:12  \n","418  2025-04-26 00:57:23  \n","419  2025-04-26 00:58:36  \n","420  2025-04-26 01:13:16  \n","421  2025-04-26 01:14:26  \n","422  2025-04-26 01:15:36  \n","423  2025-04-26 01:16:47  \n","424  2025-04-26 02:09:45  \n","425  2025-04-26 02:10:55  \n","426  2025-04-26 02:12:04  \n","427  2025-04-26 02:13:18  \n","428  2025-04-26 02:20:08  \n","429  2025-04-26 02:21:18  \n","430  2025-04-26 02:22:28  \n","431  2025-04-26 02:23:42  "],"text/html":["\n","  <div id=\"df-d88f22d9-f774-4a7c-a956-a4a9d459a7c5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>experiment_name</th>\n","      <th>epoch</th>\n","      <th>train_accuracy</th>\n","      <th>val_accuracy</th>\n","      <th>train_loss</th>\n","      <th>val_loss</th>\n","      <th>f1_train_macro</th>\n","      <th>f1_val_macro</th>\n","      <th>f1_train_weighted</th>\n","      <th>f1_val_weighted</th>\n","      <th>top5_train_accuracy</th>\n","      <th>top5_val_accuracy</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>400</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>1</td>\n","      <td>0.0672</td>\n","      <td>0.2026</td>\n","      <td>5.1371</td>\n","      <td>4.6038</td>\n","      <td>0.0261</td>\n","      <td>0.0572</td>\n","      <td>0.0490</td>\n","      <td>0.1212</td>\n","      <td>0.1567</td>\n","      <td>0.3728</td>\n","      <td>2025-04-26 00:13:07</td>\n","    </tr>\n","    <tr>\n","      <th>401</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>2</td>\n","      <td>0.1718</td>\n","      <td>0.2627</td>\n","      <td>4.4422</td>\n","      <td>3.8899</td>\n","      <td>0.0696</td>\n","      <td>0.0926</td>\n","      <td>0.1050</td>\n","      <td>0.1650</td>\n","      <td>0.3427</td>\n","      <td>0.5109</td>\n","      <td>2025-04-26 00:14:19</td>\n","    </tr>\n","    <tr>\n","      <th>402</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>3</td>\n","      <td>0.2352</td>\n","      <td>0.3306</td>\n","      <td>3.8712</td>\n","      <td>3.3727</td>\n","      <td>0.1263</td>\n","      <td>0.1675</td>\n","      <td>0.1637</td>\n","      <td>0.2395</td>\n","      <td>0.4771</td>\n","      <td>0.6388</td>\n","      <td>2025-04-26 00:15:30</td>\n","    </tr>\n","    <tr>\n","      <th>403</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>4</td>\n","      <td>0.2933</td>\n","      <td>0.3934</td>\n","      <td>3.4293</td>\n","      <td>2.9754</td>\n","      <td>0.1982</td>\n","      <td>0.2441</td>\n","      <td>0.2310</td>\n","      <td>0.3128</td>\n","      <td>0.5908</td>\n","      <td>0.7201</td>\n","      <td>2025-04-26 00:16:45</td>\n","    </tr>\n","    <tr>\n","      <th>404</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>5</td>\n","      <td>0.3582</td>\n","      <td>0.4591</td>\n","      <td>3.0522</td>\n","      <td>2.6714</td>\n","      <td>0.2791</td>\n","      <td>0.3383</td>\n","      <td>0.3077</td>\n","      <td>0.3946</td>\n","      <td>0.6635</td>\n","      <td>0.7702</td>\n","      <td>2025-04-26 00:26:13</td>\n","    </tr>\n","    <tr>\n","      <th>405</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>6</td>\n","      <td>0.4065</td>\n","      <td>0.5019</td>\n","      <td>2.7715</td>\n","      <td>2.4426</td>\n","      <td>0.3478</td>\n","      <td>0.3976</td>\n","      <td>0.3684</td>\n","      <td>0.4444</td>\n","      <td>0.7187</td>\n","      <td>0.7963</td>\n","      <td>2025-04-26 00:27:25</td>\n","    </tr>\n","    <tr>\n","      <th>406</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>7</td>\n","      <td>0.4481</td>\n","      <td>0.5337</td>\n","      <td>2.5524</td>\n","      <td>2.2706</td>\n","      <td>0.4034</td>\n","      <td>0.4404</td>\n","      <td>0.4191</td>\n","      <td>0.4830</td>\n","      <td>0.7552</td>\n","      <td>0.8152</td>\n","      <td>2025-04-26 00:28:36</td>\n","    </tr>\n","    <tr>\n","      <th>407</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>8</td>\n","      <td>0.4816</td>\n","      <td>0.5548</td>\n","      <td>2.3701</td>\n","      <td>2.1388</td>\n","      <td>0.4432</td>\n","      <td>0.4734</td>\n","      <td>0.4558</td>\n","      <td>0.5108</td>\n","      <td>0.7865</td>\n","      <td>0.8253</td>\n","      <td>2025-04-26 00:29:51</td>\n","    </tr>\n","    <tr>\n","      <th>408</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>9</td>\n","      <td>0.5068</td>\n","      <td>0.5743</td>\n","      <td>2.2208</td>\n","      <td>2.0428</td>\n","      <td>0.4719</td>\n","      <td>0.5005</td>\n","      <td>0.4837</td>\n","      <td>0.5333</td>\n","      <td>0.8090</td>\n","      <td>0.8325</td>\n","      <td>2025-04-26 00:36:55</td>\n","    </tr>\n","    <tr>\n","      <th>409</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>10</td>\n","      <td>0.5304</td>\n","      <td>0.5871</td>\n","      <td>2.1190</td>\n","      <td>1.9668</td>\n","      <td>0.5054</td>\n","      <td>0.5188</td>\n","      <td>0.5129</td>\n","      <td>0.5517</td>\n","      <td>0.8233</td>\n","      <td>0.8381</td>\n","      <td>2025-04-26 00:38:07</td>\n","    </tr>\n","    <tr>\n","      <th>410</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>11</td>\n","      <td>0.5571</td>\n","      <td>0.6004</td>\n","      <td>2.0225</td>\n","      <td>1.9070</td>\n","      <td>0.5345</td>\n","      <td>0.5330</td>\n","      <td>0.5413</td>\n","      <td>0.5677</td>\n","      <td>0.8361</td>\n","      <td>0.8475</td>\n","      <td>2025-04-26 00:39:18</td>\n","    </tr>\n","    <tr>\n","      <th>411</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>12</td>\n","      <td>0.5684</td>\n","      <td>0.6093</td>\n","      <td>1.9659</td>\n","      <td>1.8614</td>\n","      <td>0.5460</td>\n","      <td>0.5478</td>\n","      <td>0.5531</td>\n","      <td>0.5788</td>\n","      <td>0.8461</td>\n","      <td>0.8509</td>\n","      <td>2025-04-26 00:40:33</td>\n","    </tr>\n","    <tr>\n","      <th>412</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>13</td>\n","      <td>0.5821</td>\n","      <td>0.6110</td>\n","      <td>1.8907</td>\n","      <td>1.8233</td>\n","      <td>0.5656</td>\n","      <td>0.5501</td>\n","      <td>0.5701</td>\n","      <td>0.5807</td>\n","      <td>0.8557</td>\n","      <td>0.8536</td>\n","      <td>2025-04-26 00:46:46</td>\n","    </tr>\n","    <tr>\n","      <th>413</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>14</td>\n","      <td>0.5904</td>\n","      <td>0.6188</td>\n","      <td>1.8550</td>\n","      <td>1.7917</td>\n","      <td>0.5732</td>\n","      <td>0.5590</td>\n","      <td>0.5786</td>\n","      <td>0.5898</td>\n","      <td>0.8587</td>\n","      <td>0.8575</td>\n","      <td>2025-04-26 00:47:56</td>\n","    </tr>\n","    <tr>\n","      <th>414</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>15</td>\n","      <td>0.6074</td>\n","      <td>0.6227</td>\n","      <td>1.8025</td>\n","      <td>1.7637</td>\n","      <td>0.5908</td>\n","      <td>0.5648</td>\n","      <td>0.5959</td>\n","      <td>0.5951</td>\n","      <td>0.8628</td>\n","      <td>0.8637</td>\n","      <td>2025-04-26 00:49:06</td>\n","    </tr>\n","    <tr>\n","      <th>415</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>16</td>\n","      <td>0.6158</td>\n","      <td>0.6294</td>\n","      <td>1.7640</td>\n","      <td>1.7420</td>\n","      <td>0.6033</td>\n","      <td>0.5696</td>\n","      <td>0.6057</td>\n","      <td>0.6015</td>\n","      <td>0.8744</td>\n","      <td>0.8676</td>\n","      <td>2025-04-26 00:50:19</td>\n","    </tr>\n","    <tr>\n","      <th>416</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>17</td>\n","      <td>0.6190</td>\n","      <td>0.6322</td>\n","      <td>1.7323</td>\n","      <td>1.7220</td>\n","      <td>0.6077</td>\n","      <td>0.5736</td>\n","      <td>0.6099</td>\n","      <td>0.6060</td>\n","      <td>0.8763</td>\n","      <td>0.8687</td>\n","      <td>2025-04-26 00:55:00</td>\n","    </tr>\n","    <tr>\n","      <th>417</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>18</td>\n","      <td>0.6288</td>\n","      <td>0.6377</td>\n","      <td>1.6908</td>\n","      <td>1.7056</td>\n","      <td>0.6180</td>\n","      <td>0.5838</td>\n","      <td>0.6204</td>\n","      <td>0.6136</td>\n","      <td>0.8843</td>\n","      <td>0.8698</td>\n","      <td>2025-04-26 00:56:12</td>\n","    </tr>\n","    <tr>\n","      <th>418</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>19</td>\n","      <td>0.6358</td>\n","      <td>0.6427</td>\n","      <td>1.6648</td>\n","      <td>1.6908</td>\n","      <td>0.6269</td>\n","      <td>0.5881</td>\n","      <td>0.6283</td>\n","      <td>0.6186</td>\n","      <td>0.8871</td>\n","      <td>0.8742</td>\n","      <td>2025-04-26 00:57:23</td>\n","    </tr>\n","    <tr>\n","      <th>419</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>20</td>\n","      <td>0.6404</td>\n","      <td>0.6444</td>\n","      <td>1.6488</td>\n","      <td>1.6795</td>\n","      <td>0.6323</td>\n","      <td>0.5909</td>\n","      <td>0.6320</td>\n","      <td>0.6206</td>\n","      <td>0.8918</td>\n","      <td>0.8748</td>\n","      <td>2025-04-26 00:58:36</td>\n","    </tr>\n","    <tr>\n","      <th>420</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>21</td>\n","      <td>0.6534</td>\n","      <td>0.6528</td>\n","      <td>1.6160</td>\n","      <td>1.6675</td>\n","      <td>0.6465</td>\n","      <td>0.6017</td>\n","      <td>0.6463</td>\n","      <td>0.6310</td>\n","      <td>0.8966</td>\n","      <td>0.8753</td>\n","      <td>2025-04-26 01:13:16</td>\n","    </tr>\n","    <tr>\n","      <th>421</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>22</td>\n","      <td>0.6571</td>\n","      <td>0.6572</td>\n","      <td>1.6022</td>\n","      <td>1.6573</td>\n","      <td>0.6512</td>\n","      <td>0.6056</td>\n","      <td>0.6508</td>\n","      <td>0.6347</td>\n","      <td>0.8959</td>\n","      <td>0.8792</td>\n","      <td>2025-04-26 01:14:26</td>\n","    </tr>\n","    <tr>\n","      <th>422</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>23</td>\n","      <td>0.6604</td>\n","      <td>0.6578</td>\n","      <td>1.5757</td>\n","      <td>1.6477</td>\n","      <td>0.6549</td>\n","      <td>0.6079</td>\n","      <td>0.6541</td>\n","      <td>0.6359</td>\n","      <td>0.9025</td>\n","      <td>0.8809</td>\n","      <td>2025-04-26 01:15:36</td>\n","    </tr>\n","    <tr>\n","      <th>423</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>24</td>\n","      <td>0.6651</td>\n","      <td>0.6617</td>\n","      <td>1.5649</td>\n","      <td>1.6399</td>\n","      <td>0.6596</td>\n","      <td>0.6124</td>\n","      <td>0.6589</td>\n","      <td>0.6403</td>\n","      <td>0.9031</td>\n","      <td>0.8820</td>\n","      <td>2025-04-26 01:16:47</td>\n","    </tr>\n","    <tr>\n","      <th>424</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>25</td>\n","      <td>0.6734</td>\n","      <td>0.6672</td>\n","      <td>1.5400</td>\n","      <td>1.6338</td>\n","      <td>0.6674</td>\n","      <td>0.6191</td>\n","      <td>0.6681</td>\n","      <td>0.6466</td>\n","      <td>0.9057</td>\n","      <td>0.8809</td>\n","      <td>2025-04-26 02:09:45</td>\n","    </tr>\n","    <tr>\n","      <th>425</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>26</td>\n","      <td>0.6766</td>\n","      <td>0.6678</td>\n","      <td>1.5390</td>\n","      <td>1.6280</td>\n","      <td>0.6700</td>\n","      <td>0.6216</td>\n","      <td>0.6704</td>\n","      <td>0.6482</td>\n","      <td>0.9059</td>\n","      <td>0.8815</td>\n","      <td>2025-04-26 02:10:55</td>\n","    </tr>\n","    <tr>\n","      <th>426</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>27</td>\n","      <td>0.6781</td>\n","      <td>0.6683</td>\n","      <td>1.5208</td>\n","      <td>1.6213</td>\n","      <td>0.6767</td>\n","      <td>0.6213</td>\n","      <td>0.6720</td>\n","      <td>0.6489</td>\n","      <td>0.9105</td>\n","      <td>0.8804</td>\n","      <td>2025-04-26 02:12:04</td>\n","    </tr>\n","    <tr>\n","      <th>427</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>28</td>\n","      <td>0.6796</td>\n","      <td>0.6706</td>\n","      <td>1.5122</td>\n","      <td>1.6168</td>\n","      <td>0.6757</td>\n","      <td>0.6234</td>\n","      <td>0.6749</td>\n","      <td>0.6514</td>\n","      <td>0.9104</td>\n","      <td>0.8804</td>\n","      <td>2025-04-26 02:13:18</td>\n","    </tr>\n","    <tr>\n","      <th>428</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>29</td>\n","      <td>0.6930</td>\n","      <td>0.6711</td>\n","      <td>1.4941</td>\n","      <td>1.6119</td>\n","      <td>0.6882</td>\n","      <td>0.6225</td>\n","      <td>0.6868</td>\n","      <td>0.6520</td>\n","      <td>0.9137</td>\n","      <td>0.8815</td>\n","      <td>2025-04-26 02:20:08</td>\n","    </tr>\n","    <tr>\n","      <th>429</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>30</td>\n","      <td>0.6923</td>\n","      <td>0.6745</td>\n","      <td>1.4902</td>\n","      <td>1.6084</td>\n","      <td>0.6894</td>\n","      <td>0.6298</td>\n","      <td>0.6870</td>\n","      <td>0.6565</td>\n","      <td>0.9142</td>\n","      <td>0.8843</td>\n","      <td>2025-04-26 02:21:18</td>\n","    </tr>\n","    <tr>\n","      <th>430</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>31</td>\n","      <td>0.7001</td>\n","      <td>0.6767</td>\n","      <td>1.4634</td>\n","      <td>1.6036</td>\n","      <td>0.6978</td>\n","      <td>0.6334</td>\n","      <td>0.6954</td>\n","      <td>0.6585</td>\n","      <td>0.9161</td>\n","      <td>0.8843</td>\n","      <td>2025-04-26 02:22:28</td>\n","    </tr>\n","    <tr>\n","      <th>431</th>\n","      <td>18</td>\n","      <td>eff-net_with_phylum_pre-ft</td>\n","      <td>32</td>\n","      <td>0.6969</td>\n","      <td>0.6789</td>\n","      <td>1.4695</td>\n","      <td>1.5997</td>\n","      <td>0.6948</td>\n","      <td>0.6362</td>\n","      <td>0.6927</td>\n","      <td>0.6611</td>\n","      <td>0.9140</td>\n","      <td>0.8837</td>\n","      <td>2025-04-26 02:23:42</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d88f22d9-f774-4a7c-a956-a4a9d459a7c5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d88f22d9-f774-4a7c-a956-a4a9d459a7c5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d88f22d9-f774-4a7c-a956-a4a9d459a7c5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-5d5cdf07-225c-482c-97e2-de643ecbcd56\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5d5cdf07-225c-482c-97e2-de643ecbcd56')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-5d5cdf07-225c-482c-97e2-de643ecbcd56 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_cbe2a188-287d-4b85-ada0-d6d01cbf03ed\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_latest_experiment')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_cbe2a188-287d-4b85-ada0-d6d01cbf03ed button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df_latest_experiment');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_latest_experiment","repr_error":"0"}},"metadata":{},"execution_count":20}],"source":["# Load the experiment log\n","df = pd.read_csv('experiment_log.csv')\n","\n","# Identify the latest experiment\n","max_id = df['id'].max()\n","\n","# Filter the DataFrame to get the latest experiment\n","df_latest_experiment = df[df['id'] == max_id]\n","\n","# Save the latest experiment log to a CSV file\n","#df_latest_experiment.to_csv('phylum_models_results/efficient_net_phylum_3_pre_ft_history.csv', index=False)\n","\n","df_latest_experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KG6bULndsbVR"},"outputs":[],"source":["# acc_train_en = history_en.history['acc']\n","# acc_val_en = history_en.history['val_acc']\n","# plot_model_acc(num_epochs=50, train_acc=acc_train_en, val_acc=acc_val_en)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_3Ntap5KsbVR"},"outputs":[],"source":["# loss_train_en = history_en.history['loss']\n","# loss_val_en = history_en.history['val_loss']\n","# plot_model_loss(num_epochs=50, train_loss=loss_train_en, val_loss=loss_val_en)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zEi3UX2msbVR"},"outputs":[],"source":["# x_axis = range(1,50+1)\n","# plt.plot(x_axis, history_en.history['f1_score'], 'r', label='Training F1-Score')\n","# plt.plot(x_axis, history_en.history['val_f1_score'], 'g', label='Validation F1-Score')\n","# plt.title('Training and Validation F1-Score')\n","# plt.xlabel('Epochs')\n","# plt.ylabel('F1-Score')\n","# plt.legend()\n","# plt.show()"]},{"cell_type":"markdown","metadata":{"id":"YdF4jHxvsbVR"},"source":["### Fine-tune"]},{"cell_type":"markdown","metadata":{"id":"WFxO62SrsbVR"},"source":["References: https://www.tensorflow.org/tutorials/keras/keras_tuner?hl=pt-br\n","\n","\"When fine-tuning a pre-trained model that contains BatchNormalization layers, it is usually a good idea to keep them frozen (i.e., set layer.trainable = False), to avoid corrupting the running statistics that the layers have learned.\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"60Dmybb9sbVR"},"outputs":[],"source":["model_en_ft = load_model(\"eff-net_with_phylum_pre-ft_20250425-121418.keras\", compile=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5kM5_E3VsbVR"},"outputs":[],"source":["verbose = 1\n","metrics = [\n","    CategoricalAccuracy(name=\"accuracy\"),\n","    AUC(name=\"auc\"),\n","    F1Score(average=\"macro\", name=\"f1_macro\"),\n","    F1Score(average=\"weighted\", name=\"f1_weighted\"),\n","    TopKCategoricalAccuracy(k=5, name=\"top5_accuracy\")\n","]\n","\n","initial_lr = 1e-5\n","final_lr = 1e-6\n","n_epochs = 100\n","my_scheduler_fn = lr_scheduler(initial_lr, final_lr, n_epochs)\n","lr_callback = LearningRateScheduler(my_scheduler_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sW3uplUMsbVR"},"outputs":[],"source":["progressive_unfreeze = ProgressiveUnfreeze(model_en_ft) # class define in classes file\n","\n","model_en_ft.compile(\n","    optimizer=optimizers.RMSprop(learning_rate=1e-5),\n","    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.01),\n","    metrics=metrics\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2jOjFvsEsbVR","outputId":"46ecfd3a-f590-406b-8669-d6d0dbc7dfc4"},"outputs":[{"name":"stdout","output_type":"stream","text":["No checkpoint found, starting from scratch.\n","Epoch 1/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - acc: 0.7133 - auc: 0.9891 - f1_score: 0.6941 - loss: 1.4267Epoch 0: Layer now unfrozen 241 (dense_7)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 306ms/step - acc: 0.7133 - auc: 0.9891 - f1_score: 0.6942 - loss: 1.4267 - val_acc: 0.6867 - val_auc: 0.9801 - val_f1_score: 0.6611 - val_loss: 1.5418 - learning_rate: 9.7724e-06\n","Epoch 2/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 296ms/step - acc: 0.7269 - auc: 0.9894 - f1_score: 0.7065 - loss: 1.4045 - val_acc: 0.6878 - val_auc: 0.9801 - val_f1_score: 0.6624 - val_loss: 1.5405 - learning_rate: 9.5499e-06\n","Epoch 3/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - acc: 0.7130 - auc: 0.9893 - f1_score: 0.6895 - loss: 1.4263Epoch 2: Layer now unfrozen 240 (dropout_3)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 286ms/step - acc: 0.7130 - auc: 0.9893 - f1_score: 0.6896 - loss: 1.4262 - val_acc: 0.6889 - val_auc: 0.9799 - val_f1_score: 0.6628 - val_loss: 1.5397 - learning_rate: 9.3325e-06\n","Epoch 4/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 302ms/step - acc: 0.7134 - auc: 0.9885 - f1_score: 0.6935 - loss: 1.4326 - val_acc: 0.6895 - val_auc: 0.9802 - val_f1_score: 0.6639 - val_loss: 1.5383 - learning_rate: 9.1201e-06\n","Epoch 5/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - acc: 0.7122 - auc: 0.9875 - f1_score: 0.6929 - loss: 1.4220Epoch 4: Layer now unfrozen 239 (dense_6)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 293ms/step - acc: 0.7122 - auc: 0.9875 - f1_score: 0.6930 - loss: 1.4220 - val_acc: 0.6895 - val_auc: 0.9799 - val_f1_score: 0.6638 - val_loss: 1.5374 - learning_rate: 8.9125e-06\n","Epoch 6/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 292ms/step - acc: 0.7197 - auc: 0.9897 - f1_score: 0.6997 - loss: 1.4029 - val_acc: 0.6906 - val_auc: 0.9802 - val_f1_score: 0.6650 - val_loss: 1.5364 - learning_rate: 8.7096e-06\n","Epoch 7/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - acc: 0.7156 - auc: 0.9895 - f1_score: 0.6932 - loss: 1.4226Epoch 6: Layer now unfrozen 238 (global_average_pooling2d_3)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 308ms/step - acc: 0.7156 - auc: 0.9895 - f1_score: 0.6933 - loss: 1.4226 - val_acc: 0.6912 - val_auc: 0.9802 - val_f1_score: 0.6656 - val_loss: 1.5355 - learning_rate: 8.5114e-06\n","Epoch 8/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 301ms/step - acc: 0.7162 - auc: 0.9894 - f1_score: 0.6951 - loss: 1.4178 - val_acc: 0.6923 - val_auc: 0.9802 - val_f1_score: 0.6673 - val_loss: 1.5351 - learning_rate: 8.3176e-06\n","Epoch 9/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - acc: 0.7191 - auc: 0.9892 - f1_score: 0.6951 - loss: 1.4166Epoch 8: Layer now unfrozen 237 (top_activation)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 302ms/step - acc: 0.7191 - auc: 0.9892 - f1_score: 0.6952 - loss: 1.4166 - val_acc: 0.6923 - val_auc: 0.9802 - val_f1_score: 0.6674 - val_loss: 1.5345 - learning_rate: 8.1283e-06\n","Epoch 10/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 321ms/step - acc: 0.7087 - auc: 0.9887 - f1_score: 0.6902 - loss: 1.4292 - val_acc: 0.6923 - val_auc: 0.9802 - val_f1_score: 0.6669 - val_loss: 1.5341 - learning_rate: 7.9433e-06\n","Epoch 11/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - acc: 0.7182 - auc: 0.9899 - f1_score: 0.6981 - loss: 1.4064Epoch 10: Layer now unfrozen 235 (top_conv)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 320ms/step - acc: 0.7183 - auc: 0.9899 - f1_score: 0.6982 - loss: 1.4063 - val_acc: 0.6912 - val_auc: 0.9802 - val_f1_score: 0.6650 - val_loss: 1.5335 - learning_rate: 7.7625e-06\n","Epoch 12/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 300ms/step - acc: 0.7153 - auc: 0.9902 - f1_score: 0.6958 - loss: 1.4107 - val_acc: 0.6912 - val_auc: 0.9802 - val_f1_score: 0.6656 - val_loss: 1.5329 - learning_rate: 7.5858e-06\n","Epoch 13/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - acc: 0.7121 - auc: 0.9890 - f1_score: 0.6893 - loss: 1.4222Epoch 12: Layer now unfrozen 233 (block7a_project_conv)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 306ms/step - acc: 0.7121 - auc: 0.9890 - f1_score: 0.6894 - loss: 1.4221 - val_acc: 0.6928 - val_auc: 0.9802 - val_f1_score: 0.6676 - val_loss: 1.5322 - learning_rate: 7.4131e-06\n","Epoch 14/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 309ms/step - acc: 0.7243 - auc: 0.9913 - f1_score: 0.6972 - loss: 1.3769 - val_acc: 0.6934 - val_auc: 0.9805 - val_f1_score: 0.6678 - val_loss: 1.5314 - learning_rate: 7.2444e-06\n","Epoch 15/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - acc: 0.7149 - auc: 0.9895 - f1_score: 0.6953 - loss: 1.4111Epoch 14: Layer now unfrozen 232 (block7a_se_excite)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 309ms/step - acc: 0.7149 - auc: 0.9895 - f1_score: 0.6953 - loss: 1.4111 - val_acc: 0.6923 - val_auc: 0.9805 - val_f1_score: 0.6667 - val_loss: 1.5309 - learning_rate: 7.0795e-06\n","Epoch 16/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 299ms/step - acc: 0.7195 - auc: 0.9904 - f1_score: 0.6979 - loss: 1.4023 - val_acc: 0.6934 - val_auc: 0.9805 - val_f1_score: 0.6682 - val_loss: 1.5302 - learning_rate: 6.9183e-06\n","Epoch 17/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - acc: 0.7227 - auc: 0.9897 - f1_score: 0.6965 - loss: 1.3923Epoch 16: Layer now unfrozen 231 (block7a_se_expand)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 299ms/step - acc: 0.7227 - auc: 0.9897 - f1_score: 0.6966 - loss: 1.3923 - val_acc: 0.6928 - val_auc: 0.9805 - val_f1_score: 0.6678 - val_loss: 1.5294 - learning_rate: 6.7608e-06\n","Epoch 18/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 308ms/step - acc: 0.7173 - auc: 0.9897 - f1_score: 0.6945 - loss: 1.3965 - val_acc: 0.6923 - val_auc: 0.9805 - val_f1_score: 0.6672 - val_loss: 1.5287 - learning_rate: 6.6069e-06\n","Epoch 19/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - acc: 0.7215 - auc: 0.9890 - f1_score: 0.6985 - loss: 1.4053Epoch 18: Layer now unfrozen 230 (block7a_se_reduce)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 301ms/step - acc: 0.7215 - auc: 0.9890 - f1_score: 0.6986 - loss: 1.4053 - val_acc: 0.6934 - val_auc: 0.9805 - val_f1_score: 0.6686 - val_loss: 1.5282 - learning_rate: 6.4565e-06\n","Epoch 20/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 296ms/step - acc: 0.7249 - auc: 0.9906 - f1_score: 0.7038 - loss: 1.3812 - val_acc: 0.6939 - val_auc: 0.9805 - val_f1_score: 0.6690 - val_loss: 1.5277 - learning_rate: 6.3096e-06\n","Epoch 21/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - acc: 0.7216 - auc: 0.9899 - f1_score: 0.6997 - loss: 1.3998Epoch 20: Layer now unfrozen 229 (block7a_se_reshape)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 297ms/step - acc: 0.7216 - auc: 0.9899 - f1_score: 0.6998 - loss: 1.3997 - val_acc: 0.6939 - val_auc: 0.9805 - val_f1_score: 0.6690 - val_loss: 1.5272 - learning_rate: 6.1660e-06\n","Epoch 22/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 299ms/step - acc: 0.7294 - auc: 0.9896 - f1_score: 0.7104 - loss: 1.3857 - val_acc: 0.6950 - val_auc: 0.9805 - val_f1_score: 0.6703 - val_loss: 1.5270 - learning_rate: 6.0256e-06\n","Epoch 23/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - acc: 0.7245 - auc: 0.9891 - f1_score: 0.7012 - loss: 1.4033Epoch 22: Layer now unfrozen 228 (block7a_se_squeeze)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 314ms/step - acc: 0.7245 - auc: 0.9891 - f1_score: 0.7013 - loss: 1.4032 - val_acc: 0.6956 - val_auc: 0.9805 - val_f1_score: 0.6706 - val_loss: 1.5266 - learning_rate: 5.8884e-06\n","Epoch 24/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 319ms/step - acc: 0.7254 - auc: 0.9902 - f1_score: 0.7028 - loss: 1.3936 - val_acc: 0.6956 - val_auc: 0.9806 - val_f1_score: 0.6705 - val_loss: 1.5261 - learning_rate: 5.7544e-06\n","Epoch 25/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - acc: 0.7324 - auc: 0.9895 - f1_score: 0.7073 - loss: 1.3856Epoch 24: Layer now unfrozen 227 (block7a_activation)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 297ms/step - acc: 0.7324 - auc: 0.9895 - f1_score: 0.7074 - loss: 1.3856 - val_acc: 0.6956 - val_auc: 0.9806 - val_f1_score: 0.6705 - val_loss: 1.5256 - learning_rate: 5.6234e-06\n","Epoch 26/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 308ms/step - acc: 0.7149 - auc: 0.9891 - f1_score: 0.6954 - loss: 1.4000 - val_acc: 0.6950 - val_auc: 0.9806 - val_f1_score: 0.6698 - val_loss: 1.5251 - learning_rate: 5.4954e-06\n","Epoch 27/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - acc: 0.7287 - auc: 0.9896 - f1_score: 0.7032 - loss: 1.3768Epoch 26: Layer now unfrozen 225 (block7a_dwconv)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 321ms/step - acc: 0.7287 - auc: 0.9896 - f1_score: 0.7033 - loss: 1.3768 - val_acc: 0.6945 - val_auc: 0.9806 - val_f1_score: 0.6694 - val_loss: 1.5247 - learning_rate: 5.3703e-06\n","Epoch 28/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 305ms/step - acc: 0.7232 - auc: 0.9910 - f1_score: 0.7004 - loss: 1.3860 - val_acc: 0.6945 - val_auc: 0.9806 - val_f1_score: 0.6694 - val_loss: 1.5244 - learning_rate: 5.2481e-06\n","Epoch 29/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - acc: 0.7268 - auc: 0.9906 - f1_score: 0.7034 - loss: 1.3724Epoch 28: Layer now unfrozen 224 (block7a_expand_activation)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 305ms/step - acc: 0.7268 - auc: 0.9906 - f1_score: 0.7035 - loss: 1.3724 - val_acc: 0.6950 - val_auc: 0.9806 - val_f1_score: 0.6699 - val_loss: 1.5241 - learning_rate: 5.1286e-06\n","Epoch 30/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 326ms/step - acc: 0.7226 - auc: 0.9896 - f1_score: 0.7024 - loss: 1.3921 - val_acc: 0.6945 - val_auc: 0.9806 - val_f1_score: 0.6696 - val_loss: 1.5236 - learning_rate: 5.0119e-06\n","Epoch 31/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - acc: 0.7236 - auc: 0.9902 - f1_score: 0.7022 - loss: 1.3847Epoch 30: Layer now unfrozen 222 (block7a_expand_conv)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 301ms/step - acc: 0.7236 - auc: 0.9902 - f1_score: 0.7023 - loss: 1.3846 - val_acc: 0.6945 - val_auc: 0.9806 - val_f1_score: 0.6695 - val_loss: 1.5233 - learning_rate: 4.8978e-06\n","Epoch 32/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 302ms/step - acc: 0.7323 - auc: 0.9900 - f1_score: 0.7120 - loss: 1.3743 - val_acc: 0.6939 - val_auc: 0.9806 - val_f1_score: 0.6692 - val_loss: 1.5231 - learning_rate: 4.7863e-06\n","Epoch 33/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - acc: 0.7301 - auc: 0.9903 - f1_score: 0.7080 - loss: 1.3794Epoch 32: Layer now unfrozen 221 (block6d_add)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 294ms/step - acc: 0.7301 - auc: 0.9903 - f1_score: 0.7080 - loss: 1.3794 - val_acc: 0.6950 - val_auc: 0.9806 - val_f1_score: 0.6706 - val_loss: 1.5226 - learning_rate: 4.6774e-06\n","Epoch 34/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 301ms/step - acc: 0.7250 - auc: 0.9899 - f1_score: 0.7057 - loss: 1.3883 - val_acc: 0.6950 - val_auc: 0.9806 - val_f1_score: 0.6706 - val_loss: 1.5223 - learning_rate: 4.5709e-06\n","Epoch 35/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - acc: 0.7180 - auc: 0.9896 - f1_score: 0.6952 - loss: 1.3947Epoch 34: Layer now unfrozen 220 (block6d_drop)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 303ms/step - acc: 0.7180 - auc: 0.9896 - f1_score: 0.6953 - loss: 1.3947 - val_acc: 0.6950 - val_auc: 0.9806 - val_f1_score: 0.6701 - val_loss: 1.5221 - learning_rate: 4.4668e-06\n","Epoch 36/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 305ms/step - acc: 0.7243 - auc: 0.9889 - f1_score: 0.7039 - loss: 1.3795 - val_acc: 0.6950 - val_auc: 0.9806 - val_f1_score: 0.6704 - val_loss: 1.5219 - learning_rate: 4.3652e-06\n","Epoch 37/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - acc: 0.7257 - auc: 0.9898 - f1_score: 0.7046 - loss: 1.3965Epoch 36: Layer now unfrozen 218 (block6d_project_conv)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 314ms/step - acc: 0.7257 - auc: 0.9898 - f1_score: 0.7046 - loss: 1.3964 - val_acc: 0.6950 - val_auc: 0.9806 - val_f1_score: 0.6704 - val_loss: 1.5218 - learning_rate: 4.2658e-06\n","Epoch 38/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 313ms/step - acc: 0.7238 - auc: 0.9907 - f1_score: 0.7025 - loss: 1.3689 - val_acc: 0.6950 - val_auc: 0.9806 - val_f1_score: 0.6702 - val_loss: 1.5215 - learning_rate: 4.1687e-06\n","Epoch 39/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - acc: 0.7244 - auc: 0.9893 - f1_score: 0.7001 - loss: 1.3918Epoch 38: Layer now unfrozen 217 (block6d_se_excite)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 299ms/step - acc: 0.7244 - auc: 0.9893 - f1_score: 0.7002 - loss: 1.3918 - val_acc: 0.6950 - val_auc: 0.9806 - val_f1_score: 0.6703 - val_loss: 1.5213 - learning_rate: 4.0738e-06\n","Epoch 40/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 299ms/step - acc: 0.7314 - auc: 0.9905 - f1_score: 0.7095 - loss: 1.3717 - val_acc: 0.6950 - val_auc: 0.9806 - val_f1_score: 0.6700 - val_loss: 1.5209 - learning_rate: 3.9811e-06\n","Epoch 41/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - acc: 0.7136 - auc: 0.9904 - f1_score: 0.6924 - loss: 1.3916Epoch 40: Layer now unfrozen 216 (block6d_se_expand)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 294ms/step - acc: 0.7137 - auc: 0.9904 - f1_score: 0.6925 - loss: 1.3916 - val_acc: 0.6956 - val_auc: 0.9806 - val_f1_score: 0.6708 - val_loss: 1.5205 - learning_rate: 3.8905e-06\n","Epoch 42/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 299ms/step - acc: 0.7282 - auc: 0.9909 - f1_score: 0.7076 - loss: 1.3778 - val_acc: 0.6950 - val_auc: 0.9806 - val_f1_score: 0.6703 - val_loss: 1.5203 - learning_rate: 3.8019e-06\n","Epoch 43/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - acc: 0.7278 - auc: 0.9912 - f1_score: 0.7062 - loss: 1.3698Epoch 42: Layer now unfrozen 215 (block6d_se_reduce)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 300ms/step - acc: 0.7278 - auc: 0.9912 - f1_score: 0.7063 - loss: 1.3697 - val_acc: 0.6950 - val_auc: 0.9806 - val_f1_score: 0.6703 - val_loss: 1.5202 - learning_rate: 3.7154e-06\n","Epoch 44/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 305ms/step - acc: 0.7226 - auc: 0.9897 - f1_score: 0.7002 - loss: 1.3894 - val_acc: 0.6950 - val_auc: 0.9806 - val_f1_score: 0.6703 - val_loss: 1.5199 - learning_rate: 3.6308e-06\n","Epoch 45/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - acc: 0.7295 - auc: 0.9897 - f1_score: 0.7100 - loss: 1.3626Epoch 44: Layer now unfrozen 214 (block6d_se_reshape)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 306ms/step - acc: 0.7295 - auc: 0.9897 - f1_score: 0.7101 - loss: 1.3626 - val_acc: 0.6950 - val_auc: 0.9806 - val_f1_score: 0.6703 - val_loss: 1.5196 - learning_rate: 3.5481e-06\n","Epoch 46/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 314ms/step - acc: 0.7342 - auc: 0.9894 - f1_score: 0.7113 - loss: 1.3575 - val_acc: 0.6956 - val_auc: 0.9806 - val_f1_score: 0.6712 - val_loss: 1.5193 - learning_rate: 3.4674e-06\n","Epoch 47/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - acc: 0.7322 - auc: 0.9906 - f1_score: 0.7141 - loss: 1.3609Epoch 46: Layer now unfrozen 213 (block6d_se_squeeze)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 308ms/step - acc: 0.7322 - auc: 0.9906 - f1_score: 0.7141 - loss: 1.3609 - val_acc: 0.6962 - val_auc: 0.9806 - val_f1_score: 0.6720 - val_loss: 1.5190 - learning_rate: 3.3884e-06\n","Epoch 48/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 330ms/step - acc: 0.7323 - auc: 0.9904 - f1_score: 0.7106 - loss: 1.3618 - val_acc: 0.6956 - val_auc: 0.9806 - val_f1_score: 0.6712 - val_loss: 1.5188 - learning_rate: 3.3113e-06\n","Epoch 49/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - acc: 0.7242 - auc: 0.9897 - f1_score: 0.7009 - loss: 1.3728Epoch 48: Layer now unfrozen 212 (block6d_activation)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 303ms/step - acc: 0.7242 - auc: 0.9897 - f1_score: 0.7010 - loss: 1.3728 - val_acc: 0.6967 - val_auc: 0.9806 - val_f1_score: 0.6726 - val_loss: 1.5185 - learning_rate: 3.2359e-06\n","Epoch 50/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 301ms/step - acc: 0.7229 - auc: 0.9903 - f1_score: 0.7012 - loss: 1.3767 - val_acc: 0.6967 - val_auc: 0.9806 - val_f1_score: 0.6729 - val_loss: 1.5182 - learning_rate: 3.1623e-06\n","Epoch 51/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - acc: 0.7339 - auc: 0.9905 - f1_score: 0.7105 - loss: 1.3626Epoch 50: Layer now unfrozen 210 (block6d_dwconv)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 321ms/step - acc: 0.7339 - auc: 0.9905 - f1_score: 0.7106 - loss: 1.3626 - val_acc: 0.6962 - val_auc: 0.9806 - val_f1_score: 0.6722 - val_loss: 1.5181 - learning_rate: 3.0903e-06\n","Epoch 52/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 305ms/step - acc: 0.7244 - auc: 0.9895 - f1_score: 0.7035 - loss: 1.3779 - val_acc: 0.6967 - val_auc: 0.9806 - val_f1_score: 0.6729 - val_loss: 1.5180 - learning_rate: 3.0200e-06\n","Epoch 53/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - acc: 0.7295 - auc: 0.9904 - f1_score: 0.7106 - loss: 1.3727Epoch 52: Layer now unfrozen 209 (block6d_expand_activation)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 300ms/step - acc: 0.7295 - auc: 0.9904 - f1_score: 0.7107 - loss: 1.3726 - val_acc: 0.6967 - val_auc: 0.9806 - val_f1_score: 0.6729 - val_loss: 1.5179 - learning_rate: 2.9512e-06\n","Epoch 54/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 309ms/step - acc: 0.7237 - auc: 0.9913 - f1_score: 0.7027 - loss: 1.3681 - val_acc: 0.6962 - val_auc: 0.9806 - val_f1_score: 0.6723 - val_loss: 1.5177 - learning_rate: 2.8840e-06\n","Epoch 55/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - acc: 0.7339 - auc: 0.9910 - f1_score: 0.7093 - loss: 1.3667Epoch 54: Layer now unfrozen 207 (block6d_expand_conv)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 308ms/step - acc: 0.7339 - auc: 0.9910 - f1_score: 0.7094 - loss: 1.3667 - val_acc: 0.6956 - val_auc: 0.9806 - val_f1_score: 0.6715 - val_loss: 1.5175 - learning_rate: 2.8184e-06\n","Epoch 56/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 315ms/step - acc: 0.7245 - auc: 0.9902 - f1_score: 0.7017 - loss: 1.3774 - val_acc: 0.6973 - val_auc: 0.9806 - val_f1_score: 0.6732 - val_loss: 1.5174 - learning_rate: 2.7542e-06\n","Epoch 57/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - acc: 0.7167 - auc: 0.9914 - f1_score: 0.6975 - loss: 1.3661Epoch 56: Layer now unfrozen 206 (block6c_add)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 306ms/step - acc: 0.7167 - auc: 0.9914 - f1_score: 0.6976 - loss: 1.3660 - val_acc: 0.6973 - val_auc: 0.9806 - val_f1_score: 0.6732 - val_loss: 1.5173 - learning_rate: 2.6915e-06\n","Epoch 58/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 304ms/step - acc: 0.7299 - auc: 0.9909 - f1_score: 0.7067 - loss: 1.3621 - val_acc: 0.6973 - val_auc: 0.9806 - val_f1_score: 0.6732 - val_loss: 1.5173 - learning_rate: 2.6303e-06\n","Epoch 59/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - acc: 0.7287 - auc: 0.9891 - f1_score: 0.7090 - loss: 1.3637Epoch 58: Layer now unfrozen 205 (block6c_drop)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 308ms/step - acc: 0.7287 - auc: 0.9891 - f1_score: 0.7090 - loss: 1.3637 - val_acc: 0.6973 - val_auc: 0.9806 - val_f1_score: 0.6736 - val_loss: 1.5170 - learning_rate: 2.5704e-06\n","Epoch 60/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 295ms/step - acc: 0.7332 - auc: 0.9916 - f1_score: 0.7141 - loss: 1.3561 - val_acc: 0.6973 - val_auc: 0.9807 - val_f1_score: 0.6736 - val_loss: 1.5168 - learning_rate: 2.5119e-06\n","Epoch 61/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - acc: 0.7347 - auc: 0.9898 - f1_score: 0.7148 - loss: 1.3674Epoch 60: Layer now unfrozen 203 (block6c_project_conv)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 305ms/step - acc: 0.7347 - auc: 0.9898 - f1_score: 0.7148 - loss: 1.3674 - val_acc: 0.6978 - val_auc: 0.9807 - val_f1_score: 0.6740 - val_loss: 1.5167 - learning_rate: 2.4547e-06\n","Epoch 62/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 306ms/step - acc: 0.7267 - auc: 0.9900 - f1_score: 0.7066 - loss: 1.3723 - val_acc: 0.6973 - val_auc: 0.9807 - val_f1_score: 0.6733 - val_loss: 1.5165 - learning_rate: 2.3988e-06\n","Epoch 63/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - acc: 0.7296 - auc: 0.9909 - f1_score: 0.7055 - loss: 1.3684Epoch 62: Layer now unfrozen 202 (block6c_se_excite)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 303ms/step - acc: 0.7296 - auc: 0.9909 - f1_score: 0.7056 - loss: 1.3684 - val_acc: 0.6973 - val_auc: 0.9807 - val_f1_score: 0.6736 - val_loss: 1.5164 - learning_rate: 2.3442e-06\n","Epoch 64/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 302ms/step - acc: 0.7235 - auc: 0.9892 - f1_score: 0.7055 - loss: 1.3808 - val_acc: 0.6978 - val_auc: 0.9807 - val_f1_score: 0.6740 - val_loss: 1.5163 - learning_rate: 2.2909e-06\n","Epoch 65/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - acc: 0.7306 - auc: 0.9903 - f1_score: 0.7096 - loss: 1.3741Epoch 64: Layer now unfrozen 201 (block6c_se_expand)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 333ms/step - acc: 0.7306 - auc: 0.9903 - f1_score: 0.7097 - loss: 1.3740 - val_acc: 0.6978 - val_auc: 0.9807 - val_f1_score: 0.6740 - val_loss: 1.5162 - learning_rate: 2.2387e-06\n","Epoch 66/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 292ms/step - acc: 0.7303 - auc: 0.9905 - f1_score: 0.7099 - loss: 1.3604 - val_acc: 0.6978 - val_auc: 0.9807 - val_f1_score: 0.6740 - val_loss: 1.5161 - learning_rate: 2.1878e-06\n","Epoch 67/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - acc: 0.7271 - auc: 0.9902 - f1_score: 0.7052 - loss: 1.3695Epoch 66: Layer now unfrozen 200 (block6c_se_reduce)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 318ms/step - acc: 0.7272 - auc: 0.9902 - f1_score: 0.7053 - loss: 1.3695 - val_acc: 0.6978 - val_auc: 0.9807 - val_f1_score: 0.6740 - val_loss: 1.5159 - learning_rate: 2.1380e-06\n","Epoch 68/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 330ms/step - acc: 0.7266 - auc: 0.9909 - f1_score: 0.7058 - loss: 1.3601 - val_acc: 0.6978 - val_auc: 0.9807 - val_f1_score: 0.6743 - val_loss: 1.5158 - learning_rate: 2.0893e-06\n","Epoch 69/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - acc: 0.7267 - auc: 0.9916 - f1_score: 0.7066 - loss: 1.3615Epoch 68: Layer now unfrozen 199 (block6c_se_reshape)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 300ms/step - acc: 0.7267 - auc: 0.9916 - f1_score: 0.7067 - loss: 1.3614 - val_acc: 0.6989 - val_auc: 0.9807 - val_f1_score: 0.6754 - val_loss: 1.5156 - learning_rate: 2.0417e-06\n","Epoch 70/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 332ms/step - acc: 0.7248 - auc: 0.9917 - f1_score: 0.7003 - loss: 1.3649 - val_acc: 0.6989 - val_auc: 0.9807 - val_f1_score: 0.6754 - val_loss: 1.5155 - learning_rate: 1.9953e-06\n","Epoch 71/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - acc: 0.7311 - auc: 0.9906 - f1_score: 0.7106 - loss: 1.3505Epoch 70: Layer now unfrozen 198 (block6c_se_squeeze)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 298ms/step - acc: 0.7311 - auc: 0.9906 - f1_score: 0.7106 - loss: 1.3505 - val_acc: 0.6989 - val_auc: 0.9807 - val_f1_score: 0.6754 - val_loss: 1.5154 - learning_rate: 1.9498e-06\n","Epoch 72/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 292ms/step - acc: 0.7314 - auc: 0.9906 - f1_score: 0.7102 - loss: 1.3622 - val_acc: 0.6989 - val_auc: 0.9807 - val_f1_score: 0.6754 - val_loss: 1.5153 - learning_rate: 1.9055e-06\n","Epoch 73/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - acc: 0.7313 - auc: 0.9898 - f1_score: 0.7099 - loss: 1.3637Epoch 72: Layer now unfrozen 197 (block6c_activation)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 301ms/step - acc: 0.7313 - auc: 0.9898 - f1_score: 0.7100 - loss: 1.3636 - val_acc: 0.6989 - val_auc: 0.9807 - val_f1_score: 0.6754 - val_loss: 1.5153 - learning_rate: 1.8621e-06\n","Epoch 74/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 296ms/step - acc: 0.7359 - auc: 0.9912 - f1_score: 0.7153 - loss: 1.3501 - val_acc: 0.6989 - val_auc: 0.9807 - val_f1_score: 0.6754 - val_loss: 1.5152 - learning_rate: 1.8197e-06\n","Epoch 75/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - acc: 0.7291 - auc: 0.9914 - f1_score: 0.7077 - loss: 1.3549Epoch 74: Layer now unfrozen 195 (block6c_dwconv)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 320ms/step - acc: 0.7291 - auc: 0.9914 - f1_score: 0.7078 - loss: 1.3549 - val_acc: 0.6984 - val_auc: 0.9807 - val_f1_score: 0.6750 - val_loss: 1.5151 - learning_rate: 1.7783e-06\n","Epoch 76/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 300ms/step - acc: 0.7300 - auc: 0.9900 - f1_score: 0.7056 - loss: 1.3682 - val_acc: 0.6995 - val_auc: 0.9807 - val_f1_score: 0.6765 - val_loss: 1.5150 - learning_rate: 1.7378e-06\n","Epoch 77/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - acc: 0.7383 - auc: 0.9905 - f1_score: 0.7194 - loss: 1.3503Epoch 76: Layer now unfrozen 194 (block6c_expand_activation)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 300ms/step - acc: 0.7383 - auc: 0.9905 - f1_score: 0.7194 - loss: 1.3503 - val_acc: 0.6995 - val_auc: 0.9807 - val_f1_score: 0.6765 - val_loss: 1.5150 - learning_rate: 1.6982e-06\n","Epoch 78/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 300ms/step - acc: 0.7347 - auc: 0.9919 - f1_score: 0.7134 - loss: 1.3632 - val_acc: 0.6995 - val_auc: 0.9807 - val_f1_score: 0.6765 - val_loss: 1.5149 - learning_rate: 1.6596e-06\n","Epoch 79/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - acc: 0.7360 - auc: 0.9909 - f1_score: 0.7164 - loss: 1.3537Epoch 78: Layer now unfrozen 192 (block6c_expand_conv)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 290ms/step - acc: 0.7360 - auc: 0.9909 - f1_score: 0.7165 - loss: 1.3537 - val_acc: 0.6995 - val_auc: 0.9807 - val_f1_score: 0.6765 - val_loss: 1.5148 - learning_rate: 1.6218e-06\n","Epoch 80/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 293ms/step - acc: 0.7242 - auc: 0.9910 - f1_score: 0.7020 - loss: 1.3702 - val_acc: 0.6995 - val_auc: 0.9807 - val_f1_score: 0.6764 - val_loss: 1.5147 - learning_rate: 1.5849e-06\n","Epoch 81/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - acc: 0.7247 - auc: 0.9903 - f1_score: 0.7001 - loss: 1.3599Epoch 80: Layer now unfrozen 191 (block6b_add)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 312ms/step - acc: 0.7248 - auc: 0.9903 - f1_score: 0.7002 - loss: 1.3599 - val_acc: 0.6995 - val_auc: 0.9807 - val_f1_score: 0.6764 - val_loss: 1.5146 - learning_rate: 1.5488e-06\n","Epoch 82/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 317ms/step - acc: 0.7324 - auc: 0.9910 - f1_score: 0.7115 - loss: 1.3545 - val_acc: 0.6995 - val_auc: 0.9807 - val_f1_score: 0.6764 - val_loss: 1.5146 - learning_rate: 1.5136e-06\n","Epoch 83/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - acc: 0.7354 - auc: 0.9904 - f1_score: 0.7123 - loss: 1.3619Epoch 82: Layer now unfrozen 190 (block6b_drop)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 304ms/step - acc: 0.7353 - auc: 0.9904 - f1_score: 0.7123 - loss: 1.3619 - val_acc: 0.7001 - val_auc: 0.9807 - val_f1_score: 0.6771 - val_loss: 1.5144 - learning_rate: 1.4791e-06\n","Epoch 84/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 303ms/step - acc: 0.7305 - auc: 0.9900 - f1_score: 0.7064 - loss: 1.3577 - val_acc: 0.7001 - val_auc: 0.9807 - val_f1_score: 0.6771 - val_loss: 1.5143 - learning_rate: 1.4454e-06\n","Epoch 85/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - acc: 0.7236 - auc: 0.9906 - f1_score: 0.7020 - loss: 1.3568Epoch 84: Layer now unfrozen 188 (block6b_project_conv)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 310ms/step - acc: 0.7236 - auc: 0.9906 - f1_score: 0.7021 - loss: 1.3568 - val_acc: 0.7006 - val_auc: 0.9807 - val_f1_score: 0.6775 - val_loss: 1.5142 - learning_rate: 1.4125e-06\n","Epoch 86/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 324ms/step - acc: 0.7339 - auc: 0.9917 - f1_score: 0.7161 - loss: 1.3624 - val_acc: 0.7006 - val_auc: 0.9807 - val_f1_score: 0.6775 - val_loss: 1.5141 - learning_rate: 1.3804e-06\n","Epoch 87/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - acc: 0.7388 - auc: 0.9925 - f1_score: 0.7148 - loss: 1.3553Epoch 86: Layer now unfrozen 187 (block6b_se_excite)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 296ms/step - acc: 0.7388 - auc: 0.9925 - f1_score: 0.7148 - loss: 1.3552 - val_acc: 0.7001 - val_auc: 0.9807 - val_f1_score: 0.6772 - val_loss: 1.5140 - learning_rate: 1.3490e-06\n","Epoch 88/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 310ms/step - acc: 0.7292 - auc: 0.9906 - f1_score: 0.7070 - loss: 1.3646 - val_acc: 0.7012 - val_auc: 0.9807 - val_f1_score: 0.6777 - val_loss: 1.5139 - learning_rate: 1.3183e-06\n","Epoch 89/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - acc: 0.7328 - auc: 0.9906 - f1_score: 0.7112 - loss: 1.3506Epoch 88: Layer now unfrozen 186 (block6b_se_expand)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 299ms/step - acc: 0.7328 - auc: 0.9906 - f1_score: 0.7113 - loss: 1.3506 - val_acc: 0.7012 - val_auc: 0.9807 - val_f1_score: 0.6777 - val_loss: 1.5139 - learning_rate: 1.2882e-06\n","Epoch 90/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 296ms/step - acc: 0.7325 - auc: 0.9899 - f1_score: 0.7108 - loss: 1.3716 - val_acc: 0.7012 - val_auc: 0.9807 - val_f1_score: 0.6777 - val_loss: 1.5138 - learning_rate: 1.2589e-06\n","Epoch 91/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - acc: 0.7319 - auc: 0.9899 - f1_score: 0.7149 - loss: 1.3540Epoch 90: Layer now unfrozen 185 (block6b_se_reduce)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 297ms/step - acc: 0.7319 - auc: 0.9899 - f1_score: 0.7150 - loss: 1.3540 - val_acc: 0.7012 - val_auc: 0.9807 - val_f1_score: 0.6777 - val_loss: 1.5137 - learning_rate: 1.2303e-06\n","Epoch 92/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 306ms/step - acc: 0.7283 - auc: 0.9903 - f1_score: 0.7098 - loss: 1.3691 - val_acc: 0.7012 - val_auc: 0.9807 - val_f1_score: 0.6777 - val_loss: 1.5136 - learning_rate: 1.2023e-06\n","Epoch 93/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - acc: 0.7337 - auc: 0.9909 - f1_score: 0.7125 - loss: 1.3479Epoch 92: Layer now unfrozen 184 (block6b_se_reshape)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 303ms/step - acc: 0.7337 - auc: 0.9909 - f1_score: 0.7126 - loss: 1.3479 - val_acc: 0.7006 - val_auc: 0.9807 - val_f1_score: 0.6771 - val_loss: 1.5135 - learning_rate: 1.1749e-06\n","Epoch 94/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 307ms/step - acc: 0.7353 - auc: 0.9911 - f1_score: 0.7133 - loss: 1.3425 - val_acc: 0.7001 - val_auc: 0.9807 - val_f1_score: 0.6767 - val_loss: 1.5134 - learning_rate: 1.1482e-06\n","Epoch 95/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - acc: 0.7360 - auc: 0.9906 - f1_score: 0.7175 - loss: 1.3431Epoch 94: Layer now unfrozen 183 (block6b_se_squeeze)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 311ms/step - acc: 0.7360 - auc: 0.9906 - f1_score: 0.7176 - loss: 1.3431 - val_acc: 0.7001 - val_auc: 0.9807 - val_f1_score: 0.6766 - val_loss: 1.5134 - learning_rate: 1.1220e-06\n","Epoch 96/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 300ms/step - acc: 0.7272 - auc: 0.9912 - f1_score: 0.7071 - loss: 1.3597 - val_acc: 0.7006 - val_auc: 0.9807 - val_f1_score: 0.6771 - val_loss: 1.5133 - learning_rate: 1.0965e-06\n","Epoch 97/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - acc: 0.7304 - auc: 0.9919 - f1_score: 0.7123 - loss: 1.3449Epoch 96: Layer now unfrozen 182 (block6b_activation)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 300ms/step - acc: 0.7304 - auc: 0.9919 - f1_score: 0.7124 - loss: 1.3449 - val_acc: 0.7001 - val_auc: 0.9807 - val_f1_score: 0.6767 - val_loss: 1.5133 - learning_rate: 1.0715e-06\n","Epoch 98/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 328ms/step - acc: 0.7325 - auc: 0.9913 - f1_score: 0.7108 - loss: 1.3528 - val_acc: 0.6995 - val_auc: 0.9807 - val_f1_score: 0.6760 - val_loss: 1.5133 - learning_rate: 1.0471e-06\n","Epoch 99/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - acc: 0.7367 - auc: 0.9909 - f1_score: 0.7144 - loss: 1.3378Epoch 98: Layer now unfrozen 180 (block6b_dwconv)\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 301ms/step - acc: 0.7366 - auc: 0.9909 - f1_score: 0.7145 - loss: 1.3378 - val_acc: 0.7001 - val_auc: 0.9807 - val_f1_score: 0.6766 - val_loss: 1.5132 - learning_rate: 1.0233e-06\n","Epoch 100/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 313ms/step - acc: 0.7282 - auc: 0.9907 - f1_score: 0.7077 - loss: 1.3626 - val_acc: 0.7006 - val_auc: 0.9807 - val_f1_score: 0.6770 - val_loss: 1.5131 - learning_rate: 1.0000e-06\n"]}],"source":["# Initialize the experiment\n","experiment_en_ft = Experiment(\n","    model=model_en_ft,\n","    train_ds=train_ds_en_pre_ft,\n","    val_ds=val_ds_en_pre_ft,\n","    experiment_name=\"eff-net_with_phylum_ft\",\n","    resume=True,\n","    steps_per_epoch=263,\n",")\n","\n","# Run the experiment\n","history_ft_en = experiment_en_ft.run_experiment(\n","    epochs=100,\n","    callbacks=[progressive_unfreeze, lr_callback]\n",")\n","\n","# Run the experiment\n","history_en_ft = experiment_en_ft.run_experiment(callbacks=callbacks, epochs=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PP-Aq_XHsbVR","outputId":"72142b45-97cd-4084-850f-45957a712cf4"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"repr_error":"0","type":"dataframe","variable_name":"df_latest_experiment"},"text/html":["\n","  <div id=\"df-9d520d6f-8781-4710-a2d4-44679bcb8a0d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>experiment_name</th>\n","      <th>epoch</th>\n","      <th>train_accuracy</th>\n","      <th>val_accuracy</th>\n","      <th>train_loss</th>\n","      <th>val_loss</th>\n","      <th>f1_train_macro</th>\n","      <th>f1_val_macro</th>\n","      <th>f1_train_weighted</th>\n","      <th>f1_val_weighted</th>\n","      <th>top5_train_accuracy</th>\n","      <th>top5_val_accuracy</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>338</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>1</td>\n","      <td>0.0758</td>\n","      <td>0.1859</td>\n","      <td>5.0903</td>\n","      <td>4.6492</td>\n","      <td>0.0179</td>\n","      <td>0.0404</td>\n","      <td>0.0517</td>\n","      <td>NaN</td>\n","      <td>0.1684</td>\n","      <td>0.3500</td>\n","      <td>2025-04-24 21:58:37</td>\n","    </tr>\n","    <tr>\n","      <th>339</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>2</td>\n","      <td>0.1946</td>\n","      <td>0.2677</td>\n","      <td>4.3801</td>\n","      <td>4.0056</td>\n","      <td>0.0511</td>\n","      <td>0.0790</td>\n","      <td>0.1217</td>\n","      <td>NaN</td>\n","      <td>0.3587</td>\n","      <td>0.4669</td>\n","      <td>2025-04-24 21:59:26</td>\n","    </tr>\n","    <tr>\n","      <th>340</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>3</td>\n","      <td>0.2561</td>\n","      <td>0.3228</td>\n","      <td>3.8348</td>\n","      <td>3.5320</td>\n","      <td>0.0835</td>\n","      <td>0.1129</td>\n","      <td>0.1752</td>\n","      <td>NaN</td>\n","      <td>0.4793</td>\n","      <td>0.5654</td>\n","      <td>2025-04-24 22:00:15</td>\n","    </tr>\n","    <tr>\n","      <th>341</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>4</td>\n","      <td>0.3161</td>\n","      <td>0.3767</td>\n","      <td>3.4094</td>\n","      <td>3.1654</td>\n","      <td>0.1357</td>\n","      <td>0.1753</td>\n","      <td>0.2382</td>\n","      <td>NaN</td>\n","      <td>0.5741</td>\n","      <td>0.6311</td>\n","      <td>2025-04-24 22:01:02</td>\n","    </tr>\n","    <tr>\n","      <th>342</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>5</td>\n","      <td>0.3619</td>\n","      <td>0.4207</td>\n","      <td>3.0739</td>\n","      <td>2.8756</td>\n","      <td>0.1827</td>\n","      <td>0.2224</td>\n","      <td>0.2909</td>\n","      <td>NaN</td>\n","      <td>0.6369</td>\n","      <td>0.6795</td>\n","      <td>2025-04-24 22:01:51</td>\n","    </tr>\n","    <tr>\n","      <th>343</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>6</td>\n","      <td>0.4082</td>\n","      <td>0.4569</td>\n","      <td>2.8134</td>\n","      <td>2.6403</td>\n","      <td>0.2343</td>\n","      <td>0.2659</td>\n","      <td>0.3420</td>\n","      <td>NaN</td>\n","      <td>0.6782</td>\n","      <td>0.7151</td>\n","      <td>2025-04-24 22:02:38</td>\n","    </tr>\n","    <tr>\n","      <th>344</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>7</td>\n","      <td>0.4390</td>\n","      <td>0.4975</td>\n","      <td>2.5903</td>\n","      <td>2.4480</td>\n","      <td>0.2774</td>\n","      <td>0.3179</td>\n","      <td>0.3793</td>\n","      <td>NaN</td>\n","      <td>0.7208</td>\n","      <td>0.7446</td>\n","      <td>2025-04-24 22:03:27</td>\n","    </tr>\n","    <tr>\n","      <th>345</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>8</td>\n","      <td>0.4704</td>\n","      <td>0.5198</td>\n","      <td>2.4086</td>\n","      <td>2.2943</td>\n","      <td>0.3282</td>\n","      <td>0.3452</td>\n","      <td>0.4187</td>\n","      <td>NaN</td>\n","      <td>0.7577</td>\n","      <td>0.7718</td>\n","      <td>2025-04-24 22:04:14</td>\n","    </tr>\n","    <tr>\n","      <th>346</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>9</td>\n","      <td>0.5005</td>\n","      <td>0.5448</td>\n","      <td>2.2588</td>\n","      <td>2.1675</td>\n","      <td>0.3767</td>\n","      <td>0.3893</td>\n","      <td>0.4555</td>\n","      <td>NaN</td>\n","      <td>0.7830</td>\n","      <td>0.7974</td>\n","      <td>2025-04-24 22:05:02</td>\n","    </tr>\n","    <tr>\n","      <th>347</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>10</td>\n","      <td>0.5295</td>\n","      <td>0.5559</td>\n","      <td>2.1257</td>\n","      <td>2.0673</td>\n","      <td>0.4149</td>\n","      <td>0.4139</td>\n","      <td>0.4897</td>\n","      <td>NaN</td>\n","      <td>0.8089</td>\n","      <td>0.8114</td>\n","      <td>2025-04-24 22:05:49</td>\n","    </tr>\n","    <tr>\n","      <th>348</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>11</td>\n","      <td>0.5429</td>\n","      <td>0.5693</td>\n","      <td>2.0322</td>\n","      <td>1.9781</td>\n","      <td>0.4406</td>\n","      <td>0.4424</td>\n","      <td>0.5060</td>\n","      <td>NaN</td>\n","      <td>0.8222</td>\n","      <td>0.8325</td>\n","      <td>2025-04-24 22:06:37</td>\n","    </tr>\n","    <tr>\n","      <th>349</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>12</td>\n","      <td>0.5701</td>\n","      <td>0.5810</td>\n","      <td>1.9424</td>\n","      <td>1.9116</td>\n","      <td>0.4758</td>\n","      <td>0.4589</td>\n","      <td>0.5383</td>\n","      <td>NaN</td>\n","      <td>0.8404</td>\n","      <td>0.8386</td>\n","      <td>2025-04-24 22:07:25</td>\n","    </tr>\n","    <tr>\n","      <th>350</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>13</td>\n","      <td>0.5828</td>\n","      <td>0.5960</td>\n","      <td>1.8532</td>\n","      <td>1.8566</td>\n","      <td>0.4981</td>\n","      <td>0.4909</td>\n","      <td>0.5544</td>\n","      <td>NaN</td>\n","      <td>0.8518</td>\n","      <td>0.8486</td>\n","      <td>2025-04-24 22:08:20</td>\n","    </tr>\n","    <tr>\n","      <th>351</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>14</td>\n","      <td>0.6008</td>\n","      <td>0.6027</td>\n","      <td>1.7890</td>\n","      <td>1.8096</td>\n","      <td>0.5252</td>\n","      <td>0.5010</td>\n","      <td>0.5751</td>\n","      <td>NaN</td>\n","      <td>0.8656</td>\n","      <td>0.8492</td>\n","      <td>2025-04-24 22:14:47</td>\n","    </tr>\n","    <tr>\n","      <th>352</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>15</td>\n","      <td>0.6131</td>\n","      <td>0.6088</td>\n","      <td>1.7164</td>\n","      <td>1.7681</td>\n","      <td>0.5449</td>\n","      <td>0.5072</td>\n","      <td>0.5897</td>\n","      <td>NaN</td>\n","      <td>0.8774</td>\n","      <td>0.8587</td>\n","      <td>2025-04-24 22:15:37</td>\n","    </tr>\n","    <tr>\n","      <th>353</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>16</td>\n","      <td>0.6275</td>\n","      <td>0.6199</td>\n","      <td>1.6751</td>\n","      <td>1.7348</td>\n","      <td>0.5699</td>\n","      <td>0.5243</td>\n","      <td>0.6084</td>\n","      <td>NaN</td>\n","      <td>0.8839</td>\n","      <td>0.8642</td>\n","      <td>2025-04-24 22:16:25</td>\n","    </tr>\n","    <tr>\n","      <th>354</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>17</td>\n","      <td>0.6511</td>\n","      <td>0.6288</td>\n","      <td>1.6150</td>\n","      <td>1.7060</td>\n","      <td>0.5940</td>\n","      <td>0.5425</td>\n","      <td>0.6320</td>\n","      <td>NaN</td>\n","      <td>0.8907</td>\n","      <td>0.8653</td>\n","      <td>2025-04-24 22:17:13</td>\n","    </tr>\n","    <tr>\n","      <th>355</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>18</td>\n","      <td>0.6629</td>\n","      <td>0.6322</td>\n","      <td>1.5678</td>\n","      <td>1.6825</td>\n","      <td>0.6157</td>\n","      <td>0.5515</td>\n","      <td>0.6471</td>\n","      <td>NaN</td>\n","      <td>0.9003</td>\n","      <td>0.8676</td>\n","      <td>2025-04-24 22:18:01</td>\n","    </tr>\n","    <tr>\n","      <th>356</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>19</td>\n","      <td>0.6627</td>\n","      <td>0.6427</td>\n","      <td>1.5446</td>\n","      <td>1.6572</td>\n","      <td>0.6187</td>\n","      <td>0.5728</td>\n","      <td>0.6485</td>\n","      <td>NaN</td>\n","      <td>0.9038</td>\n","      <td>0.8715</td>\n","      <td>2025-04-24 22:18:49</td>\n","    </tr>\n","    <tr>\n","      <th>357</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>20</td>\n","      <td>0.6785</td>\n","      <td>0.6511</td>\n","      <td>1.4984</td>\n","      <td>1.6401</td>\n","      <td>0.6364</td>\n","      <td>0.5794</td>\n","      <td>0.6646</td>\n","      <td>NaN</td>\n","      <td>0.9097</td>\n","      <td>0.8709</td>\n","      <td>2025-04-24 22:19:37</td>\n","    </tr>\n","    <tr>\n","      <th>358</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>21</td>\n","      <td>0.6846</td>\n","      <td>0.6489</td>\n","      <td>1.4791</td>\n","      <td>1.6259</td>\n","      <td>0.6432</td>\n","      <td>0.5818</td>\n","      <td>0.6715</td>\n","      <td>NaN</td>\n","      <td>0.9136</td>\n","      <td>0.8737</td>\n","      <td>2025-04-24 22:20:25</td>\n","    </tr>\n","    <tr>\n","      <th>359</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>22</td>\n","      <td>0.6981</td>\n","      <td>0.6533</td>\n","      <td>1.4401</td>\n","      <td>1.6117</td>\n","      <td>0.6637</td>\n","      <td>0.5918</td>\n","      <td>0.6866</td>\n","      <td>NaN</td>\n","      <td>0.9178</td>\n","      <td>0.8770</td>\n","      <td>2025-04-24 22:21:13</td>\n","    </tr>\n","    <tr>\n","      <th>360</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>23</td>\n","      <td>0.6993</td>\n","      <td>0.6600</td>\n","      <td>1.4300</td>\n","      <td>1.6022</td>\n","      <td>0.6634</td>\n","      <td>0.5965</td>\n","      <td>0.6873</td>\n","      <td>NaN</td>\n","      <td>0.9228</td>\n","      <td>0.8792</td>\n","      <td>2025-04-24 22:22:01</td>\n","    </tr>\n","    <tr>\n","      <th>361</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>24</td>\n","      <td>0.7125</td>\n","      <td>0.6661</td>\n","      <td>1.3954</td>\n","      <td>1.5914</td>\n","      <td>0.6830</td>\n","      <td>0.6079</td>\n","      <td>0.7028</td>\n","      <td>NaN</td>\n","      <td>0.9280</td>\n","      <td>0.8837</td>\n","      <td>2025-04-24 22:22:49</td>\n","    </tr>\n","    <tr>\n","      <th>362</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>25</td>\n","      <td>0.7223</td>\n","      <td>0.6656</td>\n","      <td>1.3841</td>\n","      <td>1.5836</td>\n","      <td>0.6895</td>\n","      <td>0.6089</td>\n","      <td>0.7130</td>\n","      <td>NaN</td>\n","      <td>0.9298</td>\n","      <td>0.8837</td>\n","      <td>2025-04-24 22:23:38</td>\n","    </tr>\n","    <tr>\n","      <th>363</th>\n","      <td>13</td>\n","      <td>eff-net_with_phylum_no_proc_reg</td>\n","      <td>26</td>\n","      <td>0.7223</td>\n","      <td>0.6722</td>\n","      <td>1.3551</td>\n","      <td>1.5768</td>\n","      <td>0.6918</td>\n","      <td>0.6187</td>\n","      <td>0.7130</td>\n","      <td>NaN</td>\n","      <td>0.9345</td>\n","      <td>0.8848</td>\n","      <td>2025-04-24 22:24:32</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d520d6f-8781-4710-a2d4-44679bcb8a0d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9d520d6f-8781-4710-a2d4-44679bcb8a0d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9d520d6f-8781-4710-a2d4-44679bcb8a0d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c322966a-ad53-4af5-9f03-fd19bef3022a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c322966a-ad53-4af5-9f03-fd19bef3022a')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c322966a-ad53-4af5-9f03-fd19bef3022a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_d3110ed9-adac-42c1-aa20-ba3638640d2d\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_latest_experiment')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_d3110ed9-adac-42c1-aa20-ba3638640d2d button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df_latest_experiment');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["     id                  experiment_name  epoch  train_accuracy  val_accuracy  \\\n","338  13  eff-net_with_phylum_no_proc_reg      1          0.0758        0.1859   \n","339  13  eff-net_with_phylum_no_proc_reg      2          0.1946        0.2677   \n","340  13  eff-net_with_phylum_no_proc_reg      3          0.2561        0.3228   \n","341  13  eff-net_with_phylum_no_proc_reg      4          0.3161        0.3767   \n","342  13  eff-net_with_phylum_no_proc_reg      5          0.3619        0.4207   \n","343  13  eff-net_with_phylum_no_proc_reg      6          0.4082        0.4569   \n","344  13  eff-net_with_phylum_no_proc_reg      7          0.4390        0.4975   \n","345  13  eff-net_with_phylum_no_proc_reg      8          0.4704        0.5198   \n","346  13  eff-net_with_phylum_no_proc_reg      9          0.5005        0.5448   \n","347  13  eff-net_with_phylum_no_proc_reg     10          0.5295        0.5559   \n","348  13  eff-net_with_phylum_no_proc_reg     11          0.5429        0.5693   \n","349  13  eff-net_with_phylum_no_proc_reg     12          0.5701        0.5810   \n","350  13  eff-net_with_phylum_no_proc_reg     13          0.5828        0.5960   \n","351  13  eff-net_with_phylum_no_proc_reg     14          0.6008        0.6027   \n","352  13  eff-net_with_phylum_no_proc_reg     15          0.6131        0.6088   \n","353  13  eff-net_with_phylum_no_proc_reg     16          0.6275        0.6199   \n","354  13  eff-net_with_phylum_no_proc_reg     17          0.6511        0.6288   \n","355  13  eff-net_with_phylum_no_proc_reg     18          0.6629        0.6322   \n","356  13  eff-net_with_phylum_no_proc_reg     19          0.6627        0.6427   \n","357  13  eff-net_with_phylum_no_proc_reg     20          0.6785        0.6511   \n","358  13  eff-net_with_phylum_no_proc_reg     21          0.6846        0.6489   \n","359  13  eff-net_with_phylum_no_proc_reg     22          0.6981        0.6533   \n","360  13  eff-net_with_phylum_no_proc_reg     23          0.6993        0.6600   \n","361  13  eff-net_with_phylum_no_proc_reg     24          0.7125        0.6661   \n","362  13  eff-net_with_phylum_no_proc_reg     25          0.7223        0.6656   \n","363  13  eff-net_with_phylum_no_proc_reg     26          0.7223        0.6722   \n","\n","     train_loss  val_loss  f1_train_macro  f1_val_macro  f1_train_weighted  \\\n","338      5.0903    4.6492          0.0179        0.0404             0.0517   \n","339      4.3801    4.0056          0.0511        0.0790             0.1217   \n","340      3.8348    3.5320          0.0835        0.1129             0.1752   \n","341      3.4094    3.1654          0.1357        0.1753             0.2382   \n","342      3.0739    2.8756          0.1827        0.2224             0.2909   \n","343      2.8134    2.6403          0.2343        0.2659             0.3420   \n","344      2.5903    2.4480          0.2774        0.3179             0.3793   \n","345      2.4086    2.2943          0.3282        0.3452             0.4187   \n","346      2.2588    2.1675          0.3767        0.3893             0.4555   \n","347      2.1257    2.0673          0.4149        0.4139             0.4897   \n","348      2.0322    1.9781          0.4406        0.4424             0.5060   \n","349      1.9424    1.9116          0.4758        0.4589             0.5383   \n","350      1.8532    1.8566          0.4981        0.4909             0.5544   \n","351      1.7890    1.8096          0.5252        0.5010             0.5751   \n","352      1.7164    1.7681          0.5449        0.5072             0.5897   \n","353      1.6751    1.7348          0.5699        0.5243             0.6084   \n","354      1.6150    1.7060          0.5940        0.5425             0.6320   \n","355      1.5678    1.6825          0.6157        0.5515             0.6471   \n","356      1.5446    1.6572          0.6187        0.5728             0.6485   \n","357      1.4984    1.6401          0.6364        0.5794             0.6646   \n","358      1.4791    1.6259          0.6432        0.5818             0.6715   \n","359      1.4401    1.6117          0.6637        0.5918             0.6866   \n","360      1.4300    1.6022          0.6634        0.5965             0.6873   \n","361      1.3954    1.5914          0.6830        0.6079             0.7028   \n","362      1.3841    1.5836          0.6895        0.6089             0.7130   \n","363      1.3551    1.5768          0.6918        0.6187             0.7130   \n","\n","     f1_val_weighted  top5_train_accuracy  top5_val_accuracy  \\\n","338              NaN               0.1684             0.3500   \n","339              NaN               0.3587             0.4669   \n","340              NaN               0.4793             0.5654   \n","341              NaN               0.5741             0.6311   \n","342              NaN               0.6369             0.6795   \n","343              NaN               0.6782             0.7151   \n","344              NaN               0.7208             0.7446   \n","345              NaN               0.7577             0.7718   \n","346              NaN               0.7830             0.7974   \n","347              NaN               0.8089             0.8114   \n","348              NaN               0.8222             0.8325   \n","349              NaN               0.8404             0.8386   \n","350              NaN               0.8518             0.8486   \n","351              NaN               0.8656             0.8492   \n","352              NaN               0.8774             0.8587   \n","353              NaN               0.8839             0.8642   \n","354              NaN               0.8907             0.8653   \n","355              NaN               0.9003             0.8676   \n","356              NaN               0.9038             0.8715   \n","357              NaN               0.9097             0.8709   \n","358              NaN               0.9136             0.8737   \n","359              NaN               0.9178             0.8770   \n","360              NaN               0.9228             0.8792   \n","361              NaN               0.9280             0.8837   \n","362              NaN               0.9298             0.8837   \n","363              NaN               0.9345             0.8848   \n","\n","               timestamp  \n","338  2025-04-24 21:58:37  \n","339  2025-04-24 21:59:26  \n","340  2025-04-24 22:00:15  \n","341  2025-04-24 22:01:02  \n","342  2025-04-24 22:01:51  \n","343  2025-04-24 22:02:38  \n","344  2025-04-24 22:03:27  \n","345  2025-04-24 22:04:14  \n","346  2025-04-24 22:05:02  \n","347  2025-04-24 22:05:49  \n","348  2025-04-24 22:06:37  \n","349  2025-04-24 22:07:25  \n","350  2025-04-24 22:08:20  \n","351  2025-04-24 22:14:47  \n","352  2025-04-24 22:15:37  \n","353  2025-04-24 22:16:25  \n","354  2025-04-24 22:17:13  \n","355  2025-04-24 22:18:01  \n","356  2025-04-24 22:18:49  \n","357  2025-04-24 22:19:37  \n","358  2025-04-24 22:20:25  \n","359  2025-04-24 22:21:13  \n","360  2025-04-24 22:22:01  \n","361  2025-04-24 22:22:49  \n","362  2025-04-24 22:23:38  \n","363  2025-04-24 22:24:32  "]},"metadata":{},"output_type":"display_data"}],"source":["# Load the experiment log\n","df = pd.read_csv('experiment_log.csv')\n","\n","# Identify the latest experiment\n","max_id = df['id'].max()### Set-up\n","\n","# Filter the DataFrame to get the latest experiment\n","df_latest_experiment = df[df['id'] == max_id]\n","\n","# Save the latest experiment log to a CSV file\n","# df_latest_experiment.to_csv('phylum_models_results/efficient_net_phylum_3_pre_ft_history.csv', index=False)\n","\n","df_latest_experiment"]},{"cell_type":"markdown","metadata":{"id":"S8DuzZPqsbVS"},"source":["### Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"941xIZAcsbVS","outputId":"56b745f0-8e2e-4a3d-97bb-006d251d6d29"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Evaluating model: efficient_net_finetuned_final.keras\n"]},{"name":"stderr","output_type":"stream","text":["/Users/margaridabravocardoso/venvs/deep_learning_venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 34 variables whereas the saved optimizer has 6 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n","2025-04-24 11:36:30.785988: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n","/Users/margaridabravocardoso/venvs/deep_learning_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/Users/margaridabravocardoso/venvs/deep_learning_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/Users/margaridabravocardoso/venvs/deep_learning_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/Users/margaridabravocardoso/venvs/deep_learning_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0     0.7391    0.9444    0.8293        18\n","           1     0.6429    0.6923    0.6667        13\n","           2     0.6579    0.8065    0.7246        31\n","           3     0.7143    0.5556    0.6250         9\n","           4     0.6364    0.7778    0.7000        18\n","           5     0.6000    0.6000    0.6000         5\n","           6     0.0000    0.0000    0.0000         4\n","           7     0.6667    0.4000    0.5000         5\n","           8     1.0000    0.1111    0.2000         9\n","           9     1.0000    0.3333    0.5000         9\n","          10     0.6364    0.7778    0.7000        27\n","          11     0.7500    0.6667    0.7059         9\n","          12     1.0000    0.5556    0.7143         9\n","          13     1.0000    1.0000    1.0000        22\n","          14     0.7143    0.5556    0.6250         9\n","          15     1.0000    0.5000    0.6667         4\n","          16     0.5909    0.5909    0.5909        22\n","          17     1.0000    0.8000    0.8889         5\n","          18     1.0000    0.5000    0.6667         4\n","          19     0.0000    0.0000    0.0000         5\n","          20     1.0000    0.5000    0.6667         4\n","          21     0.8889    0.8889    0.8889         9\n","          22     1.0000    0.6000    0.7500         5\n","          23     0.6000    0.8333    0.6977        36\n","          24     0.6667    0.4000    0.5000         5\n","          25     0.6512    0.9032    0.7568        31\n","          26     0.7143    0.6818    0.6977        22\n","          27     1.0000    0.6667    0.8000         9\n","          28     0.8000    0.8000    0.8000         5\n","          29     0.7059    0.6667    0.6857        18\n","          30     1.0000    0.4000    0.5714         5\n","          31     1.0000    0.2000    0.3333         5\n","          32     1.0000    0.8889    0.9412         9\n","          33     0.5538    0.9000    0.6857        40\n","          34     0.7000    0.7778    0.7368         9\n","          35     0.6000    0.7500    0.6667         4\n","          36     0.7500    0.6923    0.7200        13\n","          37     1.0000    1.0000    1.0000         4\n","          38     0.6538    0.7556    0.7010        45\n","          39     1.0000    0.2000    0.3333         5\n","          40     0.3333    0.2000    0.2500         5\n","          41     0.8889    0.8889    0.8889         9\n","          42     0.6667    1.0000    0.8000         8\n","          43     0.9000    1.0000    0.9474         9\n","          44     1.0000    0.7500    0.8571         4\n","          45     0.7500    0.7500    0.7500         8\n","          46     0.2000    0.2000    0.2000         5\n","          47     0.4000    0.4000    0.4000         5\n","          48     0.7692    0.7692    0.7692        13\n","          49     0.6667    0.8000    0.7273         5\n","          50     0.6923    0.6923    0.6923        13\n","          51     1.0000    1.0000    1.0000         5\n","          52     1.0000    1.0000    1.0000         5\n","          53     0.7143    0.5556    0.6250         9\n","          54     1.0000    1.0000    1.0000         4\n","          55     0.6364    0.7778    0.7000         9\n","          56     0.3333    0.4444    0.3810         9\n","          57     0.6250    1.0000    0.7692         5\n","          58     0.8000    1.0000    0.8889         4\n","          59     1.0000    0.6000    0.7500         5\n","          60     0.7000    0.7778    0.7368        45\n","          61     0.5000    0.4000    0.4444         5\n","          62     0.5625    0.8182    0.6667        22\n","          63     0.6667    0.5000    0.5714         4\n","          64     1.0000    0.4000    0.5714         5\n","          65     0.5000    0.2000    0.2857         5\n","          66     0.5000    0.7222    0.5909        18\n","          67     1.0000    0.8000    0.8889         5\n","          68     1.0000    0.4000    0.5714         5\n","          69     0.7500    0.7778    0.7636        27\n","          70     0.8000    1.0000    0.8889         4\n","          71     0.5455    0.6667    0.6000         9\n","          72     0.6667    1.0000    0.8000         4\n","          73     0.8000    0.4444    0.5714         9\n","          74     1.0000    0.5000    0.6667         4\n","          75     1.0000    1.0000    1.0000         5\n","          76     0.5714    0.6154    0.5926        13\n","          77     0.5000    0.3333    0.4000         9\n","          78     0.7000    0.7778    0.7368         9\n","          79     0.8571    0.9767    0.9130        43\n","          80     0.7778    0.7778    0.7778         9\n","          81     1.0000    0.8000    0.8889         5\n","          82     1.0000    0.4000    0.5714         5\n","          83     0.8000    1.0000    0.8889         4\n","          84     0.5294    0.6923    0.6000        13\n","          85     1.0000    1.0000    1.0000         4\n","          86     0.5000    0.6000    0.5455         5\n","          87     0.5000    0.4000    0.4444         5\n","          88     1.0000    0.8889    0.9412         9\n","          89     0.6667    1.0000    0.8000         4\n","          90     0.3333    0.2500    0.2857         4\n","          91     0.7500    0.6000    0.6667         5\n","          92     0.3333    0.2500    0.2857         4\n","          93     0.5000    0.2500    0.3333         4\n","          94     0.6667    0.2222    0.3333         9\n","          95     1.0000    1.0000    1.0000         5\n","          96     1.0000    0.7500    0.8571         4\n","          97     0.6667    0.4615    0.5455        13\n","          98     0.0000    0.0000    0.0000         5\n","          99     0.8750    0.7778    0.8235        18\n","         100     1.0000    0.8000    0.8889         5\n","         101     0.6000    0.6667    0.6316         9\n","         102     0.7000    0.7778    0.7368         9\n","         103     0.8000    1.0000    0.8889         4\n","         104     0.8077    0.9545    0.8750        22\n","         105     0.6667    0.5000    0.5714         4\n","         106     0.7778    0.7778    0.7778         9\n","         107     0.8333    0.5556    0.6667         9\n","         108     0.8000    0.8000    0.8000         5\n","         109     1.0000    0.8000    0.8889         5\n","         110     1.0000    0.2000    0.3333         5\n","         111     1.0000    0.5556    0.7143         9\n","         112     1.0000    0.8000    0.8889         5\n","         113     1.0000    0.4000    0.5714         5\n","         114     1.0000    1.0000    1.0000         4\n","         115     0.6667    0.8000    0.7273         5\n","         116     0.3333    0.3333    0.3333         9\n","         117     0.8000    1.0000    0.8889         4\n","         118     0.7500    0.7500    0.7500         4\n","         119     1.0000    0.6000    0.7500         5\n","         120     0.8000    0.8000    0.8000         5\n","         121     0.7273    0.6154    0.6667        13\n","         122     0.5000    0.3077    0.3810        13\n","         123     0.5000    0.8000    0.6154         5\n","         124     1.0000    0.8000    0.8889         5\n","         125     1.0000    1.0000    1.0000         5\n","         126     0.8571    0.6667    0.7500         9\n","         127     1.0000    0.4000    0.5714         5\n","         128     1.0000    0.8000    0.8889         5\n","         129     0.3333    0.2500    0.2857         4\n","         130     1.0000    1.0000    1.0000         4\n","         131     0.8000    0.8000    0.8000         5\n","         132     0.7500    0.7500    0.7500         4\n","         133     0.6000    0.6000    0.6000         5\n","         134     1.0000    1.0000    1.0000         5\n","         135     1.0000    0.8000    0.8889         5\n","         136     1.0000    0.5000    0.6667         4\n","         137     0.7500    0.6000    0.6667         5\n","         138     0.7500    0.7500    0.7500         4\n","         139     0.2500    0.2500    0.2500         4\n","         140     1.0000    1.0000    1.0000         5\n","         141     1.0000    0.4000    0.5714         5\n","         142     0.5763    0.8500    0.6869        40\n","         143     1.0000    1.0000    1.0000         4\n","         144     0.6667    0.4444    0.5333         9\n","         145     0.6667    0.4000    0.5000         5\n","         146     1.0000    0.4000    0.5714         5\n","         147     0.8000    1.0000    0.8889         4\n","         148     0.6667    0.8000    0.7273         5\n","         149     0.6667    0.4000    0.5000         5\n","         150     0.5000    0.3846    0.4348        13\n","         151     0.7500    0.7500    0.7500         4\n","         152     0.6667    0.8889    0.7619        18\n","         153     0.8571    0.6667    0.7500         9\n","         154     1.0000    0.8889    0.9412         9\n","         155     0.7143    0.3846    0.5000        13\n","         156     1.0000    0.8000    0.8889         5\n","         157     0.6667    0.5000    0.5714         4\n","         158     0.5385    0.5385    0.5385        13\n","         159     1.0000    1.0000    1.0000         4\n","         160     0.7000    0.7778    0.7368         9\n","         161     1.0000    0.7500    0.8571         4\n","         162     0.0000    0.0000    0.0000         9\n","         163     0.5082    0.7750    0.6139        40\n","         164     0.3333    0.2000    0.2500         5\n","         165     0.7500    0.6000    0.6667         5\n","         166     0.7143    1.0000    0.8333         5\n","         167     0.8750    0.7778    0.8235         9\n","         168     0.6667    0.8000    0.7273         5\n","         169     0.6667    0.7692    0.7143        13\n","         170     0.6667    0.8000    0.7273         5\n","         171     0.4000    0.5000    0.4444         4\n","         172     1.0000    0.6000    0.7500         5\n","         173     0.6667    0.8000    0.7273         5\n","         174     0.6667    0.6667    0.6667         9\n","         175     0.7000    0.7778    0.7368        18\n","         176     0.0000    0.0000    0.0000        13\n","         177     0.0000    0.0000    0.0000         4\n","         178     1.0000    0.6000    0.7500         5\n","         179     0.7778    0.7778    0.7778         9\n","         180     1.0000    0.4000    0.5714         5\n","         181     1.0000    0.8000    0.8889         5\n","         182     0.7500    0.6667    0.7059         9\n","         183     0.8000    0.8889    0.8421         9\n","         184     0.8000    1.0000    0.8889         4\n","         185     1.0000    1.0000    1.0000         5\n","         186     0.5882    0.7692    0.6667        13\n","         187     0.7500    0.6000    0.6667         5\n","         188     1.0000    0.4000    0.5714         5\n","         189     0.8000    0.9231    0.8571        13\n","         190     1.0000    0.7500    0.8571         4\n","         191     0.6000    0.6000    0.6000         5\n","         192     0.8333    0.5556    0.6667         9\n","         193     0.5294    1.0000    0.6923         9\n","         194     0.4286    0.7500    0.5455         4\n","         195     1.0000    0.7778    0.8750         9\n","         196     0.6000    0.7500    0.6667         4\n","         197     0.5714    0.4444    0.5000         9\n","         198     0.8000    0.8000    0.8000         5\n","         199     0.6000    0.6000    0.6000         5\n","         200     0.5000    0.5000    0.5000         4\n","         201     0.8000    1.0000    0.8889         4\n","\n","    accuracy                         0.7006      1797\n","   macro avg     0.7439    0.6621    0.6770      1797\n","weighted avg     0.7132    0.7006    0.6859      1797\n","\n","Accuracy     : 0.7006121313299944\n","F1 (macro)   : 0.677013335354349\n","Precision    : 0.7438634419993236\n","Recall       : 0.6620633202018337\n","\n","Evaluating model: efficient_net_pre_finetuning_with_label_smoothing_batch_sized_corrected_launching_trying_lr_scheduler.keras\n"]},{"name":"stderr","output_type":"stream","text":["2025-04-24 11:37:04.922697: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n","/Users/margaridabravocardoso/venvs/deep_learning_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/Users/margaridabravocardoso/venvs/deep_learning_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/Users/margaridabravocardoso/venvs/deep_learning_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/Users/margaridabravocardoso/venvs/deep_learning_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0     0.6957    0.8889    0.7805        18\n","           1     0.6429    0.6923    0.6667        13\n","           2     0.6579    0.8065    0.7246        31\n","           3     0.7143    0.5556    0.6250         9\n","           4     0.6364    0.7778    0.7000        18\n","           5     0.5000    0.4000    0.4444         5\n","           6     0.0000    0.0000    0.0000         4\n","           7     0.7500    0.6000    0.6667         5\n","           8     1.0000    0.1111    0.2000         9\n","           9     1.0000    0.2222    0.3636         9\n","          10     0.6250    0.7407    0.6780        27\n","          11     0.7500    0.6667    0.7059         9\n","          12     1.0000    0.5556    0.7143         9\n","          13     1.0000    1.0000    1.0000        22\n","          14     0.7143    0.5556    0.6250         9\n","          15     1.0000    0.5000    0.6667         4\n","          16     0.6087    0.6364    0.6222        22\n","          17     1.0000    0.8000    0.8889         5\n","          18     1.0000    0.5000    0.6667         4\n","          19     0.0000    0.0000    0.0000         5\n","          20     1.0000    0.5000    0.6667         4\n","          21     0.8889    0.8889    0.8889         9\n","          22     0.7500    0.6000    0.6667         5\n","          23     0.6122    0.8333    0.7059        36\n","          24     0.6667    0.4000    0.5000         5\n","          25     0.6744    0.9355    0.7838        31\n","          26     0.7143    0.6818    0.6977        22\n","          27     1.0000    0.6667    0.8000         9\n","          28     0.7500    0.6000    0.6667         5\n","          29     0.6667    0.6667    0.6667        18\n","          30     1.0000    0.4000    0.5714         5\n","          31     1.0000    0.2000    0.3333         5\n","          32     1.0000    0.8889    0.9412         9\n","          33     0.5455    0.9000    0.6792        40\n","          34     0.6667    0.6667    0.6667         9\n","          35     0.6000    0.7500    0.6667         4\n","          36     0.7500    0.6923    0.7200        13\n","          37     1.0000    1.0000    1.0000         4\n","          38     0.6667    0.7556    0.7083        45\n","          39     1.0000    0.2000    0.3333         5\n","          40     0.5000    0.4000    0.4444         5\n","          41     0.8889    0.8889    0.8889         9\n","          42     0.6667    1.0000    0.8000         8\n","          43     0.9000    1.0000    0.9474         9\n","          44     1.0000    0.7500    0.8571         4\n","          45     0.7500    0.7500    0.7500         8\n","          46     0.2000    0.2000    0.2000         5\n","          47     0.3333    0.4000    0.3636         5\n","          48     0.7692    0.7692    0.7692        13\n","          49     0.6667    0.8000    0.7273         5\n","          50     0.6429    0.6923    0.6667        13\n","          51     1.0000    1.0000    1.0000         5\n","          52     1.0000    1.0000    1.0000         5\n","          53     0.8333    0.5556    0.6667         9\n","          54     1.0000    1.0000    1.0000         4\n","          55     0.7000    0.7778    0.7368         9\n","          56     0.2500    0.2222    0.2353         9\n","          57     0.6250    1.0000    0.7692         5\n","          58     0.6667    1.0000    0.8000         4\n","          59     1.0000    0.6000    0.7500         5\n","          60     0.6863    0.7778    0.7292        45\n","          61     0.0000    0.0000    0.0000         5\n","          62     0.5143    0.8182    0.6316        22\n","          63     0.6667    0.5000    0.5714         4\n","          64     1.0000    0.4000    0.5714         5\n","          65     1.0000    0.2000    0.3333         5\n","          66     0.5000    0.7222    0.5909        18\n","          67     1.0000    0.8000    0.8889         5\n","          68     1.0000    0.4000    0.5714         5\n","          69     0.7143    0.7407    0.7273        27\n","          70     0.6667    0.5000    0.5714         4\n","          71     0.5455    0.6667    0.6000         9\n","          72     0.6667    1.0000    0.8000         4\n","          73     0.8000    0.4444    0.5714         9\n","          74     1.0000    0.5000    0.6667         4\n","          75     1.0000    1.0000    1.0000         5\n","          76     0.4706    0.6154    0.5333        13\n","          77     0.5000    0.3333    0.4000         9\n","          78     0.6667    0.6667    0.6667         9\n","          79     0.8400    0.9767    0.9032        43\n","          80     0.7500    0.6667    0.7059         9\n","          81     1.0000    0.8000    0.8889         5\n","          82     1.0000    0.4000    0.5714         5\n","          83     0.6667    1.0000    0.8000         4\n","          84     0.5294    0.6923    0.6000        13\n","          85     1.0000    1.0000    1.0000         4\n","          86     0.5000    0.6000    0.5455         5\n","          87     0.6667    0.4000    0.5000         5\n","          88     1.0000    0.8889    0.9412         9\n","          89     0.5714    1.0000    0.7273         4\n","          90     0.3333    0.2500    0.2857         4\n","          91     0.7500    0.6000    0.6667         5\n","          92     0.3333    0.2500    0.2857         4\n","          93     0.5000    0.2500    0.3333         4\n","          94     0.7500    0.3333    0.4615         9\n","          95     1.0000    1.0000    1.0000         5\n","          96     1.0000    0.7500    0.8571         4\n","          97     0.6667    0.4615    0.5455        13\n","          98     0.0000    0.0000    0.0000         5\n","          99     0.8750    0.7778    0.8235        18\n","         100     1.0000    0.6000    0.7500         5\n","         101     0.6250    0.5556    0.5882         9\n","         102     0.7778    0.7778    0.7778         9\n","         103     0.8000    1.0000    0.8889         4\n","         104     0.7778    0.9545    0.8571        22\n","         105     0.6667    0.5000    0.5714         4\n","         106     0.8750    0.7778    0.8235         9\n","         107     0.8333    0.5556    0.6667         9\n","         108     0.8000    0.8000    0.8000         5\n","         109     1.0000    0.8000    0.8889         5\n","         110     0.5000    0.2000    0.2857         5\n","         111     1.0000    0.5556    0.7143         9\n","         112     1.0000    0.8000    0.8889         5\n","         113     0.5000    0.4000    0.4444         5\n","         114     1.0000    1.0000    1.0000         4\n","         115     0.6667    0.8000    0.7273         5\n","         116     0.3333    0.3333    0.3333         9\n","         117     0.8000    1.0000    0.8889         4\n","         118     0.6000    0.7500    0.6667         4\n","         119     1.0000    0.6000    0.7500         5\n","         120     0.8000    0.8000    0.8000         5\n","         121     0.7273    0.6154    0.6667        13\n","         122     0.5000    0.3077    0.3810        13\n","         123     0.3750    0.6000    0.4615         5\n","         124     1.0000    0.8000    0.8889         5\n","         125     1.0000    1.0000    1.0000         5\n","         126     0.8571    0.6667    0.7500         9\n","         127     1.0000    0.4000    0.5714         5\n","         128     1.0000    0.8000    0.8889         5\n","         129     0.3333    0.2500    0.2857         4\n","         130     1.0000    1.0000    1.0000         4\n","         131     0.8000    0.8000    0.8000         5\n","         132     0.7500    0.7500    0.7500         4\n","         133     0.6000    0.6000    0.6000         5\n","         134     1.0000    1.0000    1.0000         5\n","         135     1.0000    0.8000    0.8889         5\n","         136     1.0000    0.5000    0.6667         4\n","         137     0.7500    0.6000    0.6667         5\n","         138     0.7500    0.7500    0.7500         4\n","         139     0.2500    0.2500    0.2500         4\n","         140     1.0000    1.0000    1.0000         5\n","         141     1.0000    0.4000    0.5714         5\n","         142     0.5789    0.8250    0.6804        40\n","         143     1.0000    0.7500    0.8571         4\n","         144     0.6667    0.4444    0.5333         9\n","         145     0.6667    0.4000    0.5000         5\n","         146     1.0000    0.4000    0.5714         5\n","         147     0.6000    0.7500    0.6667         4\n","         148     0.6667    0.8000    0.7273         5\n","         149     0.6667    0.4000    0.5000         5\n","         150     0.5000    0.3846    0.4348        13\n","         151     0.7500    0.7500    0.7500         4\n","         152     0.5769    0.8333    0.6818        18\n","         153     0.6250    0.5556    0.5882         9\n","         154     1.0000    0.7778    0.8750         9\n","         155     0.5714    0.3077    0.4000        13\n","         156     1.0000    0.8000    0.8889         5\n","         157     0.6667    0.5000    0.5714         4\n","         158     0.5385    0.5385    0.5385        13\n","         159     1.0000    1.0000    1.0000         4\n","         160     0.7000    0.7778    0.7368         9\n","         161     1.0000    0.7500    0.8571         4\n","         162     0.0000    0.0000    0.0000         9\n","         163     0.4844    0.7750    0.5962        40\n","         164     0.3333    0.2000    0.2500         5\n","         165     0.7500    0.6000    0.6667         5\n","         166     0.7143    1.0000    0.8333         5\n","         167     0.7778    0.7778    0.7778         9\n","         168     0.7143    1.0000    0.8333         5\n","         169     0.6250    0.7692    0.6897        13\n","         170     0.8000    0.8000    0.8000         5\n","         171     0.4000    0.5000    0.4444         4\n","         172     1.0000    0.6000    0.7500         5\n","         173     0.6000    0.6000    0.6000         5\n","         174     0.5714    0.4444    0.5000         9\n","         175     0.6667    0.7778    0.7179        18\n","         176     0.0000    0.0000    0.0000        13\n","         177     0.0000    0.0000    0.0000         4\n","         178     1.0000    0.4000    0.5714         5\n","         179     0.7000    0.7778    0.7368         9\n","         180     1.0000    0.4000    0.5714         5\n","         181     1.0000    0.8000    0.8889         5\n","         182     0.7500    0.6667    0.7059         9\n","         183     0.8000    0.8889    0.8421         9\n","         184     0.8000    1.0000    0.8889         4\n","         185     1.0000    1.0000    1.0000         5\n","         186     0.5333    0.6154    0.5714        13\n","         187     0.6000    0.6000    0.6000         5\n","         188     1.0000    0.4000    0.5714         5\n","         189     0.7857    0.8462    0.8148        13\n","         190     1.0000    0.7500    0.8571         4\n","         191     0.6667    0.8000    0.7273         5\n","         192     1.0000    0.5556    0.7143         9\n","         193     0.5294    1.0000    0.6923         9\n","         194     0.4286    0.7500    0.5455         4\n","         195     1.0000    0.8889    0.9412         9\n","         196     0.6000    0.7500    0.6667         4\n","         197     0.5000    0.3333    0.4000         9\n","         198     0.8000    0.8000    0.8000         5\n","         199     0.6000    0.6000    0.6000         5\n","         200     0.5000    0.5000    0.5000         4\n","         201     0.8000    1.0000    0.8889         4\n","\n","    accuracy                         0.6867      1797\n","   macro avg     0.7298    0.6455    0.6609      1797\n","weighted avg     0.7007    0.6867    0.6719      1797\n","\n","Accuracy     : 0.6867000556483027\n","F1 (macro)   : 0.6609235122121856\n","Precision    : 0.72981657704705\n","Recall       : 0.6454728449839232\n","\n","Evaluating model: model_Efficient_net_baseline2_20250423-115426.keras\n"]},{"name":"stderr","output_type":"stream","text":["2025-04-24 11:37:26.793685: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n","/Users/margaridabravocardoso/venvs/deep_learning_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/Users/margaridabravocardoso/venvs/deep_learning_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/Users/margaridabravocardoso/venvs/deep_learning_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/Users/margaridabravocardoso/venvs/deep_learning_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0     0.6296    0.9444    0.7556        18\n","           1     0.5556    0.7692    0.6452        13\n","           2     0.6341    0.8387    0.7222        31\n","           3     0.8000    0.4444    0.5714         9\n","           4     0.5769    0.8333    0.6818        18\n","           5     1.0000    0.2000    0.3333         5\n","           6     0.0000    0.0000    0.0000         4\n","           7     1.0000    0.6000    0.7500         5\n","           8     1.0000    0.1111    0.2000         9\n","           9     1.0000    0.3333    0.5000         9\n","          10     0.5676    0.7778    0.6562        27\n","          11     0.4000    0.6667    0.5000         9\n","          12     1.0000    0.5556    0.7143         9\n","          13     1.0000    0.9545    0.9767        22\n","          14     0.5556    0.5556    0.5556         9\n","          15     1.0000    0.2500    0.4000         4\n","          16     0.5926    0.7273    0.6531        22\n","          17     1.0000    0.8000    0.8889         5\n","          18     1.0000    0.2500    0.4000         4\n","          19     0.0000    0.0000    0.0000         5\n","          20     0.0000    0.0000    0.0000         4\n","          21     0.8000    0.8889    0.8421         9\n","          22     1.0000    0.6000    0.7500         5\n","          23     0.5769    0.8333    0.6818        36\n","          24     0.6667    0.4000    0.5000         5\n","          25     0.6279    0.8710    0.7297        31\n","          26     0.6667    0.6364    0.6512        22\n","          27     1.0000    0.6667    0.8000         9\n","          28     1.0000    0.6000    0.7500         5\n","          29     0.6190    0.7222    0.6667        18\n","          30     1.0000    0.2000    0.3333         5\n","          31     1.0000    0.4000    0.5714         5\n","          32     0.8000    0.8889    0.8421         9\n","          33     0.4684    0.9250    0.6218        40\n","          34     0.6364    0.7778    0.7000         9\n","          35     0.7500    0.7500    0.7500         4\n","          36     0.7143    0.7692    0.7407        13\n","          37     1.0000    0.7500    0.8571         4\n","          38     0.6667    0.7556    0.7083        45\n","          39     0.0000    0.0000    0.0000         5\n","          40     0.0000    0.0000    0.0000         5\n","          41     0.9000    1.0000    0.9474         9\n","          42     0.8889    1.0000    0.9412         8\n","          43     0.8889    0.8889    0.8889         9\n","          44     1.0000    0.7500    0.8571         4\n","          45     0.8571    0.7500    0.8000         8\n","          46     0.0000    0.0000    0.0000         5\n","          47     0.0000    0.0000    0.0000         5\n","          48     0.6250    0.7692    0.6897        13\n","          49     0.5714    0.8000    0.6667         5\n","          50     0.7500    0.6923    0.7200        13\n","          51     1.0000    0.8000    0.8889         5\n","          52     1.0000    1.0000    1.0000         5\n","          53     0.5714    0.4444    0.5000         9\n","          54     1.0000    1.0000    1.0000         4\n","          55     0.5000    0.5556    0.5263         9\n","          56     0.3333    0.1111    0.1667         9\n","          57     0.7500    0.6000    0.6667         5\n","          58     0.6667    0.5000    0.5714         4\n","          59     1.0000    0.4000    0.5714         5\n","          60     0.6923    0.8000    0.7423        45\n","          61     0.0000    0.0000    0.0000         5\n","          62     0.4857    0.7727    0.5965        22\n","          63     0.6667    0.5000    0.5714         4\n","          64     1.0000    0.2000    0.3333         5\n","          65     1.0000    0.2000    0.3333         5\n","          66     0.4815    0.7222    0.5778        18\n","          67     1.0000    0.6000    0.7500         5\n","          68     1.0000    0.2000    0.3333         5\n","          69     0.6774    0.7778    0.7241        27\n","          70     0.5000    0.2500    0.3333         4\n","          71     0.8000    0.8889    0.8421         9\n","          72     0.8000    1.0000    0.8889         4\n","          73     0.4444    0.4444    0.4444         9\n","          74     1.0000    0.5000    0.6667         4\n","          75     1.0000    1.0000    1.0000         5\n","          76     0.5000    0.6923    0.5806        13\n","          77     0.5714    0.4444    0.5000         9\n","          78     0.6000    0.6667    0.6316         9\n","          79     0.7818    1.0000    0.8776        43\n","          80     0.6000    0.6667    0.6316         9\n","          81     1.0000    0.8000    0.8889         5\n","          82     0.0000    0.0000    0.0000         5\n","          83     1.0000    0.5000    0.6667         4\n","          84     0.5000    0.7692    0.6061        13\n","          85     1.0000    0.2500    0.4000         4\n","          86     0.5000    0.4000    0.4444         5\n","          87     1.0000    0.2000    0.3333         5\n","          88     1.0000    1.0000    1.0000         9\n","          89     0.8000    1.0000    0.8889         4\n","          90     0.0000    0.0000    0.0000         4\n","          91     1.0000    0.8000    0.8889         5\n","          92     0.0000    0.0000    0.0000         4\n","          93     0.0000    0.0000    0.0000         4\n","          94     0.2500    0.2222    0.2353         9\n","          95     1.0000    0.8000    0.8889         5\n","          96     1.0000    0.5000    0.6667         4\n","          97     1.0000    0.3846    0.5556        13\n","          98     0.0000    0.0000    0.0000         5\n","          99     0.7368    0.7778    0.7568        18\n","         100     0.7500    0.6000    0.6667         5\n","         101     0.6000    0.6667    0.6316         9\n","         102     0.4375    0.7778    0.5600         9\n","         103     1.0000    0.2500    0.4000         4\n","         104     0.7241    0.9545    0.8235        22\n","         105     1.0000    0.2500    0.4000         4\n","         106     0.7778    0.7778    0.7778         9\n","         107     0.3846    0.5556    0.4545         9\n","         108     0.8000    0.8000    0.8000         5\n","         109     1.0000    0.8000    0.8889         5\n","         110     1.0000    0.2000    0.3333         5\n","         111     0.8000    0.4444    0.5714         9\n","         112     1.0000    0.8000    0.8889         5\n","         113     1.0000    0.4000    0.5714         5\n","         114     1.0000    1.0000    1.0000         4\n","         115     0.6667    0.8000    0.7273         5\n","         116     0.3750    0.3333    0.3529         9\n","         117     0.6667    0.5000    0.5714         4\n","         118     1.0000    0.7500    0.8571         4\n","         119     1.0000    0.8000    0.8889         5\n","         120     0.8000    0.8000    0.8000         5\n","         121     0.6154    0.6154    0.6154        13\n","         122     0.4545    0.3846    0.4167        13\n","         123     0.0000    0.0000    0.0000         5\n","         124     1.0000    0.8000    0.8889         5\n","         125     1.0000    1.0000    1.0000         5\n","         126     0.7143    0.5556    0.6250         9\n","         127     1.0000    0.4000    0.5714         5\n","         128     1.0000    0.8000    0.8889         5\n","         129     1.0000    0.2500    0.4000         4\n","         130     1.0000    1.0000    1.0000         4\n","         131     1.0000    0.2000    0.3333         5\n","         132     0.5000    0.2500    0.3333         4\n","         133     1.0000    0.4000    0.5714         5\n","         134     1.0000    1.0000    1.0000         5\n","         135     1.0000    0.6000    0.7500         5\n","         136     0.0000    0.0000    0.0000         4\n","         137     0.7500    0.6000    0.6667         5\n","         138     1.0000    0.2500    0.4000         4\n","         139     1.0000    0.2500    0.4000         4\n","         140     1.0000    0.8000    0.8889         5\n","         141     1.0000    0.4000    0.5714         5\n","         142     0.5538    0.9000    0.6857        40\n","         143     1.0000    0.7500    0.8571         4\n","         144     0.6000    0.3333    0.4286         9\n","         145     0.5000    0.2000    0.2857         5\n","         146     1.0000    0.4000    0.5714         5\n","         147     1.0000    0.2500    0.4000         4\n","         148     0.5000    0.4000    0.4444         5\n","         149     0.0000    0.0000    0.0000         5\n","         150     0.4444    0.3077    0.3636        13\n","         151     0.6667    0.5000    0.5714         4\n","         152     0.6957    0.8889    0.7805        18\n","         153     0.7778    0.7778    0.7778         9\n","         154     0.7273    0.8889    0.8000         9\n","         155     0.6154    0.6154    0.6154        13\n","         156     1.0000    0.6000    0.7500         5\n","         157     1.0000    0.5000    0.6667         4\n","         158     0.4211    0.6154    0.5000        13\n","         159     1.0000    0.7500    0.8571         4\n","         160     0.7000    0.7778    0.7368         9\n","         161     1.0000    0.5000    0.6667         4\n","         162     0.0000    0.0000    0.0000         9\n","         163     0.5000    0.7750    0.6078        40\n","         164     0.6667    0.4000    0.5000         5\n","         165     1.0000    0.4000    0.5714         5\n","         166     0.6250    1.0000    0.7692         5\n","         167     0.8750    0.7778    0.8235         9\n","         168     0.3333    0.2000    0.2500         5\n","         169     0.6111    0.8462    0.7097        13\n","         170     0.8000    0.8000    0.8000         5\n","         171     1.0000    0.5000    0.6667         4\n","         172     1.0000    0.2000    0.3333         5\n","         173     1.0000    0.6000    0.7500         5\n","         174     0.7273    0.8889    0.8000         9\n","         175     0.7500    0.8333    0.7895        18\n","         176     0.5000    0.2308    0.3158        13\n","         177     0.0000    0.0000    0.0000         4\n","         178     1.0000    0.2000    0.3333         5\n","         179     0.8750    0.7778    0.8235         9\n","         180     1.0000    0.2000    0.3333         5\n","         181     1.0000    0.6000    0.7500         5\n","         182     0.7000    0.7778    0.7368         9\n","         183     0.6923    1.0000    0.8182         9\n","         184     0.8000    1.0000    0.8889         4\n","         185     1.0000    1.0000    1.0000         5\n","         186     0.2759    0.6154    0.3810        13\n","         187     0.7500    0.6000    0.6667         5\n","         188     1.0000    0.4000    0.5714         5\n","         189     0.8571    0.9231    0.8889        13\n","         190     1.0000    0.7500    0.8571         4\n","         191     0.5000    0.2000    0.2857         5\n","         192     0.4545    0.5556    0.5000         9\n","         193     0.5294    1.0000    0.6923         9\n","         194     1.0000    0.5000    0.6667         4\n","         195     1.0000    0.7778    0.8750         9\n","         196     0.7500    0.7500    0.7500         4\n","         197     0.5000    0.3333    0.4000         9\n","         198     0.6667    0.4000    0.5000         5\n","         199     0.5000    0.6000    0.5455         5\n","         200     0.2500    0.2500    0.2500         4\n","         201     0.8000    1.0000    0.8889         4\n","\n","    accuracy                         0.6578      1797\n","   macro avg     0.7144    0.5657    0.5917      1797\n","weighted avg     0.6768    0.6578    0.6319      1797\n","\n","Accuracy     : 0.657762938230384\n","F1 (macro)   : 0.5916760573485877\n","Precision    : 0.7143750003928288\n","Recall       : 0.5657019734231488\n","\n","Evaluating model: model_Efficient_net_baseline1_20250423-104546.keras\n","              precision    recall  f1-score   support\n","\n","           0     0.7273    0.8889    0.8000        18\n","           1     0.4762    0.7692    0.5882        13\n","           2     0.6765    0.7419    0.7077        31\n","           3     0.5000    0.5556    0.5263         9\n","           4     0.6957    0.8889    0.7805        18\n","           5     0.4000    0.4000    0.4000         5\n","           6     0.0000    0.0000    0.0000         4\n","           7     0.4000    0.4000    0.4000         5\n","           8     1.0000    0.3333    0.5000         9\n","           9     0.5556    0.5556    0.5556         9\n","          10     0.6667    0.8148    0.7333        27\n","          11     0.6364    0.7778    0.7000         9\n","          12     0.8750    0.7778    0.8235         9\n","          13     1.0000    1.0000    1.0000        22\n","          14     0.8571    0.6667    0.7500         9\n","          15     1.0000    0.2500    0.4000         4\n","          16     0.8125    0.5909    0.6842        22\n","          17     0.8000    0.8000    0.8000         5\n","          18     1.0000    0.7500    0.8571         4\n","          19     0.0000    0.0000    0.0000         5\n","          20     0.6667    0.5000    0.5714         4\n","          21     0.8000    0.8889    0.8421         9\n","          22     1.0000    0.6000    0.7500         5\n","          23     0.6444    0.8056    0.7160        36\n","          24     0.6667    0.4000    0.5000         5\n","          25     0.7368    0.9032    0.8116        31\n","          26     0.7368    0.6364    0.6829        22\n","          27     1.0000    0.6667    0.8000         9\n","          28     0.6667    0.8000    0.7273         5\n","          29     0.7222    0.7222    0.7222        18\n","          30     0.5000    0.2000    0.2857         5\n","          31     0.5000    0.2000    0.2857         5\n","          32     0.8182    1.0000    0.9000         9\n","          33     0.6078    0.7750    0.6813        40\n","          34     0.7500    0.6667    0.7059         9\n","          35     0.7500    0.7500    0.7500         4\n","          36     0.6000    0.9231    0.7273        13\n","          37     1.0000    1.0000    1.0000         4\n","          38     0.7451    0.8444    0.7917        45\n","          39     1.0000    0.2000    0.3333         5\n","          40     0.6667    0.4000    0.5000         5\n","          41     0.8889    0.8889    0.8889         9\n","          42     0.7273    1.0000    0.8421         8\n","          43     0.8889    0.8889    0.8889         9\n","          44     1.0000    1.0000    1.0000         4\n","          45     0.5455    0.7500    0.6316         8\n","          46     0.2000    0.2000    0.2000         5\n","          47     0.3333    0.4000    0.3636         5\n","          48     0.8462    0.8462    0.8462        13\n","          49     0.6667    0.8000    0.7273         5\n","          50     0.7143    0.7692    0.7407        13\n","          51     1.0000    0.8000    0.8889         5\n","          52     1.0000    1.0000    1.0000         5\n","          53     0.8571    0.6667    0.7500         9\n","          54     1.0000    1.0000    1.0000         4\n","          55     0.5000    0.7778    0.6087         9\n","          56     0.5000    0.3333    0.4000         9\n","          57     0.8000    0.8000    0.8000         5\n","          58     0.7500    0.7500    0.7500         4\n","          59     1.0000    0.6000    0.7500         5\n","          60     0.8500    0.7556    0.8000        45\n","          61     0.5000    0.2000    0.2857         5\n","          62     0.5926    0.7273    0.6531        22\n","          63     0.5000    0.5000    0.5000         4\n","          64     1.0000    0.2000    0.3333         5\n","          65     0.5000    0.4000    0.4444         5\n","          66     0.5789    0.6111    0.5946        18\n","          67     1.0000    0.8000    0.8889         5\n","          68     0.6667    0.4000    0.5000         5\n","          69     0.8000    0.7407    0.7692        27\n","          70     0.5000    0.5000    0.5000         4\n","          71     0.7778    0.7778    0.7778         9\n","          72     0.6667    1.0000    0.8000         4\n","          73     0.3333    0.3333    0.3333         9\n","          74     0.6667    0.5000    0.5714         4\n","          75     1.0000    0.8000    0.8889         5\n","          76     0.6154    0.6154    0.6154        13\n","          77     0.5714    0.4444    0.5000         9\n","          78     0.8750    0.7778    0.8235         9\n","          79     0.9535    0.9535    0.9535        43\n","          80     0.6667    0.8889    0.7619         9\n","          81     0.8000    0.8000    0.8000         5\n","          82     1.0000    0.4000    0.5714         5\n","          83     0.6667    1.0000    0.8000         4\n","          84     0.5263    0.7692    0.6250        13\n","          85     1.0000    0.7500    0.8571         4\n","          86     0.6667    0.8000    0.7273         5\n","          87     0.5000    0.4000    0.4444         5\n","          88     1.0000    1.0000    1.0000         9\n","          89     0.6667    1.0000    0.8000         4\n","          90     0.2500    0.2500    0.2500         4\n","          91     0.7500    0.6000    0.6667         5\n","          92     0.3333    0.2500    0.2857         4\n","          93     1.0000    0.2500    0.4000         4\n","          94     0.3636    0.4444    0.4000         9\n","          95     1.0000    1.0000    1.0000         5\n","          96     1.0000    0.5000    0.6667         4\n","          97     0.7000    0.5385    0.6087        13\n","          98     0.0000    0.0000    0.0000         5\n","          99     0.8824    0.8333    0.8571        18\n","         100     1.0000    0.8000    0.8889         5\n","         101     0.6667    0.6667    0.6667         9\n","         102     0.7000    0.7778    0.7368         9\n","         103     0.5000    0.7500    0.6000         4\n","         104     0.8750    0.9545    0.9130        22\n","         105     0.5000    0.5000    0.5000         4\n","         106     0.6667    0.6667    0.6667         9\n","         107     1.0000    0.5556    0.7143         9\n","         108     1.0000    0.8000    0.8889         5\n","         109     1.0000    0.8000    0.8889         5\n","         110     0.0000    0.0000    0.0000         5\n","         111     0.8333    0.5556    0.6667         9\n","         112     1.0000    0.8000    0.8889         5\n","         113     0.5000    0.4000    0.4444         5\n","         114     0.8000    1.0000    0.8889         4\n","         115     0.7500    0.6000    0.6667         5\n","         116     0.3750    0.3333    0.3529         9\n","         117     0.5000    0.5000    0.5000         4\n","         118     0.6667    0.5000    0.5714         4\n","         119     0.7500    0.6000    0.6667         5\n","         120     0.8000    0.8000    0.8000         5\n","         121     0.6667    0.6154    0.6400        13\n","         122     0.6364    0.5385    0.5833        13\n","         123     0.6000    0.6000    0.6000         5\n","         124     1.0000    0.8000    0.8889         5\n","         125     1.0000    1.0000    1.0000         5\n","         126     0.5833    0.7778    0.6667         9\n","         127     1.0000    0.6000    0.7500         5\n","         128     1.0000    0.8000    0.8889         5\n","         129     1.0000    0.2500    0.4000         4\n","         130     1.0000    1.0000    1.0000         4\n","         131     0.7500    0.6000    0.6667         5\n","         132     0.7500    0.7500    0.7500         4\n","         133     1.0000    0.4000    0.5714         5\n","         134     1.0000    1.0000    1.0000         5\n","         135     0.8000    0.8000    0.8000         5\n","         136     1.0000    0.2500    0.4000         4\n","         137     0.7500    0.6000    0.6667         5\n","         138     1.0000    0.5000    0.6667         4\n","         139     0.7500    0.7500    0.7500         4\n","         140     1.0000    0.8000    0.8889         5\n","         141     0.6667    0.4000    0.5000         5\n","         142     0.6957    0.8000    0.7442        40\n","         143     1.0000    1.0000    1.0000         4\n","         144     0.7500    0.6667    0.7059         9\n","         145     1.0000    0.4000    0.5714         5\n","         146     0.5000    0.2000    0.2857         5\n","         147     0.7500    0.7500    0.7500         4\n","         148     0.5000    0.6000    0.5455         5\n","         149     0.6667    0.4000    0.5000         5\n","         150     0.6923    0.6923    0.6923        13\n","         151     1.0000    0.5000    0.6667         4\n","         152     0.6250    0.8333    0.7143        18\n","         153     0.6364    0.7778    0.7000         9\n","         154     1.0000    0.8889    0.9412         9\n","         155     0.6429    0.6923    0.6667        13\n","         156     1.0000    1.0000    1.0000         5\n","         157     0.4000    0.5000    0.4444         4\n","         158     0.4545    0.7692    0.5714        13\n","         159     0.6000    0.7500    0.6667         4\n","         160     0.6364    0.7778    0.7000         9\n","         161     0.6667    0.5000    0.5714         4\n","         162     0.5000    0.1111    0.1818         9\n","         163     0.6458    0.7750    0.7045        40\n","         164     0.2500    0.2000    0.2222         5\n","         165     1.0000    0.8000    0.8889         5\n","         166     0.8333    1.0000    0.9091         5\n","         167     0.8750    0.7778    0.8235         9\n","         168     0.5000    0.4000    0.4444         5\n","         169     0.6667    0.7692    0.7143        13\n","         170     0.7143    1.0000    0.8333         5\n","         171     0.4000    0.5000    0.4444         4\n","         172     0.6000    0.6000    0.6000         5\n","         173     1.0000    0.4000    0.5714         5\n","         174     0.8750    0.7778    0.8235         9\n","         175     0.7895    0.8333    0.8108        18\n","         176     0.4118    0.5385    0.4667        13\n","         177     0.5000    0.2500    0.3333         4\n","         178     1.0000    0.4000    0.5714         5\n","         179     0.7778    0.7778    0.7778         9\n","         180     1.0000    0.2000    0.3333         5\n","         181     0.8000    0.8000    0.8000         5\n","         182     0.6667    0.6667    0.6667         9\n","         183     0.8889    0.8889    0.8889         9\n","         184     0.8000    1.0000    0.8889         4\n","         185     1.0000    1.0000    1.0000         5\n","         186     0.4348    0.7692    0.5556        13\n","         187     0.8000    0.8000    0.8000         5\n","         188     1.0000    0.4000    0.5714         5\n","         189     0.8000    0.9231    0.8571        13\n","         190     1.0000    0.7500    0.8571         4\n","         191     0.5714    0.8000    0.6667         5\n","         192     0.8000    0.8889    0.8421         9\n","         193     0.6000    1.0000    0.7500         9\n","         194     0.7500    0.7500    0.7500         4\n","         195     1.0000    0.6667    0.8000         9\n","         196     0.6000    0.7500    0.6667         4\n","         197     0.6667    0.4444    0.5333         9\n","         198     0.8000    0.8000    0.8000         5\n","         199     0.6000    0.6000    0.6000         5\n","         200     0.3333    0.5000    0.4000         4\n","         201     1.0000    1.0000    1.0000         4\n","\n","    accuracy                         0.7090      1797\n","   macro avg     0.7272    0.6566    0.6673      1797\n","weighted avg     0.7243    0.7090    0.6996      1797\n","\n","Accuracy     : 0.7089593767390094\n","F1 (macro)   : 0.6673219113404726\n","Precision    : 0.727222718170665\n","Recall       : 0.6565543558799298\n"]},{"name":"stderr","output_type":"stream","text":["2025-04-24 11:37:50.245592: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n","/Users/margaridabravocardoso/venvs/deep_learning_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/Users/margaridabravocardoso/venvs/deep_learning_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/Users/margaridabravocardoso/venvs/deep_learning_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/Users/margaridabravocardoso/venvs/deep_learning_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}],"source":["# get_metric(val_ds_en_pre_ft, \"efficient_net_finetuned_final.keras\")\n","# get_metric(val_ds_en_pre_ft,\"efficient_net_pre_finetuning_with_label_smoothing_batch_sized_corrected_launching_trying_lr_scheduler.keras\")\n","# get_metric(val_ds_en_no_proc_reg, \"model_Efficient_net_baseline2_20250423-115426.keras\")\n","# get_metric(val_ds_en_no_proc_no_reg, \"model_Efficient_net_baseline1_20250423-104546.keras\")\n","# # custom function to include the metrics per class, as well as the precision and recall for error analysis purposes"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["IarMyf8tHE9O","dXv1c3MsHE9X","XbVPhM7gop66","4XH3CS6uop66","LAl_TVzAyiqf","ZO4ln1fYyiqf","YdF4jHxvsbVR","S8DuzZPqsbVS"],"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}