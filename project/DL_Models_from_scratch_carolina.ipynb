{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgalao/deep-learning-project/blob/main/project/DL_Models_from_scratch_carolina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3bjYHBh_0P7"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "# **1.** Environment Setup\n",
        "\n",
        "<div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4eVeTgT_0P8"
      },
      "source": [
        "## 1.1 Connect Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "Yxqw_U7bDfHp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "inRBOfwJCH__"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8eNKnktQ_0P8",
        "outputId": "6a65a67f-c440-4404-9516-4f0db3de7d7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "DKPRL-y9_0P8",
        "outputId": "72243eb7-985e-4465-ce16-5b4929ede157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changed directory to: /content/drive/MyDrive/FACULDADE/mestrado\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# # Change to the directory where project is located\n",
        "# os.chdir('/content/drive/MyDrive/College/MSc/2nd Semester/Deep Learning/project')\n",
        "\n",
        "# Change to the directory where project is located\n",
        "os.chdir('/content/drive/MyDrive/FACULDADE/mestrado/')\n",
        "\n",
        "# # Verify that we changed the directory\n",
        "print(\"Changed directory to:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkAMUAzd_0P9"
      },
      "source": [
        "## 1.2 Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras_cv"
      ],
      "metadata": {
        "id": "UBenYuNIAH9P",
        "outputId": "2bafe608-d74b-4deb-8d26-42b51e1b5494",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras_cv in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras_cv) (24.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras_cv) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from keras_cv) (2024.11.6)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (from keras_cv) (4.9.8)\n",
            "Requirement already satisfied: keras-core in /usr/local/lib/python3.11/dist-packages (from keras_cv) (0.1.7)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from keras_cv) (0.3.11)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras_cv) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras_cv) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras_cv) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras-core->keras_cv) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras-core->keras_cv) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras-core->keras_cv) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras-core->keras_cv) (3.13.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from keras-core->keras_cv) (0.1.9)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (0.7.1)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (1.12.2)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (4.2.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (5.29.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (18.1.0)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (1.17.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (3.0.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (0.10.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (1.17.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (0.8.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (6.5.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (4.13.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_cv) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_cv) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_cv) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_cv) (2025.1.31)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->keras-core->keras_cv) (25.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from promise->tensorflow-datasets->keras_cv) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-core->keras_cv) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-core->keras_cv) (2.18.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple_parsing->tensorflow-datasets->keras_cv) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras_cv) (1.70.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras_cv) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "agKI1Ihd_0P9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "from classes import *\n",
        "from functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "f83iix03_0P9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Dropout, Input, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from keras.metrics import AUC, F1Score, CategoricalAccuracy, TopKCategoricalAccuracy\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from keras import optimizers\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D,\n",
        "                                     Dense, Dropout, Concatenate, BatchNormalization)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import tensorflow.keras.backend as K\n",
        "import gc\n",
        "from tensorflow.keras.layers import ReLU\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYIGXzBp_0P9"
      },
      "source": [
        "## 1.3 Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "7_AQhPw1_0P-"
      },
      "outputs": [],
      "source": [
        "# #Load the DataFrames from the .pkl files\n",
        "# with open(\"../data/train_df.pkl\", \"rb\") as f:\n",
        "#      train_df = pickle.load(f)\n",
        "\n",
        "# with open(\"../data/val_df.pkl\", \"rb\") as f:\n",
        "#      val_df = pickle.load(f)\n",
        "\n",
        "# with open(\"../data/test_df.pkl\", \"rb\") as f:\n",
        "#      test_df = pickle.load(f)\n",
        "\n",
        "# with open(\"../data/train_df_sampled.pkl\", \"rb\") as f:\n",
        "#      train_df_sampled = pickle.load(f)\n",
        "\n",
        "# with open(\"../data/family_encoder.pkl\", \"rb\") as f:\n",
        "#      family_encoder = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR COLLAB\n",
        "# Load the DataFrames from the .pkl files\n",
        "with open(\"data/train_df.pkl\", \"rb\") as f:\n",
        "     train_df = pickle.load(f)\n",
        "\n",
        "with open(\"data/val_df.pkl\", \"rb\") as f:\n",
        "     val_df = pickle.load(f)\n",
        "\n",
        "with open(\"data/test_df.pkl\", \"rb\") as f:\n",
        "     test_df = pickle.load(f)\n",
        "\n",
        "with open(\"data/train_df_sampled.pkl\", \"rb\") as f:\n",
        "     train_df_sampled = pickle.load(f)\n",
        "\n",
        "with open(\"data/family_encoder.pkl\", \"rb\") as f:\n",
        "     family_encoder = pickle.load(f)"
      ],
      "metadata": {
        "id": "HIZBjHq-A4oZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZODkTZPw_0P-"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "# **2.** Preprocessing\n",
        "\n",
        "<div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddZt7EeY_0P-"
      },
      "source": [
        "- Normalizes pixel values (e.g., rescaling from [0,255] to [0,1]).\n",
        "- Resizes images to a fixed size (e.g., 224x224 pixels).\n",
        "- Applies augmentation (only during training).\n",
        "- Converts images to batches (e.g., batch_size=32 loads 32 images at a time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Z81TS63u_0P-"
      },
      "outputs": [],
      "source": [
        "minority_class = train_df['family'].value_counts()[train_df['family'].value_counts() < 25].index\n",
        "minority_class=minority_class.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "XymCw7-D_0P-"
      },
      "outputs": [],
      "source": [
        "# batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "# image_size = (224, 224)\n",
        "\n",
        "# preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment='medium', oversampling=True, shuffle=True)\n",
        "# train_ds_sampled, class_names = preprocess.load_img(data_dir=\"data/rare_species/train_sampled\", minority_class=minority_class, augment='medium', oversampling=True, shuffle=True)\n",
        "# val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "# test_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/test\", minority_class=minority_class, augment=None, oversampling=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "aSj2ljMl_0P-"
      },
      "outputs": [],
      "source": [
        "# num_images = 32 ##\n",
        "# rows, cols = 8, 4 ##\n",
        "\n",
        "# plot_batch(train_ds, class_names=class_names, num_images=num_images, rows=rows, cols=cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqN0S9Vx_0P-"
      },
      "source": [
        "## (augmentations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "twyFsEKG_0P_"
      },
      "outputs": [],
      "source": [
        "# augmentations_to_test = [\n",
        "#     # \"none\",\n",
        "#     # \"light\",\n",
        "#     # \"medium\",\n",
        "#     # \"heavy\",\n",
        "#     # \"grayscale\",\n",
        "#     # \"randaugment\",\n",
        "#     \"mixup\",\n",
        "#     \"cutmix\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrMH2Fd4_0P_"
      },
      "source": [
        "<!-- ##### Simple model do test augmentations -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "PVH2ESr8_0P_"
      },
      "outputs": [],
      "source": [
        "# def build_model(num_classes):\n",
        "#     base = keras.applications.EfficientNetB0(\n",
        "#         input_shape=(224, 224, 3),\n",
        "#         include_top=False,\n",
        "#         weights=\"imagenet\",\n",
        "#         pooling=\"avg\"\n",
        "#     )\n",
        "#     base.trainable = False  # You can fine-tune later\n",
        "\n",
        "#     inputs = keras.Input(shape=(224, 224, 3))\n",
        "#     x = base(inputs, training=False)\n",
        "#     x = keras.layers.Dropout(0.2)(x)\n",
        "#     outputs = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "#     return keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "_rzVdlX-_0P_"
      },
      "outputs": [],
      "source": [
        "# def sample_dataset(dataset, fraction=None, num_batches=None, seed=42):\n",
        "#     \"\"\"Return a sampled subset of the dataset.\"\"\"\n",
        "#     if fraction:\n",
        "#         dataset = dataset.shuffle(1000, seed=seed)\n",
        "#         dataset = dataset.take(int(fraction * tf.data.experimental.cardinality(dataset).numpy()))\n",
        "#     elif num_batches:\n",
        "#         dataset = dataset.take(num_batches)\n",
        "#     return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o84WT0Dp_0P_"
      },
      "source": [
        "<!-- ##### Loop -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "RW-Wj9Ek_0P_"
      },
      "outputs": [],
      "source": [
        "# # Initialize the preprocessor\n",
        "# pre = Preprocessor(image_size=(224, 224), batch_size=32)\n",
        "\n",
        "# # Store results\n",
        "# results = {}\n",
        "\n",
        "# # Loop through each augmentation\n",
        "# for aug in augmentations_to_test:\n",
        "#     print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "#     # Load datasets\n",
        "#     train_ds, class_names = pre.load_img(\n",
        "#         data_dir=\"../data/rare_species/train\",\n",
        "#         augment=aug\n",
        "#     )\n",
        "\n",
        "#     val_ds, _ = pre.load_img(\n",
        "#         data_dir=\"../data/rare_species/val\",\n",
        "#         augment=None\n",
        "#     )\n",
        "\n",
        "#     # Sample a subset of training data\n",
        "#     train_ds = sample_dataset(train_ds, fraction=0.5)\n",
        "\n",
        "#     # Build a fresh model (you should define this function)\n",
        "#     model = build_sequential_model(list_of_layers=layers)\n",
        "\n",
        "#     # Compile\n",
        "#     model.compile(\n",
        "#         optimizer=\"adam\",\n",
        "#         loss=\"categorical_crossentropy\",\n",
        "#         metrics=[\"accuracy\"]\n",
        "#     )\n",
        "\n",
        "#     # Train\n",
        "#     history = model.fit(\n",
        "#         train_ds,\n",
        "#         validation_data=val_ds,\n",
        "#         epochs=5,\n",
        "#         verbose=1\n",
        "#     )\n",
        "\n",
        "#     # Predict entire validation set at once\n",
        "#     preds = model.predict(val_ds)\n",
        "#     y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "#     # Extract true labels in order\n",
        "#     y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "#     # Compute metrics\n",
        "#     f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "#     f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "#     precision = precision_score(y_true, y_pred, average='weighted')\n",
        "#     recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "#     # Store in results\n",
        "#     results[aug] = {\n",
        "#         \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "#         \"f1_macro\": f1_macro,\n",
        "#         \"f1_weighted\": f1_weighted,\n",
        "#         \"precision\": precision,\n",
        "#         \"recall\": recall\n",
        "#     }\n",
        "\n",
        "#     print(f\"Finished '{aug}'\")\n",
        "#     print(f\"  Accuracy:      {results[aug]['val_accuracy']:.4f}\")\n",
        "#     print(f\"  F1 (macro):    {results[aug]['f1_macro']:.4f}\")\n",
        "#     print(f\"  F1 (weighted): {results[aug]['f1_weighted']:.4f}\")\n",
        "#     print(f\"  Precision:     {results[aug]['precision']:.4f}\")\n",
        "#     print(f\"  Recall:        {results[aug]['recall']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ZqLt45IX_0P_"
      },
      "outputs": [],
      "source": [
        "# augmentations_to_test = [\n",
        "#     \"none\",\n",
        "#     \"light\",\n",
        "#     \"medium\",\n",
        "#     \"heavy\",\n",
        "#     \"grayscale\",\n",
        "#     \"randaugment\",\n",
        "#     \"mixup\",\n",
        "#     \"cutmix\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "V8kfR66V_0P_"
      },
      "outputs": [],
      "source": [
        "# # Initialize the preprocessor\n",
        "# pre = Preprocessor(image_size=(224, 224), batch_size=32)\n",
        "\n",
        "# # Store results\n",
        "# results = {}\n",
        "\n",
        "# # Loop through each augmentation\n",
        "# for aug in augmentations_to_test:\n",
        "#     print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "#     # Load datasets\n",
        "#     train_ds, class_names = pre.load_img(\n",
        "#         data_dir=\"../data/rare_species/train\",\n",
        "#         augment=aug\n",
        "#     )\n",
        "\n",
        "#     val_ds, _ = pre.load_img(\n",
        "#         data_dir=\"../data/rare_species/val\",\n",
        "#         augment=None\n",
        "#     )\n",
        "\n",
        "#     # Sample a subset of training data\n",
        "#     train_ds = sample_dataset(train_ds, fraction=0.5)\n",
        "\n",
        "#     # Build a fresh model (you should define this function)\n",
        "#     model = build_sequential_model(list_of_layers=layers)\n",
        "\n",
        "#     # Compile\n",
        "#     model.compile(\n",
        "#         optimizer=\"adam\",\n",
        "#         loss=\"categorical_crossentropy\",\n",
        "#         metrics=[\"accuracy\"]\n",
        "#     )\n",
        "\n",
        "#     # Train\n",
        "#     history = model.fit(\n",
        "#         train_ds,\n",
        "#         validation_data=val_ds,\n",
        "#         epochs=15,\n",
        "#         verbose=1\n",
        "#     )\n",
        "\n",
        "#     # Predict entire validation set at once\n",
        "#     preds = model.predict(val_ds)\n",
        "#     y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "#     # Extract true labels in order\n",
        "#     y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "#     # Compute metrics\n",
        "#     f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "#     f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "#     precision = precision_score(y_true, y_pred, average='weighted')\n",
        "#     recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "#     # Store in results\n",
        "#     results[aug] = {\n",
        "#         \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "#         \"f1_macro\": f1_macro,\n",
        "#         \"f1_weighted\": f1_weighted,\n",
        "#         \"precision\": precision,\n",
        "#         \"recall\": recall\n",
        "#     }\n",
        "\n",
        "#     print(f\"Finished '{aug}'\")\n",
        "#     print(f\"  Accuracy:      {results[aug]['val_accuracy']:.4f}\")\n",
        "#     print(f\"  F1 (macro):    {results[aug]['f1_macro']:.4f}\")\n",
        "#     print(f\"  F1 (weighted): {results[aug]['f1_weighted']:.4f}\")\n",
        "#     print(f\"  Precision:     {results[aug]['precision']:.4f}\")\n",
        "#     print(f\"  Recall:        {results[aug]['recall']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1yrcIQb_0P_"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "# **3.** Parameters\n",
        "\n",
        "<div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "3GDURq8Z_0P_"
      },
      "outputs": [],
      "source": [
        "# Add callbacks\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    )\n",
        "    ,EarlyStopping(patience=7, restore_best_weights=True, monitor=\"val_loss\", verbose=1)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "AQPZikTL_0QA"
      },
      "outputs": [],
      "source": [
        "metrics = [\n",
        "    CategoricalAccuracy(name=\"accuracy\"),\n",
        "    AUC(name=\"auc\"),\n",
        "    F1Score(average=\"macro\", name=\"f1_macro\"),\n",
        "    F1Score(average=\"weighted\", name=\"f1_weighted\"),\n",
        "    TopKCategoricalAccuracy(k=5, name=\"top5_accuracy\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "S7H9evt8_0QA"
      },
      "outputs": [],
      "source": [
        "augmentations_to_test = [\n",
        "    \"none\",\n",
        "    \"light\",\n",
        "    \"mixup\"\n",
        "    \"medium\",\n",
        "    \"heavy\",\n",
        "    \"grayscale_plus\",\n",
        "    \"randaugment\",\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGIiWxn__0QA"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "# **4.** Models\n",
        "\n",
        "<div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Y9HttOig_0QA",
        "outputId": "b29bbfb5-a92a-4af3-9a97-478c14b0910a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │        \u001b[38;5;34m34,944\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │           \u001b[38;5;34m384\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m614,656\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │       \u001b[38;5;34m885,120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,327,488\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m884,992\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6400\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m26,218,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m16,781,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m202\u001b[0m)            │       \u001b[38;5;34m827,594\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">34,944</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">614,656</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">885,120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,327,488</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">884,992</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">26,218,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">827,594</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m47,576,010\u001b[0m (181.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,576,010</span> (181.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m47,575,306\u001b[0m (181.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,575,306</span> (181.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def build_alexnet(input_shape=(224, 224, 3), num_classes=202):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer 1\n",
        "    model.add(Conv2D(96, (11, 11), strides=4, activation='relu', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
        "\n",
        "    # Layer 2\n",
        "    model.add(Conv2D(256, (5, 5), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
        "\n",
        "    # Layer 3\n",
        "    model.add(Conv2D(384, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "    # Layer 4\n",
        "    model.add(Conv2D(384, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "    # Layer 5\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
        "\n",
        "    # Flatten and FC\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_alexnet()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1FL-tGd_0QA"
      },
      "source": [
        "## 4.2 AlexNet - No oversampling\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the preprocessor\n",
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Loop through each augmentation\n",
        "for aug in augmentations_to_test:\n",
        "    print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "    model = build_alexnet()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "    if aug==\"grayscale_plus\":\n",
        "      val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment='grayscale', oversampling=False)\n",
        "    else:\n",
        "      val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "    # Initialize the experiment\n",
        "    experiment = Experiment(\n",
        "        model=model,\n",
        "        train_ds=train_ds,\n",
        "        val_ds=val_ds,\n",
        "        experiment_name=f\"alexnet_with_{aug}_no_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "        batch_size=32,\n",
        "        image_size=(224, 224),\n",
        "        save_model = False\n",
        "    )\n",
        "\n",
        "    # Run the experiment\n",
        "    history = experiment.run_experiment(callbacks=callbacks, epochs=1)\n",
        "\n",
        "    # Predict entire validation set at once\n",
        "    preds = model.predict(val_ds)\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Extract true labels in order\n",
        "    y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "    # Compute metrics\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Store in results\n",
        "    train_eval = model.evaluate(train_ds, verbose=0)\n",
        "    val_eval = model.evaluate(val_ds, verbose=0)\n",
        "\n",
        "    metric_names = [\"loss\", \"accuracy\", \"auc\", \"f1_macro\", \"f1_weighted\", \"top5_accuracy\"]\n",
        "\n",
        "    train_metrics = dict(zip(metric_names, train_eval))\n",
        "    val_metrics = dict(zip(metric_names, val_eval))\n",
        "\n",
        "    # Results\n",
        "    results[aug] = {\n",
        "        \"train_loss\": train_metrics[\"loss\"],\n",
        "        \"val_loss\": val_metrics[\"loss\"],\n",
        "\n",
        "        \"train_accuracy\": train_metrics[\"accuracy\"],\n",
        "        \"val_accuracy\": val_metrics[\"accuracy\"],\n",
        "\n",
        "        \"train_f1_macro\": train_metrics.get(\"f1_macro\"),\n",
        "        \"val_f1_macro\": val_metrics.get(\"f1_macro\"),\n",
        "\n",
        "        \"val_f1_weighted\": val_metrics.get(\"f1_weighted\")\n",
        "    }"
      ],
      "metadata": {
        "id": "HnaM4e1njKJp",
        "outputId": "12ea7d49-0ec8-493e-8075-6cddbdcb0952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: none\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "\u001b[1m 97/263\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:59\u001b[0m 1s/step - accuracy: 0.0266 - auc: 0.6103 - f1_macro: 0.0020 - f1_weighted: 0.0092 - loss: 6.1449 - top5_accuracy: 0.0960"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-c2008ee6a274>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Run the experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Predict entire validation set at once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/FACULDADE/mestrado/classes.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, epochs, callbacks)\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         history = self.model.fit(\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# Display the table\n",
        "display(results_df.round(4))\n"
      ],
      "metadata": {
        "id": "QRO3OpRbkN8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melt the DataFrame for seaborn plotting\n",
        "metrics_to_plot = ['train_accuracy', 'val_accuracy']\n",
        "melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "                            var_name='metric', value_name='value')\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "plt.title(\"Comparison of Accuracy Across Augmentation Strategies\")\n",
        "plt.ylim(0, 0.4)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MRXufZX6kPMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1U6g861_0QB"
      },
      "outputs": [],
      "source": [
        "# # Initialize the preprocessor\n",
        "# batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "# image_size = (224, 224)\n",
        "\n",
        "# preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# # Store results\n",
        "# results = {}\n",
        "\n",
        "# # Loop through each augmentation\n",
        "# for aug in augmentations_to_test:\n",
        "#     print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "#     model = build_alexnet()\n",
        "\n",
        "#     model.compile(\n",
        "#         optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "#         loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "#         metrics=metrics\n",
        "#     )\n",
        "\n",
        "#     train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "#     train_ds_sampled, class_names = preprocess.load_img(data_dir=\"data/rare_species/train_sampled\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "#     val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "#     test_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/test\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "\n",
        "#     # Initialize the experiment\n",
        "#     experiment = Experiment(\n",
        "#         model=model,\n",
        "#         train_ds=train_ds_sampled,\n",
        "#         val_ds=val_ds,\n",
        "#         experiment_name=f\"alexnet_with_{aug}_no_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "#         batch_size=32,\n",
        "#         image_size=(224, 224),\n",
        "#         resume=False,\n",
        "#         save_model = False\n",
        "#     )\n",
        "\n",
        "#     # Run the experiment\n",
        "#     history = experiment.run_experiment(callbacks=callbacks, epochs=40)\n",
        "\n",
        "#     # Predict entire validation set at once\n",
        "#     preds = model.predict(val_ds)\n",
        "#     y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "#     # Extract true labels in order\n",
        "#     y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "#     # Compute metrics\n",
        "#     f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "#     f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "#     precision = precision_score(y_true, y_pred, average='weighted')\n",
        "#     recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "#     # Store in results\n",
        "#     results[aug] = {\n",
        "#         \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "#         \"f1_macro\": f1_macro,\n",
        "#         \"f1_weighted\": f1_weighted,\n",
        "#         \"precision\": precision,\n",
        "#         \"recall\": recall\n",
        "#     }\n",
        "\n",
        "#     print(f\"Finished '{aug}'\")\n",
        "#     print(f\"  Accuracy:      {results[aug]['accuracy']:.4f}\")\n",
        "#     print(f\"  F1 (macro):    {results[aug]['f1_macro']:.4f}\")\n",
        "#     print(f\"  F1 (weighted): {results[aug]['f1_weighted']:.4f}\")\n",
        "#     print(f\"  Precision:     {results[aug]['precision']:.4f}\")\n",
        "#     print(f\"  Recall:        {results[aug]['recall']:.4f}\")\n",
        "\n",
        "\n",
        "#     # Clear memory to avoid OOM\n",
        "#     del model\n",
        "#     del experiment\n",
        "#     K.clear_session()\n",
        "#     gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mB8LVp0f_0QB"
      },
      "outputs": [],
      "source": [
        "# # Convert results to a DataFrame\n",
        "# results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "# results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# # Display the table\n",
        "# display(results_df.round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRsSJqtR_0QB"
      },
      "outputs": [],
      "source": [
        "# # Melt the DataFrame for seaborn plotting\n",
        "# metrics_to_plot = ['accuracy', 'f1_macro', 'f1_weighted', 'precision', 'recall']\n",
        "# melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "#                             var_name='metric', value_name='value')\n",
        "\n",
        "# # Plot using seaborn\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "# plt.title(\"Comparison of Metrics Across Augmentation Strategies\")\n",
        "# plt.ylim(0, 0.4)\n",
        "# plt.xticks(rotation=45)\n",
        "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AlexNet with oversampling"
      ],
      "metadata": {
        "id": "tQjmkS3knO0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the preprocessor\n",
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Loop through each augmentation\n",
        "for aug in augmentations_to_test:\n",
        "    print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "    model = build_alexnet()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=True, shuffle=True)\n",
        "    if aug==\"grayscale_plus\":\n",
        "      val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment='grayscale', oversampling=False)\n",
        "    else:\n",
        "      val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "    # Initialize the experiment\n",
        "    experiment = Experiment(\n",
        "        model=model,\n",
        "        train_ds=train_ds,\n",
        "        val_ds=val_ds,\n",
        "        experiment_name=f\"alexnet_with_{aug}_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "        batch_size=32,\n",
        "        image_size=(224, 224),\n",
        "        save_model = False\n",
        "    )\n",
        "\n",
        "    # Run the experiment\n",
        "    history = experiment.run_experiment(callbacks=callbacks, epochs=1)\n",
        "\n",
        "    # Predict entire validation set at once\n",
        "    preds = model.predict(val_ds)\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Extract true labels in order\n",
        "    y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "    # Compute metrics\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Store in results\n",
        "    train_eval = model.evaluate(train_ds, verbose=0)\n",
        "    val_eval = model.evaluate(val_ds, verbose=0)\n",
        "\n",
        "    metric_names = [\"loss\", \"accuracy\", \"auc\", \"f1_macro\", \"f1_weighted\", \"top5_accuracy\"]\n",
        "\n",
        "    train_metrics = dict(zip(metric_names, train_eval))\n",
        "    val_metrics = dict(zip(metric_names, val_eval))\n",
        "\n",
        "    # Results\n",
        "    results[aug] = {\n",
        "        \"train_loss\": train_metrics[\"loss\"],\n",
        "        \"val_loss\": val_metrics[\"loss\"],\n",
        "\n",
        "        \"train_accuracy\": train_metrics[\"accuracy\"],\n",
        "        \"val_accuracy\": val_metrics[\"accuracy\"],\n",
        "\n",
        "        \"train_f1_macro\": train_metrics.get(\"f1_macro\"),\n",
        "        \"val_f1_macro\": val_metrics.get(\"f1_macro\"),\n",
        "\n",
        "        \"val_f1_weighted\": val_metrics.get(\"f1_weighted\")\n",
        "    }"
      ],
      "metadata": {
        "id": "0q8rqZgRnSHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhI2UMVt_0QB"
      },
      "source": [
        "## 4.3 ZF net - No oversampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud-PuFlY_0QB"
      },
      "source": [
        "It’s very similar to AlexNet but with:\n",
        "\n",
        "Smaller initial filters (7×7 instead of 11×11),\n",
        "Smaller strides,\n",
        "Overall more fine-grained feature extraction early on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z39N7eUo_0QB",
        "outputId": "505ad2e2-c070-45cb-b57b-668c9300d6b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m14,208\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │           \u001b[38;5;34m384\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m614,656\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │       \u001b[38;5;34m885,120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,327,488\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m884,992\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36864\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │   \u001b[38;5;34m150,999,040\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m16,781,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m202\u001b[0m)            │       \u001b[38;5;34m827,594\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,208</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">614,656</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">885,120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,327,488</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">884,992</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36864</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │   <span style=\"color: #00af00; text-decoration-color: #00af00\">150,999,040</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">827,594</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m172,335,818\u001b[0m (657.41 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">172,335,818</span> (657.41 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m172,335,114\u001b[0m (657.41 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">172,335,114</span> (657.41 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def build_zfnet(input_shape=(224, 224, 3), num_classes=202):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Conv Layer 1\n",
        "    model.add(Conv2D(96, (7, 7), strides=2, activation='relu', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
        "\n",
        "    # Conv Layer 2\n",
        "    model.add(Conv2D(256, (5, 5), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
        "\n",
        "    # Conv Layer 3\n",
        "    model.add(Conv2D(384, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "    # Conv Layer 4\n",
        "    model.add(Conv2D(384, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "    # Conv Layer 5\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
        "\n",
        "    # Fully connected layers\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(1e-4)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(1e-4)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_zfnet()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yvxMRqF4ljNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyWCYHW4_0QF",
        "outputId": "9d954fe0-ea98-4b3f-b76c-f4fc491e5e81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: none\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 4194 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Found 749 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 214ms/step - accuracy: 0.0188 - auc: 0.6032 - f1_macro: 0.0014 - f1_weighted: 0.0037 - loss: 46128.8281 - top5_accuracy: 0.2542 - val_accuracy: 0.0223 - val_auc: 0.6408 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 23.2046 - val_top5_accuracy: 0.1018 - learning_rate: 0.0100\n",
            "Epoch 2/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.0172 - auc: 0.6285 - f1_macro: 1.7005e-04 - f1_weighted: 6.5081e-04 - loss: 43.2986 - top5_accuracy: 0.0966 - val_accuracy: 0.0223 - val_auc: 0.6604 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 18.2397 - val_top5_accuracy: 0.1096 - learning_rate: 0.0100\n",
            "Epoch 3/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.0173 - auc: 0.6460 - f1_macro: 4.7024e-04 - f1_weighted: 7.9752e-04 - loss: 28.8078 - top5_accuracy: 0.1047 - val_accuracy: 0.0223 - val_auc: 0.6640 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 16.6997 - val_top5_accuracy: 0.1163 - learning_rate: 0.0100\n",
            "Epoch 4/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.0170 - auc: 0.6388 - f1_macro: 4.3936e-04 - f1_weighted: 0.0015 - loss: 43.0560 - top5_accuracy: 0.1178 - val_accuracy: 0.0223 - val_auc: 0.6601 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 15.9907 - val_top5_accuracy: 0.1163 - learning_rate: 0.0100\n",
            "Epoch 5/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.0204 - auc: 0.6298 - f1_macro: 3.7757e-04 - f1_weighted: 0.0018 - loss: 28.2781 - top5_accuracy: 0.1115 - val_accuracy: 0.0250 - val_auc: 0.6581 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 15.5407 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 6/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0239 - auc: 0.6306 - f1_macro: 4.1763e-04 - f1_weighted: 0.0020 - loss: 21.7756 - top5_accuracy: 0.1125 - val_accuracy: 0.0250 - val_auc: 0.6546 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 15.1927 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 7/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0242 - auc: 0.6317 - f1_macro: 4.2228e-04 - f1_weighted: 0.0021 - loss: 16.9412 - top5_accuracy: 0.1099 - val_accuracy: 0.0250 - val_auc: 0.6551 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 14.8954 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 8/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.0219 - auc: 0.6312 - f1_macro: 4.1950e-04 - f1_weighted: 0.0020 - loss: 20.0563 - top5_accuracy: 0.1092 - val_accuracy: 0.0250 - val_auc: 0.6552 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 14.6285 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 9/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.0208 - auc: 0.6311 - f1_macro: 4.4150e-04 - f1_weighted: 0.0020 - loss: 16.8485 - top5_accuracy: 0.1085 - val_accuracy: 0.0250 - val_auc: 0.6547 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 14.3810 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 10/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.0198 - auc: 0.6320 - f1_macro: 3.3804e-04 - f1_weighted: 0.0015 - loss: 19.6521 - top5_accuracy: 0.1108 - val_accuracy: 0.0250 - val_auc: 0.6547 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 14.1494 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 11/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.0205 - auc: 0.6316 - f1_macro: 3.3072e-04 - f1_weighted: 0.0015 - loss: 16.1916 - top5_accuracy: 0.1090 - val_accuracy: 0.0250 - val_auc: 0.6547 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 13.9304 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 12/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.0205 - auc: 0.6317 - f1_macro: 3.3071e-04 - f1_weighted: 0.0015 - loss: 15.4740 - top5_accuracy: 0.1084 - val_accuracy: 0.0250 - val_auc: 0.6547 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 13.7225 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 13/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.0213 - auc: 0.6325 - f1_macro: 3.5205e-04 - f1_weighted: 0.0016 - loss: 15.4713 - top5_accuracy: 0.1077 - val_accuracy: 0.0250 - val_auc: 0.6547 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 13.5241 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 14/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0213 - auc: 0.6323 - f1_macro: 3.5267e-04 - f1_weighted: 0.0016 - loss: 14.7055 - top5_accuracy: 0.1079 - val_accuracy: 0.0250 - val_auc: 0.6547 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 13.3334 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 15/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0213 - auc: 0.6323 - f1_macro: 3.5251e-04 - f1_weighted: 0.0016 - loss: 14.0281 - top5_accuracy: 0.1078 - val_accuracy: 0.0250 - val_auc: 0.6541 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 13.1503 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 16/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.0214 - auc: 0.6321 - f1_macro: 3.8781e-04 - f1_weighted: 0.0017 - loss: 13.6951 - top5_accuracy: 0.1084 - val_accuracy: 0.0250 - val_auc: 0.6547 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 12.9741 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 17/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.0213 - auc: 0.6330 - f1_macro: 3.5042e-04 - f1_weighted: 0.0016 - loss: 13.0748 - top5_accuracy: 0.1076 - val_accuracy: 0.0250 - val_auc: 0.6547 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 12.8037 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 18/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0213 - auc: 0.6324 - f1_macro: 3.5180e-04 - f1_weighted: 0.0016 - loss: 13.4490 - top5_accuracy: 0.1069 - val_accuracy: 0.0250 - val_auc: 0.6547 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 12.6379 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 19/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0207 - auc: 0.6319 - f1_macro: 4.0836e-04 - f1_weighted: 0.0017 - loss: 13.6615 - top5_accuracy: 0.1075 - val_accuracy: 0.0250 - val_auc: 0.6552 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 12.4764 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 20/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0205 - auc: 0.6330 - f1_macro: 3.3064e-04 - f1_weighted: 0.0015 - loss: 13.1551 - top5_accuracy: 0.1073 - val_accuracy: 0.0250 - val_auc: 0.6553 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 12.3193 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 21/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0205 - auc: 0.6327 - f1_macro: 3.3037e-04 - f1_weighted: 0.0015 - loss: 12.4031 - top5_accuracy: 0.1063 - val_accuracy: 0.0250 - val_auc: 0.6553 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 12.1664 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 22/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.0213 - auc: 0.6329 - f1_macro: 3.4550e-04 - f1_weighted: 0.0016 - loss: 12.8759 - top5_accuracy: 0.1066 - val_accuracy: 0.0250 - val_auc: 0.6547 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 12.0181 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 23/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.0222 - auc: 0.6320 - f1_macro: 3.8026e-04 - f1_weighted: 0.0017 - loss: 12.2520 - top5_accuracy: 0.1068 - val_accuracy: 0.0250 - val_auc: 0.6547 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.8713 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 24/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0213 - auc: 0.6320 - f1_macro: 3.5050e-04 - f1_weighted: 0.0016 - loss: 11.9050 - top5_accuracy: 0.1071 - val_accuracy: 0.0250 - val_auc: 0.6553 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.7271 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 25/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0213 - auc: 0.6326 - f1_macro: 3.5181e-04 - f1_weighted: 0.0016 - loss: 12.0966 - top5_accuracy: 0.1068 - val_accuracy: 0.0250 - val_auc: 0.6547 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.5866 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 26/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0213 - auc: 0.6322 - f1_macro: 3.5130e-04 - f1_weighted: 0.0016 - loss: 11.7841 - top5_accuracy: 0.1076 - val_accuracy: 0.0250 - val_auc: 0.6547 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.4484 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 27/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0211 - auc: 0.6324 - f1_macro: 3.5340e-04 - f1_weighted: 0.0016 - loss: 18.0002 - top5_accuracy: 0.1091 - val_accuracy: 0.0250 - val_auc: 0.6553 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.3162 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 28/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0204 - auc: 0.6325 - f1_macro: 3.2903e-04 - f1_weighted: 0.0015 - loss: 16.8122 - top5_accuracy: 0.1090 - val_accuracy: 0.0250 - val_auc: 0.6553 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.1827 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 29/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0204 - auc: 0.6309 - f1_macro: 3.6358e-04 - f1_weighted: 0.0016 - loss: 40.6683 - top5_accuracy: 0.1115 - val_accuracy: 0.0250 - val_auc: 0.6586 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 12.4451 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 30/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0213 - auc: 0.6296 - f1_macro: 6.8814e-04 - f1_weighted: 0.0030 - loss: 9641.6270 - top5_accuracy: 0.1486 - val_accuracy: 0.0250 - val_auc: 0.6591 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 41.4300 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 31/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0213 - auc: 0.6338 - f1_macro: 3.9924e-04 - f1_weighted: 0.0018 - loss: 59502.4688 - top5_accuracy: 0.1114 - val_accuracy: 0.0250 - val_auc: 0.6585 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 60.1806 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 32/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0198 - auc: 0.6329 - f1_macro: 3.3401e-04 - f1_weighted: 0.0015 - loss: 22439.0645 - top5_accuracy: 0.1095 - val_accuracy: 0.0250 - val_auc: 0.6558 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 61.4852 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 33/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.0213 - auc: 0.6321 - f1_macro: 3.5107e-04 - f1_weighted: 0.0016 - loss: 65.6459 - top5_accuracy: 0.1062\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0213 - auc: 0.6323 - f1_macro: 3.5153e-04 - f1_weighted: 0.0016 - loss: 65.9018 - top5_accuracy: 0.1063 - val_accuracy: 0.0250 - val_auc: 0.6564 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 60.8941 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 34/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0226 - auc: 0.6316 - f1_macro: 4.1849e-04 - f1_weighted: 0.0019 - loss: 96.3245 - top5_accuracy: 0.1064 - val_accuracy: 0.0250 - val_auc: 0.6564 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 60.6257 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 35/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0205 - auc: 0.6304 - f1_macro: 3.2428e-04 - f1_weighted: 0.0015 - loss: 60.5962 - top5_accuracy: 0.1074 - val_accuracy: 0.0250 - val_auc: 0.6547 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 60.3399 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 36/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0213 - auc: 0.6308 - f1_macro: 3.3929e-04 - f1_weighted: 0.0015 - loss: 60.3112 - top5_accuracy: 0.1082 - val_accuracy: 0.0250 - val_auc: 0.6547 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 60.0583 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 37/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0221 - auc: 0.6307 - f1_macro: 3.5618e-04 - f1_weighted: 0.0016 - loss: 269.1737 - top5_accuracy: 0.1092 - val_accuracy: 0.0223 - val_auc: 0.6546 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 59.8870 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 38/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.0208 - auc: 0.6309 - f1_macro: 2.2015e-04 - f1_weighted: 9.6315e-04 - loss: 204.0287 - top5_accuracy: 0.1070 \n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0208 - auc: 0.6311 - f1_macro: 2.2122e-04 - f1_weighted: 9.6887e-04 - loss: 205.7259 - top5_accuracy: 0.1071 - val_accuracy: 0.0223 - val_auc: 0.6547 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 59.6454 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 39/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0209 - auc: 0.6329 - f1_macro: 2.0246e-04 - f1_weighted: 8.7136e-04 - loss: 1052.0265 - top5_accuracy: 0.1091 - val_accuracy: 0.0223 - val_auc: 0.6546 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 59.5441 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 40/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.0209 - auc: 0.6327 - f1_macro: 2.0235e-04 - f1_weighted: 8.7092e-04 - loss: 177.2657 - top5_accuracy: 0.1074 - val_accuracy: 0.0223 - val_auc: 0.6545 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 59.4082 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step\n",
            "Finished 'none'\n",
            "  Accuracy:      0.0223\n",
            "  F1 (macro):    0.0002\n",
            "  F1 (weighted): 0.0010\n",
            "  Precision:     0.0005\n",
            "  Recall:        0.0223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: grayscale_plus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 4194 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Found 749 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 209ms/step - accuracy: 0.0216 - auc: 0.6304 - f1_macro: 0.0017 - f1_weighted: 0.0065 - loss: 51056.4414 - top5_accuracy: 0.1520 - val_accuracy: 0.0223 - val_auc: 0.6662 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 23.8122 - val_top5_accuracy: 0.1096 - learning_rate: 0.0100\n",
            "Epoch 2/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0273 - auc: 0.6637 - f1_macro: 0.0013 - f1_weighted: 0.0063 - loss: 22.1152 - top5_accuracy: 0.1120 - val_accuracy: 0.0223 - val_auc: 0.6628 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 18.9764 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 3/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0200 - auc: 0.6689 - f1_macro: 8.7347e-04 - f1_weighted: 0.0042 - loss: 18.4854 - top5_accuracy: 0.1172 - val_accuracy: 0.0223 - val_auc: 0.6614 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 17.4118 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 4/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0260 - auc: 0.6668 - f1_macro: 0.0012 - f1_weighted: 0.0065 - loss: 17.1963 - top5_accuracy: 0.1121 - val_accuracy: 0.0223 - val_auc: 0.6623 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 16.6227 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 5/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0275 - auc: 0.6684 - f1_macro: 0.0015 - f1_weighted: 0.0075 - loss: 16.4817 - top5_accuracy: 0.1173 - val_accuracy: 0.0250 - val_auc: 0.6602 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 16.0816 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 6/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0214 - auc: 0.6643 - f1_macro: 0.0010 - f1_weighted: 0.0051 - loss: 15.9707 - top5_accuracy: 0.1149 - val_accuracy: 0.0250 - val_auc: 0.6596 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 15.6532 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 7/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0246 - auc: 0.6649 - f1_macro: 9.9203e-04 - f1_weighted: 0.0052 - loss: 15.5577 - top5_accuracy: 0.1210 - val_accuracy: 0.0250 - val_auc: 0.6616 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 15.2820 - val_top5_accuracy: 0.1169 - learning_rate: 0.0100\n",
            "Epoch 8/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0257 - auc: 0.6637 - f1_macro: 0.0013 - f1_weighted: 0.0066 - loss: 15.1908 - top5_accuracy: 0.1201 - val_accuracy: 0.0250 - val_auc: 0.6594 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 14.9518 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 9/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0234 - auc: 0.6639 - f1_macro: 9.0810e-04 - f1_weighted: 0.0044 - loss: 14.8707 - top5_accuracy: 0.1183 - val_accuracy: 0.0250 - val_auc: 0.6591 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 14.6561 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 10/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0254 - auc: 0.6645 - f1_macro: 0.0010 - f1_weighted: 0.0053 - loss: 14.5752 - top5_accuracy: 0.1220 - val_accuracy: 0.0250 - val_auc: 0.6611 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 14.3852 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 11/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0200 - auc: 0.6677 - f1_macro: 8.2542e-04 - f1_weighted: 0.0042 - loss: 14.3090 - top5_accuracy: 0.1186 - val_accuracy: 0.0250 - val_auc: 0.6592 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 14.1320 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 12/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0255 - auc: 0.6658 - f1_macro: 0.0010 - f1_weighted: 0.0049 - loss: 14.0605 - top5_accuracy: 0.1205 - val_accuracy: 0.0250 - val_auc: 0.6567 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 13.8971 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 13/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0260 - auc: 0.6617 - f1_macro: 8.8513e-04 - f1_weighted: 0.0046 - loss: 13.8270 - top5_accuracy: 0.1244 - val_accuracy: 0.0250 - val_auc: 0.6570 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 13.6762 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 14/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0206 - auc: 0.6649 - f1_macro: 6.7245e-04 - f1_weighted: 0.0035 - loss: 13.6053 - top5_accuracy: 0.1236 - val_accuracy: 0.0250 - val_auc: 0.6600 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 13.4665 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 15/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0256 - auc: 0.6601 - f1_macro: 8.0567e-04 - f1_weighted: 0.0042 - loss: 13.3986 - top5_accuracy: 0.1183 - val_accuracy: 0.0250 - val_auc: 0.6586 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 13.2701 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 16/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0303 - auc: 0.6591 - f1_macro: 7.5836e-04 - f1_weighted: 0.0041 - loss: 13.2009 - top5_accuracy: 0.1233 - val_accuracy: 0.0250 - val_auc: 0.6570 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 13.0781 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 17/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0220 - auc: 0.6572 - f1_macro: 5.3252e-04 - f1_weighted: 0.0029 - loss: 13.0109 - top5_accuracy: 0.1189 - val_accuracy: 0.0250 - val_auc: 0.6575 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 12.8956 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 18/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0257 - auc: 0.6562 - f1_macro: 5.9380e-04 - f1_weighted: 0.0031 - loss: 12.8286 - top5_accuracy: 0.1190 - val_accuracy: 0.0250 - val_auc: 0.6570 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 12.7199 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 19/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0193 - auc: 0.6564 - f1_macro: 4.7925e-04 - f1_weighted: 0.0025 - loss: 12.6543 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6564 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 12.5506 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 20/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0241 - auc: 0.6565 - f1_macro: 4.0660e-04 - f1_weighted: 0.0022 - loss: 12.4856 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6570 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 12.3864 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 21/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0229 - auc: 0.6553 - f1_macro: 5.5613e-04 - f1_weighted: 0.0029 - loss: 12.3221 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6570 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 12.2269 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 22/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0223 - auc: 0.6549 - f1_macro: 4.7401e-04 - f1_weighted: 0.0024 - loss: 12.1634 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6572 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 12.0715 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 23/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0218 - auc: 0.6550 - f1_macro: 4.5194e-04 - f1_weighted: 0.0023 - loss: 12.0088 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6578 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.9198 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 24/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0215 - auc: 0.6554 - f1_macro: 4.4446e-04 - f1_weighted: 0.0023 - loss: 11.8578 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6584 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.7713 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 25/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0215 - auc: 0.6557 - f1_macro: 4.4446e-04 - f1_weighted: 0.0023 - loss: 11.7100 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6584 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.6257 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 26/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0215 - auc: 0.6564 - f1_macro: 4.4446e-04 - f1_weighted: 0.0023 - loss: 11.5651 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6584 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.4828 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 27/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0215 - auc: 0.6564 - f1_macro: 4.4446e-04 - f1_weighted: 0.0023 - loss: 11.4227 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6584 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.3422 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 28/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0215 - auc: 0.6565 - f1_macro: 4.4446e-04 - f1_weighted: 0.0023 - loss: 11.2827 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6589 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.2038 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 29/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0215 - auc: 0.6566 - f1_macro: 4.4446e-04 - f1_weighted: 0.0023 - loss: 11.1448 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6589 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.0674 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 30/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0215 - auc: 0.6565 - f1_macro: 4.4446e-04 - f1_weighted: 0.0023 - loss: 11.0089 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6589 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 10.9329 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 31/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0215 - auc: 0.6565 - f1_macro: 4.4446e-04 - f1_weighted: 0.0023 - loss: 10.8747 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6589 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 10.8000 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 32/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0215 - auc: 0.6564 - f1_macro: 4.4446e-04 - f1_weighted: 0.0023 - loss: 10.7423 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6589 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 10.6688 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 33/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0215 - auc: 0.6564 - f1_macro: 4.4446e-04 - f1_weighted: 0.0023 - loss: 10.6114 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6589 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 10.5390 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 34/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0215 - auc: 0.6564 - f1_macro: 4.4446e-04 - f1_weighted: 0.0023 - loss: 10.4821 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6589 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 10.4107 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 35/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0215 - auc: 0.6564 - f1_macro: 4.4446e-04 - f1_weighted: 0.0023 - loss: 10.3541 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6589 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 10.2838 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 36/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0215 - auc: 0.6564 - f1_macro: 4.4446e-04 - f1_weighted: 0.0023 - loss: 10.2275 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6589 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 10.1582 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 37/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0215 - auc: 0.6564 - f1_macro: 4.4446e-04 - f1_weighted: 0.0023 - loss: 10.1022 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6589 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 10.0339 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 38/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0215 - auc: 0.6564 - f1_macro: 4.4446e-04 - f1_weighted: 0.0023 - loss: 9.9782 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6589 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 9.9108 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 39/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0215 - auc: 0.6564 - f1_macro: 4.4446e-04 - f1_weighted: 0.0023 - loss: 9.8554 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6589 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 9.7889 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 40/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0215 - auc: 0.6564 - f1_macro: 4.4446e-04 - f1_weighted: 0.0023 - loss: 9.7338 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6589 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 9.6682 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
            "Finished 'grayscale_plus'\n",
            "  Accuracy:      0.0250\n",
            "  F1 (macro):    0.0002\n",
            "  F1 (weighted): 0.0012\n",
            "  Precision:     0.0006\n",
            "  Recall:        0.0250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: mixup\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 4194 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Found 749 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 196ms/step - accuracy: 0.0184 - auc: 0.5886 - f1_macro: 0.0014 - f1_weighted: 0.0049 - loss: 33186.6133 - top5_accuracy: 0.1730 - val_accuracy: 0.0167 - val_auc: 0.6430 - val_f1_macro: 3.7735e-04 - val_f1_weighted: 0.0013 - val_loss: 24.1015 - val_top5_accuracy: 0.0751 - learning_rate: 0.0100\n",
            "Epoch 2/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 112ms/step - accuracy: 0.0123 - auc: 0.6332 - f1_macro: 0.0014 - f1_weighted: 0.0039 - loss: 75.1437 - top5_accuracy: 0.0977 - val_accuracy: 0.0239 - val_auc: 0.6604 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 19.5872 - val_top5_accuracy: 0.0957 - learning_rate: 0.0100\n",
            "Epoch 3/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 112ms/step - accuracy: 0.0226 - auc: 0.6519 - f1_macro: 3.5864e-04 - f1_weighted: 0.0015 - loss: 49.2579 - top5_accuracy: 0.0994 - val_accuracy: 0.0223 - val_auc: 0.6673 - val_f1_macro: 2.9547e-04 - val_f1_weighted: 0.0014 - val_loss: 18.1605 - val_top5_accuracy: 0.1074 - learning_rate: 0.0100\n",
            "Epoch 4/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 112ms/step - accuracy: 0.0196 - auc: 0.6584 - f1_macro: 3.3374e-04 - f1_weighted: 0.0016 - loss: 18.8612 - top5_accuracy: 0.1078 - val_accuracy: 0.0223 - val_auc: 0.6660 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 17.4349 - val_top5_accuracy: 0.1163 - learning_rate: 0.0100\n",
            "Epoch 5/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 112ms/step - accuracy: 0.0203 - auc: 0.6572 - f1_macro: 3.4565e-04 - f1_weighted: 0.0016 - loss: 23.1092 - top5_accuracy: 0.1152 - val_accuracy: 0.0239 - val_auc: 0.6645 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 16.9387 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 6/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 112ms/step - accuracy: 0.0197 - auc: 0.6567 - f1_macro: 4.7193e-04 - f1_weighted: 0.0023 - loss: 19.4674 - top5_accuracy: 0.1233 - val_accuracy: 0.0239 - val_auc: 0.6639 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 16.5400 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 7/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0238 - auc: 0.6547 - f1_macro: 4.2230e-04 - f1_weighted: 0.0023 - loss: 16.6726 - top5_accuracy: 0.1230 - val_accuracy: 0.0250 - val_auc: 0.6634 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 16.1788 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 8/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0280 - auc: 0.6556 - f1_macro: 2.6807e-04 - f1_weighted: 0.0015 - loss: 16.0858 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6634 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 15.8404 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 9/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0280 - auc: 0.6551 - f1_macro: 2.6861e-04 - f1_weighted: 0.0015 - loss: 15.8891 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6633 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 15.5253 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 10/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0280 - auc: 0.6564 - f1_macro: 2.6891e-04 - f1_weighted: 0.0015 - loss: 16.5445 - top5_accuracy: 0.1241 - val_accuracy: 0.0250 - val_auc: 0.6633 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 15.2305 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 11/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0280 - auc: 0.6564 - f1_macro: 2.6796e-04 - f1_weighted: 0.0015 - loss: 15.1439 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6639 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 14.9421 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 12/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0280 - auc: 0.6569 - f1_macro: 2.6804e-04 - f1_weighted: 0.0015 - loss: 14.8609 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 14.6668 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 13/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0276 - auc: 0.6578 - f1_macro: 2.7304e-04 - f1_weighted: 0.0016 - loss: 14.5919 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 14.4016 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 14/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0280 - auc: 0.6579 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 14.3231 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 14.1441 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 15/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0280 - auc: 0.6582 - f1_macro: 2.6818e-04 - f1_weighted: 0.0015 - loss: 14.0687 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 13.8972 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 16/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0280 - auc: 0.6585 - f1_macro: 2.6813e-04 - f1_weighted: 0.0015 - loss: 14.3969 - top5_accuracy: 0.1233 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 13.6628 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 17/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0280 - auc: 0.6589 - f1_macro: 2.6825e-04 - f1_weighted: 0.0015 - loss: 13.6468 - top5_accuracy: 0.1236 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 13.4306 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 18/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0280 - auc: 0.6590 - f1_macro: 2.6804e-04 - f1_weighted: 0.0015 - loss: 14.1377 - top5_accuracy: 0.1230 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 13.2069 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 19/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0286 - auc: 0.6575 - f1_macro: 4.1296e-04 - f1_weighted: 0.0022 - loss: 17.4631 - top5_accuracy: 0.1234 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 13.0048 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 20/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0280 - auc: 0.6588 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 12.9363 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 12.7843 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 21/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0280 - auc: 0.6588 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 12.7171 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 12.5691 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 22/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0280 - auc: 0.6588 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 12.5032 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 12.3588 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 23/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.0280 - auc: 0.6588 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 12.2941 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 12.1532 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 24/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0280 - auc: 0.6588 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 12.0895 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.9519 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 25/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0280 - auc: 0.6589 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 11.8893 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.7549 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 26/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0280 - auc: 0.6589 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 11.6934 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.5621 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 27/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0280 - auc: 0.6589 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 11.5015 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.3732 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 28/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0280 - auc: 0.6589 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 11.3137 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.1883 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 29/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0280 - auc: 0.6589 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 11.1297 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 11.0072 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 30/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0280 - auc: 0.6589 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 10.9495 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 10.8298 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 31/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0280 - auc: 0.6589 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 10.7731 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 10.6562 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 32/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0280 - auc: 0.6589 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 10.6003 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 10.4859 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 33/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0280 - auc: 0.6589 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 10.4310 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 10.3192 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 34/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0280 - auc: 0.6589 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 10.2651 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 10.1560 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 35/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0280 - auc: 0.6589 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 10.1028 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 9.9961 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 36/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0280 - auc: 0.6589 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 9.9437 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 9.8395 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 37/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0280 - auc: 0.6589 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 9.7880 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 9.6862 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 38/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0280 - auc: 0.6589 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 9.6354 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 9.5360 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 39/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0280 - auc: 0.6589 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 9.4860 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 9.3889 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 40/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.0280 - auc: 0.6589 - f1_macro: 2.6795e-04 - f1_weighted: 0.0015 - loss: 9.3397 - top5_accuracy: 0.1229 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 9.2449 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
            "Finished 'mixup'\n",
            "  Accuracy:      0.0250\n",
            "  F1 (macro):    0.0002\n",
            "  F1 (weighted): 0.0012\n",
            "  Precision:     0.0006\n",
            "  Recall:        0.0250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Initialize the preprocessor\n",
        "batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "image_size = (224, 224)\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Loop through each augmentation\n",
        "for aug in augmentations_to_test:\n",
        "    print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "    model = build_zfnet()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "    train_ds_sampled, class_names = preprocess.load_img(data_dir=\"data/rare_species/train_sampled\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "    val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "    test_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/test\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "    # Initialize the experiment\n",
        "    experiment = Experiment(\n",
        "        model=model,\n",
        "        train_ds=train_ds_sampled,\n",
        "        val_ds=val_ds,\n",
        "        experiment_name=f\"zfnet_with_{aug}_no_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "        batch_size=32,\n",
        "        image_size=(224, 224),\n",
        "        save_model=False\n",
        "    )\n",
        "\n",
        "    # Run the experiment\n",
        "    history = experiment.run_experiment(callbacks=callbacks, epochs=40)\n",
        "\n",
        "    # Predict entire validation set at once\n",
        "    preds = model.predict(val_ds)\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Extract true labels in order\n",
        "    y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "    # Compute metrics\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Store in results\n",
        "    results[aug] = {\n",
        "        \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "        \"f1_macro\": f1_macro,\n",
        "        \"f1_weighted\": f1_weighted,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall\n",
        "    }\n",
        "\n",
        "    print(f\"Finished '{aug}'\")\n",
        "    print(f\"  Accuracy:      {results[aug]['accuracy']:.4f}\")\n",
        "    print(f\"  F1 (macro):    {results[aug]['f1_macro']:.4f}\")\n",
        "    print(f\"  F1 (weighted): {results[aug]['f1_weighted']:.4f}\")\n",
        "    print(f\"  Precision:     {results[aug]['precision']:.4f}\")\n",
        "    print(f\"  Recall:        {results[aug]['recall']:.4f}\")\n",
        "\n",
        "    # Clear memory to avoid OOM\n",
        "    del model\n",
        "    del experiment\n",
        "    K.clear_session()\n",
        "    gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJ9DH3AK_0QF",
        "outputId": "e28a1fd0-9f50-48cf-f601-12c2360b9f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     augmentation  accuracy  f1_macro  f1_weighted  precision  recall\n",
              "0            none    0.0223    0.0002       0.0010     0.0005  0.0223\n",
              "1  grayscale_plus    0.0250    0.0002       0.0012     0.0006  0.0250\n",
              "2           mixup    0.0250    0.0002       0.0012     0.0006  0.0250"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb243915-e458-4d19-9af1-666b3e812026\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>augmentation</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>f1_weighted</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>none</td>\n",
              "      <td>0.0223</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>0.0223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>grayscale_plus</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0006</td>\n",
              "      <td>0.0250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mixup</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0006</td>\n",
              "      <td>0.0250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb243915-e458-4d19-9af1-666b3e812026')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eb243915-e458-4d19-9af1-666b3e812026 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eb243915-e458-4d19-9af1-666b3e812026');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aa903d8e-7f34-4528-b98a-f969516c1472\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa903d8e-7f34-4528-b98a-f969516c1472')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aa903d8e-7f34-4528-b98a-f969516c1472 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(results_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"augmentation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"none\",\n          \"grayscale_plus\",\n          \"mixup\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00155884572681199,\n        \"min\": 0.0223,\n        \"max\": 0.025,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.025,\n          0.0223\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0002,\n        \"max\": 0.0002,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_weighted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00011547005383792509,\n        \"min\": 0.001,\n        \"max\": 0.0012,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0012\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.7735026918962544e-05,\n        \"min\": 0.0005,\n        \"max\": 0.0006,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0006\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00155884572681199,\n        \"min\": 0.0223,\n        \"max\": 0.025,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.025\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# Display the table\n",
        "display(results_df.round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gatsKB-M_0QF",
        "outputId": "cf37bea9-970d-4606-ade2-ef50a4139101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# Melt the DataFrame for seaborn plotting\n",
        "metrics_to_plot = ['accuracy', 'f1_macro', 'f1_weighted', 'precision', 'recall']\n",
        "melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "                            var_name='metric', value_name='value')\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "plt.title(\"Comparison of Metrics Across Augmentation Strategies\")\n",
        "plt.ylim(0, 0.4)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK5Cf7QY_0QG"
      },
      "source": [
        "## 4.5 VGGNet - No oversampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUQltkeB_0QG"
      },
      "source": [
        "inspired by VGG16 — a deep and uniform architecture with 3x3 convolutions and max pooling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuhVLEkt_0QG",
        "outputId": "a3c884e9-14ec-43d3-89ea-f783bb1dc225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200704\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │   \u001b[38;5;34m102,760,960\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m202\u001b[0m)            │       \u001b[38;5;34m103,626\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200704</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │   <span style=\"color: #00af00; text-decoration-color: #00af00\">102,760,960</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">103,626</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,601,866\u001b[0m (399.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,601,866</span> (399.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m104,600,970\u001b[0m (399.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,600,970</span> (399.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def build_vgg_model(input_shape=(224, 224, 3), num_classes=202):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Block 4 (optional to reduce overfitting)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_vgg_model()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXEV9N8g_0QG",
        "outputId": "0119d35f-2b66-4761-da11-8fa8ce5b9742",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: none\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 4194 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Found 749 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 399ms/step - accuracy: 0.0220 - auc: 0.6234 - f1_macro: 0.0022 - f1_weighted: 0.0039 - loss: 127.4607 - top5_accuracy: 0.1234 - val_accuracy: 0.0050 - val_auc: 0.5218 - val_f1_macro: 0.0019 - val_f1_weighted: 0.0015 - val_loss: 826.8123 - val_top5_accuracy: 0.3428 - learning_rate: 0.0100\n",
            "Epoch 2/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0200 - auc: 0.6501 - f1_macro: 1.9426e-04 - f1_weighted: 8.0456e-04 - loss: 5.1736 - top5_accuracy: 0.1048 - val_accuracy: 0.0245 - val_auc: 0.6599 - val_f1_macro: 5.6841e-04 - val_f1_weighted: 0.0018 - val_loss: 6.5003 - val_top5_accuracy: 0.1135 - learning_rate: 0.0100\n",
            "Epoch 3/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0203 - auc: 0.6536 - f1_macro: 8.3145e-04 - f1_weighted: 0.0024 - loss: 5.1045 - top5_accuracy: 0.1132 - val_accuracy: 0.0239 - val_auc: 0.6589 - val_f1_macro: 2.3189e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0867 - val_top5_accuracy: 0.1180 - learning_rate: 0.0100\n",
            "Epoch 4/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0205 - auc: 0.6525 - f1_macro: 3.2753e-04 - f1_weighted: 0.0015 - loss: 5.0856 - top5_accuracy: 0.1186 - val_accuracy: 0.0239 - val_auc: 0.6564 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0870 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 5/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0198 - auc: 0.6506 - f1_macro: 3.3965e-04 - f1_weighted: 0.0016 - loss: 5.0826 - top5_accuracy: 0.1186 - val_accuracy: 0.0239 - val_auc: 0.6560 - val_f1_macro: 2.3151e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0858 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 6/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0159 - auc: 0.6490 - f1_macro: 4.5834e-04 - f1_weighted: 0.0021 - loss: 5.0883 - top5_accuracy: 0.1186 - val_accuracy: 0.0239 - val_auc: 0.6569 - val_f1_macro: 2.3151e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0868 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 7/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0176 - auc: 0.6491 - f1_macro: 4.4670e-04 - f1_weighted: 0.0020 - loss: 5.0834 - top5_accuracy: 0.1186 - val_accuracy: 0.0239 - val_auc: 0.6583 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0824 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 8/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0185 - auc: 0.6504 - f1_macro: 4.4886e-04 - f1_weighted: 0.0020 - loss: 5.0825 - top5_accuracy: 0.1186 - val_accuracy: 0.0239 - val_auc: 0.6599 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 9/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0182 - auc: 0.6511 - f1_macro: 4.2274e-04 - f1_weighted: 0.0018 - loss: 5.0826 - top5_accuracy: 0.1186 - val_accuracy: 0.0239 - val_auc: 0.6599 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0826 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 10/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0176 - auc: 0.6511 - f1_macro: 4.0377e-04 - f1_weighted: 0.0018 - loss: 5.0828 - top5_accuracy: 0.1186 - val_accuracy: 0.0239 - val_auc: 0.6605 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0827 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 11/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0176 - auc: 0.6513 - f1_macro: 3.8656e-04 - f1_weighted: 0.0017 - loss: 5.0829 - top5_accuracy: 0.1186 - val_accuracy: 0.0239 - val_auc: 0.6605 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0827 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 12/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.0176 - auc: 0.6512 - f1_macro: 3.8662e-04 - f1_weighted: 0.0017 - loss: 5.0830 - top5_accuracy: 0.1186\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0176 - auc: 0.6512 - f1_macro: 3.9090e-04 - f1_weighted: 0.0017 - loss: 5.0830 - top5_accuracy: 0.1186 - val_accuracy: 0.0239 - val_auc: 0.6605 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 13/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0190 - auc: 0.6503 - f1_macro: 3.3937e-04 - f1_weighted: 0.0014 - loss: 5.0807 - top5_accuracy: 0.1174 - val_accuracy: 0.0239 - val_auc: 0.6605 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0826 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 14/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0189 - auc: 0.6506 - f1_macro: 3.2313e-04 - f1_weighted: 0.0013 - loss: 5.0799 - top5_accuracy: 0.1184 - val_accuracy: 0.0239 - val_auc: 0.6599 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0826 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 15/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0208 - auc: 0.6504 - f1_macro: 3.5790e-04 - f1_weighted: 0.0015 - loss: 5.0795 - top5_accuracy: 0.1185 - val_accuracy: 0.0223 - val_auc: 0.6597 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 16/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0208 - auc: 0.6505 - f1_macro: 2.1287e-04 - f1_weighted: 9.2399e-04 - loss: 5.0791 - top5_accuracy: 0.1186 - val_accuracy: 0.0223 - val_auc: 0.6580 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 17/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.0208 - auc: 0.6498 - f1_macro: 2.0584e-04 - f1_weighted: 8.8693e-04 - loss: 5.0789 - top5_accuracy: 0.1183\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0208 - auc: 0.6499 - f1_macro: 2.0735e-04 - f1_weighted: 8.9524e-04 - loss: 5.0789 - top5_accuracy: 0.1183 - val_accuracy: 0.0223 - val_auc: 0.6580 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 18/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6519 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0775 - top5_accuracy: 0.1186 - val_accuracy: 0.0223 - val_auc: 0.6575 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 19/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6521 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0773 - top5_accuracy: 0.1174 - val_accuracy: 0.0223 - val_auc: 0.6569 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 20/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6517 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0771 - top5_accuracy: 0.1189 - val_accuracy: 0.0223 - val_auc: 0.6569 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 21/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6505 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0769 - top5_accuracy: 0.1184 - val_accuracy: 0.0223 - val_auc: 0.6569 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 22/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.0209 - auc: 0.6510 - f1_macro: 2.0215e-04 - f1_weighted: 8.6776e-04 - loss: 5.0768 - top5_accuracy: 0.1189\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6510 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0768 - top5_accuracy: 0.1189 - val_accuracy: 0.0223 - val_auc: 0.6564 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 23/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6514 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0760 - top5_accuracy: 0.1189 - val_accuracy: 0.0223 - val_auc: 0.6559 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 0.0012\n",
            "Epoch 24/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6525 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0759 - top5_accuracy: 0.1185 - val_accuracy: 0.0223 - val_auc: 0.6559 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 0.0012\n",
            "Epoch 25/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6527 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0758 - top5_accuracy: 0.1185 - val_accuracy: 0.0223 - val_auc: 0.6559 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 0.0012\n",
            "Epoch 26/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6534 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0757 - top5_accuracy: 0.1186 - val_accuracy: 0.0223 - val_auc: 0.6559 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 0.0012\n",
            "Epoch 27/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.0209 - auc: 0.6534 - f1_macro: 2.0215e-04 - f1_weighted: 8.6776e-04 - loss: 5.0757 - top5_accuracy: 0.1185\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6534 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0756 - top5_accuracy: 0.1185 - val_accuracy: 0.0223 - val_auc: 0.6548 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 0.0012\n",
            "Epoch 28/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6537 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0753 - top5_accuracy: 0.1196 - val_accuracy: 0.0223 - val_auc: 0.6542 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 6.2500e-04\n",
            "Epoch 29/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6538 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0752 - top5_accuracy: 0.1196 - val_accuracy: 0.0223 - val_auc: 0.6542 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 6.2500e-04\n",
            "Epoch 30/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6540 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0752 - top5_accuracy: 0.1196 - val_accuracy: 0.0223 - val_auc: 0.6537 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 6.2500e-04\n",
            "Epoch 31/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6543 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0751 - top5_accuracy: 0.1196 - val_accuracy: 0.0223 - val_auc: 0.6537 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 6.2500e-04\n",
            "Epoch 32/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.0209 - auc: 0.6544 - f1_macro: 2.0215e-04 - f1_weighted: 8.6776e-04 - loss: 5.0751 - top5_accuracy: 0.1196\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6544 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0751 - top5_accuracy: 0.1196 - val_accuracy: 0.0223 - val_auc: 0.6537 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 6.2500e-04\n",
            "Epoch 33/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6544 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0749 - top5_accuracy: 0.1196 - val_accuracy: 0.0223 - val_auc: 0.6537 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 3.1250e-04\n",
            "Epoch 34/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6543 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0749 - top5_accuracy: 0.1196 - val_accuracy: 0.0223 - val_auc: 0.6537 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 3.1250e-04\n",
            "Epoch 35/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6544 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0748 - top5_accuracy: 0.1196 - val_accuracy: 0.0223 - val_auc: 0.6532 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 3.1250e-04\n",
            "Epoch 36/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6545 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0748 - top5_accuracy: 0.1196 - val_accuracy: 0.0223 - val_auc: 0.6532 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 3.1250e-04\n",
            "Epoch 37/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.0209 - auc: 0.6546 - f1_macro: 2.0215e-04 - f1_weighted: 8.6776e-04 - loss: 5.0748 - top5_accuracy: 0.1196\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6546 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0748 - top5_accuracy: 0.1196 - val_accuracy: 0.0223 - val_auc: 0.6532 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 3.1250e-04\n",
            "Epoch 38/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6546 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0747 - top5_accuracy: 0.1196 - val_accuracy: 0.0223 - val_auc: 0.6532 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 1.5625e-04\n",
            "Epoch 39/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6547 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0747 - top5_accuracy: 0.1196 - val_accuracy: 0.0223 - val_auc: 0.6532 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 1.5625e-04\n",
            "Epoch 40/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 223ms/step - accuracy: 0.0209 - auc: 0.6547 - f1_macro: 2.0237e-04 - f1_weighted: 8.6948e-04 - loss: 5.0747 - top5_accuracy: 0.1196 - val_accuracy: 0.0223 - val_auc: 0.6532 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0825 - val_top5_accuracy: 0.1185 - learning_rate: 1.5625e-04\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step\n",
            "Finished 'none'\n",
            "  Accuracy:      0.0223\n",
            "  F1 (macro):    0.0002\n",
            "  F1 (weighted): 0.0010\n",
            "  Precision:     0.0005\n",
            "  Recall:        0.0223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: grayscale_plus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 4194 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Found 749 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 298ms/step - accuracy: 0.0181 - auc: 0.6212 - f1_macro: 5.7455e-04 - f1_weighted: 0.0023 - loss: 96.3492 - top5_accuracy: 0.1218 - val_accuracy: 0.0067 - val_auc: 0.5181 - val_f1_macro: 9.7821e-04 - val_f1_weighted: 0.0024 - val_loss: 303.2379 - val_top5_accuracy: 0.1247 - learning_rate: 0.0100\n",
            "Epoch 2/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 227ms/step - accuracy: 0.0234 - auc: 0.6534 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.1455 - top5_accuracy: 0.1113 - val_accuracy: 0.0250 - val_auc: 0.6610 - val_f1_macro: 2.4794e-04 - val_f1_weighted: 0.0013 - val_loss: 5.1432 - val_top5_accuracy: 0.1152 - learning_rate: 0.0100\n",
            "Epoch 3/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 225ms/step - accuracy: 0.0234 - auc: 0.6575 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0960 - top5_accuracy: 0.1177 - val_accuracy: 0.0250 - val_auc: 0.6568 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0871 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 4/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0234 - auc: 0.6522 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0821 - top5_accuracy: 0.1194 - val_accuracy: 0.0250 - val_auc: 0.6553 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0829 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 5/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0222 - auc: 0.6521 - f1_macro: 3.3657e-04 - f1_weighted: 0.0016 - loss: 5.0790 - top5_accuracy: 0.1194 - val_accuracy: 0.0250 - val_auc: 0.6564 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0822 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 6/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0177 - auc: 0.6517 - f1_macro: 3.6810e-04 - f1_weighted: 0.0018 - loss: 5.0787 - top5_accuracy: 0.1175 - val_accuracy: 0.0250 - val_auc: 0.6564 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0822 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 7/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0203 - auc: 0.6505 - f1_macro: 3.9375e-04 - f1_weighted: 0.0019 - loss: 5.0788 - top5_accuracy: 0.1180 - val_accuracy: 0.0250 - val_auc: 0.6575 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0824 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 8/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0212 - auc: 0.6507 - f1_macro: 4.1814e-04 - f1_weighted: 0.0020 - loss: 5.0791 - top5_accuracy: 0.1176 - val_accuracy: 0.0250 - val_auc: 0.6580 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0826 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 9/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 225ms/step - accuracy: 0.0212 - auc: 0.6508 - f1_macro: 4.1814e-04 - f1_weighted: 0.0020 - loss: 5.0794 - top5_accuracy: 0.1178 - val_accuracy: 0.0250 - val_auc: 0.6586 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0827 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 10/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0212 - auc: 0.6513 - f1_macro: 4.1603e-04 - f1_weighted: 0.0020 - loss: 5.0795 - top5_accuracy: 0.1178\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0212 - auc: 0.6513 - f1_macro: 4.1726e-04 - f1_weighted: 0.0020 - loss: 5.0796 - top5_accuracy: 0.1178 - val_accuracy: 0.0250 - val_auc: 0.6586 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 11/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0217 - auc: 0.6520 - f1_macro: 3.3275e-04 - f1_weighted: 0.0016 - loss: 5.0772 - top5_accuracy: 0.1169 - val_accuracy: 0.0250 - val_auc: 0.6586 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 12/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0209 - auc: 0.6507 - f1_macro: 3.5912e-04 - f1_weighted: 0.0018 - loss: 5.0768 - top5_accuracy: 0.1173 - val_accuracy: 0.0250 - val_auc: 0.6580 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 13/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0211 - auc: 0.6503 - f1_macro: 3.5104e-04 - f1_weighted: 0.0017 - loss: 5.0765 - top5_accuracy: 0.1174 - val_accuracy: 0.0250 - val_auc: 0.6575 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 14/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0213 - auc: 0.6508 - f1_macro: 3.5392e-04 - f1_weighted: 0.0017 - loss: 5.0763 - top5_accuracy: 0.1183 - val_accuracy: 0.0250 - val_auc: 0.6570 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 15/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0219 - auc: 0.6506 - f1_macro: 3.6646e-04 - f1_weighted: 0.0018 - loss: 5.0761 - top5_accuracy: 0.1179\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0219 - auc: 0.6506 - f1_macro: 3.6735e-04 - f1_weighted: 0.0018 - loss: 5.0762 - top5_accuracy: 0.1179 - val_accuracy: 0.0250 - val_auc: 0.6569 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 16/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0226 - auc: 0.6528 - f1_macro: 2.5272e-04 - f1_weighted: 0.0012 - loss: 5.0748 - top5_accuracy: 0.1173 - val_accuracy: 0.0250 - val_auc: 0.6563 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 17/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0207 - auc: 0.6532 - f1_macro: 3.6730e-04 - f1_weighted: 0.0018 - loss: 5.0746 - top5_accuracy: 0.1169 - val_accuracy: 0.0250 - val_auc: 0.6563 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 18/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0195 - auc: 0.6532 - f1_macro: 3.3346e-04 - f1_weighted: 0.0016 - loss: 5.0745 - top5_accuracy: 0.1171 - val_accuracy: 0.0250 - val_auc: 0.6558 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 19/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0203 - auc: 0.6537 - f1_macro: 3.4389e-04 - f1_weighted: 0.0017 - loss: 5.0743 - top5_accuracy: 0.1173 - val_accuracy: 0.0250 - val_auc: 0.6558 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 20/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0208 - auc: 0.6541 - f1_macro: 3.4624e-04 - f1_weighted: 0.0017 - loss: 5.0742 - top5_accuracy: 0.1172\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0208 - auc: 0.6541 - f1_macro: 3.4701e-04 - f1_weighted: 0.0017 - loss: 5.0742 - top5_accuracy: 0.1172 - val_accuracy: 0.0250 - val_auc: 0.6558 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 21/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0234 - auc: 0.6544 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0735 - top5_accuracy: 0.1158 - val_accuracy: 0.0250 - val_auc: 0.6552 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 0.0012\n",
            "Epoch 22/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0234 - auc: 0.6543 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0734 - top5_accuracy: 0.1154 - val_accuracy: 0.0250 - val_auc: 0.6552 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 0.0012\n",
            "Epoch 23/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0215 - auc: 0.6539 - f1_macro: 2.3889e-04 - f1_weighted: 0.0011 - loss: 5.0733 - top5_accuracy: 0.1172 - val_accuracy: 0.0250 - val_auc: 0.6541 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 0.0012\n",
            "Epoch 24/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0209 - auc: 0.6539 - f1_macro: 3.4043e-04 - f1_weighted: 0.0017 - loss: 5.0733 - top5_accuracy: 0.1171 - val_accuracy: 0.0250 - val_auc: 0.6541 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 0.0012\n",
            "Epoch 25/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0207 - auc: 0.6545 - f1_macro: 3.7165e-04 - f1_weighted: 0.0018 - loss: 5.0732 - top5_accuracy: 0.1169\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0207 - auc: 0.6545 - f1_macro: 3.7284e-04 - f1_weighted: 0.0018 - loss: 5.0732 - top5_accuracy: 0.1169 - val_accuracy: 0.0250 - val_auc: 0.6536 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 0.0012\n",
            "Epoch 26/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0234 - auc: 0.6552 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0728 - top5_accuracy: 0.1165 - val_accuracy: 0.0250 - val_auc: 0.6536 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 6.2500e-04\n",
            "Epoch 27/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0234 - auc: 0.6555 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0728 - top5_accuracy: 0.1161 - val_accuracy: 0.0250 - val_auc: 0.6536 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 6.2500e-04\n",
            "Epoch 28/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0234 - auc: 0.6552 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0728 - top5_accuracy: 0.1158 - val_accuracy: 0.0250 - val_auc: 0.6536 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 6.2500e-04\n",
            "Epoch 29/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0234 - auc: 0.6552 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0727 - top5_accuracy: 0.1156 - val_accuracy: 0.0250 - val_auc: 0.6536 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 6.2500e-04\n",
            "Epoch 30/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0234 - auc: 0.6554 - f1_macro: 2.2594e-04 - f1_weighted: 0.0011 - loss: 5.0727 - top5_accuracy: 0.1158\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0234 - auc: 0.6554 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0727 - top5_accuracy: 0.1159 - val_accuracy: 0.0250 - val_auc: 0.6536 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 6.2500e-04\n",
            "Epoch 31/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0234 - auc: 0.6556 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0725 - top5_accuracy: 0.1188 - val_accuracy: 0.0250 - val_auc: 0.6536 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 3.1250e-04\n",
            "Epoch 32/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0234 - auc: 0.6556 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0725 - top5_accuracy: 0.1188 - val_accuracy: 0.0250 - val_auc: 0.6536 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 3.1250e-04\n",
            "Epoch 33/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0234 - auc: 0.6558 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0725 - top5_accuracy: 0.1188 - val_accuracy: 0.0250 - val_auc: 0.6530 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 3.1250e-04\n",
            "Epoch 34/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 225ms/step - accuracy: 0.0234 - auc: 0.6558 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0725 - top5_accuracy: 0.1188 - val_accuracy: 0.0250 - val_auc: 0.6530 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 3.1250e-04\n",
            "Epoch 35/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0234 - auc: 0.6557 - f1_macro: 2.2594e-04 - f1_weighted: 0.0011 - loss: 5.0724 - top5_accuracy: 0.1188\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 225ms/step - accuracy: 0.0234 - auc: 0.6557 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0725 - top5_accuracy: 0.1188 - val_accuracy: 0.0250 - val_auc: 0.6530 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 3.1250e-04\n",
            "Epoch 36/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0234 - auc: 0.6563 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0724 - top5_accuracy: 0.1188 - val_accuracy: 0.0250 - val_auc: 0.6530 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 1.5625e-04\n",
            "Epoch 37/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 225ms/step - accuracy: 0.0234 - auc: 0.6563 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0724 - top5_accuracy: 0.1188 - val_accuracy: 0.0250 - val_auc: 0.6530 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 1.5625e-04\n",
            "Epoch 38/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 225ms/step - accuracy: 0.0234 - auc: 0.6562 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0723 - top5_accuracy: 0.1188 - val_accuracy: 0.0250 - val_auc: 0.6530 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 1.5625e-04\n",
            "Epoch 39/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 225ms/step - accuracy: 0.0234 - auc: 0.6562 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0723 - top5_accuracy: 0.1188 - val_accuracy: 0.0250 - val_auc: 0.6530 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 1.5625e-04\n",
            "Epoch 40/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0234 - auc: 0.6560 - f1_macro: 2.2594e-04 - f1_weighted: 0.0011 - loss: 5.0723 - top5_accuracy: 0.1188\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 225ms/step - accuracy: 0.0234 - auc: 0.6560 - f1_macro: 2.2618e-04 - f1_weighted: 0.0011 - loss: 5.0723 - top5_accuracy: 0.1188 - val_accuracy: 0.0250 - val_auc: 0.6530 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0828 - val_top5_accuracy: 0.1185 - learning_rate: 1.5625e-04\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step\n",
            "Finished 'grayscale_plus'\n",
            "  Accuracy:      0.0250\n",
            "  F1 (macro):    0.0002\n",
            "  F1 (weighted): 0.0012\n",
            "  Precision:     0.0006\n",
            "  Recall:        0.0250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: mixup\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 4194 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Found 749 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 298ms/step - accuracy: 0.0217 - auc: 0.6054 - f1_macro: 0.0015 - f1_weighted: 0.0032 - loss: 169.6764 - top5_accuracy: 0.1449 - val_accuracy: 0.0139 - val_auc: 0.6094 - val_f1_macro: 1.5887e-04 - val_f1_weighted: 8.0365e-04 - val_loss: 10.6255 - val_top5_accuracy: 0.0940 - learning_rate: 0.0100\n",
            "Epoch 2/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 227ms/step - accuracy: 0.0204 - auc: 0.6460 - f1_macro: 2.9920e-04 - f1_weighted: 0.0014 - loss: 5.1485 - top5_accuracy: 0.1100 - val_accuracy: 0.0250 - val_auc: 0.6584 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.1113 - val_top5_accuracy: 0.1135 - learning_rate: 0.0100\n",
            "Epoch 3/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0221 - auc: 0.6570 - f1_macro: 3.7954e-04 - f1_weighted: 0.0019 - loss: 5.0950 - top5_accuracy: 0.1142 - val_accuracy: 0.0250 - val_auc: 0.6586 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0919 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 4/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0243 - auc: 0.6578 - f1_macro: 2.5082e-04 - f1_weighted: 0.0014 - loss: 5.0779 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6584 - val_f1_macro: 2.3151e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0945 - val_top5_accuracy: 0.1180 - learning_rate: 0.0100\n",
            "Epoch 5/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 227ms/step - accuracy: 0.0292 - auc: 0.6573 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0734 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6600 - val_f1_macro: 2.3151e-04 - val_f1_weighted: 0.0011 - val_loss: 5.5168 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 6/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0285 - auc: 0.6572 - f1_macro: 3.4282e-04 - f1_weighted: 0.0020 - loss: 5.0724 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6609 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 6.3707 - val_top5_accuracy: 0.1191 - learning_rate: 0.0100\n",
            "Epoch 7/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0281 - auc: 0.6583 - f1_macro: 3.5409e-04 - f1_weighted: 0.0021 - loss: 5.0723 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6609 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 6.9297 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 8/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.0265 - auc: 0.6589 - f1_macro: 3.6989e-04 - f1_weighted: 0.0022 - loss: 5.0726 - top5_accuracy: 0.1210\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 227ms/step - accuracy: 0.0265 - auc: 0.6589 - f1_macro: 3.7001e-04 - f1_weighted: 0.0022 - loss: 5.0725 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6613 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.1288 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 9/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6615 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0700 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6613 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.1867 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 10/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0285 - auc: 0.6616 - f1_macro: 3.3347e-04 - f1_weighted: 0.0020 - loss: 5.0695 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6613 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2024 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 11/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0284 - auc: 0.6616 - f1_macro: 3.4669e-04 - f1_weighted: 0.0020 - loss: 5.0691 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6613 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2068 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 12/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0285 - auc: 0.6617 - f1_macro: 3.5917e-04 - f1_weighted: 0.0021 - loss: 5.0688 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6613 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2081 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 13/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0282 - auc: 0.6618 - f1_macro: 3.5005e-04 - f1_weighted: 0.0021 - loss: 5.0687 - top5_accuracy: 0.1210\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0282 - auc: 0.6618 - f1_macro: 3.5080e-04 - f1_weighted: 0.0021 - loss: 5.0687 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6607 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2086 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 14/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6627 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0671 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6607 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2086 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 15/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6627 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0669 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6607 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2086 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 16/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6628 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0667 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6607 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2087 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 17/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6629 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0666 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6607 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2087 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 18/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0293 - auc: 0.6630 - f1_macro: 2.7192e-04 - f1_weighted: 0.0017 - loss: 5.0665 - top5_accuracy: 0.1210\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6630 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0664 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6607 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2087 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 19/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6627 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0656 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6607 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2088 - val_top5_accuracy: 0.1185 - learning_rate: 0.0012\n",
            "Epoch 20/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6627 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0655 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6607 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2088 - val_top5_accuracy: 0.1185 - learning_rate: 0.0012\n",
            "Epoch 21/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6628 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0655 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6607 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2088 - val_top5_accuracy: 0.1185 - learning_rate: 0.0012\n",
            "Epoch 22/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6628 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0654 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6607 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2088 - val_top5_accuracy: 0.1185 - learning_rate: 0.0012\n",
            "Epoch 23/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0293 - auc: 0.6628 - f1_macro: 2.7192e-04 - f1_weighted: 0.0017 - loss: 5.0654 - top5_accuracy: 0.1210\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6628 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0653 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6607 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2088 - val_top5_accuracy: 0.1185 - learning_rate: 0.0012\n",
            "Epoch 24/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6628 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0649 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6607 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2089 - val_top5_accuracy: 0.1185 - learning_rate: 6.2500e-04\n",
            "Epoch 25/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6629 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0648 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6607 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2089 - val_top5_accuracy: 0.1185 - learning_rate: 6.2500e-04\n",
            "Epoch 26/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6629 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0648 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6607 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2089 - val_top5_accuracy: 0.1185 - learning_rate: 6.2500e-04\n",
            "Epoch 27/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6629 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0647 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6604 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2089 - val_top5_accuracy: 0.1185 - learning_rate: 6.2500e-04\n",
            "Epoch 28/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0293 - auc: 0.6625 - f1_macro: 2.7192e-04 - f1_weighted: 0.0017 - loss: 5.0648 - top5_accuracy: 0.1210\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6625 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0647 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6604 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2089 - val_top5_accuracy: 0.1185 - learning_rate: 6.2500e-04\n",
            "Epoch 29/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6628 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0645 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6604 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2089 - val_top5_accuracy: 0.1185 - learning_rate: 3.1250e-04\n",
            "Epoch 30/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6626 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0645 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6604 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2089 - val_top5_accuracy: 0.1185 - learning_rate: 3.1250e-04\n",
            "Epoch 31/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6625 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0645 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6604 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2089 - val_top5_accuracy: 0.1185 - learning_rate: 3.1250e-04\n",
            "Epoch 32/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6624 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0644 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6604 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2089 - val_top5_accuracy: 0.1185 - learning_rate: 3.1250e-04\n",
            "Epoch 33/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0293 - auc: 0.6620 - f1_macro: 2.7192e-04 - f1_weighted: 0.0017 - loss: 5.0645 - top5_accuracy: 0.1210\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6620 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0644 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6598 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2089 - val_top5_accuracy: 0.1185 - learning_rate: 3.1250e-04\n",
            "Epoch 34/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6621 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0643 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6598 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2089 - val_top5_accuracy: 0.1185 - learning_rate: 1.5625e-04\n",
            "Epoch 35/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6621 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0643 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6598 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2089 - val_top5_accuracy: 0.1185 - learning_rate: 1.5625e-04\n",
            "Epoch 36/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6621 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0643 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6598 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2089 - val_top5_accuracy: 0.1185 - learning_rate: 1.5625e-04\n",
            "Epoch 37/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6621 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0643 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6598 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2089 - val_top5_accuracy: 0.1185 - learning_rate: 1.5625e-04\n",
            "Epoch 38/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0293 - auc: 0.6620 - f1_macro: 2.7192e-04 - f1_weighted: 0.0017 - loss: 5.0644 - top5_accuracy: 0.1210\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6621 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0643 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6598 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2089 - val_top5_accuracy: 0.1185 - learning_rate: 1.5625e-04\n",
            "Epoch 39/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6621 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0642 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6598 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2089 - val_top5_accuracy: 0.1185 - learning_rate: 7.8125e-05\n",
            "Epoch 40/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 226ms/step - accuracy: 0.0292 - auc: 0.6621 - f1_macro: 2.7154e-04 - f1_weighted: 0.0016 - loss: 5.0642 - top5_accuracy: 0.1210 - val_accuracy: 0.0239 - val_auc: 0.6598 - val_f1_macro: 2.3163e-04 - val_f1_weighted: 0.0011 - val_loss: 7.2089 - val_top5_accuracy: 0.1185 - learning_rate: 7.8125e-05\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step\n",
            "Finished 'mixup'\n",
            "  Accuracy:      0.0239\n",
            "  F1 (macro):    0.0002\n",
            "  F1 (weighted): 0.0011\n",
            "  Precision:     0.0006\n",
            "  Recall:        0.0239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Initialize the preprocessor\n",
        "batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "image_size = (224, 224)\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Loop through each augmentation\n",
        "for aug in augmentations_to_test:\n",
        "    print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "    model = build_vgg_model()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "    train_ds_sampled, class_names = preprocess.load_img(data_dir=\"data/rare_species/train_sampled\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "    val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "    test_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/test\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "    # Initialize the experiment\n",
        "    experiment = Experiment(\n",
        "        model=model,\n",
        "        train_ds=train_ds_sampled,\n",
        "        val_ds=val_ds,\n",
        "        experiment_name=f\"vggnet_with_{aug}_no_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "        batch_size=32,\n",
        "        image_size=(224, 224),\n",
        "        save_model = False\n",
        "    )\n",
        "\n",
        "    # Run the experiment\n",
        "    history = experiment.run_experiment(callbacks=callbacks, epochs=40)\n",
        "\n",
        "    # Predict entire validation set at once\n",
        "    preds = model.predict(val_ds)\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Extract true labels in order\n",
        "    y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "    # Compute metrics\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Store in results\n",
        "    results[aug] = {\n",
        "        \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "        \"f1_macro\": f1_macro,\n",
        "        \"f1_weighted\": f1_weighted,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall\n",
        "    }\n",
        "\n",
        "    print(f\"Finished '{aug}'\")\n",
        "    print(f\"  Accuracy:      {results[aug]['accuracy']:.4f}\")\n",
        "    print(f\"  F1 (macro):    {results[aug]['f1_macro']:.4f}\")\n",
        "    print(f\"  F1 (weighted): {results[aug]['f1_weighted']:.4f}\")\n",
        "    print(f\"  Precision:     {results[aug]['precision']:.4f}\")\n",
        "    print(f\"  Recall:        {results[aug]['recall']:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    # Clear memory to avoid OOM\n",
        "    del model\n",
        "    del experiment\n",
        "    K.clear_session()\n",
        "    gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZAbCMzH_0QG",
        "outputId": "1483002c-d921-41fa-f88a-069846f444e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     augmentation  accuracy  f1_macro  f1_weighted  precision  recall\n",
              "0            none    0.0223    0.0002       0.0010     0.0005  0.0223\n",
              "1  grayscale_plus    0.0250    0.0002       0.0012     0.0006  0.0250\n",
              "2           mixup    0.0239    0.0002       0.0011     0.0006  0.0239"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a93a903d-dee5-43df-9b4e-ff8c85785515\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>augmentation</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>f1_weighted</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>none</td>\n",
              "      <td>0.0223</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>0.0223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>grayscale_plus</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0006</td>\n",
              "      <td>0.0250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mixup</td>\n",
              "      <td>0.0239</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0011</td>\n",
              "      <td>0.0006</td>\n",
              "      <td>0.0239</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a93a903d-dee5-43df-9b4e-ff8c85785515')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a93a903d-dee5-43df-9b4e-ff8c85785515 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a93a903d-dee5-43df-9b4e-ff8c85785515');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c342877e-c77b-42e6-ace3-157d4baea8e7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c342877e-c77b-42e6-ace3-157d4baea8e7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c342877e-c77b-42e6-ace3-157d4baea8e7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(results_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"augmentation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"none\",\n          \"grayscale_plus\",\n          \"mixup\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0013576941236277539,\n        \"min\": 0.0223,\n        \"max\": 0.025,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0223,\n          0.025,\n          0.0239\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0002,\n        \"max\": 0.0002,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_weighted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.999999999999994e-05,\n        \"min\": 0.001,\n        \"max\": 0.0012,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.7735026918962544e-05,\n        \"min\": 0.0005,\n        \"max\": 0.0006,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0006\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0013576941236277539,\n        \"min\": 0.0223,\n        \"max\": 0.025,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0223\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# Display the table\n",
        "display(results_df.round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zakvyghM_0QG",
        "outputId": "a64a5bb4-349c-42eb-8aeb-90faa1916a86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# Melt the DataFrame for seaborn plotting\n",
        "metrics_to_plot = ['accuracy', 'f1_macro', 'f1_weighted', 'precision', 'recall']\n",
        "melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "                            var_name='metric', value_name='value')\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "plt.title(\"Comparison of Metrics Across Augmentation Strategies\")\n",
        "plt.ylim(0, 0.4)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGGNet2 - With oversampling"
      ],
      "metadata": {
        "id": "rnh9jUYNEhri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vgg_model(input_shape=(224, 224, 3), num_classes=202):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Block 4 (optional to reduce overfitting)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_vgg_model()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "inKrTDPGEkIx",
        "outputId": "d5a419b2-01ea-4d1b-d9d1-5aadfa72b5f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200704\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │   \u001b[38;5;34m102,760,960\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m202\u001b[0m)            │       \u001b[38;5;34m103,626\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200704</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │   <span style=\"color: #00af00; text-decoration-color: #00af00\">102,760,960</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">103,626</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,601,866\u001b[0m (399.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,601,866</span> (399.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m104,600,970\u001b[0m (399.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,600,970</span> (399.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the preprocessor\n",
        "batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "image_size = (224, 224)\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Loop through each augmentation\n",
        "for aug in augmentations_to_test:\n",
        "    print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "    model = build_vgg_model()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=True, shuffle=True)\n",
        "    train_ds_sampled, class_names = preprocess.load_img(data_dir=\"data/rare_species/train_sampled\", minority_class=minority_class, augment=aug, oversampling=True, shuffle=True)\n",
        "    val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "    test_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/test\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "    # Initialize the experiment\n",
        "    experiment = Experiment(\n",
        "        model=model,\n",
        "        train_ds=train_ds_sampled,\n",
        "        val_ds=val_ds,\n",
        "        experiment_name=f\"vggnet_with_{aug}_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "        batch_size=32,\n",
        "        image_size=(224, 224),\n",
        "        save_model = False\n",
        "    )\n",
        "\n",
        "    # Run the experiment\n",
        "    history = experiment.run_experiment(callbacks=callbacks, epochs=40)\n",
        "\n",
        "    # Predict entire validation set at once\n",
        "    preds = model.predict(val_ds)\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Extract true labels in order\n",
        "    y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "    # Compute metrics\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Store in results\n",
        "    results[aug] = {\n",
        "        \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "        \"f1_macro\": f1_macro,\n",
        "        \"f1_weighted\": f1_weighted,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall\n",
        "    }\n",
        "\n",
        "    print(f\"Finished '{aug}'\")\n",
        "    print(f\"  Accuracy:      {results[aug]['accuracy']:.4f}\")\n",
        "    print(f\"  F1 (macro):    {results[aug]['f1_macro']:.4f}\")\n",
        "    print(f\"  F1 (weighted): {results[aug]['f1_weighted']:.4f}\")\n",
        "    print(f\"  Precision:     {results[aug]['precision']:.4f}\")\n",
        "    print(f\"  Recall:        {results[aug]['recall']:.4f}\")\n",
        "\n",
        "\n",
        "    # Clear memory to avoid OOM\n",
        "    del model\n",
        "    del experiment\n",
        "    K.clear_session()\n",
        "    gc.collect()\n"
      ],
      "metadata": {
        "id": "ZponFmi3EmXP",
        "outputId": "739dcaf1-2ceb-443b-fbfc-9bd21cdec874",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: none\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 4194 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Found 749 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 253ms/step - accuracy: 0.0202 - auc: 0.5918 - f1_macro: 0.0013 - f1_weighted: 0.0038 - loss: 120.3212 - top5_accuracy: 0.1295 - val_accuracy: 0.0262 - val_auc: 0.6052 - val_f1_macro: 8.8517e-04 - val_f1_weighted: 0.0028 - val_loss: 23.0474 - val_top5_accuracy: 0.1018 - learning_rate: 0.0100\n",
            "Epoch 2/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0212 - auc: 0.6043 - f1_macro: 3.9399e-04 - f1_weighted: 0.0017 - loss: 5.3263 - top5_accuracy: 0.0952 - val_accuracy: 0.0250 - val_auc: 0.6474 - val_f1_macro: 2.4360e-04 - val_f1_weighted: 0.0012 - val_loss: 5.1340 - val_top5_accuracy: 0.1163 - learning_rate: 0.0100\n",
            "Epoch 3/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0212 - auc: 0.6105 - f1_macro: 2.0536e-04 - f1_weighted: 8.9807e-04 - loss: 5.1755 - top5_accuracy: 0.0974 - val_accuracy: 0.0250 - val_auc: 0.6504 - val_f1_macro: 2.4241e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0880 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 4/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0204 - auc: 0.6113 - f1_macro: 3.1840e-04 - f1_weighted: 0.0013 - loss: 5.1738 - top5_accuracy: 0.1025 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0785 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 5/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0154 - auc: 0.6113 - f1_macro: 3.6804e-04 - f1_weighted: 0.0016 - loss: 5.1632 - top5_accuracy: 0.1027 - val_accuracy: 0.0239 - val_auc: 0.6498 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0741 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 6/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0198 - auc: 0.6113 - f1_macro: 4.7077e-04 - f1_weighted: 0.0021 - loss: 5.1628 - top5_accuracy: 0.1027 - val_accuracy: 0.0239 - val_auc: 0.6498 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0722 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 7/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0201 - auc: 0.6113 - f1_macro: 4.8012e-04 - f1_weighted: 0.0022 - loss: 5.1630 - top5_accuracy: 0.1027 - val_accuracy: 0.0239 - val_auc: 0.6500 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0713 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 8/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0206 - auc: 0.6113 - f1_macro: 4.9736e-04 - f1_weighted: 0.0023 - loss: 5.1632 - top5_accuracy: 0.1027 - val_accuracy: 0.0239 - val_auc: 0.6500 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0709 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 9/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0206 - auc: 0.6116 - f1_macro: 4.9736e-04 - f1_weighted: 0.0023 - loss: 5.1634 - top5_accuracy: 0.1027 - val_accuracy: 0.0239 - val_auc: 0.6500 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0706 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 10/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0206 - auc: 0.6115 - f1_macro: 4.9736e-04 - f1_weighted: 0.0023 - loss: 5.1635 - top5_accuracy: 0.1027 - val_accuracy: 0.0239 - val_auc: 0.6500 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0705 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 11/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0206 - auc: 0.6115 - f1_macro: 4.9736e-04 - f1_weighted: 0.0023 - loss: 5.1636 - top5_accuracy: 0.1027 - val_accuracy: 0.0239 - val_auc: 0.6500 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0705 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 12/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0206 - auc: 0.6115 - f1_macro: 4.9736e-04 - f1_weighted: 0.0023 - loss: 5.1637 - top5_accuracy: 0.1027 - val_accuracy: 0.0239 - val_auc: 0.6500 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0705 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 13/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0206 - auc: 0.6115 - f1_macro: 4.9736e-04 - f1_weighted: 0.0023 - loss: 5.1638 - top5_accuracy: 0.1027 - val_accuracy: 0.0239 - val_auc: 0.6500 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0704 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 14/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0206 - auc: 0.6115 - f1_macro: 4.9736e-04 - f1_weighted: 0.0023 - loss: 5.1638 - top5_accuracy: 0.1027 - val_accuracy: 0.0239 - val_auc: 0.6500 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0704 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 15/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0206 - auc: 0.6115 - f1_macro: 4.9736e-04 - f1_weighted: 0.0023 - loss: 5.1638 - top5_accuracy: 0.1027 - val_accuracy: 0.0239 - val_auc: 0.6500 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0704 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 16/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0206 - auc: 0.6115 - f1_macro: 4.9736e-04 - f1_weighted: 0.0023 - loss: 5.1638 - top5_accuracy: 0.1027 - val_accuracy: 0.0239 - val_auc: 0.6500 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0704 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 17/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0206 - auc: 0.6115 - f1_macro: 4.9736e-04 - f1_weighted: 0.0023 - loss: 5.1639 - top5_accuracy: 0.1027 - val_accuracy: 0.0239 - val_auc: 0.6500 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0704 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 18/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0206 - auc: 0.6115 - f1_macro: 4.9736e-04 - f1_weighted: 0.0023 - loss: 5.1639 - top5_accuracy: 0.1027 - val_accuracy: 0.0239 - val_auc: 0.6500 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0704 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 19/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0206 - auc: 0.6115 - f1_macro: 4.9736e-04 - f1_weighted: 0.0023 - loss: 5.1639 - top5_accuracy: 0.1027 - val_accuracy: 0.0239 - val_auc: 0.6500 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0704 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 20/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0212 - auc: 0.6116 - f1_macro: 5.1403e-04 - f1_weighted: 0.0024 - loss: 5.1638 - top5_accuracy: 0.1028\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0212 - auc: 0.6115 - f1_macro: 5.1411e-04 - f1_weighted: 0.0024 - loss: 5.1639 - top5_accuracy: 0.1027 - val_accuracy: 0.0239 - val_auc: 0.6500 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0704 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 21/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0196 - auc: 0.6114 - f1_macro: 3.2090e-04 - f1_weighted: 0.0014 - loss: 5.1607 - top5_accuracy: 0.1017 - val_accuracy: 0.0239 - val_auc: 0.6500 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0701 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 22/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0194 - auc: 0.6115 - f1_macro: 3.4153e-04 - f1_weighted: 0.0015 - loss: 5.1598 - top5_accuracy: 0.1023 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0700 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 23/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0169 - auc: 0.6116 - f1_macro: 4.0335e-04 - f1_weighted: 0.0018 - loss: 5.1591 - top5_accuracy: 0.1027 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0699 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 24/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0158 - auc: 0.6117 - f1_macro: 3.8895e-04 - f1_weighted: 0.0017 - loss: 5.1586 - top5_accuracy: 0.1030 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0698 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 25/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0158 - auc: 0.6117 - f1_macro: 3.8256e-04 - f1_weighted: 0.0017 - loss: 5.1583 - top5_accuracy: 0.1038 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0697 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 26/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0158 - auc: 0.6117 - f1_macro: 3.8256e-04 - f1_weighted: 0.0017 - loss: 5.1580 - top5_accuracy: 0.1041 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0697 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 27/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0158 - auc: 0.6118 - f1_macro: 3.8012e-04 - f1_weighted: 0.0017 - loss: 5.1578 - top5_accuracy: 0.1041 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0697 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 28/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0156 - auc: 0.6118 - f1_macro: 3.7310e-04 - f1_weighted: 0.0016 - loss: 5.1577 - top5_accuracy: 0.1041 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0697 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 29/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0156 - auc: 0.6118 - f1_macro: 3.7310e-04 - f1_weighted: 0.0016 - loss: 5.1576 - top5_accuracy: 0.1041 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0697 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 30/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.0156 - auc: 0.6119 - f1_macro: 3.7288e-04 - f1_weighted: 0.0016 - loss: 5.1574 - top5_accuracy: 0.1041\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0156 - auc: 0.6119 - f1_macro: 3.7310e-04 - f1_weighted: 0.0016 - loss: 5.1575 - top5_accuracy: 0.1041 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0697 - val_top5_accuracy: 0.1185 - learning_rate: 0.0050\n",
            "Epoch 31/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0205 - auc: 0.6116 - f1_macro: 2.8146e-04 - f1_weighted: 0.0012 - loss: 5.1557 - top5_accuracy: 0.1023 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0696 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 32/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0204 - auc: 0.6117 - f1_macro: 2.7794e-04 - f1_weighted: 0.0012 - loss: 5.1555 - top5_accuracy: 0.1036 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0696 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 33/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0204 - auc: 0.6118 - f1_macro: 2.7320e-04 - f1_weighted: 0.0012 - loss: 5.1552 - top5_accuracy: 0.1044 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0695 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 34/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0204 - auc: 0.6119 - f1_macro: 2.7320e-04 - f1_weighted: 0.0012 - loss: 5.1550 - top5_accuracy: 0.1055 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0695 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 35/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0205 - auc: 0.6119 - f1_macro: 2.7572e-04 - f1_weighted: 0.0012 - loss: 5.1549 - top5_accuracy: 0.1040 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0695 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 36/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0202 - auc: 0.6120 - f1_macro: 2.5852e-04 - f1_weighted: 0.0011 - loss: 5.1547 - top5_accuracy: 0.1033 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0694 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 37/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0202 - auc: 0.6120 - f1_macro: 2.5852e-04 - f1_weighted: 0.0011 - loss: 5.1546 - top5_accuracy: 0.1037 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0694 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 38/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0202 - auc: 0.6120 - f1_macro: 2.5852e-04 - f1_weighted: 0.0011 - loss: 5.1545 - top5_accuracy: 0.1042 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0694 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 39/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0203 - auc: 0.6120 - f1_macro: 2.5832e-04 - f1_weighted: 0.0011 - loss: 5.1543 - top5_accuracy: 0.1059\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0202 - auc: 0.6120 - f1_macro: 2.5852e-04 - f1_weighted: 0.0011 - loss: 5.1544 - top5_accuracy: 0.1059 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0694 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 40/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0206 - auc: 0.6119 - f1_macro: 2.4391e-04 - f1_weighted: 0.0011 - loss: 5.1535 - top5_accuracy: 0.1069 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0694 - val_top5_accuracy: 0.1185 - learning_rate: 0.0012\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step\n",
            "Finished 'none'\n",
            "  Accuracy:      0.0250\n",
            "  F1 (macro):    0.0002\n",
            "  F1 (weighted): 0.0012\n",
            "  Precision:     0.0006\n",
            "  Recall:        0.0250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: grayscale_plus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 4194 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Found 749 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 252ms/step - accuracy: 0.0202 - auc: 0.5897 - f1_macro: 0.0022 - f1_weighted: 0.0039 - loss: 119.1801 - top5_accuracy: 0.1293 - val_accuracy: 0.0250 - val_auc: 0.6366 - val_f1_macro: 2.5031e-04 - val_f1_weighted: 0.0013 - val_loss: 5.4159 - val_top5_accuracy: 0.1157 - learning_rate: 0.0100\n",
            "Epoch 2/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0152 - auc: 0.6005 - f1_macro: 2.6727e-04 - f1_weighted: 0.0010 - loss: 5.2119 - top5_accuracy: 0.0876 - val_accuracy: 0.0250 - val_auc: 0.6484 - val_f1_macro: 2.4201e-04 - val_f1_weighted: 0.0012 - val_loss: 5.1388 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 3/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0144 - auc: 0.6051 - f1_macro: 2.5238e-04 - f1_weighted: 9.8801e-04 - loss: 5.1847 - top5_accuracy: 0.0898 - val_accuracy: 0.0256 - val_auc: 0.6500 - val_f1_macro: 9.0234e-04 - val_f1_weighted: 0.0022 - val_loss: 5.7695 - val_top5_accuracy: 0.1196 - learning_rate: 0.0100\n",
            "Epoch 4/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0157 - auc: 0.6063 - f1_macro: 2.5414e-04 - f1_weighted: 9.9766e-04 - loss: 5.1787 - top5_accuracy: 0.0889 - val_accuracy: 0.0256 - val_auc: 0.6499 - val_f1_macro: 9.0274e-04 - val_f1_weighted: 0.0022 - val_loss: 8.3884 - val_top5_accuracy: 0.1196 - learning_rate: 0.0100\n",
            "Epoch 5/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0160 - auc: 0.6062 - f1_macro: 2.4580e-04 - f1_weighted: 9.7409e-04 - loss: 5.1778 - top5_accuracy: 0.0896 - val_accuracy: 0.0256 - val_auc: 0.6493 - val_f1_macro: 9.0300e-04 - val_f1_weighted: 0.0022 - val_loss: 11.4271 - val_top5_accuracy: 0.1196 - learning_rate: 0.0100\n",
            "Epoch 6/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0160 - auc: 0.6063 - f1_macro: 2.4580e-04 - f1_weighted: 9.7409e-04 - loss: 5.1778 - top5_accuracy: 0.0902 - val_accuracy: 0.0256 - val_auc: 0.6496 - val_f1_macro: 9.0300e-04 - val_f1_weighted: 0.0022 - val_loss: 14.8828 - val_top5_accuracy: 0.1202 - learning_rate: 0.0100\n",
            "Epoch 7/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0159 - auc: 0.6062 - f1_macro: 2.4499e-04 - f1_weighted: 9.7033e-04 - loss: 5.1780 - top5_accuracy: 0.0902\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0160 - auc: 0.6062 - f1_macro: 2.4564e-04 - f1_weighted: 9.7331e-04 - loss: 5.1780 - top5_accuracy: 0.0902 - val_accuracy: 0.0256 - val_auc: 0.6496 - val_f1_macro: 9.0300e-04 - val_f1_weighted: 0.0022 - val_loss: 18.8213 - val_top5_accuracy: 0.1202 - learning_rate: 0.0100\n",
            "Epoch 8/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0142 - auc: 0.6062 - f1_macro: 2.7357e-04 - f1_weighted: 0.0011 - loss: 5.1748 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6496 - val_f1_macro: 9.0300e-04 - val_f1_weighted: 0.0022 - val_loss: 21.5444 - val_top5_accuracy: 0.1202 - learning_rate: 0.0050\n",
            "Epoch 9/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0150 - auc: 0.6062 - f1_macro: 2.6218e-04 - f1_weighted: 0.0010 - loss: 5.1741 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6496 - val_f1_macro: 9.0300e-04 - val_f1_weighted: 0.0022 - val_loss: 22.4063 - val_top5_accuracy: 0.1202 - learning_rate: 0.0050\n",
            "Epoch 10/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0158 - auc: 0.6062 - f1_macro: 2.5469e-04 - f1_weighted: 9.9996e-04 - loss: 5.1736 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0300e-04 - val_f1_weighted: 0.0022 - val_loss: 22.5774 - val_top5_accuracy: 0.1202 - learning_rate: 0.0050\n",
            "Epoch 11/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0159 - auc: 0.6063 - f1_macro: 2.4000e-04 - f1_weighted: 9.4969e-04 - loss: 5.1732 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0300e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6087 - val_top5_accuracy: 0.1202 - learning_rate: 0.0050\n",
            "Epoch 12/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0162 - auc: 0.6062 - f1_macro: 2.3259e-04 - f1_weighted: 9.2260e-04 - loss: 5.1730 - top5_accuracy: 0.0908\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0162 - auc: 0.6062 - f1_macro: 2.3328e-04 - f1_weighted: 9.2575e-04 - loss: 5.1730 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0300e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6131 - val_top5_accuracy: 0.1202 - learning_rate: 0.0050\n",
            "Epoch 13/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0144 - auc: 0.6063 - f1_macro: 2.6154e-04 - f1_weighted: 0.0010 - loss: 5.1711 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0300e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6139 - val_top5_accuracy: 0.1202 - learning_rate: 0.0025\n",
            "Epoch 14/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0149 - auc: 0.6063 - f1_macro: 2.4345e-04 - f1_weighted: 9.5418e-04 - loss: 5.1708 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0300e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6139 - val_top5_accuracy: 0.1202 - learning_rate: 0.0025\n",
            "Epoch 15/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0161 - auc: 0.6063 - f1_macro: 2.3153e-04 - f1_weighted: 9.1850e-04 - loss: 5.1705 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0300e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6139 - val_top5_accuracy: 0.1202 - learning_rate: 0.0025\n",
            "Epoch 16/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0170 - auc: 0.6063 - f1_macro: 2.2072e-04 - f1_weighted: 8.8085e-04 - loss: 5.1703 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0300e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6138 - val_top5_accuracy: 0.1202 - learning_rate: 0.0025\n",
            "Epoch 17/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.0169 - auc: 0.6063 - f1_macro: 2.1228e-04 - f1_weighted: 8.4630e-04 - loss: 5.1702 - top5_accuracy: 0.0908\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0169 - auc: 0.6063 - f1_macro: 2.1313e-04 - f1_weighted: 8.5007e-04 - loss: 5.1701 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0300e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6138 - val_top5_accuracy: 0.1202 - learning_rate: 0.0025\n",
            "Epoch 18/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0161 - auc: 0.6063 - f1_macro: 2.3038e-04 - f1_weighted: 9.1366e-04 - loss: 5.1691 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0300e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6138 - val_top5_accuracy: 0.1202 - learning_rate: 0.0012\n",
            "Epoch 19/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0169 - auc: 0.6063 - f1_macro: 2.1443e-04 - f1_weighted: 8.5561e-04 - loss: 5.1690 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0300e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6138 - val_top5_accuracy: 0.1202 - learning_rate: 0.0012\n",
            "Epoch 20/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0183 - auc: 0.6063 - f1_macro: 2.2829e-04 - f1_weighted: 9.1074e-04 - loss: 5.1689 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0300e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6138 - val_top5_accuracy: 0.1202 - learning_rate: 0.0012\n",
            "Epoch 21/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0188 - auc: 0.6063 - f1_macro: 2.1329e-04 - f1_weighted: 8.4220e-04 - loss: 5.1688 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6138 - val_top5_accuracy: 0.1202 - learning_rate: 0.0012\n",
            "Epoch 22/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.0188 - auc: 0.6063 - f1_macro: 2.0390e-04 - f1_weighted: 8.0699e-04 - loss: 5.1687 - top5_accuracy: 0.0908\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0188 - auc: 0.6063 - f1_macro: 2.0441e-04 - f1_weighted: 8.0937e-04 - loss: 5.1687 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6138 - val_top5_accuracy: 0.1202 - learning_rate: 0.0012\n",
            "Epoch 23/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8559e-04 - f1_weighted: 7.2937e-04 - loss: 5.1681 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6138 - val_top5_accuracy: 0.1202 - learning_rate: 6.2500e-04\n",
            "Epoch 24/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8559e-04 - f1_weighted: 7.2937e-04 - loss: 5.1681 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6138 - val_top5_accuracy: 0.1202 - learning_rate: 6.2500e-04\n",
            "Epoch 25/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8559e-04 - f1_weighted: 7.2937e-04 - loss: 5.1680 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6137 - val_top5_accuracy: 0.1202 - learning_rate: 6.2500e-04\n",
            "Epoch 26/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8559e-04 - f1_weighted: 7.2937e-04 - loss: 5.1680 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6137 - val_top5_accuracy: 0.1202 - learning_rate: 6.2500e-04\n",
            "Epoch 27/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8550e-04 - f1_weighted: 7.2874e-04 - loss: 5.1679 - top5_accuracy: 0.0908\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8559e-04 - f1_weighted: 7.2937e-04 - loss: 5.1679 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6137 - val_top5_accuracy: 0.1202 - learning_rate: 6.2500e-04\n",
            "Epoch 28/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8559e-04 - f1_weighted: 7.2937e-04 - loss: 5.1676 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6137 - val_top5_accuracy: 0.1202 - learning_rate: 3.1250e-04\n",
            "Epoch 29/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8559e-04 - f1_weighted: 7.2937e-04 - loss: 5.1676 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6137 - val_top5_accuracy: 0.1202 - learning_rate: 3.1250e-04\n",
            "Epoch 30/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8559e-04 - f1_weighted: 7.2937e-04 - loss: 5.1676 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6137 - val_top5_accuracy: 0.1202 - learning_rate: 3.1250e-04\n",
            "Epoch 31/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8559e-04 - f1_weighted: 7.2937e-04 - loss: 5.1676 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6137 - val_top5_accuracy: 0.1202 - learning_rate: 3.1250e-04\n",
            "Epoch 32/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8550e-04 - f1_weighted: 7.2874e-04 - loss: 5.1676 - top5_accuracy: 0.0908\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8559e-04 - f1_weighted: 7.2937e-04 - loss: 5.1675 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6137 - val_top5_accuracy: 0.1202 - learning_rate: 3.1250e-04\n",
            "Epoch 33/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8559e-04 - f1_weighted: 7.2937e-04 - loss: 5.1674 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6137 - val_top5_accuracy: 0.1202 - learning_rate: 1.5625e-04\n",
            "Epoch 34/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8559e-04 - f1_weighted: 7.2937e-04 - loss: 5.1674 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6137 - val_top5_accuracy: 0.1202 - learning_rate: 1.5625e-04\n",
            "Epoch 35/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8559e-04 - f1_weighted: 7.2937e-04 - loss: 5.1674 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6137 - val_top5_accuracy: 0.1202 - learning_rate: 1.5625e-04\n",
            "Epoch 36/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8559e-04 - f1_weighted: 7.2937e-04 - loss: 5.1674 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6137 - val_top5_accuracy: 0.1202 - learning_rate: 1.5625e-04\n",
            "Epoch 37/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8550e-04 - f1_weighted: 7.2874e-04 - loss: 5.1674 - top5_accuracy: 0.0908\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8559e-04 - f1_weighted: 7.2937e-04 - loss: 5.1673 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6137 - val_top5_accuracy: 0.1202 - learning_rate: 1.5625e-04\n",
            "Epoch 38/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8559e-04 - f1_weighted: 7.2937e-04 - loss: 5.1673 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6137 - val_top5_accuracy: 0.1202 - learning_rate: 7.8125e-05\n",
            "Epoch 39/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8559e-04 - f1_weighted: 7.2937e-04 - loss: 5.1673 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6137 - val_top5_accuracy: 0.1202 - learning_rate: 7.8125e-05\n",
            "Epoch 40/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0191 - auc: 0.6063 - f1_macro: 1.8559e-04 - f1_weighted: 7.2937e-04 - loss: 5.1673 - top5_accuracy: 0.0909 - val_accuracy: 0.0256 - val_auc: 0.6494 - val_f1_macro: 9.0327e-04 - val_f1_weighted: 0.0022 - val_loss: 22.6137 - val_top5_accuracy: 0.1202 - learning_rate: 7.8125e-05\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step\n",
            "Finished 'grayscale_plus'\n",
            "  Accuracy:      0.0256\n",
            "  F1 (macro):    0.0009\n",
            "  F1 (weighted): 0.0022\n",
            "  Precision:     0.0042\n",
            "  Recall:        0.0256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: mixup\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 4194 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Found 749 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 251ms/step - accuracy: 0.0209 - auc: 0.5788 - f1_macro: 0.0023 - f1_weighted: 0.0046 - loss: 113.4940 - top5_accuracy: 0.1264 - val_accuracy: 0.0245 - val_auc: 0.6150 - val_f1_macro: 7.7438e-04 - val_f1_weighted: 0.0023 - val_loss: 9.0297 - val_top5_accuracy: 0.1013 - learning_rate: 0.0100\n",
            "Epoch 2/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0148 - auc: 0.5918 - f1_macro: 1.8515e-04 - f1_weighted: 6.5595e-04 - loss: 5.2156 - top5_accuracy: 0.0895 - val_accuracy: 0.0239 - val_auc: 0.6479 - val_f1_macro: 2.3189e-04 - val_f1_weighted: 0.0011 - val_loss: 5.1589 - val_top5_accuracy: 0.1169 - learning_rate: 0.0100\n",
            "Epoch 3/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0143 - auc: 0.5986 - f1_macro: 2.4645e-04 - f1_weighted: 9.2879e-04 - loss: 5.1892 - top5_accuracy: 0.0901 - val_accuracy: 0.0239 - val_auc: 0.6472 - val_f1_macro: 2.3227e-04 - val_f1_weighted: 0.0011 - val_loss: 5.3295 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 4/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0150 - auc: 0.6003 - f1_macro: 2.7475e-04 - f1_weighted: 0.0011 - loss: 5.1839 - top5_accuracy: 0.0914 - val_accuracy: 0.0239 - val_auc: 0.6476 - val_f1_macro: 2.3227e-04 - val_f1_weighted: 0.0011 - val_loss: 5.5122 - val_top5_accuracy: 0.1191 - learning_rate: 0.0100\n",
            "Epoch 5/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0139 - auc: 0.6008 - f1_macro: 3.0501e-04 - f1_weighted: 0.0012 - loss: 5.1839 - top5_accuracy: 0.0903 - val_accuracy: 0.0239 - val_auc: 0.6476 - val_f1_macro: 2.3252e-04 - val_f1_weighted: 0.0011 - val_loss: 5.5684 - val_top5_accuracy: 0.1196 - learning_rate: 0.0100\n",
            "Epoch 6/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0131 - auc: 0.6006 - f1_macro: 3.4710e-04 - f1_weighted: 0.0013 - loss: 5.1847 - top5_accuracy: 0.0907 - val_accuracy: 0.0239 - val_auc: 0.6496 - val_f1_macro: 2.3252e-04 - val_f1_weighted: 0.0011 - val_loss: 5.5804 - val_top5_accuracy: 0.1191 - learning_rate: 0.0100\n",
            "Epoch 7/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.0136 - auc: 0.6003 - f1_macro: 3.6158e-04 - f1_weighted: 0.0014 - loss: 5.1855 - top5_accuracy: 0.0907\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0136 - auc: 0.6004 - f1_macro: 3.6226e-04 - f1_weighted: 0.0014 - loss: 5.1855 - top5_accuracy: 0.0907 - val_accuracy: 0.0239 - val_auc: 0.6492 - val_f1_macro: 2.3252e-04 - val_f1_weighted: 0.0011 - val_loss: 5.5824 - val_top5_accuracy: 0.1191 - learning_rate: 0.0100\n",
            "Epoch 8/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0144 - auc: 0.6002 - f1_macro: 2.8786e-04 - f1_weighted: 0.0011 - loss: 5.1819 - top5_accuracy: 0.0910 - val_accuracy: 0.0239 - val_auc: 0.6487 - val_f1_macro: 2.3252e-04 - val_f1_weighted: 0.0011 - val_loss: 5.5827 - val_top5_accuracy: 0.1191 - learning_rate: 0.0050\n",
            "Epoch 9/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0141 - auc: 0.6006 - f1_macro: 2.7261e-04 - f1_weighted: 0.0010 - loss: 5.1814 - top5_accuracy: 0.0910 - val_accuracy: 0.0239 - val_auc: 0.6487 - val_f1_macro: 2.3252e-04 - val_f1_weighted: 0.0011 - val_loss: 5.5826 - val_top5_accuracy: 0.1191 - learning_rate: 0.0050\n",
            "Epoch 10/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0117 - auc: 0.6008 - f1_macro: 3.0904e-04 - f1_weighted: 0.0012 - loss: 5.1810 - top5_accuracy: 0.0899 - val_accuracy: 0.0239 - val_auc: 0.6487 - val_f1_macro: 2.3252e-04 - val_f1_weighted: 0.0011 - val_loss: 5.5825 - val_top5_accuracy: 0.1191 - learning_rate: 0.0050\n",
            "Epoch 11/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0127 - auc: 0.6004 - f1_macro: 3.3067e-04 - f1_weighted: 0.0013 - loss: 5.1807 - top5_accuracy: 0.0897 - val_accuracy: 0.0239 - val_auc: 0.6492 - val_f1_macro: 2.3252e-04 - val_f1_weighted: 0.0011 - val_loss: 5.5824 - val_top5_accuracy: 0.1191 - learning_rate: 0.0050\n",
            "Epoch 12/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0113 - auc: 0.6002 - f1_macro: 3.1091e-04 - f1_weighted: 0.0012 - loss: 5.1806 - top5_accuracy: 0.0892\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0113 - auc: 0.6002 - f1_macro: 3.1160e-04 - f1_weighted: 0.0012 - loss: 5.1805 - top5_accuracy: 0.0893 - val_accuracy: 0.0239 - val_auc: 0.6492 - val_f1_macro: 2.3252e-04 - val_f1_weighted: 0.0011 - val_loss: 5.5823 - val_top5_accuracy: 0.1191 - learning_rate: 0.0050\n",
            "Epoch 13/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0143 - auc: 0.6007 - f1_macro: 2.7852e-04 - f1_weighted: 0.0011 - loss: 5.1783 - top5_accuracy: 0.0910 - val_accuracy: 0.0239 - val_auc: 0.6477 - val_f1_macro: 2.3252e-04 - val_f1_weighted: 0.0011 - val_loss: 5.5823 - val_top5_accuracy: 0.1191 - learning_rate: 0.0025\n",
            "Epoch 14/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0121 - auc: 0.6009 - f1_macro: 3.1130e-04 - f1_weighted: 0.0012 - loss: 5.1780 - top5_accuracy: 0.0910 - val_accuracy: 0.0239 - val_auc: 0.6480 - val_f1_macro: 2.3252e-04 - val_f1_weighted: 0.0011 - val_loss: 5.5823 - val_top5_accuracy: 0.1191 - learning_rate: 0.0025\n",
            "Epoch 15/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0108 - auc: 0.6013 - f1_macro: 2.9024e-04 - f1_weighted: 0.0011 - loss: 5.1778 - top5_accuracy: 0.0910 - val_accuracy: 0.0239 - val_auc: 0.6480 - val_f1_macro: 2.3252e-04 - val_f1_weighted: 0.0011 - val_loss: 5.5822 - val_top5_accuracy: 0.1191 - learning_rate: 0.0025\n",
            "Epoch 16/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0108 - auc: 0.6018 - f1_macro: 2.8822e-04 - f1_weighted: 0.0011 - loss: 5.1776 - top5_accuracy: 0.0910 - val_accuracy: 0.0239 - val_auc: 0.6480 - val_f1_macro: 2.3252e-04 - val_f1_weighted: 0.0011 - val_loss: 5.5822 - val_top5_accuracy: 0.1191 - learning_rate: 0.0025\n",
            "Epoch 17/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.0108 - auc: 0.6019 - f1_macro: 2.9393e-04 - f1_weighted: 0.0011 - loss: 5.1775 - top5_accuracy: 0.0909\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0108 - auc: 0.6019 - f1_macro: 2.9460e-04 - f1_weighted: 0.0011 - loss: 5.1775 - top5_accuracy: 0.0910 - val_accuracy: 0.0239 - val_auc: 0.6480 - val_f1_macro: 2.3252e-04 - val_f1_weighted: 0.0011 - val_loss: 5.5822 - val_top5_accuracy: 0.1191 - learning_rate: 0.0025\n",
            "Epoch 18/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0120 - auc: 0.6021 - f1_macro: 2.3462e-04 - f1_weighted: 8.6732e-04 - loss: 5.1763 - top5_accuracy: 0.0910 - val_accuracy: 0.0239 - val_auc: 0.6480 - val_f1_macro: 2.3252e-04 - val_f1_weighted: 0.0011 - val_loss: 5.5822 - val_top5_accuracy: 0.1191 - learning_rate: 0.0012\n",
            "Epoch 19/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 220ms/step - accuracy: 0.0112 - auc: 0.6021 - f1_macro: 2.4416e-04 - f1_weighted: 9.1302e-04 - loss: 5.1761 - top5_accuracy: 0.0910 - val_accuracy: 0.0239 - val_auc: 0.6480 - val_f1_macro: 2.3252e-04 - val_f1_weighted: 0.0011 - val_loss: 5.5822 - val_top5_accuracy: 0.1191 - learning_rate: 0.0012\n",
            "Epoch 20/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0112 - auc: 0.6021 - f1_macro: 2.7776e-04 - f1_weighted: 0.0011 - loss: 5.1760 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5822 - val_top5_accuracy: 0.1191 - learning_rate: 0.0012\n",
            "Epoch 21/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0154 - auc: 0.6021 - f1_macro: 3.2912e-04 - f1_weighted: 0.0013 - loss: 5.1759 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5822 - val_top5_accuracy: 0.1191 - learning_rate: 0.0012\n",
            "Epoch 22/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.0176 - auc: 0.6021 - f1_macro: 3.1423e-04 - f1_weighted: 0.0012 - loss: 5.1759 - top5_accuracy: 0.0909\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 221ms/step - accuracy: 0.0176 - auc: 0.6021 - f1_macro: 3.1461e-04 - f1_weighted: 0.0013 - loss: 5.1758 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 0.0012\n",
            "Epoch 23/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0199 - auc: 0.6021 - f1_macro: 1.8849e-04 - f1_weighted: 7.7837e-04 - loss: 5.1752 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 6.2500e-04\n",
            "Epoch 24/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9066e-04 - f1_weighted: 7.8685e-04 - loss: 5.1752 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 6.2500e-04\n",
            "Epoch 25/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9066e-04 - f1_weighted: 7.8685e-04 - loss: 5.1751 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 6.2500e-04\n",
            "Epoch 26/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9066e-04 - f1_weighted: 7.8685e-04 - loss: 5.1751 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 6.2500e-04\n",
            "Epoch 27/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9064e-04 - f1_weighted: 7.8687e-04 - loss: 5.1751 - top5_accuracy: 0.0909\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9066e-04 - f1_weighted: 7.8685e-04 - loss: 5.1750 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 6.2500e-04\n",
            "Epoch 28/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9066e-04 - f1_weighted: 7.8685e-04 - loss: 5.1747 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 3.1250e-04\n",
            "Epoch 29/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9066e-04 - f1_weighted: 7.8685e-04 - loss: 5.1747 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 3.1250e-04\n",
            "Epoch 30/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9066e-04 - f1_weighted: 7.8685e-04 - loss: 5.1746 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 3.1250e-04\n",
            "Epoch 31/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9066e-04 - f1_weighted: 7.8685e-04 - loss: 5.1746 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 3.1250e-04\n",
            "Epoch 32/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9064e-04 - f1_weighted: 7.8687e-04 - loss: 5.1747 - top5_accuracy: 0.0909\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9066e-04 - f1_weighted: 7.8685e-04 - loss: 5.1746 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 3.1250e-04\n",
            "Epoch 33/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9066e-04 - f1_weighted: 7.8685e-04 - loss: 5.1744 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 1.5625e-04\n",
            "Epoch 34/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9066e-04 - f1_weighted: 7.8685e-04 - loss: 5.1744 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 1.5625e-04\n",
            "Epoch 35/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9066e-04 - f1_weighted: 7.8685e-04 - loss: 5.1744 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 1.5625e-04\n",
            "Epoch 36/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9066e-04 - f1_weighted: 7.8685e-04 - loss: 5.1744 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 1.5625e-04\n",
            "Epoch 37/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9064e-04 - f1_weighted: 7.8687e-04 - loss: 5.1744 - top5_accuracy: 0.0909\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9066e-04 - f1_weighted: 7.8685e-04 - loss: 5.1744 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 1.5625e-04\n",
            "Epoch 38/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9066e-04 - f1_weighted: 7.8685e-04 - loss: 5.1743 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 7.8125e-05\n",
            "Epoch 39/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9066e-04 - f1_weighted: 7.8685e-04 - loss: 5.1743 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 7.8125e-05\n",
            "Epoch 40/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 220ms/step - accuracy: 0.0204 - auc: 0.6022 - f1_macro: 1.9066e-04 - f1_weighted: 7.8685e-04 - loss: 5.1743 - top5_accuracy: 0.0910 - val_accuracy: 0.0223 - val_auc: 0.6480 - val_f1_macro: 2.1653e-04 - val_f1_weighted: 9.7362e-04 - val_loss: 5.5821 - val_top5_accuracy: 0.1191 - learning_rate: 7.8125e-05\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step\n",
            "Finished 'mixup'\n",
            "  Accuracy:      0.0223\n",
            "  F1 (macro):    0.0002\n",
            "  F1 (weighted): 0.0010\n",
            "  Precision:     0.0005\n",
            "  Recall:        0.0223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# Display the table\n",
        "display(results_df.round(4))"
      ],
      "metadata": {
        "id": "M-JsROiWFoBL",
        "outputId": "9eef2af5-d99f-466f-8a11-9e08609a6817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     augmentation  accuracy  f1_macro  f1_weighted  precision  recall\n",
              "0            none    0.0250    0.0002       0.0012     0.0006  0.0250\n",
              "1  grayscale_plus    0.0256    0.0009       0.0022     0.0042  0.0256\n",
              "2           mixup    0.0223    0.0002       0.0010     0.0005  0.0223"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d05b4d56-72da-4435-9ca9-2a9cc74a7965\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>augmentation</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>f1_weighted</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>none</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0006</td>\n",
              "      <td>0.0250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>grayscale_plus</td>\n",
              "      <td>0.0256</td>\n",
              "      <td>0.0009</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mixup</td>\n",
              "      <td>0.0223</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>0.0223</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d05b4d56-72da-4435-9ca9-2a9cc74a7965')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d05b4d56-72da-4435-9ca9-2a9cc74a7965 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d05b4d56-72da-4435-9ca9-2a9cc74a7965');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1c6a838c-52de-4865-b79c-cf0c9becae88\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1c6a838c-52de-4865-b79c-cf0c9becae88')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1c6a838c-52de-4865-b79c-cf0c9becae88 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(results_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"augmentation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"none\",\n          \"grayscale_plus\",\n          \"mixup\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.001757839583124695,\n        \"min\": 0.0223,\n        \"max\": 0.0256,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.025,\n          0.0256,\n          0.0223\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.000404145188432738,\n        \"min\": 0.0002,\n        \"max\": 0.0009,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0009,\n          0.0002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_weighted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0006429100507328638,\n        \"min\": 0.001,\n        \"max\": 0.0022,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0012,\n          0.0022\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0021079215671683167,\n        \"min\": 0.0005,\n        \"max\": 0.0042,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0006,\n          0.0042\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.001757839583124695,\n        \"min\": 0.0223,\n        \"max\": 0.0256,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.025,\n          0.0256\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melt the DataFrame for seaborn plotting\n",
        "metrics_to_plot = ['accuracy', 'f1_macro', 'f1_weighted', 'precision', 'recall']\n",
        "melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "                            var_name='metric', value_name='value')\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "plt.title(\"Comparison of Metrics Across Augmentation Strategies\")\n",
        "plt.ylim(0, 0.4)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0vmKh3YHFub9",
        "outputId": "f46a5a7a-8546-402b-852b-807f62ca5a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dbov_G3v_0QH"
      },
      "source": [
        "## 4.7 DenseNet - No Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohHuNN5T_0QH",
        "outputId": "e69128e1-6049-4ba4-e5f5-e2c088e2ee0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │      \u001b[38;5;34m9,472\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m18,464\u001b[0m │ re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m96\u001b[0m)               │            │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m27,680\u001b[0m │ re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m36,896\u001b[0m │ re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m160\u001b[0m)              │            │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m640\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m46,112\u001b[0m │ re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m192\u001b[0m)              │            │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m768\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m18,528\u001b[0m │ re_lu_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m27,680\u001b[0m │ re_lu_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_7 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m36,896\u001b[0m │ re_lu_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m160\u001b[0m)              │            │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m640\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_8 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m46,112\u001b[0m │ re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m192\u001b[0m)              │            │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m768\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_9 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m55,328\u001b[0m │ re_lu_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m224\u001b[0m)              │            │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m896\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m224\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_10 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m224\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m25,200\u001b[0m │ re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m448\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_11 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m32,288\u001b[0m │ re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m144\u001b[0m)              │            │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m576\u001b[0m │ concatenate_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m144\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_12 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m144\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m41,504\u001b[0m │ re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m176\u001b[0m)              │            │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m704\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m176\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_13 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m176\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m50,720\u001b[0m │ re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m208\u001b[0m)              │            │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m832\u001b[0m │ concatenate_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m208\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_14 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m208\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m59,936\u001b[0m │ re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m240\u001b[0m)              │            │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m960\u001b[0m │ concatenate_11[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m240\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_15 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m240\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m28,920\u001b[0m │ re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m120\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_3 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m120\u001b[0m) │        \u001b[38;5;34m480\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_16 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m34,592\u001b[0m │ re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m152\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m152\u001b[0m) │        \u001b[38;5;34m608\u001b[0m │ concatenate_12[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_17 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m152\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m43,808\u001b[0m │ re_lu_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m184\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ concatenate_12[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m184\u001b[0m) │        \u001b[38;5;34m736\u001b[0m │ concatenate_13[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_18 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m184\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m53,024\u001b[0m │ re_lu_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m216\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ concatenate_13[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m216\u001b[0m) │        \u001b[38;5;34m864\u001b[0m │ concatenate_14[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_19 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m216\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m62,240\u001b[0m │ re_lu_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m248\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ concatenate_14[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m248\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_15[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m202\u001b[0m)       │     \u001b[38;5;34m50,298\u001b[0m │ global_average_p… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,472</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │ re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,680</span> │ re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,896</span> │ re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">46,112</span> │ re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,528</span> │ re_lu_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,680</span> │ re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,896</span> │ re_lu_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">46,112</span> │ re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">55,328</span> │ re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │            │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">25,200</span> │ re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,288</span> │ re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              │            │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,504</span> │ re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>)              │            │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">50,720</span> │ re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)              │            │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │ concatenate_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">59,936</span> │ re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)              │            │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> │ concatenate_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">28,920</span> │ re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_3 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">34,592</span> │ re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> │ concatenate_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">43,808</span> │ re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">736</span> │ concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">53,024</span> │ re_lu_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span> │ concatenate_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">62,240</span> │ re_lu_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">248</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">248</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">50,298</span> │ global_average_p… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m817,922\u001b[0m (3.12 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">817,922</span> (3.12 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m811,810\u001b[0m (3.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">811,810</span> (3.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6,112\u001b[0m (23.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,112</span> (23.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "def dense_layer(x, growth_rate):\n",
        "    \"\"\"Single layer inside a dense block.\"\"\"\n",
        "    out = BatchNormalization()(x)\n",
        "    out = ReLU()(out)\n",
        "    out = Conv2D(growth_rate, (3, 3), padding='same', kernel_regularizer=l2(1e-4))(out)\n",
        "    x = Concatenate()([x, out])  # Concatenate input and output (dense connection)\n",
        "    return x\n",
        "\n",
        "def dense_block(x, num_layers, growth_rate):\n",
        "    \"\"\"Dense block with several dense layers.\"\"\"\n",
        "    for _ in range(num_layers):\n",
        "        x = dense_layer(x, growth_rate)\n",
        "    return x\n",
        "\n",
        "def transition_layer(x, reduction=0.5):\n",
        "    \"\"\"Reduces spatial size and number of filters.\"\"\"\n",
        "    filters = int(tf.keras.backend.int_shape(x)[-1] * reduction)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=l2(1e-4))(x)\n",
        "    x = AveragePooling2D((2, 2), strides=2)(x)\n",
        "    return x\n",
        "\n",
        "def build_densenet(input_shape=(224, 224, 3), num_classes=202, growth_rate=32):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Initial conv\n",
        "    x = Conv2D(64, (7, 7), strides=2, padding='same', kernel_regularizer=l2(1e-4))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = AveragePooling2D((3, 3), strides=2, padding='same')(x)\n",
        "\n",
        "    # Dense Block 1\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "    x = transition_layer(x)\n",
        "\n",
        "    # Dense Block 2\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "    x = transition_layer(x)\n",
        "\n",
        "    # Dense Block 3\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "    x = transition_layer(x)\n",
        "\n",
        "    # Dense Block 4\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "\n",
        "    # Classification\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "model = build_densenet()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2CDiw1d_0QH",
        "outputId": "2ebe82cd-f70d-4544-ca86-4c7d5d4b064a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: none\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 4194 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Found 749 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 2s/step - accuracy: 0.0223 - auc: 0.5766 - f1_macro: 0.0035 - f1_weighted: 0.0101 - loss: 7.7733 - top5_accuracy: 0.0712 - val_accuracy: 0.0161 - val_auc: 0.5892 - val_f1_macro: 0.0011 - val_f1_weighted: 0.0049 - val_loss: 16.5151 - val_top5_accuracy: 0.0757 - learning_rate: 0.0100\n",
            "Epoch 2/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.0349 - auc: 0.6535 - f1_macro: 0.0046 - f1_weighted: 0.0136 - loss: 5.8001 - top5_accuracy: 0.1245 - val_accuracy: 0.0506 - val_auc: 0.6680 - val_f1_macro: 0.0045 - val_f1_weighted: 0.0191 - val_loss: 5.3546 - val_top5_accuracy: 0.1519 - learning_rate: 0.0100\n",
            "Epoch 3/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.0446 - auc: 0.6783 - f1_macro: 0.0047 - f1_weighted: 0.0168 - loss: 5.3338 - top5_accuracy: 0.1511 - val_accuracy: 0.0467 - val_auc: 0.6771 - val_f1_macro: 0.0033 - val_f1_weighted: 0.0134 - val_loss: 5.3062 - val_top5_accuracy: 0.1525 - learning_rate: 0.0100\n",
            "Epoch 4/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.0488 - auc: 0.6944 - f1_macro: 0.0058 - f1_weighted: 0.0174 - loss: 5.1810 - top5_accuracy: 0.1549 - val_accuracy: 0.0339 - val_auc: 0.6465 - val_f1_macro: 0.0025 - val_f1_weighted: 0.0112 - val_loss: 5.5662 - val_top5_accuracy: 0.1280 - learning_rate: 0.0100\n",
            "Epoch 5/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.0533 - auc: 0.7109 - f1_macro: 0.0066 - f1_weighted: 0.0208 - loss: 5.0769 - top5_accuracy: 0.1618 - val_accuracy: 0.0456 - val_auc: 0.6854 - val_f1_macro: 0.0032 - val_f1_weighted: 0.0144 - val_loss: 5.1373 - val_top5_accuracy: 0.1569 - learning_rate: 0.0100\n",
            "Epoch 6/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.0649 - auc: 0.7219 - f1_macro: 0.0086 - f1_weighted: 0.0257 - loss: 4.9799 - top5_accuracy: 0.1798 - val_accuracy: 0.0495 - val_auc: 0.6474 - val_f1_macro: 0.0038 - val_f1_weighted: 0.0170 - val_loss: 5.4092 - val_top5_accuracy: 0.1258 - learning_rate: 0.0100\n",
            "Epoch 7/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.0653 - auc: 0.7400 - f1_macro: 0.0085 - f1_weighted: 0.0280 - loss: 4.9036 - top5_accuracy: 0.1852 - val_accuracy: 0.0501 - val_auc: 0.6924 - val_f1_macro: 0.0060 - val_f1_weighted: 0.0186 - val_loss: 5.1383 - val_top5_accuracy: 0.1553 - learning_rate: 0.0100\n",
            "Epoch 8/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.0655 - auc: 0.7440 - f1_macro: 0.0090 - f1_weighted: 0.0296 - loss: 4.8264 - top5_accuracy: 0.1828 - val_accuracy: 0.0490 - val_auc: 0.6746 - val_f1_macro: 0.0063 - val_f1_weighted: 0.0207 - val_loss: 5.2518 - val_top5_accuracy: 0.1313 - learning_rate: 0.0100\n",
            "Epoch 9/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.0730 - auc: 0.7528 - f1_macro: 0.0118 - f1_weighted: 0.0343 - loss: 4.7699 - top5_accuracy: 0.1893 - val_accuracy: 0.0640 - val_auc: 0.6948 - val_f1_macro: 0.0092 - val_f1_weighted: 0.0296 - val_loss: 5.3061 - val_top5_accuracy: 0.1692 - learning_rate: 0.0100\n",
            "Epoch 10/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0769 - auc: 0.7631 - f1_macro: 0.0130 - f1_weighted: 0.0356 - loss: 4.6967 - top5_accuracy: 0.2056\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.0769 - auc: 0.7631 - f1_macro: 0.0130 - f1_weighted: 0.0356 - loss: 4.6963 - top5_accuracy: 0.2057 - val_accuracy: 0.0512 - val_auc: 0.6547 - val_f1_macro: 0.0071 - val_f1_weighted: 0.0234 - val_loss: 5.4842 - val_top5_accuracy: 0.1308 - learning_rate: 0.0100\n",
            "Epoch 11/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.0854 - auc: 0.7777 - f1_macro: 0.0152 - f1_weighted: 0.0411 - loss: 4.6005 - top5_accuracy: 0.2155 - val_accuracy: 0.0534 - val_auc: 0.6854 - val_f1_macro: 0.0085 - val_f1_weighted: 0.0233 - val_loss: 5.5937 - val_top5_accuracy: 0.1597 - learning_rate: 0.0050\n",
            "Epoch 12/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.0860 - auc: 0.7823 - f1_macro: 0.0180 - f1_weighted: 0.0440 - loss: 4.5536 - top5_accuracy: 0.2256 - val_accuracy: 0.0612 - val_auc: 0.7106 - val_f1_macro: 0.0110 - val_f1_weighted: 0.0300 - val_loss: 5.2577 - val_top5_accuracy: 0.1753 - learning_rate: 0.0050\n",
            "Epoch 13/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.0875 - auc: 0.7895 - f1_macro: 0.0183 - f1_weighted: 0.0459 - loss: 4.5039 - top5_accuracy: 0.2433 - val_accuracy: 0.0679 - val_auc: 0.7166 - val_f1_macro: 0.0128 - val_f1_weighted: 0.0311 - val_loss: 5.1777 - val_top5_accuracy: 0.1809 - learning_rate: 0.0050\n",
            "Epoch 14/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.0893 - auc: 0.7952 - f1_macro: 0.0225 - f1_weighted: 0.0474 - loss: 4.4595 - top5_accuracy: 0.2369 - val_accuracy: 0.0746 - val_auc: 0.7319 - val_f1_macro: 0.0114 - val_f1_weighted: 0.0307 - val_loss: 5.0960 - val_top5_accuracy: 0.2020 - learning_rate: 0.0050\n",
            "Epoch 15/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.0883 - auc: 0.7992 - f1_macro: 0.0263 - f1_weighted: 0.0488 - loss: 4.4340 - top5_accuracy: 0.2408 - val_accuracy: 0.0512 - val_auc: 0.6947 - val_f1_macro: 0.0065 - val_f1_weighted: 0.0218 - val_loss: 5.6085 - val_top5_accuracy: 0.1614 - learning_rate: 0.0050\n",
            "Epoch 16/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.0886 - auc: 0.8017 - f1_macro: 0.0261 - f1_weighted: 0.0494 - loss: 4.4121 - top5_accuracy: 0.2455 - val_accuracy: 0.0690 - val_auc: 0.7280 - val_f1_macro: 0.0113 - val_f1_weighted: 0.0328 - val_loss: 5.1999 - val_top5_accuracy: 0.1909 - learning_rate: 0.0050\n",
            "Epoch 17/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.0946 - auc: 0.8114 - f1_macro: 0.0316 - f1_weighted: 0.0557 - loss: 4.3784 - top5_accuracy: 0.2607 - val_accuracy: 0.0623 - val_auc: 0.7027 - val_f1_macro: 0.0164 - val_f1_weighted: 0.0350 - val_loss: 6.1582 - val_top5_accuracy: 0.1814 - learning_rate: 0.0050\n",
            "Epoch 18/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.0925 - auc: 0.8088 - f1_macro: 0.0299 - f1_weighted: 0.0550 - loss: 4.3700 - top5_accuracy: 0.2594 - val_accuracy: 0.0556 - val_auc: 0.7023 - val_f1_macro: 0.0131 - val_f1_weighted: 0.0286 - val_loss: 5.9005 - val_top5_accuracy: 0.1797 - learning_rate: 0.0050\n",
            "Epoch 19/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0967 - auc: 0.8157 - f1_macro: 0.0305 - f1_weighted: 0.0579 - loss: 4.3332 - top5_accuracy: 0.2683\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.0967 - auc: 0.8157 - f1_macro: 0.0306 - f1_weighted: 0.0580 - loss: 4.3331 - top5_accuracy: 0.2683 - val_accuracy: 0.0707 - val_auc: 0.7267 - val_f1_macro: 0.0170 - val_f1_weighted: 0.0392 - val_loss: 5.6050 - val_top5_accuracy: 0.2020 - learning_rate: 0.0050\n",
            "Epoch 20/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.1086 - auc: 0.8245 - f1_macro: 0.0393 - f1_weighted: 0.0667 - loss: 4.2741 - top5_accuracy: 0.2945 - val_accuracy: 0.0584 - val_auc: 0.6982 - val_f1_macro: 0.0144 - val_f1_weighted: 0.0334 - val_loss: 5.6003 - val_top5_accuracy: 0.2048 - learning_rate: 0.0025\n",
            "Epoch 21/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.1102 - auc: 0.8303 - f1_macro: 0.0451 - f1_weighted: 0.0711 - loss: 4.2139 - top5_accuracy: 0.2945 - val_accuracy: 0.0812 - val_auc: 0.7158 - val_f1_macro: 0.0244 - val_f1_weighted: 0.0492 - val_loss: 5.3757 - val_top5_accuracy: 0.2076 - learning_rate: 0.0025\n",
            "Epoch 22/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.1097 - auc: 0.8362 - f1_macro: 0.0497 - f1_weighted: 0.0731 - loss: 4.1623 - top5_accuracy: 0.3036 - val_accuracy: 0.0751 - val_auc: 0.7218 - val_f1_macro: 0.0246 - val_f1_weighted: 0.0451 - val_loss: 5.3470 - val_top5_accuracy: 0.2204 - learning_rate: 0.0025\n",
            "Epoch 23/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.1140 - auc: 0.8423 - f1_macro: 0.0533 - f1_weighted: 0.0790 - loss: 4.1130 - top5_accuracy: 0.3191 - val_accuracy: 0.0879 - val_auc: 0.7206 - val_f1_macro: 0.0309 - val_f1_weighted: 0.0553 - val_loss: 5.4029 - val_top5_accuracy: 0.2126 - learning_rate: 0.0025\n",
            "Epoch 24/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1185 - auc: 0.8496 - f1_macro: 0.0567 - f1_weighted: 0.0840 - loss: 4.0676 - top5_accuracy: 0.3337\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.1186 - auc: 0.8496 - f1_macro: 0.0569 - f1_weighted: 0.0841 - loss: 4.0673 - top5_accuracy: 0.3338 - val_accuracy: 0.0595 - val_auc: 0.6890 - val_f1_macro: 0.0213 - val_f1_weighted: 0.0378 - val_loss: 5.9077 - val_top5_accuracy: 0.1886 - learning_rate: 0.0025\n",
            "Epoch 25/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.1377 - auc: 0.8591 - f1_macro: 0.0716 - f1_weighted: 0.1018 - loss: 4.0003 - top5_accuracy: 0.3502 - val_accuracy: 0.1046 - val_auc: 0.7597 - val_f1_macro: 0.0373 - val_f1_weighted: 0.0669 - val_loss: 5.0150 - val_top5_accuracy: 0.2660 - learning_rate: 0.0012\n",
            "Epoch 26/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.1474 - auc: 0.8638 - f1_macro: 0.0828 - f1_weighted: 0.1120 - loss: 3.9171 - top5_accuracy: 0.3695 - val_accuracy: 0.1080 - val_auc: 0.7589 - val_f1_macro: 0.0390 - val_f1_weighted: 0.0701 - val_loss: 5.0148 - val_top5_accuracy: 0.2705 - learning_rate: 0.0012\n",
            "Epoch 27/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.1553 - auc: 0.8674 - f1_macro: 0.0924 - f1_weighted: 0.1221 - loss: 3.8591 - top5_accuracy: 0.3845 - val_accuracy: 0.1130 - val_auc: 0.7615 - val_f1_macro: 0.0444 - val_f1_weighted: 0.0761 - val_loss: 5.0194 - val_top5_accuracy: 0.2760 - learning_rate: 0.0012\n",
            "Epoch 28/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.1643 - auc: 0.8724 - f1_macro: 0.1062 - f1_weighted: 0.1350 - loss: 3.8059 - top5_accuracy: 0.4003 - val_accuracy: 0.1135 - val_auc: 0.7634 - val_f1_macro: 0.0485 - val_f1_weighted: 0.0790 - val_loss: 4.9893 - val_top5_accuracy: 0.2693 - learning_rate: 0.0012\n",
            "Epoch 29/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.1725 - auc: 0.8781 - f1_macro: 0.1176 - f1_weighted: 0.1446 - loss: 3.7551 - top5_accuracy: 0.4126 - val_accuracy: 0.1113 - val_auc: 0.7628 - val_f1_macro: 0.0494 - val_f1_weighted: 0.0797 - val_loss: 5.0546 - val_top5_accuracy: 0.2710 - learning_rate: 0.0012\n",
            "Epoch 30/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.1786 - auc: 0.8835 - f1_macro: 0.1251 - f1_weighted: 0.1520 - loss: 3.7088 - top5_accuracy: 0.4235 - val_accuracy: 0.1102 - val_auc: 0.7636 - val_f1_macro: 0.0491 - val_f1_weighted: 0.0798 - val_loss: 5.1022 - val_top5_accuracy: 0.2649 - learning_rate: 0.0012\n",
            "Epoch 31/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.1948 - auc: 0.8872 - f1_macro: 0.1420 - f1_weighted: 0.1699 - loss: 3.6567 - top5_accuracy: 0.4399 - val_accuracy: 0.1085 - val_auc: 0.7623 - val_f1_macro: 0.0455 - val_f1_weighted: 0.0752 - val_loss: 5.1204 - val_top5_accuracy: 0.2627 - learning_rate: 0.0012\n",
            "Epoch 32/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.2073 - auc: 0.8926 - f1_macro: 0.1569 - f1_weighted: 0.1829 - loss: 3.6026 - top5_accuracy: 0.4487 - val_accuracy: 0.1029 - val_auc: 0.7599 - val_f1_macro: 0.0455 - val_f1_weighted: 0.0726 - val_loss: 5.1921 - val_top5_accuracy: 0.2554 - learning_rate: 0.0012\n",
            "Epoch 33/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2167 - auc: 0.8951 - f1_macro: 0.1721 - f1_weighted: 0.1948 - loss: 3.5471 - top5_accuracy: 0.4623\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.2168 - auc: 0.8952 - f1_macro: 0.1725 - f1_weighted: 0.1949 - loss: 3.5468 - top5_accuracy: 0.4624 - val_accuracy: 0.1002 - val_auc: 0.7582 - val_f1_macro: 0.0484 - val_f1_weighted: 0.0731 - val_loss: 5.2168 - val_top5_accuracy: 0.2532 - learning_rate: 0.0012\n",
            "Epoch 34/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.2398 - auc: 0.9000 - f1_macro: 0.2028 - f1_weighted: 0.2210 - loss: 3.4800 - top5_accuracy: 0.4806 - val_accuracy: 0.1002 - val_auc: 0.7514 - val_f1_macro: 0.0469 - val_f1_weighted: 0.0749 - val_loss: 5.2229 - val_top5_accuracy: 0.2487 - learning_rate: 6.2500e-04\n",
            "Epoch 35/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.2546 - auc: 0.9082 - f1_macro: 0.2059 - f1_weighted: 0.2343 - loss: 3.4109 - top5_accuracy: 0.4918 - val_accuracy: 0.0902 - val_auc: 0.7457 - val_f1_macro: 0.0442 - val_f1_weighted: 0.0683 - val_loss: 5.2912 - val_top5_accuracy: 0.2449 - learning_rate: 6.2500e-04\n",
            "Epoch 36/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.2647 - auc: 0.9107 - f1_macro: 0.2184 - f1_weighted: 0.2452 - loss: 3.3575 - top5_accuracy: 0.5067 - val_accuracy: 0.0824 - val_auc: 0.7429 - val_f1_macro: 0.0419 - val_f1_weighted: 0.0631 - val_loss: 5.3830 - val_top5_accuracy: 0.2371 - learning_rate: 6.2500e-04\n",
            "Epoch 37/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.2766 - auc: 0.9135 - f1_macro: 0.2330 - f1_weighted: 0.2591 - loss: 3.3116 - top5_accuracy: 0.5163 - val_accuracy: 0.0801 - val_auc: 0.7377 - val_f1_macro: 0.0409 - val_f1_weighted: 0.0605 - val_loss: 5.4484 - val_top5_accuracy: 0.2326 - learning_rate: 6.2500e-04\n",
            "Epoch 38/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2868 - auc: 0.9158 - f1_macro: 0.2483 - f1_weighted: 0.2717 - loss: 3.2667 - top5_accuracy: 0.5288\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.2869 - auc: 0.9158 - f1_macro: 0.2488 - f1_weighted: 0.2718 - loss: 3.2664 - top5_accuracy: 0.5289 - val_accuracy: 0.0779 - val_auc: 0.7376 - val_f1_macro: 0.0386 - val_f1_weighted: 0.0580 - val_loss: 5.5207 - val_top5_accuracy: 0.2332 - learning_rate: 6.2500e-04\n",
            "Epoch 39/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.2922 - auc: 0.9186 - f1_macro: 0.2538 - f1_weighted: 0.2781 - loss: 3.2210 - top5_accuracy: 0.5444 - val_accuracy: 0.1052 - val_auc: 0.7525 - val_f1_macro: 0.0617 - val_f1_weighted: 0.0848 - val_loss: 5.3892 - val_top5_accuracy: 0.2705 - learning_rate: 3.1250e-04\n",
            "Epoch 40/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.2953 - auc: 0.9199 - f1_macro: 0.2649 - f1_weighted: 0.2824 - loss: 3.1786 - top5_accuracy: 0.5518 - val_accuracy: 0.1068 - val_auc: 0.7536 - val_f1_macro: 0.0624 - val_f1_weighted: 0.0864 - val_loss: 5.4052 - val_top5_accuracy: 0.2760 - learning_rate: 3.1250e-04\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step\n",
            "Finished 'none'\n",
            "  Accuracy:      0.1068\n",
            "  F1 (macro):    0.0624\n",
            "  F1 (weighted): 0.0864\n",
            "  Precision:     0.0895\n",
            "  Recall:        0.1068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: grayscale_plus\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 4194 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Found 749 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 325ms/step - accuracy: 0.0655 - auc: 0.6699 - f1_macro: 0.0380 - f1_weighted: 0.0531 - loss: 8.2546 - top5_accuracy: 0.1769 - val_accuracy: 0.0312 - val_auc: 0.6542 - val_f1_macro: 0.0014 - val_f1_weighted: 0.0068 - val_loss: 5.4329 - val_top5_accuracy: 0.1163 - learning_rate: 0.0100\n",
            "Epoch 2/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0381 - auc: 0.6493 - f1_macro: 0.0041 - f1_weighted: 0.0134 - loss: 5.5683 - top5_accuracy: 0.1248 - val_accuracy: 0.0423 - val_auc: 0.6693 - val_f1_macro: 0.0018 - val_f1_weighted: 0.0087 - val_loss: 5.2828 - val_top5_accuracy: 0.1308 - learning_rate: 0.0100\n",
            "Epoch 3/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0426 - auc: 0.6783 - f1_macro: 0.0049 - f1_weighted: 0.0165 - loss: 5.3048 - top5_accuracy: 0.1391 - val_accuracy: 0.0312 - val_auc: 0.6542 - val_f1_macro: 0.0011 - val_f1_weighted: 0.0053 - val_loss: 5.2940 - val_top5_accuracy: 0.1274 - learning_rate: 0.0100\n",
            "Epoch 4/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0491 - auc: 0.6848 - f1_macro: 0.0053 - f1_weighted: 0.0195 - loss: 5.2144 - top5_accuracy: 0.1502 - val_accuracy: 0.0334 - val_auc: 0.6184 - val_f1_macro: 6.2783e-04 - val_f1_weighted: 0.0030 - val_loss: 5.4515 - val_top5_accuracy: 0.1029 - learning_rate: 0.0100\n",
            "Epoch 5/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0520 - auc: 0.7035 - f1_macro: 0.0056 - f1_weighted: 0.0200 - loss: 5.0572 - top5_accuracy: 0.1482 - val_accuracy: 0.0039 - val_auc: 0.5160 - val_f1_macro: 5.7475e-04 - val_f1_weighted: 0.0028 - val_loss: 10.4704 - val_top5_accuracy: 0.0245 - learning_rate: 0.0100\n",
            "Epoch 6/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0496 - auc: 0.7071 - f1_macro: 0.0050 - f1_weighted: 0.0187 - loss: 4.9995 - top5_accuracy: 0.1579 - val_accuracy: 0.0406 - val_auc: 0.6560 - val_f1_macro: 0.0021 - val_f1_weighted: 0.0078 - val_loss: 5.2285 - val_top5_accuracy: 0.1185 - learning_rate: 0.0100\n",
            "Epoch 7/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0500 - auc: 0.7078 - f1_macro: 0.0058 - f1_weighted: 0.0200 - loss: 4.9798 - top5_accuracy: 0.1483 - val_accuracy: 0.0412 - val_auc: 0.6591 - val_f1_macro: 0.0022 - val_f1_weighted: 0.0094 - val_loss: 5.3587 - val_top5_accuracy: 0.1169 - learning_rate: 0.0100\n",
            "Epoch 8/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0558 - auc: 0.7139 - f1_macro: 0.0069 - f1_weighted: 0.0217 - loss: 4.9517 - top5_accuracy: 0.1537 - val_accuracy: 0.0440 - val_auc: 0.6662 - val_f1_macro: 0.0030 - val_f1_weighted: 0.0109 - val_loss: 5.1702 - val_top5_accuracy: 0.1475 - learning_rate: 0.0100\n",
            "Epoch 9/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0522 - auc: 0.7202 - f1_macro: 0.0064 - f1_weighted: 0.0212 - loss: 4.9173 - top5_accuracy: 0.1593 - val_accuracy: 0.0278 - val_auc: 0.6231 - val_f1_macro: 0.0014 - val_f1_weighted: 0.0042 - val_loss: 5.5873 - val_top5_accuracy: 0.0863 - learning_rate: 0.0100\n",
            "Epoch 10/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0624 - auc: 0.7276 - f1_macro: 0.0096 - f1_weighted: 0.0270 - loss: 4.8714 - top5_accuracy: 0.1693 - val_accuracy: 0.0223 - val_auc: 0.5856 - val_f1_macro: 0.0014 - val_f1_weighted: 0.0060 - val_loss: 6.3981 - val_top5_accuracy: 0.0707 - learning_rate: 0.0100\n",
            "Epoch 11/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0635 - auc: 0.7308 - f1_macro: 0.0104 - f1_weighted: 0.0293 - loss: 4.8439 - top5_accuracy: 0.1793 - val_accuracy: 0.0083 - val_auc: 0.5136 - val_f1_macro: 5.2590e-04 - val_f1_weighted: 0.0012 - val_loss: 18.2248 - val_top5_accuracy: 0.0479 - learning_rate: 0.0100\n",
            "Epoch 12/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0573 - auc: 0.7369 - f1_macro: 0.0082 - f1_weighted: 0.0256 - loss: 4.8238 - top5_accuracy: 0.1753 - val_accuracy: 0.0067 - val_auc: 0.5096 - val_f1_macro: 9.1404e-04 - val_f1_weighted: 0.0045 - val_loss: 26.3007 - val_top5_accuracy: 0.0440 - learning_rate: 0.0100\n",
            "Epoch 13/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0619 - auc: 0.7439 - f1_macro: 0.0092 - f1_weighted: 0.0263 - loss: 4.7907 - top5_accuracy: 0.1755\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0620 - auc: 0.7439 - f1_macro: 0.0092 - f1_weighted: 0.0263 - loss: 4.7905 - top5_accuracy: 0.1755 - val_accuracy: 0.0345 - val_auc: 0.6405 - val_f1_macro: 0.0037 - val_f1_weighted: 0.0114 - val_loss: 5.6848 - val_top5_accuracy: 0.1163 - learning_rate: 0.0100\n",
            "Epoch 14/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0691 - auc: 0.7553 - f1_macro: 0.0134 - f1_weighted: 0.0304 - loss: 4.7162 - top5_accuracy: 0.1973 - val_accuracy: 0.0590 - val_auc: 0.6714 - val_f1_macro: 0.0051 - val_f1_weighted: 0.0196 - val_loss: 5.2015 - val_top5_accuracy: 0.1603 - learning_rate: 0.0050\n",
            "Epoch 15/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0713 - auc: 0.7551 - f1_macro: 0.0147 - f1_weighted: 0.0336 - loss: 4.6695 - top5_accuracy: 0.2019 - val_accuracy: 0.0273 - val_auc: 0.5912 - val_f1_macro: 0.0023 - val_f1_weighted: 0.0104 - val_loss: 7.0338 - val_top5_accuracy: 0.0946 - learning_rate: 0.0050\n",
            "Epoch 16/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0740 - auc: 0.7596 - f1_macro: 0.0138 - f1_weighted: 0.0341 - loss: 4.6476 - top5_accuracy: 0.2115 - val_accuracy: 0.0384 - val_auc: 0.6506 - val_f1_macro: 0.0039 - val_f1_weighted: 0.0144 - val_loss: 5.5248 - val_top5_accuracy: 0.1352 - learning_rate: 0.0050\n",
            "Epoch 17/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0773 - auc: 0.7630 - f1_macro: 0.0191 - f1_weighted: 0.0403 - loss: 4.6186 - top5_accuracy: 0.2149 - val_accuracy: 0.0551 - val_auc: 0.6763 - val_f1_macro: 0.0057 - val_f1_weighted: 0.0220 - val_loss: 5.1951 - val_top5_accuracy: 0.1597 - learning_rate: 0.0050\n",
            "Epoch 18/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0773 - auc: 0.7700 - f1_macro: 0.0191 - f1_weighted: 0.0409 - loss: 4.5932 - top5_accuracy: 0.2162\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0773 - auc: 0.7700 - f1_macro: 0.0192 - f1_weighted: 0.0409 - loss: 4.5931 - top5_accuracy: 0.2161 - val_accuracy: 0.0579 - val_auc: 0.7008 - val_f1_macro: 0.0060 - val_f1_weighted: 0.0209 - val_loss: 5.2208 - val_top5_accuracy: 0.1725 - learning_rate: 0.0050\n",
            "Epoch 19/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0827 - auc: 0.7777 - f1_macro: 0.0205 - f1_weighted: 0.0438 - loss: 4.5509 - top5_accuracy: 0.2205 - val_accuracy: 0.0612 - val_auc: 0.7141 - val_f1_macro: 0.0056 - val_f1_weighted: 0.0216 - val_loss: 4.9554 - val_top5_accuracy: 0.1786 - learning_rate: 0.0025\n",
            "Epoch 20/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0870 - auc: 0.7871 - f1_macro: 0.0268 - f1_weighted: 0.0496 - loss: 4.5058 - top5_accuracy: 0.2307 - val_accuracy: 0.0646 - val_auc: 0.7032 - val_f1_macro: 0.0068 - val_f1_weighted: 0.0257 - val_loss: 4.9868 - val_top5_accuracy: 0.1797 - learning_rate: 0.0025\n",
            "Epoch 21/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0882 - auc: 0.7887 - f1_macro: 0.0277 - f1_weighted: 0.0499 - loss: 4.4862 - top5_accuracy: 0.2373 - val_accuracy: 0.0712 - val_auc: 0.7213 - val_f1_macro: 0.0090 - val_f1_weighted: 0.0295 - val_loss: 4.9382 - val_top5_accuracy: 0.1970 - learning_rate: 0.0025\n",
            "Epoch 22/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0874 - auc: 0.7939 - f1_macro: 0.0260 - f1_weighted: 0.0485 - loss: 4.4572 - top5_accuracy: 0.2402 - val_accuracy: 0.0746 - val_auc: 0.7231 - val_f1_macro: 0.0101 - val_f1_weighted: 0.0327 - val_loss: 4.8990 - val_top5_accuracy: 0.1976 - learning_rate: 0.0025\n",
            "Epoch 23/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0898 - auc: 0.7956 - f1_macro: 0.0311 - f1_weighted: 0.0531 - loss: 4.4367 - top5_accuracy: 0.2444 - val_accuracy: 0.0762 - val_auc: 0.7204 - val_f1_macro: 0.0123 - val_f1_weighted: 0.0336 - val_loss: 4.9306 - val_top5_accuracy: 0.1931 - learning_rate: 0.0025\n",
            "Epoch 24/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0934 - auc: 0.7991 - f1_macro: 0.0346 - f1_weighted: 0.0573 - loss: 4.4155 - top5_accuracy: 0.2502 - val_accuracy: 0.0735 - val_auc: 0.7156 - val_f1_macro: 0.0156 - val_f1_weighted: 0.0368 - val_loss: 4.9620 - val_top5_accuracy: 0.1836 - learning_rate: 0.0025\n",
            "Epoch 25/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0961 - auc: 0.8028 - f1_macro: 0.0397 - f1_weighted: 0.0623 - loss: 4.3951 - top5_accuracy: 0.2505 - val_accuracy: 0.0618 - val_auc: 0.7144 - val_f1_macro: 0.0103 - val_f1_weighted: 0.0251 - val_loss: 5.0407 - val_top5_accuracy: 0.1742 - learning_rate: 0.0025\n",
            "Epoch 26/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1003 - auc: 0.8072 - f1_macro: 0.0429 - f1_weighted: 0.0673 - loss: 4.3732 - top5_accuracy: 0.2537 - val_accuracy: 0.0634 - val_auc: 0.6964 - val_f1_macro: 0.0124 - val_f1_weighted: 0.0298 - val_loss: 5.3322 - val_top5_accuracy: 0.1669 - learning_rate: 0.0025\n",
            "Epoch 27/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0961 - auc: 0.8074 - f1_macro: 0.0425 - f1_weighted: 0.0648 - loss: 4.3590 - top5_accuracy: 0.2613\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0960 - auc: 0.8074 - f1_macro: 0.0426 - f1_weighted: 0.0647 - loss: 4.3590 - top5_accuracy: 0.2613 - val_accuracy: 0.0456 - val_auc: 0.6642 - val_f1_macro: 0.0112 - val_f1_weighted: 0.0240 - val_loss: 5.5055 - val_top5_accuracy: 0.1452 - learning_rate: 0.0025\n",
            "Epoch 28/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1049 - auc: 0.8155 - f1_macro: 0.0521 - f1_weighted: 0.0724 - loss: 4.3164 - top5_accuracy: 0.2634 - val_accuracy: 0.0651 - val_auc: 0.7160 - val_f1_macro: 0.0095 - val_f1_weighted: 0.0277 - val_loss: 5.1303 - val_top5_accuracy: 0.1753 - learning_rate: 0.0012\n",
            "Epoch 29/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1128 - auc: 0.8212 - f1_macro: 0.0578 - f1_weighted: 0.0806 - loss: 4.2665 - top5_accuracy: 0.2747 - val_accuracy: 0.0584 - val_auc: 0.7237 - val_f1_macro: 0.0108 - val_f1_weighted: 0.0324 - val_loss: 5.0786 - val_top5_accuracy: 0.1825 - learning_rate: 0.0012\n",
            "Epoch 30/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1141 - auc: 0.8261 - f1_macro: 0.0642 - f1_weighted: 0.0854 - loss: 4.2326 - top5_accuracy: 0.2867 - val_accuracy: 0.0729 - val_auc: 0.7282 - val_f1_macro: 0.0219 - val_f1_weighted: 0.0396 - val_loss: 5.0550 - val_top5_accuracy: 0.2020 - learning_rate: 0.0012\n",
            "Epoch 31/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1180 - auc: 0.8309 - f1_macro: 0.0710 - f1_weighted: 0.0918 - loss: 4.1986 - top5_accuracy: 0.2920 - val_accuracy: 0.0657 - val_auc: 0.7130 - val_f1_macro: 0.0162 - val_f1_weighted: 0.0336 - val_loss: 5.1810 - val_top5_accuracy: 0.1914 - learning_rate: 0.0012\n",
            "Epoch 32/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1224 - auc: 0.8338 - f1_macro: 0.0766 - f1_weighted: 0.0962 - loss: 4.1719 - top5_accuracy: 0.2976\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1224 - auc: 0.8338 - f1_macro: 0.0768 - f1_weighted: 0.0963 - loss: 4.1718 - top5_accuracy: 0.2976 - val_accuracy: 0.0723 - val_auc: 0.7209 - val_f1_macro: 0.0168 - val_f1_weighted: 0.0365 - val_loss: 5.1073 - val_top5_accuracy: 0.1903 - learning_rate: 0.0012\n",
            "Epoch 33/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1300 - auc: 0.8368 - f1_macro: 0.0893 - f1_weighted: 0.1056 - loss: 4.1404 - top5_accuracy: 0.3050 - val_accuracy: 0.0618 - val_auc: 0.7122 - val_f1_macro: 0.0098 - val_f1_weighted: 0.0311 - val_loss: 5.2987 - val_top5_accuracy: 0.1814 - learning_rate: 6.2500e-04\n",
            "Epoch 34/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1347 - auc: 0.8401 - f1_macro: 0.0983 - f1_weighted: 0.1131 - loss: 4.1077 - top5_accuracy: 0.3147 - val_accuracy: 0.0657 - val_auc: 0.7123 - val_f1_macro: 0.0136 - val_f1_weighted: 0.0351 - val_loss: 5.3210 - val_top5_accuracy: 0.1864 - learning_rate: 6.2500e-04\n",
            "Epoch 35/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1401 - auc: 0.8429 - f1_macro: 0.1034 - f1_weighted: 0.1189 - loss: 4.0809 - top5_accuracy: 0.3190 - val_accuracy: 0.0646 - val_auc: 0.7108 - val_f1_macro: 0.0146 - val_f1_weighted: 0.0365 - val_loss: 5.3743 - val_top5_accuracy: 0.1831 - learning_rate: 6.2500e-04\n",
            "Epoch 36/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1449 - auc: 0.8465 - f1_macro: 0.1051 - f1_weighted: 0.1224 - loss: 4.0564 - top5_accuracy: 0.3286 - val_accuracy: 0.0646 - val_auc: 0.7065 - val_f1_macro: 0.0131 - val_f1_weighted: 0.0365 - val_loss: 5.4290 - val_top5_accuracy: 0.1792 - learning_rate: 6.2500e-04\n",
            "Epoch 37/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1464 - auc: 0.8483 - f1_macro: 0.1061 - f1_weighted: 0.1248 - loss: 4.0333 - top5_accuracy: 0.3343\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1464 - auc: 0.8483 - f1_macro: 0.1064 - f1_weighted: 0.1249 - loss: 4.0330 - top5_accuracy: 0.3344 - val_accuracy: 0.0673 - val_auc: 0.7100 - val_f1_macro: 0.0134 - val_f1_weighted: 0.0372 - val_loss: 5.3695 - val_top5_accuracy: 0.1842 - learning_rate: 6.2500e-04\n",
            "Epoch 38/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1540 - auc: 0.8507 - f1_macro: 0.1139 - f1_weighted: 0.1332 - loss: 4.0073 - top5_accuracy: 0.3488 - val_accuracy: 0.0723 - val_auc: 0.7159 - val_f1_macro: 0.0185 - val_f1_weighted: 0.0429 - val_loss: 5.4563 - val_top5_accuracy: 0.1859 - learning_rate: 3.1250e-04\n",
            "Epoch 39/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1539 - auc: 0.8540 - f1_macro: 0.1164 - f1_weighted: 0.1339 - loss: 3.9795 - top5_accuracy: 0.3554 - val_accuracy: 0.0707 - val_auc: 0.7131 - val_f1_macro: 0.0179 - val_f1_weighted: 0.0420 - val_loss: 5.5159 - val_top5_accuracy: 0.1903 - learning_rate: 3.1250e-04\n",
            "Epoch 40/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1568 - auc: 0.8565 - f1_macro: 0.1176 - f1_weighted: 0.1358 - loss: 3.9576 - top5_accuracy: 0.3592 - val_accuracy: 0.0707 - val_auc: 0.7139 - val_f1_macro: 0.0196 - val_f1_weighted: 0.0427 - val_loss: 5.5153 - val_top5_accuracy: 0.1859 - learning_rate: 3.1250e-04\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step\n",
            "Finished 'grayscale_plus'\n",
            "  Accuracy:      0.0707\n",
            "  F1 (macro):    0.0196\n",
            "  F1 (weighted): 0.0427\n",
            "  Precision:     0.0444\n",
            "  Recall:        0.0707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: mixup\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 4194 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Found 749 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 294ms/step - accuracy: 0.0456 - auc: 0.6308 - f1_macro: 0.0131 - f1_weighted: 0.0280 - loss: 7.8470 - top5_accuracy: 0.1332 - val_accuracy: 0.0189 - val_auc: 0.6069 - val_f1_macro: 7.7032e-04 - val_f1_weighted: 0.0029 - val_loss: 7.7505 - val_top5_accuracy: 0.0868 - learning_rate: 0.0100\n",
            "Epoch 2/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0261 - auc: 0.6540 - f1_macro: 0.0027 - f1_weighted: 0.0111 - loss: 5.6106 - top5_accuracy: 0.1183 - val_accuracy: 0.0250 - val_auc: 0.6596 - val_f1_macro: 0.0011 - val_f1_weighted: 0.0047 - val_loss: 5.3677 - val_top5_accuracy: 0.1091 - learning_rate: 0.0100\n",
            "Epoch 3/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0325 - auc: 0.6502 - f1_macro: 0.0024 - f1_weighted: 0.0101 - loss: 5.4652 - top5_accuracy: 0.1192 - val_accuracy: 0.0284 - val_auc: 0.6409 - val_f1_macro: 7.5847e-04 - val_f1_weighted: 0.0031 - val_loss: 5.7775 - val_top5_accuracy: 0.1107 - learning_rate: 0.0100\n",
            "Epoch 4/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0389 - auc: 0.6575 - f1_macro: 0.0037 - f1_weighted: 0.0141 - loss: 5.2608 - top5_accuracy: 0.1443 - val_accuracy: 0.0306 - val_auc: 0.6555 - val_f1_macro: 0.0026 - val_f1_weighted: 0.0084 - val_loss: 5.4425 - val_top5_accuracy: 0.1213 - learning_rate: 0.0100\n",
            "Epoch 5/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0416 - auc: 0.6639 - f1_macro: 0.0038 - f1_weighted: 0.0138 - loss: 5.1526 - top5_accuracy: 0.1448 - val_accuracy: 0.0262 - val_auc: 0.6372 - val_f1_macro: 0.0022 - val_f1_weighted: 0.0061 - val_loss: 5.4795 - val_top5_accuracy: 0.1163 - learning_rate: 0.0100\n",
            "Epoch 6/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0441 - auc: 0.6653 - f1_macro: 0.0036 - f1_weighted: 0.0148 - loss: 5.0589 - top5_accuracy: 0.1559 - val_accuracy: 0.0278 - val_auc: 0.6622 - val_f1_macro: 0.0025 - val_f1_weighted: 0.0082 - val_loss: 5.3314 - val_top5_accuracy: 0.1230 - learning_rate: 0.0100\n",
            "Epoch 7/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0475 - auc: 0.6685 - f1_macro: 0.0038 - f1_weighted: 0.0135 - loss: 4.9879 - top5_accuracy: 0.1543 - val_accuracy: 0.0234 - val_auc: 0.6557 - val_f1_macro: 0.0027 - val_f1_weighted: 0.0105 - val_loss: 5.5724 - val_top5_accuracy: 0.1163 - learning_rate: 0.0100\n",
            "Epoch 8/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0553 - auc: 0.6714 - f1_macro: 0.0051 - f1_weighted: 0.0186 - loss: 4.9377 - top5_accuracy: 0.1675 - val_accuracy: 0.0473 - val_auc: 0.6852 - val_f1_macro: 0.0038 - val_f1_weighted: 0.0129 - val_loss: 5.0659 - val_top5_accuracy: 0.1547 - learning_rate: 0.0100\n",
            "Epoch 9/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0546 - auc: 0.6763 - f1_macro: 0.0045 - f1_weighted: 0.0171 - loss: 4.9045 - top5_accuracy: 0.1673 - val_accuracy: 0.0111 - val_auc: 0.5665 - val_f1_macro: 0.0014 - val_f1_weighted: 0.0035 - val_loss: 7.5766 - val_top5_accuracy: 0.0467 - learning_rate: 0.0100\n",
            "Epoch 10/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0609 - auc: 0.6749 - f1_macro: 0.0055 - f1_weighted: 0.0189 - loss: 4.8832 - top5_accuracy: 0.1696 - val_accuracy: 0.0250 - val_auc: 0.5707 - val_f1_macro: 0.0018 - val_f1_weighted: 0.0054 - val_loss: 14.7512 - val_top5_accuracy: 0.0657 - learning_rate: 0.0100\n",
            "Epoch 11/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0619 - auc: 0.6820 - f1_macro: 0.0046 - f1_weighted: 0.0186 - loss: 4.8522 - top5_accuracy: 0.1723 - val_accuracy: 0.0540 - val_auc: 0.6740 - val_f1_macro: 0.0044 - val_f1_weighted: 0.0149 - val_loss: 5.1563 - val_top5_accuracy: 0.1402 - learning_rate: 0.0100\n",
            "Epoch 12/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0584 - auc: 0.6831 - f1_macro: 0.0041 - f1_weighted: 0.0170 - loss: 4.8395 - top5_accuracy: 0.1775 - val_accuracy: 0.0106 - val_auc: 0.5335 - val_f1_macro: 0.0018 - val_f1_weighted: 0.0049 - val_loss: 9.5326 - val_top5_accuracy: 0.0518 - learning_rate: 0.0100\n",
            "Epoch 13/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0590 - auc: 0.6808 - f1_macro: 0.0065 - f1_weighted: 0.0205 - loss: 4.8316 - top5_accuracy: 0.1723\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0589 - auc: 0.6807 - f1_macro: 0.0066 - f1_weighted: 0.0206 - loss: 4.8319 - top5_accuracy: 0.1723 - val_accuracy: 0.0239 - val_auc: 0.5405 - val_f1_macro: 0.0013 - val_f1_weighted: 0.0024 - val_loss: 7.2584 - val_top5_accuracy: 0.0623 - learning_rate: 0.0100\n",
            "Epoch 14/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0651 - auc: 0.6869 - f1_macro: 0.0078 - f1_weighted: 0.0250 - loss: 4.7948 - top5_accuracy: 0.1799 - val_accuracy: 0.0523 - val_auc: 0.6814 - val_f1_macro: 0.0062 - val_f1_weighted: 0.0184 - val_loss: 5.0995 - val_top5_accuracy: 0.1692 - learning_rate: 0.0050\n",
            "Epoch 15/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0626 - auc: 0.6908 - f1_macro: 0.0065 - f1_weighted: 0.0210 - loss: 4.7405 - top5_accuracy: 0.1848 - val_accuracy: 0.0451 - val_auc: 0.6965 - val_f1_macro: 0.0036 - val_f1_weighted: 0.0134 - val_loss: 5.0701 - val_top5_accuracy: 0.1747 - learning_rate: 0.0050\n",
            "Epoch 16/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0694 - auc: 0.6914 - f1_macro: 0.0086 - f1_weighted: 0.0264 - loss: 4.7116 - top5_accuracy: 0.1937 - val_accuracy: 0.0100 - val_auc: 0.5409 - val_f1_macro: 0.0034 - val_f1_weighted: 0.0085 - val_loss: 14.9788 - val_top5_accuracy: 0.0467 - learning_rate: 0.0050\n",
            "Epoch 17/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0707 - auc: 0.6927 - f1_macro: 0.0102 - f1_weighted: 0.0287 - loss: 4.6913 - top5_accuracy: 0.1921 - val_accuracy: 0.0356 - val_auc: 0.6284 - val_f1_macro: 0.0064 - val_f1_weighted: 0.0174 - val_loss: 5.6484 - val_top5_accuracy: 0.1157 - learning_rate: 0.0050\n",
            "Epoch 18/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0665 - auc: 0.6929 - f1_macro: 0.0075 - f1_weighted: 0.0242 - loss: 4.6595 - top5_accuracy: 0.2025\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0666 - auc: 0.6929 - f1_macro: 0.0075 - f1_weighted: 0.0242 - loss: 4.6598 - top5_accuracy: 0.2024 - val_accuracy: 0.0384 - val_auc: 0.6096 - val_f1_macro: 0.0081 - val_f1_weighted: 0.0193 - val_loss: 5.7876 - val_top5_accuracy: 0.1269 - learning_rate: 0.0050\n",
            "Epoch 19/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.0743 - auc: 0.6969 - f1_macro: 0.0108 - f1_weighted: 0.0299 - loss: 4.6261 - top5_accuracy: 0.2108 - val_accuracy: 0.0428 - val_auc: 0.6709 - val_f1_macro: 0.0075 - val_f1_weighted: 0.0210 - val_loss: 5.7919 - val_top5_accuracy: 0.1503 - learning_rate: 0.0025\n",
            "Epoch 20/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.0778 - auc: 0.6969 - f1_macro: 0.0141 - f1_weighted: 0.0330 - loss: 4.6028 - top5_accuracy: 0.2177 - val_accuracy: 0.0401 - val_auc: 0.6777 - val_f1_macro: 0.0081 - val_f1_weighted: 0.0214 - val_loss: 5.6107 - val_top5_accuracy: 0.1380 - learning_rate: 0.0025\n",
            "Epoch 21/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0796 - auc: 0.6974 - f1_macro: 0.0138 - f1_weighted: 0.0339 - loss: 4.5700 - top5_accuracy: 0.2284 - val_accuracy: 0.0646 - val_auc: 0.7186 - val_f1_macro: 0.0125 - val_f1_weighted: 0.0289 - val_loss: 5.0511 - val_top5_accuracy: 0.1859 - learning_rate: 0.0025\n",
            "Epoch 22/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0860 - auc: 0.6983 - f1_macro: 0.0189 - f1_weighted: 0.0406 - loss: 4.5513 - top5_accuracy: 0.2288 - val_accuracy: 0.0651 - val_auc: 0.7101 - val_f1_macro: 0.0128 - val_f1_weighted: 0.0312 - val_loss: 5.0597 - val_top5_accuracy: 0.2042 - learning_rate: 0.0025\n",
            "Epoch 23/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0836 - auc: 0.7021 - f1_macro: 0.0198 - f1_weighted: 0.0410 - loss: 4.5205 - top5_accuracy: 0.2303 - val_accuracy: 0.0595 - val_auc: 0.7102 - val_f1_macro: 0.0111 - val_f1_weighted: 0.0293 - val_loss: 5.1081 - val_top5_accuracy: 0.1970 - learning_rate: 0.0025\n",
            "Epoch 24/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0846 - auc: 0.7033 - f1_macro: 0.0217 - f1_weighted: 0.0428 - loss: 4.4844 - top5_accuracy: 0.2393 - val_accuracy: 0.0657 - val_auc: 0.7186 - val_f1_macro: 0.0148 - val_f1_weighted: 0.0336 - val_loss: 5.1323 - val_top5_accuracy: 0.2076 - learning_rate: 0.0025\n",
            "Epoch 25/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0898 - auc: 0.7053 - f1_macro: 0.0249 - f1_weighted: 0.0475 - loss: 4.4546 - top5_accuracy: 0.2452 - val_accuracy: 0.0568 - val_auc: 0.6875 - val_f1_macro: 0.0188 - val_f1_weighted: 0.0314 - val_loss: 5.8385 - val_top5_accuracy: 0.1658 - learning_rate: 0.0025\n",
            "Epoch 26/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0915 - auc: 0.7072 - f1_macro: 0.0248 - f1_weighted: 0.0492 - loss: 4.4285 - top5_accuracy: 0.2521\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0915 - auc: 0.7072 - f1_macro: 0.0248 - f1_weighted: 0.0492 - loss: 4.4288 - top5_accuracy: 0.2521 - val_accuracy: 0.0590 - val_auc: 0.7094 - val_f1_macro: 0.0192 - val_f1_weighted: 0.0326 - val_loss: 5.5310 - val_top5_accuracy: 0.1820 - learning_rate: 0.0025\n",
            "Epoch 27/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.0945 - auc: 0.7094 - f1_macro: 0.0291 - f1_weighted: 0.0525 - loss: 4.3880 - top5_accuracy: 0.2652 - val_accuracy: 0.0484 - val_auc: 0.6668 - val_f1_macro: 0.0146 - val_f1_weighted: 0.0262 - val_loss: 6.6278 - val_top5_accuracy: 0.1469 - learning_rate: 0.0012\n",
            "Epoch 28/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1034 - auc: 0.7144 - f1_macro: 0.0308 - f1_weighted: 0.0572 - loss: 4.3431 - top5_accuracy: 0.2775 - val_accuracy: 0.0462 - val_auc: 0.6641 - val_f1_macro: 0.0150 - val_f1_weighted: 0.0275 - val_loss: 7.1179 - val_top5_accuracy: 0.1369 - learning_rate: 0.0012\n",
            "Epoch 29/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1009 - auc: 0.7167 - f1_macro: 0.0320 - f1_weighted: 0.0569 - loss: 4.3132 - top5_accuracy: 0.2857 - val_accuracy: 0.0479 - val_auc: 0.6706 - val_f1_macro: 0.0184 - val_f1_weighted: 0.0300 - val_loss: 6.6682 - val_top5_accuracy: 0.1503 - learning_rate: 0.0012\n",
            "Epoch 30/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1043 - auc: 0.7180 - f1_macro: 0.0434 - f1_weighted: 0.0661 - loss: 4.2824 - top5_accuracy: 0.2994 - val_accuracy: 0.0467 - val_auc: 0.6819 - val_f1_macro: 0.0148 - val_f1_weighted: 0.0259 - val_loss: 6.5622 - val_top5_accuracy: 0.1592 - learning_rate: 0.0012\n",
            "Epoch 31/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1061 - auc: 0.7206 - f1_macro: 0.0455 - f1_weighted: 0.0684 - loss: 4.2602 - top5_accuracy: 0.3024\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1062 - auc: 0.7206 - f1_macro: 0.0457 - f1_weighted: 0.0684 - loss: 4.2602 - top5_accuracy: 0.3024 - val_accuracy: 0.0451 - val_auc: 0.6657 - val_f1_macro: 0.0179 - val_f1_weighted: 0.0304 - val_loss: 7.1327 - val_top5_accuracy: 0.1447 - learning_rate: 0.0012\n",
            "Epoch 32/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1134 - auc: 0.7221 - f1_macro: 0.0466 - f1_weighted: 0.0718 - loss: 4.2201 - top5_accuracy: 0.3142 - val_accuracy: 0.0607 - val_auc: 0.6987 - val_f1_macro: 0.0199 - val_f1_weighted: 0.0367 - val_loss: 6.0909 - val_top5_accuracy: 0.1898 - learning_rate: 6.2500e-04\n",
            "Epoch 33/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1169 - auc: 0.7245 - f1_macro: 0.0507 - f1_weighted: 0.0756 - loss: 4.1929 - top5_accuracy: 0.3213 - val_accuracy: 0.0629 - val_auc: 0.7066 - val_f1_macro: 0.0209 - val_f1_weighted: 0.0379 - val_loss: 5.9482 - val_top5_accuracy: 0.1925 - learning_rate: 6.2500e-04\n",
            "Epoch 34/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1226 - auc: 0.7258 - f1_macro: 0.0554 - f1_weighted: 0.0809 - loss: 4.1626 - top5_accuracy: 0.3330 - val_accuracy: 0.0679 - val_auc: 0.7138 - val_f1_macro: 0.0238 - val_f1_weighted: 0.0422 - val_loss: 5.7396 - val_top5_accuracy: 0.1964 - learning_rate: 6.2500e-04\n",
            "Epoch 35/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1282 - auc: 0.7278 - f1_macro: 0.0606 - f1_weighted: 0.0853 - loss: 4.1373 - top5_accuracy: 0.3326 - val_accuracy: 0.0679 - val_auc: 0.7147 - val_f1_macro: 0.0245 - val_f1_weighted: 0.0419 - val_loss: 5.7606 - val_top5_accuracy: 0.1998 - learning_rate: 6.2500e-04\n",
            "Epoch 36/40\n",
            "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1350 - auc: 0.7300 - f1_macro: 0.0656 - f1_weighted: 0.0917 - loss: 4.1107 - top5_accuracy: 0.3393\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1352 - auc: 0.7300 - f1_macro: 0.0660 - f1_weighted: 0.0919 - loss: 4.1103 - top5_accuracy: 0.3394 - val_accuracy: 0.0735 - val_auc: 0.7183 - val_f1_macro: 0.0259 - val_f1_weighted: 0.0456 - val_loss: 5.6826 - val_top5_accuracy: 0.2053 - learning_rate: 6.2500e-04\n",
            "Epoch 37/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1374 - auc: 0.7305 - f1_macro: 0.0657 - f1_weighted: 0.0948 - loss: 4.0799 - top5_accuracy: 0.3487 - val_accuracy: 0.0890 - val_auc: 0.7392 - val_f1_macro: 0.0321 - val_f1_weighted: 0.0568 - val_loss: 5.2504 - val_top5_accuracy: 0.2332 - learning_rate: 3.1250e-04\n",
            "Epoch 38/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1398 - auc: 0.7322 - f1_macro: 0.0734 - f1_weighted: 0.0988 - loss: 4.0508 - top5_accuracy: 0.3539 - val_accuracy: 0.0885 - val_auc: 0.7360 - val_f1_macro: 0.0328 - val_f1_weighted: 0.0578 - val_loss: 5.2971 - val_top5_accuracy: 0.2309 - learning_rate: 3.1250e-04\n",
            "Epoch 39/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1446 - auc: 0.7332 - f1_macro: 0.0755 - f1_weighted: 0.1024 - loss: 4.0307 - top5_accuracy: 0.3574 - val_accuracy: 0.0896 - val_auc: 0.7353 - val_f1_macro: 0.0358 - val_f1_weighted: 0.0592 - val_loss: 5.3132 - val_top5_accuracy: 0.2309 - learning_rate: 3.1250e-04\n",
            "Epoch 40/40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.1462 - auc: 0.7341 - f1_macro: 0.0796 - f1_weighted: 0.1053 - loss: 4.0131 - top5_accuracy: 0.3597 - val_accuracy: 0.0907 - val_auc: 0.7356 - val_f1_macro: 0.0344 - val_f1_weighted: 0.0596 - val_loss: 5.3434 - val_top5_accuracy: 0.2309 - learning_rate: 3.1250e-04\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step\n",
            "Finished 'mixup'\n",
            "  Accuracy:      0.0907\n",
            "  F1 (macro):    0.0344\n",
            "  F1 (weighted): 0.0596\n",
            "  Precision:     0.0597\n",
            "  Recall:        0.0907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Initialize the preprocessor\n",
        "batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "image_size = (224, 224)\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Loop through each augmentation\n",
        "for aug in augmentations_to_test:\n",
        "    print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "    model = build_densenet()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "    train_ds_sampled, class_names = preprocess.load_img(data_dir=\"data/rare_species/train_sampled\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "    val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "    test_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/test\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "    # Initialize the experiment\n",
        "    experiment = Experiment(\n",
        "        model=model,\n",
        "        train_ds=train_ds_sampled,\n",
        "        val_ds=val_ds,\n",
        "        experiment_name=f\"densenet_with_{aug}_no_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "        batch_size=32,\n",
        "        image_size=(224, 224),\n",
        "        save_model = False\n",
        "    )\n",
        "\n",
        "    # Run the experiment\n",
        "    history = experiment.run_experiment(callbacks=callbacks, epochs=40)\n",
        "\n",
        "    # Predict entire validation set at once\n",
        "    preds = model.predict(val_ds)\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Extract true labels in order\n",
        "    y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "    # Compute metrics\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Store in results\n",
        "    results[aug] = {\n",
        "        \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "        \"f1_macro\": f1_macro,\n",
        "        \"f1_weighted\": f1_weighted,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall\n",
        "    }\n",
        "\n",
        "    print(f\"Finished '{aug}'\")\n",
        "    print(f\"  Accuracy:      {results[aug]['accuracy']:.4f}\")\n",
        "    print(f\"  F1 (macro):    {results[aug]['f1_macro']:.4f}\")\n",
        "    print(f\"  F1 (weighted): {results[aug]['f1_weighted']:.4f}\")\n",
        "    print(f\"  Precision:     {results[aug]['precision']:.4f}\")\n",
        "    print(f\"  Recall:        {results[aug]['recall']:.4f}\")\n",
        "\n",
        "    # Clear memory to avoid OOM\n",
        "    del model\n",
        "    del experiment\n",
        "    K.clear_session()\n",
        "    gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJO872qA_0QI",
        "outputId": "33427c69-9268-46c2-82ef-164f751ecefd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     augmentation  accuracy  f1_macro  f1_weighted  precision  recall\n",
              "0            none    0.1068    0.0624       0.0864     0.0895  0.1068\n",
              "1  grayscale_plus    0.0707    0.0196       0.0427     0.0444  0.0707\n",
              "2           mixup    0.0907    0.0344       0.0596     0.0597  0.0907"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-195bc172-b08b-46c6-9374-0297582de607\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>augmentation</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>f1_weighted</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>none</td>\n",
              "      <td>0.1068</td>\n",
              "      <td>0.0624</td>\n",
              "      <td>0.0864</td>\n",
              "      <td>0.0895</td>\n",
              "      <td>0.1068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>grayscale_plus</td>\n",
              "      <td>0.0707</td>\n",
              "      <td>0.0196</td>\n",
              "      <td>0.0427</td>\n",
              "      <td>0.0444</td>\n",
              "      <td>0.0707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mixup</td>\n",
              "      <td>0.0907</td>\n",
              "      <td>0.0344</td>\n",
              "      <td>0.0596</td>\n",
              "      <td>0.0597</td>\n",
              "      <td>0.0907</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-195bc172-b08b-46c6-9374-0297582de607')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-195bc172-b08b-46c6-9374-0297582de607 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-195bc172-b08b-46c6-9374-0297582de607');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-88296cce-d819-4534-a43b-2e2026c11167\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88296cce-d819-4534-a43b-2e2026c11167')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-88296cce-d819-4534-a43b-2e2026c11167 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(results_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"augmentation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"none\",\n          \"grayscale_plus\",\n          \"mixup\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.018085076720876805,\n        \"min\": 0.0707,\n        \"max\": 0.1068,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.1068,\n          0.0707,\n          0.0907\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02173660507070964,\n        \"min\": 0.0196,\n        \"max\": 0.0624,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0624,\n          0.0196,\n          0.0344\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_weighted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.022036106734176074,\n        \"min\": 0.0427,\n        \"max\": 0.0864,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0864,\n          0.0427,\n          0.0596\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.022935198567558407,\n        \"min\": 0.0444,\n        \"max\": 0.0895,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0895,\n          0.0444,\n          0.0597\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.018085076720876805,\n        \"min\": 0.0707,\n        \"max\": 0.1068,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.1068,\n          0.0707,\n          0.0907\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# Display the table\n",
        "display(results_df.round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSX0pOmD_0QI",
        "outputId": "ab2890be-2ef8-4236-b9cf-b3ded69d3d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Melt the DataFrame for seaborn plotting\n",
        "metrics_to_plot = ['accuracy', 'f1_macro', 'f1_weighted', 'precision', 'recall']\n",
        "melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "                            var_name='metric', value_name='value')\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "plt.title(\"Comparison of Metrics Across Augmentation Strategies\")\n",
        "plt.ylim(0, 0.4)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet 2 - With Oversampling"
      ],
      "metadata": {
        "id": "336DD3hE782A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def dense_layer(x, growth_rate):\n",
        "    \"\"\"Single layer inside a dense block.\"\"\"\n",
        "    out = BatchNormalization()(x)\n",
        "    out = ReLU()(out)\n",
        "    out = Conv2D(growth_rate, (3, 3), padding='same', kernel_regularizer=l2(1e-4))(out)\n",
        "    x = Concatenate()([x, out])  # Concatenate input and output (dense connection)\n",
        "    return x\n",
        "\n",
        "def dense_block(x, num_layers, growth_rate):\n",
        "    \"\"\"Dense block with several dense layers.\"\"\"\n",
        "    for _ in range(num_layers):\n",
        "        x = dense_layer(x, growth_rate)\n",
        "    return x\n",
        "\n",
        "def transition_layer(x, reduction=0.5):\n",
        "    \"\"\"Reduces spatial size and number of filters.\"\"\"\n",
        "    filters = int(tf.keras.backend.int_shape(x)[-1] * reduction)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=l2(1e-4))(x)\n",
        "    x = AveragePooling2D((2, 2), strides=2)(x)\n",
        "    return x\n",
        "\n",
        "def build_densenet(input_shape=(224, 224, 3), num_classes=202, growth_rate=32):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Initial conv\n",
        "    x = Conv2D(64, (7, 7), strides=2, padding='same', kernel_regularizer=l2(1e-4))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = AveragePooling2D((3, 3), strides=2, padding='same')(x)\n",
        "\n",
        "    # Dense Block 1\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "    x = transition_layer(x)\n",
        "\n",
        "    # Dense Block 2\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "    x = transition_layer(x)\n",
        "\n",
        "    # Dense Block 3\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "    x = transition_layer(x)\n",
        "\n",
        "    # Dense Block 4\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "\n",
        "    # Classification\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "model = build_densenet()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "390TQdSy7-st",
        "outputId": "de03553e-76c5-4c94-81b5-7b2ce8d6d460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │      \u001b[38;5;34m9,472\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m18,464\u001b[0m │ re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m96\u001b[0m)               │            │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m27,680\u001b[0m │ re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m36,896\u001b[0m │ re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m160\u001b[0m)              │            │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m640\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m46,112\u001b[0m │ re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m192\u001b[0m)              │            │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m768\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m18,528\u001b[0m │ re_lu_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m27,680\u001b[0m │ re_lu_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_7 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m36,896\u001b[0m │ re_lu_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m160\u001b[0m)              │            │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m640\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_8 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m46,112\u001b[0m │ re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m192\u001b[0m)              │            │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m768\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_9 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m55,328\u001b[0m │ re_lu_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m224\u001b[0m)              │            │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m896\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m224\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_10 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m224\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m25,200\u001b[0m │ re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m448\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_11 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m32,288\u001b[0m │ re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m144\u001b[0m)              │            │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m576\u001b[0m │ concatenate_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m144\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_12 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m144\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m41,504\u001b[0m │ re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m176\u001b[0m)              │            │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m704\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m176\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_13 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m176\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m50,720\u001b[0m │ re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m208\u001b[0m)              │            │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m832\u001b[0m │ concatenate_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m208\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_14 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m208\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m59,936\u001b[0m │ re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m240\u001b[0m)              │            │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m960\u001b[0m │ concatenate_11[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m240\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_15 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m240\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m28,920\u001b[0m │ re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m120\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_3 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m120\u001b[0m) │        \u001b[38;5;34m480\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_16 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m34,592\u001b[0m │ re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m152\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m152\u001b[0m) │        \u001b[38;5;34m608\u001b[0m │ concatenate_12[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_17 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m152\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m43,808\u001b[0m │ re_lu_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m184\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ concatenate_12[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m184\u001b[0m) │        \u001b[38;5;34m736\u001b[0m │ concatenate_13[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_18 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m184\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m53,024\u001b[0m │ re_lu_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m216\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ concatenate_13[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m216\u001b[0m) │        \u001b[38;5;34m864\u001b[0m │ concatenate_14[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_19 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m216\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m62,240\u001b[0m │ re_lu_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m248\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ concatenate_14[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m248\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_15[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m202\u001b[0m)       │     \u001b[38;5;34m50,298\u001b[0m │ global_average_p… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,472</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │ re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,680</span> │ re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,896</span> │ re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">46,112</span> │ re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,528</span> │ re_lu_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,680</span> │ re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,896</span> │ re_lu_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">46,112</span> │ re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">55,328</span> │ re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │            │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">25,200</span> │ re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,288</span> │ re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              │            │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,504</span> │ re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>)              │            │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">50,720</span> │ re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)              │            │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │ concatenate_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">59,936</span> │ re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)              │            │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> │ concatenate_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">28,920</span> │ re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_3 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">34,592</span> │ re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> │ concatenate_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">43,808</span> │ re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">736</span> │ concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">53,024</span> │ re_lu_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span> │ concatenate_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">62,240</span> │ re_lu_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">248</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">248</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">50,298</span> │ global_average_p… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m817,922\u001b[0m (3.12 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">817,922</span> (3.12 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m811,810\u001b[0m (3.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">811,810</span> (3.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6,112\u001b[0m (23.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,112</span> (23.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the preprocessor\n",
        "batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "image_size = (224, 224)\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Loop through each augmentation\n",
        "for aug in augmentations_to_test:\n",
        "    print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "    model = build_densenet()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=True, shuffle=True)\n",
        "    train_ds_sampled, class_names = preprocess.load_img(data_dir=\"data/rare_species/train_sampled\", minority_class=minority_class, augment=aug, oversampling=True, shuffle=True)\n",
        "    val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "    test_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/test\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "    # Initialize the experiment\n",
        "    experiment = Experiment(\n",
        "        model=model,\n",
        "        train_ds=train_ds_sampled,\n",
        "        val_ds=val_ds,\n",
        "        experiment_name=f\"densenet_with_{aug}_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "        batch_size=32,\n",
        "        image_size=(224, 224),\n",
        "        save_model = False\n",
        "    )\n",
        "\n",
        "    # Run the experiment\n",
        "    history = experiment.run_experiment(callbacks=callbacks, epochs=40)\n",
        "\n",
        "    # Predict entire validation set at once\n",
        "    preds = model.predict(val_ds)\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Extract true labels in order\n",
        "    y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "    # Compute metrics\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Store in results\n",
        "    results[aug] = {\n",
        "        \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "        \"f1_macro\": f1_macro,\n",
        "        \"f1_weighted\": f1_weighted,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall\n",
        "    }\n",
        "\n",
        "    print(f\"Finished '{aug}'\")\n",
        "    print(f\"  Accuracy:      {results[aug]['accuracy']:.4f}\")\n",
        "    print(f\"  F1 (macro):    {results[aug]['f1_macro']:.4f}\")\n",
        "    print(f\"  F1 (weighted): {results[aug]['f1_weighted']:.4f}\")\n",
        "    print(f\"  Precision:     {results[aug]['precision']:.4f}\")\n",
        "    print(f\"  Recall:        {results[aug]['recall']:.4f}\")\n",
        "\n",
        "    # Clear memory to avoid OOM\n",
        "    del model\n",
        "    del experiment\n",
        "    K.clear_session()\n",
        "    gc.collect()\n"
      ],
      "metadata": {
        "id": "-yc3nOJp8DX9",
        "outputId": "59401e85-2f6f-4377-afff-42cd04015ee2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: none\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 4194 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Found 749 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 132ms/step - accuracy: 0.0460 - auc: 0.6265 - f1_macro: 0.0208 - f1_weighted: 0.0352 - loss: 8.8930 - top5_accuracy: 0.1278 - val_accuracy: 0.0184 - val_auc: 0.5982 - val_f1_macro: 0.0024 - val_f1_weighted: 0.0067 - val_loss: 5.6827 - val_top5_accuracy: 0.0640 - learning_rate: 0.0100\n",
            "Epoch 2/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0242 - auc: 0.5969 - f1_macro: 0.0044 - f1_weighted: 0.0097 - loss: 5.8467 - top5_accuracy: 0.0917 - val_accuracy: 0.0317 - val_auc: 0.6170 - val_f1_macro: 0.0042 - val_f1_weighted: 0.0118 - val_loss: 5.6268 - val_top5_accuracy: 0.1113 - learning_rate: 0.0100\n",
            "Epoch 3/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0284 - auc: 0.6241 - f1_macro: 0.0042 - f1_weighted: 0.0096 - loss: 5.4736 - top5_accuracy: 0.1147 - val_accuracy: 0.0306 - val_auc: 0.6264 - val_f1_macro: 0.0038 - val_f1_weighted: 0.0144 - val_loss: 5.8299 - val_top5_accuracy: 0.1002 - learning_rate: 0.0100\n",
            "Epoch 4/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0397 - auc: 0.6417 - f1_macro: 0.0042 - f1_weighted: 0.0125 - loss: 5.3211 - top5_accuracy: 0.1137 - val_accuracy: 0.0573 - val_auc: 0.6440 - val_f1_macro: 0.0046 - val_f1_weighted: 0.0181 - val_loss: 5.2902 - val_top5_accuracy: 0.1503 - learning_rate: 0.0100\n",
            "Epoch 5/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0416 - auc: 0.6565 - f1_macro: 0.0043 - f1_weighted: 0.0139 - loss: 5.2056 - top5_accuracy: 0.1251 - val_accuracy: 0.0228 - val_auc: 0.6228 - val_f1_macro: 0.0028 - val_f1_weighted: 0.0077 - val_loss: 5.6528 - val_top5_accuracy: 0.0940 - learning_rate: 0.0100\n",
            "Epoch 6/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0455 - auc: 0.6701 - f1_macro: 0.0062 - f1_weighted: 0.0169 - loss: 5.1554 - top5_accuracy: 0.1211 - val_accuracy: 0.0406 - val_auc: 0.6421 - val_f1_macro: 0.0038 - val_f1_weighted: 0.0150 - val_loss: 5.3450 - val_top5_accuracy: 0.1347 - learning_rate: 0.0100\n",
            "Epoch 7/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0490 - auc: 0.6734 - f1_macro: 0.0066 - f1_weighted: 0.0172 - loss: 5.1011 - top5_accuracy: 0.1383 - val_accuracy: 0.0451 - val_auc: 0.6600 - val_f1_macro: 0.0050 - val_f1_weighted: 0.0186 - val_loss: 5.2340 - val_top5_accuracy: 0.1436 - learning_rate: 0.0100\n",
            "Epoch 8/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0495 - auc: 0.6849 - f1_macro: 0.0071 - f1_weighted: 0.0183 - loss: 5.0306 - top5_accuracy: 0.1425 - val_accuracy: 0.0428 - val_auc: 0.6487 - val_f1_macro: 0.0025 - val_f1_weighted: 0.0084 - val_loss: 5.2231 - val_top5_accuracy: 0.1319 - learning_rate: 0.0100\n",
            "Epoch 9/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0489 - auc: 0.6906 - f1_macro: 0.0075 - f1_weighted: 0.0184 - loss: 4.9907 - top5_accuracy: 0.1460 - val_accuracy: 0.0384 - val_auc: 0.6485 - val_f1_macro: 0.0043 - val_f1_weighted: 0.0111 - val_loss: 5.3436 - val_top5_accuracy: 0.1408 - learning_rate: 0.0100\n",
            "Epoch 10/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0493 - auc: 0.6945 - f1_macro: 0.0074 - f1_weighted: 0.0185 - loss: 4.9638 - top5_accuracy: 0.1523 - val_accuracy: 0.0356 - val_auc: 0.6137 - val_f1_macro: 0.0046 - val_f1_weighted: 0.0126 - val_loss: 5.5836 - val_top5_accuracy: 0.1057 - learning_rate: 0.0100\n",
            "Epoch 11/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0454 - auc: 0.7068 - f1_macro: 0.0083 - f1_weighted: 0.0181 - loss: 4.9212 - top5_accuracy: 0.1491 - val_accuracy: 0.0417 - val_auc: 0.6298 - val_f1_macro: 0.0051 - val_f1_weighted: 0.0161 - val_loss: 5.4148 - val_top5_accuracy: 0.1247 - learning_rate: 0.0100\n",
            "Epoch 12/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0522 - auc: 0.7053 - f1_macro: 0.0089 - f1_weighted: 0.0221 - loss: 4.8974 - top5_accuracy: 0.1557 - val_accuracy: 0.0351 - val_auc: 0.6658 - val_f1_macro: 0.0052 - val_f1_weighted: 0.0149 - val_loss: 5.2399 - val_top5_accuracy: 0.1514 - learning_rate: 0.0100\n",
            "Epoch 13/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0533 - auc: 0.7108 - f1_macro: 0.0107 - f1_weighted: 0.0243 - loss: 4.8619 - top5_accuracy: 0.1624\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0533 - auc: 0.7109 - f1_macro: 0.0107 - f1_weighted: 0.0244 - loss: 4.8617 - top5_accuracy: 0.1625 - val_accuracy: 0.0434 - val_auc: 0.6580 - val_f1_macro: 0.0044 - val_f1_weighted: 0.0146 - val_loss: 5.2519 - val_top5_accuracy: 0.1441 - learning_rate: 0.0100\n",
            "Epoch 14/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0595 - auc: 0.7232 - f1_macro: 0.0119 - f1_weighted: 0.0244 - loss: 4.8108 - top5_accuracy: 0.1664 - val_accuracy: 0.0629 - val_auc: 0.6990 - val_f1_macro: 0.0103 - val_f1_weighted: 0.0244 - val_loss: 4.9685 - val_top5_accuracy: 0.1875 - learning_rate: 0.0050\n",
            "Epoch 15/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0630 - auc: 0.7343 - f1_macro: 0.0117 - f1_weighted: 0.0274 - loss: 4.7603 - top5_accuracy: 0.1817 - val_accuracy: 0.0490 - val_auc: 0.6791 - val_f1_macro: 0.0059 - val_f1_weighted: 0.0222 - val_loss: 5.2106 - val_top5_accuracy: 0.1736 - learning_rate: 0.0050\n",
            "Epoch 16/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0649 - auc: 0.7425 - f1_macro: 0.0153 - f1_weighted: 0.0310 - loss: 4.7218 - top5_accuracy: 0.1874 - val_accuracy: 0.0445 - val_auc: 0.6976 - val_f1_macro: 0.0069 - val_f1_weighted: 0.0250 - val_loss: 5.0519 - val_top5_accuracy: 0.1775 - learning_rate: 0.0050\n",
            "Epoch 17/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0668 - auc: 0.7488 - f1_macro: 0.0180 - f1_weighted: 0.0334 - loss: 4.6870 - top5_accuracy: 0.1976 - val_accuracy: 0.0595 - val_auc: 0.6505 - val_f1_macro: 0.0115 - val_f1_weighted: 0.0340 - val_loss: 6.2433 - val_top5_accuracy: 0.1575 - learning_rate: 0.0050\n",
            "Epoch 18/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0686 - auc: 0.7542 - f1_macro: 0.0181 - f1_weighted: 0.0338 - loss: 4.6678 - top5_accuracy: 0.2003 - val_accuracy: 0.0345 - val_auc: 0.6074 - val_f1_macro: 0.0095 - val_f1_weighted: 0.0204 - val_loss: 6.1563 - val_top5_accuracy: 0.1208 - learning_rate: 0.0050\n",
            "Epoch 19/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0676 - auc: 0.7618 - f1_macro: 0.0177 - f1_weighted: 0.0332 - loss: 4.6423 - top5_accuracy: 0.2016\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0676 - auc: 0.7619 - f1_macro: 0.0178 - f1_weighted: 0.0333 - loss: 4.6421 - top5_accuracy: 0.2017 - val_accuracy: 0.0473 - val_auc: 0.6881 - val_f1_macro: 0.0113 - val_f1_weighted: 0.0284 - val_loss: 5.0753 - val_top5_accuracy: 0.1742 - learning_rate: 0.0050\n",
            "Epoch 20/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0736 - auc: 0.7674 - f1_macro: 0.0221 - f1_weighted: 0.0381 - loss: 4.5874 - top5_accuracy: 0.2223 - val_accuracy: 0.0740 - val_auc: 0.7163 - val_f1_macro: 0.0207 - val_f1_weighted: 0.0387 - val_loss: 4.9658 - val_top5_accuracy: 0.2148 - learning_rate: 0.0025\n",
            "Epoch 21/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0807 - auc: 0.7693 - f1_macro: 0.0284 - f1_weighted: 0.0442 - loss: 4.5590 - top5_accuracy: 0.2232 - val_accuracy: 0.0768 - val_auc: 0.7228 - val_f1_macro: 0.0223 - val_f1_weighted: 0.0426 - val_loss: 4.9431 - val_top5_accuracy: 0.2087 - learning_rate: 0.0025\n",
            "Epoch 22/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0861 - auc: 0.7772 - f1_macro: 0.0351 - f1_weighted: 0.0502 - loss: 4.5192 - top5_accuracy: 0.2325 - val_accuracy: 0.0718 - val_auc: 0.7209 - val_f1_macro: 0.0235 - val_f1_weighted: 0.0410 - val_loss: 5.0057 - val_top5_accuracy: 0.2081 - learning_rate: 0.0025\n",
            "Epoch 23/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0886 - auc: 0.7831 - f1_macro: 0.0386 - f1_weighted: 0.0529 - loss: 4.4858 - top5_accuracy: 0.2360 - val_accuracy: 0.0735 - val_auc: 0.7258 - val_f1_macro: 0.0251 - val_f1_weighted: 0.0435 - val_loss: 5.0132 - val_top5_accuracy: 0.2031 - learning_rate: 0.0025\n",
            "Epoch 24/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0959 - auc: 0.7882 - f1_macro: 0.0437 - f1_weighted: 0.0599 - loss: 4.4461 - top5_accuracy: 0.2494 - val_accuracy: 0.0712 - val_auc: 0.7192 - val_f1_macro: 0.0266 - val_f1_weighted: 0.0420 - val_loss: 5.0388 - val_top5_accuracy: 0.2104 - learning_rate: 0.0025\n",
            "Epoch 25/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0981 - auc: 0.7947 - f1_macro: 0.0464 - f1_weighted: 0.0637 - loss: 4.4078 - top5_accuracy: 0.2605 - val_accuracy: 0.0829 - val_auc: 0.7253 - val_f1_macro: 0.0275 - val_f1_weighted: 0.0506 - val_loss: 5.0646 - val_top5_accuracy: 0.2076 - learning_rate: 0.0025\n",
            "Epoch 26/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1026 - auc: 0.8051 - f1_macro: 0.0510 - f1_weighted: 0.0676 - loss: 4.3593 - top5_accuracy: 0.2749\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1025 - auc: 0.8052 - f1_macro: 0.0511 - f1_weighted: 0.0676 - loss: 4.3590 - top5_accuracy: 0.2748 - val_accuracy: 0.0646 - val_auc: 0.7197 - val_f1_macro: 0.0227 - val_f1_weighted: 0.0384 - val_loss: 5.2182 - val_top5_accuracy: 0.1931 - learning_rate: 0.0025\n",
            "Epoch 27/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1078 - auc: 0.8127 - f1_macro: 0.0564 - f1_weighted: 0.0731 - loss: 4.2906 - top5_accuracy: 0.2824 - val_accuracy: 0.0712 - val_auc: 0.7297 - val_f1_macro: 0.0258 - val_f1_weighted: 0.0426 - val_loss: 5.1257 - val_top5_accuracy: 0.2003 - learning_rate: 0.0012\n",
            "Epoch 28/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1119 - auc: 0.8213 - f1_macro: 0.0583 - f1_weighted: 0.0773 - loss: 4.2349 - top5_accuracy: 0.2994 - val_accuracy: 0.0701 - val_auc: 0.7228 - val_f1_macro: 0.0279 - val_f1_weighted: 0.0440 - val_loss: 5.2204 - val_top5_accuracy: 0.1948 - learning_rate: 0.0012\n",
            "Epoch 29/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1174 - auc: 0.8264 - f1_macro: 0.0668 - f1_weighted: 0.0847 - loss: 4.1857 - top5_accuracy: 0.3101 - val_accuracy: 0.0690 - val_auc: 0.7271 - val_f1_macro: 0.0264 - val_f1_weighted: 0.0451 - val_loss: 5.2781 - val_top5_accuracy: 0.1970 - learning_rate: 0.0012\n",
            "Epoch 30/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1196 - auc: 0.8328 - f1_macro: 0.0696 - f1_weighted: 0.0882 - loss: 4.1379 - top5_accuracy: 0.3231 - val_accuracy: 0.0712 - val_auc: 0.7264 - val_f1_macro: 0.0287 - val_f1_weighted: 0.0480 - val_loss: 5.3272 - val_top5_accuracy: 0.1998 - learning_rate: 0.0012\n",
            "Epoch 31/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1252 - auc: 0.8376 - f1_macro: 0.0781 - f1_weighted: 0.0956 - loss: 4.0986 - top5_accuracy: 0.3325\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1253 - auc: 0.8377 - f1_macro: 0.0782 - f1_weighted: 0.0957 - loss: 4.0982 - top5_accuracy: 0.3325 - val_accuracy: 0.0707 - val_auc: 0.7209 - val_f1_macro: 0.0333 - val_f1_weighted: 0.0520 - val_loss: 5.3996 - val_top5_accuracy: 0.1942 - learning_rate: 0.0012\n",
            "Epoch 32/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1380 - auc: 0.8463 - f1_macro: 0.0933 - f1_weighted: 0.1089 - loss: 4.0378 - top5_accuracy: 0.3437 - val_accuracy: 0.0757 - val_auc: 0.7311 - val_f1_macro: 0.0365 - val_f1_weighted: 0.0528 - val_loss: 5.3434 - val_top5_accuracy: 0.2092 - learning_rate: 6.2500e-04\n",
            "Epoch 33/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1524 - auc: 0.8520 - f1_macro: 0.1057 - f1_weighted: 0.1241 - loss: 3.9845 - top5_accuracy: 0.3515 - val_accuracy: 0.0801 - val_auc: 0.7363 - val_f1_macro: 0.0373 - val_f1_weighted: 0.0571 - val_loss: 5.3665 - val_top5_accuracy: 0.2176 - learning_rate: 6.2500e-04\n",
            "Epoch 34/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1558 - auc: 0.8558 - f1_macro: 0.1074 - f1_weighted: 0.1272 - loss: 3.9398 - top5_accuracy: 0.3636 - val_accuracy: 0.0829 - val_auc: 0.7402 - val_f1_macro: 0.0414 - val_f1_weighted: 0.0606 - val_loss: 5.3036 - val_top5_accuracy: 0.2237 - learning_rate: 6.2500e-04\n",
            "Epoch 35/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1634 - auc: 0.8605 - f1_macro: 0.1170 - f1_weighted: 0.1363 - loss: 3.8977 - top5_accuracy: 0.3781 - val_accuracy: 0.0863 - val_auc: 0.7410 - val_f1_macro: 0.0440 - val_f1_weighted: 0.0641 - val_loss: 5.3633 - val_top5_accuracy: 0.2226 - learning_rate: 6.2500e-04\n",
            "Epoch 36/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1749 - auc: 0.8641 - f1_macro: 0.1309 - f1_weighted: 0.1500 - loss: 3.8585 - top5_accuracy: 0.3870\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1750 - auc: 0.8642 - f1_macro: 0.1311 - f1_weighted: 0.1501 - loss: 3.8581 - top5_accuracy: 0.3871 - val_accuracy: 0.0874 - val_auc: 0.7424 - val_f1_macro: 0.0432 - val_f1_weighted: 0.0634 - val_loss: 5.3611 - val_top5_accuracy: 0.2243 - learning_rate: 6.2500e-04\n",
            "Epoch 37/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1792 - auc: 0.8698 - f1_macro: 0.1384 - f1_weighted: 0.1546 - loss: 3.8135 - top5_accuracy: 0.3938 - val_accuracy: 0.0918 - val_auc: 0.7442 - val_f1_macro: 0.0488 - val_f1_weighted: 0.0673 - val_loss: 5.4955 - val_top5_accuracy: 0.2382 - learning_rate: 3.1250e-04\n",
            "Epoch 38/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1912 - auc: 0.8723 - f1_macro: 0.1539 - f1_weighted: 0.1671 - loss: 3.7694 - top5_accuracy: 0.4108 - val_accuracy: 0.0885 - val_auc: 0.7442 - val_f1_macro: 0.0463 - val_f1_weighted: 0.0643 - val_loss: 5.5143 - val_top5_accuracy: 0.2382 - learning_rate: 3.1250e-04\n",
            "Epoch 39/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.2002 - auc: 0.8736 - f1_macro: 0.1630 - f1_weighted: 0.1784 - loss: 3.7403 - top5_accuracy: 0.4242 - val_accuracy: 0.0868 - val_auc: 0.7443 - val_f1_macro: 0.0447 - val_f1_weighted: 0.0622 - val_loss: 5.5837 - val_top5_accuracy: 0.2443 - learning_rate: 3.1250e-04\n",
            "Epoch 40/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.2074 - auc: 0.8756 - f1_macro: 0.1718 - f1_weighted: 0.1864 - loss: 3.7137 - top5_accuracy: 0.4285 - val_accuracy: 0.0885 - val_auc: 0.7444 - val_f1_macro: 0.0501 - val_f1_weighted: 0.0654 - val_loss: 5.5336 - val_top5_accuracy: 0.2426 - learning_rate: 3.1250e-04\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step\n",
            "Finished 'none'\n",
            "  Accuracy:      0.0885\n",
            "  F1 (macro):    0.0501\n",
            "  F1 (weighted): 0.0654\n",
            "  Precision:     0.0690\n",
            "  Recall:        0.0885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: grayscale_plus\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 4194 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Found 749 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 166ms/step - accuracy: 0.0464 - auc: 0.6341 - f1_macro: 0.0276 - f1_weighted: 0.0352 - loss: 8.2846 - top5_accuracy: 0.1331 - val_accuracy: 0.0245 - val_auc: 0.6328 - val_f1_macro: 0.0011 - val_f1_weighted: 0.0043 - val_loss: 5.9573 - val_top5_accuracy: 0.1013 - learning_rate: 0.0100\n",
            "Epoch 2/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0235 - auc: 0.6052 - f1_macro: 0.0033 - f1_weighted: 0.0085 - loss: 5.7064 - top5_accuracy: 0.0873 - val_accuracy: 0.0334 - val_auc: 0.6547 - val_f1_macro: 0.0017 - val_f1_weighted: 0.0076 - val_loss: 5.3454 - val_top5_accuracy: 0.1369 - learning_rate: 0.0100\n",
            "Epoch 3/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0318 - auc: 0.6438 - f1_macro: 0.0035 - f1_weighted: 0.0095 - loss: 5.4207 - top5_accuracy: 0.0983 - val_accuracy: 0.0067 - val_auc: 0.5355 - val_f1_macro: 3.6941e-04 - val_f1_weighted: 0.0016 - val_loss: 10.0823 - val_top5_accuracy: 0.0440 - learning_rate: 0.0100\n",
            "Epoch 4/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0338 - auc: 0.6560 - f1_macro: 0.0052 - f1_weighted: 0.0118 - loss: 5.2838 - top5_accuracy: 0.1105 - val_accuracy: 0.0083 - val_auc: 0.5773 - val_f1_macro: 0.0014 - val_f1_weighted: 0.0039 - val_loss: 7.5842 - val_top5_accuracy: 0.0612 - learning_rate: 0.0100\n",
            "Epoch 5/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0366 - auc: 0.6620 - f1_macro: 0.0043 - f1_weighted: 0.0119 - loss: 5.2285 - top5_accuracy: 0.1091 - val_accuracy: 0.0184 - val_auc: 0.5192 - val_f1_macro: 6.9460e-04 - val_f1_weighted: 0.0021 - val_loss: 8.1296 - val_top5_accuracy: 0.0412 - learning_rate: 0.0100\n",
            "Epoch 6/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0375 - auc: 0.6699 - f1_macro: 0.0058 - f1_weighted: 0.0138 - loss: 5.1444 - top5_accuracy: 0.1207 - val_accuracy: 0.0072 - val_auc: 0.5064 - val_f1_macro: 7.1112e-05 - val_f1_weighted: 1.0392e-04 - val_loss: 20.9595 - val_top5_accuracy: 0.0501 - learning_rate: 0.0100\n",
            "Epoch 7/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0365 - auc: 0.6728 - f1_macro: 0.0043 - f1_weighted: 0.0118 - loss: 5.0995 - top5_accuracy: 0.1178\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0365 - auc: 0.6728 - f1_macro: 0.0043 - f1_weighted: 0.0118 - loss: 5.0995 - top5_accuracy: 0.1178 - val_accuracy: 0.0122 - val_auc: 0.5304 - val_f1_macro: 3.2406e-04 - val_f1_weighted: 0.0013 - val_loss: 8.0440 - val_top5_accuracy: 0.0573 - learning_rate: 0.0100\n",
            "Epoch 8/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0448 - auc: 0.6817 - f1_macro: 0.0054 - f1_weighted: 0.0142 - loss: 5.0512 - top5_accuracy: 0.1258 - val_accuracy: 0.0540 - val_auc: 0.6583 - val_f1_macro: 0.0056 - val_f1_weighted: 0.0207 - val_loss: 5.1630 - val_top5_accuracy: 0.1436 - learning_rate: 0.0050\n",
            "Epoch 9/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0443 - auc: 0.6935 - f1_macro: 0.0063 - f1_weighted: 0.0151 - loss: 5.0006 - top5_accuracy: 0.1305 - val_accuracy: 0.0301 - val_auc: 0.6223 - val_f1_macro: 0.0022 - val_f1_weighted: 0.0091 - val_loss: 5.7221 - val_top5_accuracy: 0.1007 - learning_rate: 0.0050\n",
            "Epoch 10/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0427 - auc: 0.7013 - f1_macro: 0.0062 - f1_weighted: 0.0152 - loss: 4.9659 - top5_accuracy: 0.1333 - val_accuracy: 0.0406 - val_auc: 0.6280 - val_f1_macro: 0.0053 - val_f1_weighted: 0.0177 - val_loss: 5.5554 - val_top5_accuracy: 0.1241 - learning_rate: 0.0050\n",
            "Epoch 11/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0423 - auc: 0.7109 - f1_macro: 0.0060 - f1_weighted: 0.0147 - loss: 4.9197 - top5_accuracy: 0.1479 - val_accuracy: 0.0239 - val_auc: 0.6137 - val_f1_macro: 0.0022 - val_f1_weighted: 0.0102 - val_loss: 6.2300 - val_top5_accuracy: 0.0913 - learning_rate: 0.0050\n",
            "Epoch 12/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0470 - auc: 0.7165 - f1_macro: 0.0077 - f1_weighted: 0.0176 - loss: 4.8949 - top5_accuracy: 0.1462 - val_accuracy: 0.0384 - val_auc: 0.6719 - val_f1_macro: 0.0056 - val_f1_weighted: 0.0169 - val_loss: 5.3130 - val_top5_accuracy: 0.1430 - learning_rate: 0.0050\n",
            "Epoch 13/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0427 - auc: 0.7243 - f1_macro: 0.0075 - f1_weighted: 0.0168 - loss: 4.8631 - top5_accuracy: 0.1445\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0428 - auc: 0.7243 - f1_macro: 0.0075 - f1_weighted: 0.0168 - loss: 4.8630 - top5_accuracy: 0.1445 - val_accuracy: 0.0428 - val_auc: 0.6708 - val_f1_macro: 0.0048 - val_f1_weighted: 0.0176 - val_loss: 5.3445 - val_top5_accuracy: 0.1441 - learning_rate: 0.0050\n",
            "Epoch 14/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0493 - auc: 0.7335 - f1_macro: 0.0090 - f1_weighted: 0.0196 - loss: 4.8161 - top5_accuracy: 0.1574 - val_accuracy: 0.0512 - val_auc: 0.6531 - val_f1_macro: 0.0079 - val_f1_weighted: 0.0246 - val_loss: 6.8870 - val_top5_accuracy: 0.1336 - learning_rate: 0.0025\n",
            "Epoch 15/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0469 - auc: 0.7452 - f1_macro: 0.0098 - f1_weighted: 0.0197 - loss: 4.7674 - top5_accuracy: 0.1680 - val_accuracy: 0.0390 - val_auc: 0.6091 - val_f1_macro: 0.0069 - val_f1_weighted: 0.0211 - val_loss: 7.3062 - val_top5_accuracy: 0.1152 - learning_rate: 0.0025\n",
            "Epoch 16/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0479 - auc: 0.7498 - f1_macro: 0.0097 - f1_weighted: 0.0200 - loss: 4.7457 - top5_accuracy: 0.1689 - val_accuracy: 0.0223 - val_auc: 0.5637 - val_f1_macro: 0.0050 - val_f1_weighted: 0.0113 - val_loss: 8.7672 - val_top5_accuracy: 0.0690 - learning_rate: 0.0025\n",
            "Epoch 17/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0506 - auc: 0.7566 - f1_macro: 0.0125 - f1_weighted: 0.0228 - loss: 4.7196 - top5_accuracy: 0.1726 - val_accuracy: 0.0568 - val_auc: 0.6766 - val_f1_macro: 0.0105 - val_f1_weighted: 0.0291 - val_loss: 5.5400 - val_top5_accuracy: 0.1514 - learning_rate: 0.0025\n",
            "Epoch 18/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0522 - auc: 0.7629 - f1_macro: 0.0133 - f1_weighted: 0.0241 - loss: 4.6929 - top5_accuracy: 0.1746\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0523 - auc: 0.7629 - f1_macro: 0.0133 - f1_weighted: 0.0241 - loss: 4.6929 - top5_accuracy: 0.1746 - val_accuracy: 0.0646 - val_auc: 0.6938 - val_f1_macro: 0.0130 - val_f1_weighted: 0.0338 - val_loss: 5.5498 - val_top5_accuracy: 0.1625 - learning_rate: 0.0025\n",
            "Epoch 19/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0518 - auc: 0.7687 - f1_macro: 0.0127 - f1_weighted: 0.0226 - loss: 4.6691 - top5_accuracy: 0.1894 - val_accuracy: 0.0473 - val_auc: 0.6743 - val_f1_macro: 0.0103 - val_f1_weighted: 0.0227 - val_loss: 5.3263 - val_top5_accuracy: 0.1464 - learning_rate: 0.0012\n",
            "Epoch 20/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0577 - auc: 0.7750 - f1_macro: 0.0164 - f1_weighted: 0.0270 - loss: 4.6276 - top5_accuracy: 0.1945 - val_accuracy: 0.0551 - val_auc: 0.6712 - val_f1_macro: 0.0104 - val_f1_weighted: 0.0266 - val_loss: 5.2871 - val_top5_accuracy: 0.1491 - learning_rate: 0.0012\n",
            "Epoch 21/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0643 - auc: 0.7825 - f1_macro: 0.0208 - f1_weighted: 0.0324 - loss: 4.5969 - top5_accuracy: 0.2016 - val_accuracy: 0.0423 - val_auc: 0.6565 - val_f1_macro: 0.0094 - val_f1_weighted: 0.0232 - val_loss: 5.5689 - val_top5_accuracy: 0.1219 - learning_rate: 0.0012\n",
            "Epoch 22/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0614 - auc: 0.7872 - f1_macro: 0.0264 - f1_weighted: 0.0347 - loss: 4.5700 - top5_accuracy: 0.2064 - val_accuracy: 0.0328 - val_auc: 0.6742 - val_f1_macro: 0.0087 - val_f1_weighted: 0.0171 - val_loss: 5.5194 - val_top5_accuracy: 0.1391 - learning_rate: 0.0012\n",
            "Epoch 23/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0683 - auc: 0.7921 - f1_macro: 0.0287 - f1_weighted: 0.0397 - loss: 4.5355 - top5_accuracy: 0.2116\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0683 - auc: 0.7921 - f1_macro: 0.0288 - f1_weighted: 0.0398 - loss: 4.5355 - top5_accuracy: 0.2117 - val_accuracy: 0.0289 - val_auc: 0.6407 - val_f1_macro: 0.0057 - val_f1_weighted: 0.0139 - val_loss: 5.7329 - val_top5_accuracy: 0.1002 - learning_rate: 0.0012\n",
            "Epoch 24/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0714 - auc: 0.7959 - f1_macro: 0.0344 - f1_weighted: 0.0444 - loss: 4.5064 - top5_accuracy: 0.2357 - val_accuracy: 0.0518 - val_auc: 0.6917 - val_f1_macro: 0.0086 - val_f1_weighted: 0.0251 - val_loss: 5.1765 - val_top5_accuracy: 0.1675 - learning_rate: 6.2500e-04\n",
            "Epoch 25/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0751 - auc: 0.7978 - f1_macro: 0.0355 - f1_weighted: 0.0466 - loss: 4.4748 - top5_accuracy: 0.2356 - val_accuracy: 0.0640 - val_auc: 0.6947 - val_f1_macro: 0.0172 - val_f1_weighted: 0.0332 - val_loss: 5.2021 - val_top5_accuracy: 0.1681 - learning_rate: 6.2500e-04\n",
            "Epoch 26/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0765 - auc: 0.8048 - f1_macro: 0.0372 - f1_weighted: 0.0481 - loss: 4.4459 - top5_accuracy: 0.2453 - val_accuracy: 0.0723 - val_auc: 0.7016 - val_f1_macro: 0.0153 - val_f1_weighted: 0.0358 - val_loss: 5.1523 - val_top5_accuracy: 0.1742 - learning_rate: 6.2500e-04\n",
            "Epoch 27/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0795 - auc: 0.8087 - f1_macro: 0.0417 - f1_weighted: 0.0516 - loss: 4.4103 - top5_accuracy: 0.2546 - val_accuracy: 0.0696 - val_auc: 0.7008 - val_f1_macro: 0.0139 - val_f1_weighted: 0.0323 - val_loss: 5.1413 - val_top5_accuracy: 0.1836 - learning_rate: 6.2500e-04\n",
            "Epoch 28/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0868 - auc: 0.8131 - f1_macro: 0.0509 - f1_weighted: 0.0599 - loss: 4.3814 - top5_accuracy: 0.2600 - val_accuracy: 0.0774 - val_auc: 0.7054 - val_f1_macro: 0.0179 - val_f1_weighted: 0.0378 - val_loss: 5.0669 - val_top5_accuracy: 0.1892 - learning_rate: 6.2500e-04\n",
            "Epoch 29/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0884 - auc: 0.8150 - f1_macro: 0.0520 - f1_weighted: 0.0619 - loss: 4.3606 - top5_accuracy: 0.2713 - val_accuracy: 0.0735 - val_auc: 0.7082 - val_f1_macro: 0.0168 - val_f1_weighted: 0.0357 - val_loss: 5.0282 - val_top5_accuracy: 0.1797 - learning_rate: 6.2500e-04\n",
            "Epoch 30/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0876 - auc: 0.8172 - f1_macro: 0.0545 - f1_weighted: 0.0634 - loss: 4.3348 - top5_accuracy: 0.2787 - val_accuracy: 0.0701 - val_auc: 0.7046 - val_f1_macro: 0.0162 - val_f1_weighted: 0.0365 - val_loss: 5.0734 - val_top5_accuracy: 0.1753 - learning_rate: 6.2500e-04\n",
            "Epoch 31/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0922 - auc: 0.8221 - f1_macro: 0.0613 - f1_weighted: 0.0691 - loss: 4.3042 - top5_accuracy: 0.2836 - val_accuracy: 0.0629 - val_auc: 0.6958 - val_f1_macro: 0.0151 - val_f1_weighted: 0.0327 - val_loss: 5.1579 - val_top5_accuracy: 0.1614 - learning_rate: 6.2500e-04\n",
            "Epoch 32/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0972 - auc: 0.8243 - f1_macro: 0.0658 - f1_weighted: 0.0742 - loss: 4.2874 - top5_accuracy: 0.2848 - val_accuracy: 0.0646 - val_auc: 0.7029 - val_f1_macro: 0.0187 - val_f1_weighted: 0.0351 - val_loss: 5.1364 - val_top5_accuracy: 0.1669 - learning_rate: 6.2500e-04\n",
            "Epoch 33/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1008 - auc: 0.8281 - f1_macro: 0.0710 - f1_weighted: 0.0787 - loss: 4.2600 - top5_accuracy: 0.2913 - val_accuracy: 0.0662 - val_auc: 0.6984 - val_f1_macro: 0.0197 - val_f1_weighted: 0.0368 - val_loss: 5.1637 - val_top5_accuracy: 0.1703 - learning_rate: 6.2500e-04\n",
            "Epoch 34/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1084 - auc: 0.8320 - f1_macro: 0.0811 - f1_weighted: 0.0867 - loss: 4.2369 - top5_accuracy: 0.2980\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1084 - auc: 0.8320 - f1_macro: 0.0812 - f1_weighted: 0.0867 - loss: 4.2368 - top5_accuracy: 0.2980 - val_accuracy: 0.0673 - val_auc: 0.7001 - val_f1_macro: 0.0192 - val_f1_weighted: 0.0370 - val_loss: 5.1907 - val_top5_accuracy: 0.1764 - learning_rate: 6.2500e-04\n",
            "Epoch 35/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1095 - auc: 0.8288 - f1_macro: 0.0829 - f1_weighted: 0.0886 - loss: 4.2369 - top5_accuracy: 0.2967 - val_accuracy: 0.0607 - val_auc: 0.6766 - val_f1_macro: 0.0197 - val_f1_weighted: 0.0357 - val_loss: 5.3995 - val_top5_accuracy: 0.1653 - learning_rate: 3.1250e-04\n",
            "Epoch 36/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1106 - auc: 0.8293 - f1_macro: 0.0828 - f1_weighted: 0.0892 - loss: 4.2159 - top5_accuracy: 0.3029 - val_accuracy: 0.0646 - val_auc: 0.6814 - val_f1_macro: 0.0189 - val_f1_weighted: 0.0357 - val_loss: 5.3292 - val_top5_accuracy: 0.1625 - learning_rate: 3.1250e-04\n",
            "Epoch 37/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1107 - auc: 0.8320 - f1_macro: 0.0824 - f1_weighted: 0.0893 - loss: 4.2067 - top5_accuracy: 0.3030 - val_accuracy: 0.0662 - val_auc: 0.6851 - val_f1_macro: 0.0210 - val_f1_weighted: 0.0376 - val_loss: 5.3896 - val_top5_accuracy: 0.1736 - learning_rate: 3.1250e-04\n",
            "Epoch 38/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1168 - auc: 0.8348 - f1_macro: 0.0931 - f1_weighted: 0.0979 - loss: 4.1889 - top5_accuracy: 0.3049 - val_accuracy: 0.0618 - val_auc: 0.6810 - val_f1_macro: 0.0192 - val_f1_weighted: 0.0379 - val_loss: 5.5654 - val_top5_accuracy: 0.1669 - learning_rate: 3.1250e-04\n",
            "Epoch 39/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1222 - auc: 0.8357 - f1_macro: 0.0954 - f1_weighted: 0.1017 - loss: 4.1693 - top5_accuracy: 0.3124\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1223 - auc: 0.8357 - f1_macro: 0.0955 - f1_weighted: 0.1018 - loss: 4.1692 - top5_accuracy: 0.3124 - val_accuracy: 0.0690 - val_auc: 0.6901 - val_f1_macro: 0.0220 - val_f1_weighted: 0.0397 - val_loss: 5.4167 - val_top5_accuracy: 0.1758 - learning_rate: 3.1250e-04\n",
            "Epoch 40/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1212 - auc: 0.8329 - f1_macro: 0.0936 - f1_weighted: 0.0996 - loss: 4.1762 - top5_accuracy: 0.3064 - val_accuracy: 0.0612 - val_auc: 0.6930 - val_f1_macro: 0.0213 - val_f1_weighted: 0.0346 - val_loss: 5.3143 - val_top5_accuracy: 0.1658 - learning_rate: 1.5625e-04\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step\n",
            "Finished 'grayscale_plus'\n",
            "  Accuracy:      0.0612\n",
            "  F1 (macro):    0.0213\n",
            "  F1 (weighted): 0.0346\n",
            "  Precision:     0.0303\n",
            "  Recall:        0.0612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: mixup\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 4194 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Found 749 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 129ms/step - accuracy: 0.0340 - auc: 0.5849 - f1_macro: 0.0130 - f1_weighted: 0.0205 - loss: 7.8102 - top5_accuracy: 0.0983 - val_accuracy: 0.0267 - val_auc: 0.6335 - val_f1_macro: 8.7751e-04 - val_f1_weighted: 0.0043 - val_loss: 6.2711 - val_top5_accuracy: 0.1174 - learning_rate: 0.0100\n",
            "Epoch 2/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0181 - auc: 0.5769 - f1_macro: 0.0026 - f1_weighted: 0.0060 - loss: 5.8761 - top5_accuracy: 0.0777 - val_accuracy: 0.0306 - val_auc: 0.6480 - val_f1_macro: 0.0016 - val_f1_weighted: 0.0053 - val_loss: 5.3909 - val_top5_accuracy: 0.1130 - learning_rate: 0.0100\n",
            "Epoch 3/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0216 - auc: 0.5925 - f1_macro: 0.0021 - f1_weighted: 0.0062 - loss: 5.4940 - top5_accuracy: 0.0905 - val_accuracy: 0.0362 - val_auc: 0.6458 - val_f1_macro: 0.0031 - val_f1_weighted: 0.0132 - val_loss: 5.5436 - val_top5_accuracy: 0.1230 - learning_rate: 0.0100\n",
            "Epoch 4/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0384 - auc: 0.6062 - f1_macro: 0.0052 - f1_weighted: 0.0153 - loss: 5.3953 - top5_accuracy: 0.1002 - val_accuracy: 0.0273 - val_auc: 0.6058 - val_f1_macro: 0.0034 - val_f1_weighted: 0.0114 - val_loss: 6.4245 - val_top5_accuracy: 0.1041 - learning_rate: 0.0100\n",
            "Epoch 5/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0387 - auc: 0.6149 - f1_macro: 0.0058 - f1_weighted: 0.0132 - loss: 5.2918 - top5_accuracy: 0.1150 - val_accuracy: 0.0301 - val_auc: 0.6460 - val_f1_macro: 0.0024 - val_f1_weighted: 0.0097 - val_loss: 5.7290 - val_top5_accuracy: 0.1219 - learning_rate: 0.0100\n",
            "Epoch 6/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0383 - auc: 0.6213 - f1_macro: 0.0047 - f1_weighted: 0.0124 - loss: 5.2090 - top5_accuracy: 0.1093 - val_accuracy: 0.0211 - val_auc: 0.6261 - val_f1_macro: 0.0016 - val_f1_weighted: 0.0064 - val_loss: 5.6676 - val_top5_accuracy: 0.0807 - learning_rate: 0.0100\n",
            "Epoch 7/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0373 - auc: 0.6256 - f1_macro: 0.0042 - f1_weighted: 0.0122 - loss: 5.1519 - top5_accuracy: 0.1180 - val_accuracy: 0.0289 - val_auc: 0.6541 - val_f1_macro: 0.0027 - val_f1_weighted: 0.0111 - val_loss: 5.3707 - val_top5_accuracy: 0.1247 - learning_rate: 0.0100\n",
            "Epoch 8/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.0402 - auc: 0.6300 - f1_macro: 0.0058 - f1_weighted: 0.0133 - loss: 5.0864 - top5_accuracy: 0.1163 - val_accuracy: 0.0373 - val_auc: 0.6620 - val_f1_macro: 0.0030 - val_f1_weighted: 0.0123 - val_loss: 5.4751 - val_top5_accuracy: 0.1419 - learning_rate: 0.0100\n",
            "Epoch 9/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.0429 - auc: 0.6341 - f1_macro: 0.0067 - f1_weighted: 0.0151 - loss: 5.0442 - top5_accuracy: 0.1239 - val_accuracy: 0.0250 - val_auc: 0.6494 - val_f1_macro: 0.0029 - val_f1_weighted: 0.0102 - val_loss: 5.4721 - val_top5_accuracy: 0.1063 - learning_rate: 0.0100\n",
            "Epoch 10/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0402 - auc: 0.6409 - f1_macro: 0.0057 - f1_weighted: 0.0144 - loss: 5.0030 - top5_accuracy: 0.1243 - val_accuracy: 0.0173 - val_auc: 0.6112 - val_f1_macro: 0.0024 - val_f1_weighted: 0.0070 - val_loss: 7.7801 - val_top5_accuracy: 0.0857 - learning_rate: 0.0100\n",
            "Epoch 11/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0393 - auc: 0.6450 - f1_macro: 0.0066 - f1_weighted: 0.0145 - loss: 4.9884 - top5_accuracy: 0.1293 - val_accuracy: 0.0256 - val_auc: 0.6178 - val_f1_macro: 0.0033 - val_f1_weighted: 0.0070 - val_loss: 6.5413 - val_top5_accuracy: 0.0968 - learning_rate: 0.0100\n",
            "Epoch 12/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0434 - auc: 0.6402 - f1_macro: 0.0070 - f1_weighted: 0.0152 - loss: 4.9983 - top5_accuracy: 0.1310\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0434 - auc: 0.6402 - f1_macro: 0.0070 - f1_weighted: 0.0153 - loss: 4.9983 - top5_accuracy: 0.1311 - val_accuracy: 0.0234 - val_auc: 0.5720 - val_f1_macro: 0.0017 - val_f1_weighted: 0.0064 - val_loss: 7.5272 - val_top5_accuracy: 0.0807 - learning_rate: 0.0100\n",
            "Epoch 13/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0486 - auc: 0.6434 - f1_macro: 0.0063 - f1_weighted: 0.0149 - loss: 4.9354 - top5_accuracy: 0.1476 - val_accuracy: 0.0440 - val_auc: 0.6570 - val_f1_macro: 0.0046 - val_f1_weighted: 0.0159 - val_loss: 6.3796 - val_top5_accuracy: 0.1330 - learning_rate: 0.0050\n",
            "Epoch 14/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0466 - auc: 0.6502 - f1_macro: 0.0058 - f1_weighted: 0.0138 - loss: 4.8710 - top5_accuracy: 0.1531 - val_accuracy: 0.0378 - val_auc: 0.6634 - val_f1_macro: 0.0053 - val_f1_weighted: 0.0144 - val_loss: 5.5932 - val_top5_accuracy: 0.1330 - learning_rate: 0.0050\n",
            "Epoch 15/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.0493 - auc: 0.6531 - f1_macro: 0.0066 - f1_weighted: 0.0156 - loss: 4.8338 - top5_accuracy: 0.1572 - val_accuracy: 0.0401 - val_auc: 0.6626 - val_f1_macro: 0.0055 - val_f1_weighted: 0.0149 - val_loss: 5.3115 - val_top5_accuracy: 0.1319 - learning_rate: 0.0050\n",
            "Epoch 16/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0537 - auc: 0.6539 - f1_macro: 0.0099 - f1_weighted: 0.0207 - loss: 4.8237 - top5_accuracy: 0.1672 - val_accuracy: 0.0495 - val_auc: 0.6659 - val_f1_macro: 0.0054 - val_f1_weighted: 0.0137 - val_loss: 5.1685 - val_top5_accuracy: 0.1336 - learning_rate: 0.0050\n",
            "Epoch 17/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0529 - auc: 0.6604 - f1_macro: 0.0089 - f1_weighted: 0.0199 - loss: 4.7926 - top5_accuracy: 0.1740 - val_accuracy: 0.0423 - val_auc: 0.6606 - val_f1_macro: 0.0039 - val_f1_weighted: 0.0112 - val_loss: 5.2695 - val_top5_accuracy: 0.1269 - learning_rate: 0.0050\n",
            "Epoch 18/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0512 - auc: 0.6618 - f1_macro: 0.0100 - f1_weighted: 0.0198 - loss: 4.7885 - top5_accuracy: 0.1669 - val_accuracy: 0.0428 - val_auc: 0.6763 - val_f1_macro: 0.0047 - val_f1_weighted: 0.0141 - val_loss: 5.1430 - val_top5_accuracy: 0.1330 - learning_rate: 0.0050\n",
            "Epoch 19/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0538 - auc: 0.6600 - f1_macro: 0.0102 - f1_weighted: 0.0209 - loss: 4.7747 - top5_accuracy: 0.1716 - val_accuracy: 0.0445 - val_auc: 0.6655 - val_f1_macro: 0.0058 - val_f1_weighted: 0.0161 - val_loss: 5.3790 - val_top5_accuracy: 0.1202 - learning_rate: 0.0050\n",
            "Epoch 20/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0513 - auc: 0.6636 - f1_macro: 0.0104 - f1_weighted: 0.0209 - loss: 4.7572 - top5_accuracy: 0.1826 - val_accuracy: 0.0362 - val_auc: 0.6645 - val_f1_macro: 0.0049 - val_f1_weighted: 0.0136 - val_loss: 5.2967 - val_top5_accuracy: 0.1297 - learning_rate: 0.0050\n",
            "Epoch 21/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0533 - auc: 0.6664 - f1_macro: 0.0115 - f1_weighted: 0.0232 - loss: 4.7448 - top5_accuracy: 0.1831 - val_accuracy: 0.0428 - val_auc: 0.6785 - val_f1_macro: 0.0057 - val_f1_weighted: 0.0168 - val_loss: 5.2036 - val_top5_accuracy: 0.1336 - learning_rate: 0.0050\n",
            "Epoch 22/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0573 - auc: 0.6673 - f1_macro: 0.0138 - f1_weighted: 0.0278 - loss: 4.7272 - top5_accuracy: 0.1839 - val_accuracy: 0.0451 - val_auc: 0.6764 - val_f1_macro: 0.0076 - val_f1_weighted: 0.0214 - val_loss: 5.3548 - val_top5_accuracy: 0.1352 - learning_rate: 0.0050\n",
            "Epoch 23/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.0565 - auc: 0.6698 - f1_macro: 0.0130 - f1_weighted: 0.0252 - loss: 4.7130 - top5_accuracy: 0.1870\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0565 - auc: 0.6698 - f1_macro: 0.0131 - f1_weighted: 0.0252 - loss: 4.7129 - top5_accuracy: 0.1870 - val_accuracy: 0.0273 - val_auc: 0.6344 - val_f1_macro: 0.0071 - val_f1_weighted: 0.0088 - val_loss: 6.1523 - val_top5_accuracy: 0.1102 - learning_rate: 0.0050\n",
            "Epoch 24/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0706 - auc: 0.6692 - f1_macro: 0.0221 - f1_weighted: 0.0356 - loss: 4.6714 - top5_accuracy: 0.2051 - val_accuracy: 0.0434 - val_auc: 0.6752 - val_f1_macro: 0.0113 - val_f1_weighted: 0.0249 - val_loss: 5.3495 - val_top5_accuracy: 0.1369 - learning_rate: 0.0025\n",
            "Epoch 25/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0743 - auc: 0.6695 - f1_macro: 0.0240 - f1_weighted: 0.0393 - loss: 4.6361 - top5_accuracy: 0.1993 - val_accuracy: 0.0618 - val_auc: 0.6901 - val_f1_macro: 0.0140 - val_f1_weighted: 0.0287 - val_loss: 5.3291 - val_top5_accuracy: 0.1558 - learning_rate: 0.0025\n",
            "Epoch 26/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0763 - auc: 0.6749 - f1_macro: 0.0269 - f1_weighted: 0.0429 - loss: 4.5898 - top5_accuracy: 0.2162 - val_accuracy: 0.0601 - val_auc: 0.6979 - val_f1_macro: 0.0124 - val_f1_weighted: 0.0289 - val_loss: 5.3254 - val_top5_accuracy: 0.1708 - learning_rate: 0.0025\n",
            "Epoch 27/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0810 - auc: 0.6780 - f1_macro: 0.0311 - f1_weighted: 0.0477 - loss: 4.5574 - top5_accuracy: 0.2239 - val_accuracy: 0.0584 - val_auc: 0.6971 - val_f1_macro: 0.0147 - val_f1_weighted: 0.0304 - val_loss: 5.2716 - val_top5_accuracy: 0.1664 - learning_rate: 0.0025\n",
            "Epoch 28/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.0853 - auc: 0.6820 - f1_macro: 0.0367 - f1_weighted: 0.0529 - loss: 4.5190 - top5_accuracy: 0.2290\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0853 - auc: 0.6820 - f1_macro: 0.0367 - f1_weighted: 0.0529 - loss: 4.5189 - top5_accuracy: 0.2290 - val_accuracy: 0.0607 - val_auc: 0.6957 - val_f1_macro: 0.0120 - val_f1_weighted: 0.0309 - val_loss: 5.4985 - val_top5_accuracy: 0.1753 - learning_rate: 0.0025\n",
            "Epoch 29/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0897 - auc: 0.6864 - f1_macro: 0.0390 - f1_weighted: 0.0557 - loss: 4.4667 - top5_accuracy: 0.2563 - val_accuracy: 0.0601 - val_auc: 0.6969 - val_f1_macro: 0.0162 - val_f1_weighted: 0.0358 - val_loss: 5.5288 - val_top5_accuracy: 0.1775 - learning_rate: 0.0012\n",
            "Epoch 30/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0972 - auc: 0.6903 - f1_macro: 0.0510 - f1_weighted: 0.0665 - loss: 4.4085 - top5_accuracy: 0.2737 - val_accuracy: 0.0623 - val_auc: 0.7043 - val_f1_macro: 0.0152 - val_f1_weighted: 0.0353 - val_loss: 5.6045 - val_top5_accuracy: 0.1820 - learning_rate: 0.0012\n",
            "Epoch 31/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0985 - auc: 0.6932 - f1_macro: 0.0545 - f1_weighted: 0.0694 - loss: 4.3580 - top5_accuracy: 0.2934 - val_accuracy: 0.0629 - val_auc: 0.7096 - val_f1_macro: 0.0159 - val_f1_weighted: 0.0353 - val_loss: 5.7286 - val_top5_accuracy: 0.1825 - learning_rate: 0.0012\n",
            "Epoch 32/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.1053 - auc: 0.6966 - f1_macro: 0.0636 - f1_weighted: 0.0780 - loss: 4.3147 - top5_accuracy: 0.3043 - val_accuracy: 0.0607 - val_auc: 0.7086 - val_f1_macro: 0.0152 - val_f1_weighted: 0.0341 - val_loss: 5.8414 - val_top5_accuracy: 0.1809 - learning_rate: 0.0012\n",
            "Epoch 33/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1160 - auc: 0.7009 - f1_macro: 0.0771 - f1_weighted: 0.0910 - loss: 4.2678 - top5_accuracy: 0.3230\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.1161 - auc: 0.7009 - f1_macro: 0.0772 - f1_weighted: 0.0911 - loss: 4.2677 - top5_accuracy: 0.3230 - val_accuracy: 0.0623 - val_auc: 0.7057 - val_f1_macro: 0.0194 - val_f1_weighted: 0.0377 - val_loss: 6.1143 - val_top5_accuracy: 0.1775 - learning_rate: 0.0012\n",
            "Epoch 34/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1299 - auc: 0.7034 - f1_macro: 0.0916 - f1_weighted: 0.1061 - loss: 4.2245 - top5_accuracy: 0.3297 - val_accuracy: 0.0718 - val_auc: 0.7158 - val_f1_macro: 0.0234 - val_f1_weighted: 0.0426 - val_loss: 5.8501 - val_top5_accuracy: 0.1987 - learning_rate: 6.2500e-04\n",
            "Epoch 35/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.1447 - auc: 0.7073 - f1_macro: 0.1031 - f1_weighted: 0.1214 - loss: 4.1786 - top5_accuracy: 0.3354 - val_accuracy: 0.0735 - val_auc: 0.7183 - val_f1_macro: 0.0248 - val_f1_weighted: 0.0449 - val_loss: 5.7689 - val_top5_accuracy: 0.2020 - learning_rate: 6.2500e-04\n",
            "Epoch 36/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.1529 - auc: 0.7093 - f1_macro: 0.1119 - f1_weighted: 0.1314 - loss: 4.1357 - top5_accuracy: 0.3499 - val_accuracy: 0.0746 - val_auc: 0.7122 - val_f1_macro: 0.0291 - val_f1_weighted: 0.0468 - val_loss: 5.8613 - val_top5_accuracy: 0.2037 - learning_rate: 6.2500e-04\n",
            "Epoch 37/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.1566 - auc: 0.7118 - f1_macro: 0.1169 - f1_weighted: 0.1359 - loss: 4.0973 - top5_accuracy: 0.3602 - val_accuracy: 0.0746 - val_auc: 0.7127 - val_f1_macro: 0.0279 - val_f1_weighted: 0.0474 - val_loss: 5.9293 - val_top5_accuracy: 0.2031 - learning_rate: 6.2500e-04\n",
            "Epoch 38/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1665 - auc: 0.7132 - f1_macro: 0.1269 - f1_weighted: 0.1455 - loss: 4.0588 - top5_accuracy: 0.3718\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.1666 - auc: 0.7133 - f1_macro: 0.1270 - f1_weighted: 0.1456 - loss: 4.0587 - top5_accuracy: 0.3718 - val_accuracy: 0.0735 - val_auc: 0.7104 - val_f1_macro: 0.0288 - val_f1_weighted: 0.0469 - val_loss: 6.0125 - val_top5_accuracy: 0.2048 - learning_rate: 6.2500e-04\n",
            "Epoch 39/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.1757 - auc: 0.7149 - f1_macro: 0.1370 - f1_weighted: 0.1556 - loss: 4.0282 - top5_accuracy: 0.3771 - val_accuracy: 0.0812 - val_auc: 0.7145 - val_f1_macro: 0.0365 - val_f1_weighted: 0.0572 - val_loss: 5.7763 - val_top5_accuracy: 0.2109 - learning_rate: 3.1250e-04\n",
            "Epoch 40/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.1861 - auc: 0.7164 - f1_macro: 0.1489 - f1_weighted: 0.1679 - loss: 3.9933 - top5_accuracy: 0.3882 - val_accuracy: 0.0801 - val_auc: 0.7146 - val_f1_macro: 0.0359 - val_f1_weighted: 0.0573 - val_loss: 5.7699 - val_top5_accuracy: 0.2181 - learning_rate: 3.1250e-04\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step\n",
            "Finished 'mixup'\n",
            "  Accuracy:      0.0801\n",
            "  F1 (macro):    0.0359\n",
            "  F1 (weighted): 0.0573\n",
            "  Precision:     0.0570\n",
            "  Recall:        0.0801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# Display the table\n",
        "display(results_df.round(4))\n"
      ],
      "metadata": {
        "id": "-RP620dL8F2a",
        "outputId": "90a94553-9ff8-4389-958b-21e5e91b7b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     augmentation  accuracy  f1_macro  f1_weighted  precision  recall\n",
              "0            none    0.0885    0.0501       0.0654     0.0690  0.0885\n",
              "1  grayscale_plus    0.0612    0.0213       0.0346     0.0303  0.0612\n",
              "2           mixup    0.0801    0.0359       0.0573     0.0570  0.0801"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b81d34f6-3355-434b-84fe-07dfa1be1442\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>augmentation</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>f1_weighted</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>none</td>\n",
              "      <td>0.0885</td>\n",
              "      <td>0.0501</td>\n",
              "      <td>0.0654</td>\n",
              "      <td>0.0690</td>\n",
              "      <td>0.0885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>grayscale_plus</td>\n",
              "      <td>0.0612</td>\n",
              "      <td>0.0213</td>\n",
              "      <td>0.0346</td>\n",
              "      <td>0.0303</td>\n",
              "      <td>0.0612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mixup</td>\n",
              "      <td>0.0801</td>\n",
              "      <td>0.0359</td>\n",
              "      <td>0.0573</td>\n",
              "      <td>0.0570</td>\n",
              "      <td>0.0801</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b81d34f6-3355-434b-84fe-07dfa1be1442')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b81d34f6-3355-434b-84fe-07dfa1be1442 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b81d34f6-3355-434b-84fe-07dfa1be1442');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9f4fa88a-5928-4102-b858-eb7352f6e7b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f4fa88a-5928-4102-b858-eb7352f6e7b2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9f4fa88a-5928-4102-b858-eb7352f6e7b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(results_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"augmentation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"none\",\n          \"grayscale_plus\",\n          \"mixup\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013982489048806725,\n        \"min\": 0.0612,\n        \"max\": 0.0885,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0885,\n          0.0612,\n          0.0801\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014400462955521024,\n        \"min\": 0.0213,\n        \"max\": 0.0501,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0501,\n          0.0213,\n          0.0359\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_weighted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015966318715763296,\n        \"min\": 0.0346,\n        \"max\": 0.0654,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0654,\n          0.0346,\n          0.0573\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.019809846036756572,\n        \"min\": 0.0303,\n        \"max\": 0.069,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.069,\n          0.0303,\n          0.057\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013982489048806725,\n        \"min\": 0.0612,\n        \"max\": 0.0885,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0885,\n          0.0612,\n          0.0801\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melt the DataFrame for seaborn plotting\n",
        "metrics_to_plot = ['accuracy', 'f1_macro', 'f1_weighted', 'precision', 'recall']\n",
        "melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "                            var_name='metric', value_name='value')\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "plt.title(\"Comparison of Metrics Across Augmentation Strategies\")\n",
        "plt.ylim(0, 0.4)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bvRJlfXq8IS_",
        "outputId": "c16faa8a-263d-432c-a73c-e7a1e6b83cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet Grayscale Augmentation - With Oversampling"
      ],
      "metadata": {
        "id": "H6uPhf0RTocm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dense_layer(x, growth_rate):\n",
        "    \"\"\"Single layer inside a dense block.\"\"\"\n",
        "    out = BatchNormalization()(x)\n",
        "    out = ReLU()(out)\n",
        "    out = Conv2D(growth_rate, (3, 3), padding='same', kernel_regularizer=l2(1e-4))(out)\n",
        "    x = Concatenate()([x, out])  # Concatenate input and output (dense connection)\n",
        "    return x\n",
        "\n",
        "def dense_block(x, num_layers, growth_rate):\n",
        "    \"\"\"Dense block with several dense layers.\"\"\"\n",
        "    for _ in range(num_layers):\n",
        "        x = dense_layer(x, growth_rate)\n",
        "    return x\n",
        "\n",
        "def transition_layer(x, reduction=0.5):\n",
        "    \"\"\"Reduces spatial size and number of filters.\"\"\"\n",
        "    filters = int(tf.keras.backend.int_shape(x)[-1] * reduction)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=l2(1e-4))(x)\n",
        "    x = AveragePooling2D((2, 2), strides=2)(x)\n",
        "    return x\n",
        "\n",
        "def build_densenet(input_shape=(224, 224, 3), num_classes=202, growth_rate=32):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Initial conv\n",
        "    x = Conv2D(64, (7, 7), strides=2, padding='same', kernel_regularizer=l2(1e-4))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = AveragePooling2D((3, 3), strides=2, padding='same')(x)\n",
        "\n",
        "    # Dense Block 1\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "    x = transition_layer(x)\n",
        "\n",
        "    # Dense Block 2\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "    x = transition_layer(x)\n",
        "\n",
        "    # Dense Block 3\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "    x = transition_layer(x)\n",
        "\n",
        "    # Dense Block 4\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "\n",
        "    # Classification\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "model = build_densenet()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "f6abK5wCTqtq",
        "outputId": "e43f671c-2b88-4561-b84d-c5fda769fa03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │      \u001b[38;5;34m9,472\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m18,464\u001b[0m │ re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m96\u001b[0m)               │            │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m27,680\u001b[0m │ re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m36,896\u001b[0m │ re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m160\u001b[0m)              │            │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m640\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m46,112\u001b[0m │ re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m192\u001b[0m)              │            │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m768\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m18,528\u001b[0m │ re_lu_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m27,680\u001b[0m │ re_lu_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_7 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m36,896\u001b[0m │ re_lu_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m160\u001b[0m)              │            │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m640\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_8 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m46,112\u001b[0m │ re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m192\u001b[0m)              │            │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m768\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_9 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m55,328\u001b[0m │ re_lu_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m224\u001b[0m)              │            │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m896\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m224\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_10 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m224\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m25,200\u001b[0m │ re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m448\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_11 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m32,288\u001b[0m │ re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m144\u001b[0m)              │            │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m576\u001b[0m │ concatenate_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m144\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_12 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m144\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m41,504\u001b[0m │ re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m176\u001b[0m)              │            │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m704\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m176\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_13 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m176\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m50,720\u001b[0m │ re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m208\u001b[0m)              │            │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m832\u001b[0m │ concatenate_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m208\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_14 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m208\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m59,936\u001b[0m │ re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m240\u001b[0m)              │            │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m960\u001b[0m │ concatenate_11[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m240\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_15 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m240\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m28,920\u001b[0m │ re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m120\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_3 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m120\u001b[0m) │        \u001b[38;5;34m480\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_16 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m34,592\u001b[0m │ re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m152\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m152\u001b[0m) │        \u001b[38;5;34m608\u001b[0m │ concatenate_12[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_17 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m152\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m43,808\u001b[0m │ re_lu_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m184\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ concatenate_12[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m184\u001b[0m) │        \u001b[38;5;34m736\u001b[0m │ concatenate_13[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_18 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m184\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m53,024\u001b[0m │ re_lu_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m216\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ concatenate_13[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m216\u001b[0m) │        \u001b[38;5;34m864\u001b[0m │ concatenate_14[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_19 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m216\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m62,240\u001b[0m │ re_lu_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m248\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ concatenate_14[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m248\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_15[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m202\u001b[0m)       │     \u001b[38;5;34m50,298\u001b[0m │ global_average_p… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,472</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │ re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,680</span> │ re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,896</span> │ re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">46,112</span> │ re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,528</span> │ re_lu_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,680</span> │ re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,896</span> │ re_lu_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">46,112</span> │ re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">55,328</span> │ re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │            │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">25,200</span> │ re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,288</span> │ re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              │            │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,504</span> │ re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>)              │            │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">50,720</span> │ re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)              │            │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │ concatenate_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">59,936</span> │ re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)              │            │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> │ concatenate_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">28,920</span> │ re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_3 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">34,592</span> │ re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> │ concatenate_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">43,808</span> │ re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">736</span> │ concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">53,024</span> │ re_lu_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span> │ concatenate_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">62,240</span> │ re_lu_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">248</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">248</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">50,298</span> │ global_average_p… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m817,922\u001b[0m (3.12 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">817,922</span> (3.12 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m811,810\u001b[0m (3.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">811,810</span> (3.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6,112\u001b[0m (23.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,112</span> (23.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the preprocessor\n",
        "batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "image_size = (224, 224)\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "print(f\"\\nTraining with augmentation: greysclae\")\n",
        "\n",
        "model = build_densenet()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment='grayscale_plus', oversampling=True, shuffle=True)\n",
        "train_ds_sampled, class_names = preprocess.load_img(data_dir=\"data/rare_species/train_sampled\", minority_class=minority_class, augment='grayscale_plus', oversampling=True, shuffle=True)\n",
        "val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment='grayscale', oversampling=False)\n",
        "test_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/test\", minority_class=minority_class, augment='grayscale', oversampling=False)\n",
        "\n",
        "# Initialize the experiment\n",
        "experiment = Experiment(\n",
        "    model=model,\n",
        "    train_ds=train_ds_sampled,\n",
        "    val_ds=val_ds,\n",
        "    experiment_name=f\"densenet_with_gray_scale_oversampling_2\", # MUDAR NOME!!!!!!!!!!!!\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    save_model = False\n",
        ")\n",
        "\n",
        "# Run the experiment\n",
        "history = experiment.run_experiment(callbacks=callbacks, epochs=40)\n",
        "\n",
        "# Predict entire validation set at once\n",
        "preds = model.predict(val_ds)\n",
        "y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "# Extract true labels in order\n",
        "y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "# Compute metrics\n",
        "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# Store in results\n",
        "results['grayscale'] = {\n",
        "    \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "    \"f1_macro\": f1_macro,\n",
        "    \"f1_weighted\": f1_weighted,\n",
        "    \"precision\": precision,\n",
        "    \"recall\": recall\n",
        "}\n",
        "\n",
        "print(f\"Finished '{'grayscale'}'\")\n",
        "print(f\"  Accuracy:      {results['grayscale']['accuracy']:.4f}\")\n",
        "print(f\"  F1 (macro):    {results['grayscale']['f1_macro']:.4f}\")\n",
        "print(f\"  F1 (weighted): {results['grayscale']['f1_weighted']:.4f}\")\n",
        "print(f\"  Precision:     {results['garyscale']['precision']:.4f}\")\n",
        "print(f\"  Recall:        {results['grayscale']['recall']:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "BCoYtu8UTwhq",
        "outputId": "43024d9d-3af2-43c5-9f6b-b70d40ab374d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: greysclae\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 4194 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Found 749 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 165ms/step - accuracy: 0.0101 - auc: 0.5342 - f1_macro: 0.0013 - f1_weighted: 0.0042 - loss: 7.8880 - top5_accuracy: 0.0577 - val_accuracy: 0.0250 - val_auc: 0.6252 - val_f1_macro: 0.0012 - val_f1_weighted: 0.0056 - val_loss: 5.5427 - val_top5_accuracy: 0.1024 - learning_rate: 0.0100\n",
            "Epoch 2/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0302 - auc: 0.6059 - f1_macro: 0.0026 - f1_weighted: 0.0093 - loss: 5.7435 - top5_accuracy: 0.0970 - val_accuracy: 0.0189 - val_auc: 0.5972 - val_f1_macro: 4.5906e-04 - val_f1_weighted: 0.0021 - val_loss: 6.1200 - val_top5_accuracy: 0.0935 - learning_rate: 0.0100\n",
            "Epoch 3/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0328 - auc: 0.6245 - f1_macro: 0.0033 - f1_weighted: 0.0101 - loss: 5.4488 - top5_accuracy: 0.1125 - val_accuracy: 0.0178 - val_auc: 0.5437 - val_f1_macro: 0.0016 - val_f1_weighted: 0.0076 - val_loss: 9.3897 - val_top5_accuracy: 0.0568 - learning_rate: 0.0100\n",
            "Epoch 4/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0383 - auc: 0.6436 - f1_macro: 0.0040 - f1_weighted: 0.0115 - loss: 5.2651 - top5_accuracy: 0.1224 - val_accuracy: 0.0367 - val_auc: 0.6467 - val_f1_macro: 0.0018 - val_f1_weighted: 0.0084 - val_loss: 5.2321 - val_top5_accuracy: 0.1330 - learning_rate: 0.0100\n",
            "Epoch 5/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0416 - auc: 0.6514 - f1_macro: 0.0040 - f1_weighted: 0.0119 - loss: 5.1811 - top5_accuracy: 0.1246 - val_accuracy: 0.0195 - val_auc: 0.6166 - val_f1_macro: 0.0011 - val_f1_weighted: 0.0050 - val_loss: 5.5851 - val_top5_accuracy: 0.0929 - learning_rate: 0.0100\n",
            "Epoch 6/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0401 - auc: 0.6607 - f1_macro: 0.0035 - f1_weighted: 0.0114 - loss: 5.1419 - top5_accuracy: 0.1238 - val_accuracy: 0.0467 - val_auc: 0.6650 - val_f1_macro: 0.0028 - val_f1_weighted: 0.0131 - val_loss: 5.1592 - val_top5_accuracy: 0.1369 - learning_rate: 0.0100\n",
            "Epoch 7/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0427 - auc: 0.6672 - f1_macro: 0.0045 - f1_weighted: 0.0128 - loss: 5.1039 - top5_accuracy: 0.1323 - val_accuracy: 0.0228 - val_auc: 0.6328 - val_f1_macro: 9.5768e-04 - val_f1_weighted: 0.0041 - val_loss: 5.4059 - val_top5_accuracy: 0.1046 - learning_rate: 0.0100\n",
            "Epoch 8/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0461 - auc: 0.6765 - f1_macro: 0.0049 - f1_weighted: 0.0142 - loss: 5.0820 - top5_accuracy: 0.1314 - val_accuracy: 0.0228 - val_auc: 0.6341 - val_f1_macro: 0.0024 - val_f1_weighted: 0.0090 - val_loss: 5.3214 - val_top5_accuracy: 0.1068 - learning_rate: 0.0100\n",
            "Epoch 9/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0452 - auc: 0.6791 - f1_macro: 0.0055 - f1_weighted: 0.0162 - loss: 5.0681 - top5_accuracy: 0.1426 - val_accuracy: 0.0273 - val_auc: 0.6536 - val_f1_macro: 0.0020 - val_f1_weighted: 0.0086 - val_loss: 5.2900 - val_top5_accuracy: 0.1263 - learning_rate: 0.0100\n",
            "Epoch 10/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0492 - auc: 0.6857 - f1_macro: 0.0060 - f1_weighted: 0.0173 - loss: 5.0102 - top5_accuracy: 0.1398 - val_accuracy: 0.0050 - val_auc: 0.5419 - val_f1_macro: 8.3848e-04 - val_f1_weighted: 0.0039 - val_loss: 14.8036 - val_top5_accuracy: 0.0662 - learning_rate: 0.0100\n",
            "Epoch 11/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0464 - auc: 0.6912 - f1_macro: 0.0073 - f1_weighted: 0.0176 - loss: 4.9840 - top5_accuracy: 0.1440 - val_accuracy: 0.0479 - val_auc: 0.6632 - val_f1_macro: 0.0026 - val_f1_weighted: 0.0126 - val_loss: 5.1090 - val_top5_accuracy: 0.1324 - learning_rate: 0.0100\n",
            "Epoch 12/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0466 - auc: 0.6945 - f1_macro: 0.0051 - f1_weighted: 0.0155 - loss: 4.9556 - top5_accuracy: 0.1502 - val_accuracy: 0.0540 - val_auc: 0.6716 - val_f1_macro: 0.0044 - val_f1_weighted: 0.0161 - val_loss: 5.1169 - val_top5_accuracy: 0.1369 - learning_rate: 0.0100\n",
            "Epoch 13/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0534 - auc: 0.7001 - f1_macro: 0.0067 - f1_weighted: 0.0183 - loss: 4.9295 - top5_accuracy: 0.1457 - val_accuracy: 0.0495 - val_auc: 0.6481 - val_f1_macro: 0.0031 - val_f1_weighted: 0.0120 - val_loss: 5.3607 - val_top5_accuracy: 0.1308 - learning_rate: 0.0100\n",
            "Epoch 14/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0537 - auc: 0.7011 - f1_macro: 0.0061 - f1_weighted: 0.0179 - loss: 4.9140 - top5_accuracy: 0.1516 - val_accuracy: 0.0323 - val_auc: 0.6613 - val_f1_macro: 0.0020 - val_f1_weighted: 0.0091 - val_loss: 5.3132 - val_top5_accuracy: 0.1191 - learning_rate: 0.0100\n",
            "Epoch 15/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0583 - auc: 0.7032 - f1_macro: 0.0067 - f1_weighted: 0.0198 - loss: 4.8891 - top5_accuracy: 0.1578 - val_accuracy: 0.0178 - val_auc: 0.5373 - val_f1_macro: 0.0016 - val_f1_weighted: 0.0067 - val_loss: 17.2293 - val_top5_accuracy: 0.0679 - learning_rate: 0.0100\n",
            "Epoch 16/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0573 - auc: 0.7072 - f1_macro: 0.0069 - f1_weighted: 0.0199 - loss: 4.8789 - top5_accuracy: 0.1589\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0572 - auc: 0.7073 - f1_macro: 0.0069 - f1_weighted: 0.0198 - loss: 4.8790 - top5_accuracy: 0.1589 - val_accuracy: 0.0306 - val_auc: 0.6358 - val_f1_macro: 0.0027 - val_f1_weighted: 0.0109 - val_loss: 5.4606 - val_top5_accuracy: 0.1035 - learning_rate: 0.0100\n",
            "Epoch 17/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0589 - auc: 0.7215 - f1_macro: 0.0094 - f1_weighted: 0.0216 - loss: 4.8356 - top5_accuracy: 0.1688 - val_accuracy: 0.0545 - val_auc: 0.6955 - val_f1_macro: 0.0053 - val_f1_weighted: 0.0152 - val_loss: 4.9809 - val_top5_accuracy: 0.1608 - learning_rate: 0.0050\n",
            "Epoch 18/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0636 - auc: 0.7252 - f1_macro: 0.0099 - f1_weighted: 0.0231 - loss: 4.8028 - top5_accuracy: 0.1708 - val_accuracy: 0.0390 - val_auc: 0.6698 - val_f1_macro: 0.0026 - val_f1_weighted: 0.0110 - val_loss: 5.0762 - val_top5_accuracy: 0.1291 - learning_rate: 0.0050\n",
            "Epoch 19/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0598 - auc: 0.7272 - f1_macro: 0.0093 - f1_weighted: 0.0213 - loss: 4.7961 - top5_accuracy: 0.1693 - val_accuracy: 0.0406 - val_auc: 0.6704 - val_f1_macro: 0.0039 - val_f1_weighted: 0.0111 - val_loss: 5.1014 - val_top5_accuracy: 0.1330 - learning_rate: 0.0050\n",
            "Epoch 20/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0625 - auc: 0.7298 - f1_macro: 0.0087 - f1_weighted: 0.0223 - loss: 4.7800 - top5_accuracy: 0.1736 - val_accuracy: 0.0412 - val_auc: 0.6766 - val_f1_macro: 0.0023 - val_f1_weighted: 0.0096 - val_loss: 5.0397 - val_top5_accuracy: 0.1397 - learning_rate: 0.0050\n",
            "Epoch 21/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0649 - auc: 0.7332 - f1_macro: 0.0102 - f1_weighted: 0.0234 - loss: 4.7680 - top5_accuracy: 0.1714 - val_accuracy: 0.0545 - val_auc: 0.6931 - val_f1_macro: 0.0073 - val_f1_weighted: 0.0173 - val_loss: 4.9718 - val_top5_accuracy: 0.1541 - learning_rate: 0.0050\n",
            "Epoch 22/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0635 - auc: 0.7342 - f1_macro: 0.0101 - f1_weighted: 0.0228 - loss: 4.7547 - top5_accuracy: 0.1732 - val_accuracy: 0.0384 - val_auc: 0.6763 - val_f1_macro: 0.0033 - val_f1_weighted: 0.0114 - val_loss: 5.0537 - val_top5_accuracy: 0.1302 - learning_rate: 0.0050\n",
            "Epoch 23/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0666 - auc: 0.7333 - f1_macro: 0.0104 - f1_weighted: 0.0250 - loss: 4.7543 - top5_accuracy: 0.1829 - val_accuracy: 0.0595 - val_auc: 0.7041 - val_f1_macro: 0.0071 - val_f1_weighted: 0.0173 - val_loss: 4.9585 - val_top5_accuracy: 0.1608 - learning_rate: 0.0050\n",
            "Epoch 24/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0659 - auc: 0.7356 - f1_macro: 0.0111 - f1_weighted: 0.0256 - loss: 4.7501 - top5_accuracy: 0.1754 - val_accuracy: 0.0312 - val_auc: 0.6587 - val_f1_macro: 0.0023 - val_f1_weighted: 0.0088 - val_loss: 5.3328 - val_top5_accuracy: 0.1219 - learning_rate: 0.0050\n",
            "Epoch 25/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0662 - auc: 0.7338 - f1_macro: 0.0116 - f1_weighted: 0.0262 - loss: 4.7449 - top5_accuracy: 0.1761 - val_accuracy: 0.0423 - val_auc: 0.6802 - val_f1_macro: 0.0054 - val_f1_weighted: 0.0113 - val_loss: 5.0744 - val_top5_accuracy: 0.1569 - learning_rate: 0.0050\n",
            "Epoch 26/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0669 - auc: 0.7402 - f1_macro: 0.0128 - f1_weighted: 0.0281 - loss: 4.7317 - top5_accuracy: 0.1807 - val_accuracy: 0.0345 - val_auc: 0.6307 - val_f1_macro: 0.0040 - val_f1_weighted: 0.0095 - val_loss: 5.4295 - val_top5_accuracy: 0.1119 - learning_rate: 0.0050\n",
            "Epoch 27/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0684 - auc: 0.7416 - f1_macro: 0.0142 - f1_weighted: 0.0290 - loss: 4.7293 - top5_accuracy: 0.1801 - val_accuracy: 0.0529 - val_auc: 0.6856 - val_f1_macro: 0.0053 - val_f1_weighted: 0.0175 - val_loss: 5.2799 - val_top5_accuracy: 0.1441 - learning_rate: 0.0050\n",
            "Epoch 28/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0677 - auc: 0.7403 - f1_macro: 0.0139 - f1_weighted: 0.0284 - loss: 4.7238 - top5_accuracy: 0.1854\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0676 - auc: 0.7403 - f1_macro: 0.0139 - f1_weighted: 0.0284 - loss: 4.7239 - top5_accuracy: 0.1853 - val_accuracy: 0.0451 - val_auc: 0.6867 - val_f1_macro: 0.0064 - val_f1_weighted: 0.0197 - val_loss: 5.1334 - val_top5_accuracy: 0.1380 - learning_rate: 0.0050\n",
            "Epoch 29/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0719 - auc: 0.7481 - f1_macro: 0.0163 - f1_weighted: 0.0312 - loss: 4.6935 - top5_accuracy: 0.1848 - val_accuracy: 0.0484 - val_auc: 0.6846 - val_f1_macro: 0.0064 - val_f1_weighted: 0.0177 - val_loss: 5.2817 - val_top5_accuracy: 0.1441 - learning_rate: 0.0025\n",
            "Epoch 30/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0700 - auc: 0.7477 - f1_macro: 0.0159 - f1_weighted: 0.0317 - loss: 4.6841 - top5_accuracy: 0.1880 - val_accuracy: 0.0395 - val_auc: 0.6526 - val_f1_macro: 0.0057 - val_f1_weighted: 0.0142 - val_loss: 5.8673 - val_top5_accuracy: 0.1169 - learning_rate: 0.0025\n",
            "Epoch 31/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0703 - auc: 0.7531 - f1_macro: 0.0164 - f1_weighted: 0.0324 - loss: 4.6596 - top5_accuracy: 0.1861 - val_accuracy: 0.0490 - val_auc: 0.6797 - val_f1_macro: 0.0062 - val_f1_weighted: 0.0167 - val_loss: 5.2512 - val_top5_accuracy: 0.1536 - learning_rate: 0.0025\n",
            "Epoch 32/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0718 - auc: 0.7550 - f1_macro: 0.0165 - f1_weighted: 0.0318 - loss: 4.6435 - top5_accuracy: 0.1945 - val_accuracy: 0.0506 - val_auc: 0.6792 - val_f1_macro: 0.0076 - val_f1_weighted: 0.0205 - val_loss: 5.3012 - val_top5_accuracy: 0.1530 - learning_rate: 0.0025\n",
            "Epoch 33/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0701 - auc: 0.7566 - f1_macro: 0.0172 - f1_weighted: 0.0315 - loss: 4.6295 - top5_accuracy: 0.2017\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0700 - auc: 0.7567 - f1_macro: 0.0172 - f1_weighted: 0.0315 - loss: 4.6295 - top5_accuracy: 0.2017 - val_accuracy: 0.0518 - val_auc: 0.6729 - val_f1_macro: 0.0040 - val_f1_weighted: 0.0167 - val_loss: 5.1866 - val_top5_accuracy: 0.1380 - learning_rate: 0.0025\n",
            "Epoch 34/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0750 - auc: 0.7590 - f1_macro: 0.0214 - f1_weighted: 0.0358 - loss: 4.6154 - top5_accuracy: 0.2043 - val_accuracy: 0.0573 - val_auc: 0.7020 - val_f1_macro: 0.0083 - val_f1_weighted: 0.0254 - val_loss: 5.0043 - val_top5_accuracy: 0.1636 - learning_rate: 0.0012\n",
            "Epoch 35/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0795 - auc: 0.7636 - f1_macro: 0.0272 - f1_weighted: 0.0424 - loss: 4.5849 - top5_accuracy: 0.2036 - val_accuracy: 0.0534 - val_auc: 0.6970 - val_f1_macro: 0.0074 - val_f1_weighted: 0.0239 - val_loss: 5.1150 - val_top5_accuracy: 0.1603 - learning_rate: 0.0012\n",
            "Epoch 36/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0808 - auc: 0.7683 - f1_macro: 0.0278 - f1_weighted: 0.0442 - loss: 4.5663 - top5_accuracy: 0.2050 - val_accuracy: 0.0595 - val_auc: 0.7012 - val_f1_macro: 0.0091 - val_f1_weighted: 0.0280 - val_loss: 5.1318 - val_top5_accuracy: 0.1669 - learning_rate: 0.0012\n",
            "Epoch 37/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0817 - auc: 0.7704 - f1_macro: 0.0298 - f1_weighted: 0.0457 - loss: 4.5493 - top5_accuracy: 0.2123 - val_accuracy: 0.0540 - val_auc: 0.6918 - val_f1_macro: 0.0107 - val_f1_weighted: 0.0278 - val_loss: 5.4916 - val_top5_accuracy: 0.1619 - learning_rate: 0.0012\n",
            "Epoch 38/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0838 - auc: 0.7738 - f1_macro: 0.0310 - f1_weighted: 0.0477 - loss: 4.5324 - top5_accuracy: 0.2154\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0838 - auc: 0.7738 - f1_macro: 0.0310 - f1_weighted: 0.0477 - loss: 4.5323 - top5_accuracy: 0.2154 - val_accuracy: 0.0562 - val_auc: 0.6972 - val_f1_macro: 0.0099 - val_f1_weighted: 0.0273 - val_loss: 5.3255 - val_top5_accuracy: 0.1675 - learning_rate: 0.0012\n",
            "Epoch 39/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0850 - auc: 0.7755 - f1_macro: 0.0327 - f1_weighted: 0.0496 - loss: 4.5111 - top5_accuracy: 0.2212 - val_accuracy: 0.0467 - val_auc: 0.6884 - val_f1_macro: 0.0102 - val_f1_weighted: 0.0272 - val_loss: 5.2029 - val_top5_accuracy: 0.1514 - learning_rate: 6.2500e-04\n",
            "Epoch 40/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0876 - auc: 0.7815 - f1_macro: 0.0356 - f1_weighted: 0.0522 - loss: 4.4893 - top5_accuracy: 0.2222 - val_accuracy: 0.0529 - val_auc: 0.6974 - val_f1_macro: 0.0112 - val_f1_weighted: 0.0285 - val_loss: 5.0695 - val_top5_accuracy: 0.1642 - learning_rate: 6.2500e-04\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step\n",
            "Finished 'grayscale'\n",
            "  Accuracy:      0.0529\n",
            "  F1 (macro):    0.0112\n",
            "  F1 (weighted): 0.0285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'garyscale'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-5e456b2f1661>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  F1 (macro):    {results['grayscale']['f1_macro']:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  F1 (weighted): {results['grayscale']['f1_weighted']:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Precision:     {results['garyscale']['precision']:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Recall:        {results['grayscale']['recall']:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'garyscale'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store in results\n",
        "results['grayscale'] = {\n",
        "    \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "    \"f1_macro\": f1_macro,\n",
        "    \"f1_weighted\": f1_weighted,\n",
        "    \"precision\": precision,\n",
        "    \"recall\": recall\n",
        "}\n",
        "\n",
        "print(f\"Finished '{'grayscale'}'\")\n",
        "print(f\"  Accuracy:      {results['grayscale']['accuracy']:.4f}\")\n",
        "print(f\"  F1 (macro):    {results['grayscale']['f1_macro']:.4f}\")\n",
        "print(f\"  F1 (weighted): {results['grayscale']['f1_weighted']:.4f}\")\n",
        "print(f\"  Precision:     {results['grayscale']['precision']:.4f}\")\n",
        "print(f\"  Recall:        {results['grayscale']['recall']:.4f}\")\n",
        "\n",
        "# Clear memory to avoid OOM\n",
        "del model\n",
        "del experiment\n",
        "K.clear_session()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "tdVoJStTWkF1",
        "outputId": "2b92735e-62c1-4bbd-9246-362c1db3aadf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished 'grayscale'\n",
            "  Accuracy:      0.0529\n",
            "  F1 (macro):    0.0112\n",
            "  F1 (weighted): 0.0285\n",
            "  Precision:     0.0249\n",
            "  Recall:        0.0529\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet Medium Augmentation - With Oversampling"
      ],
      "metadata": {
        "id": "iai7uSJwXBY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dense_layer(x, growth_rate):\n",
        "    \"\"\"Single layer inside a dense block.\"\"\"\n",
        "    out = BatchNormalization()(x)\n",
        "    out = ReLU()(out)\n",
        "    out = Conv2D(growth_rate, (3, 3), padding='same', kernel_regularizer=l2(1e-4))(out)\n",
        "    x = Concatenate()([x, out])  # Concatenate input and output (dense connection)\n",
        "    return x\n",
        "\n",
        "def dense_block(x, num_layers, growth_rate):\n",
        "    \"\"\"Dense block with several -dense layers.\"\"\"\n",
        "    for _ in range(num_layers):\n",
        "        x = dense_layer(x, growth_rate)\n",
        "    return x\n",
        "\n",
        "def transition_layer(x, reduction=0.5):\n",
        "    \"\"\"Reduces spatial size and number of filters.\"\"\"\n",
        "    filters = int(tf.keras.backend.int_shape(x)[-1] * reduction)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=l2(1e-4))(x)\n",
        "    x = AveragePooling2D((2, 2), strides=2)(x)\n",
        "    return x\n",
        "\n",
        "def build_densenet(input_shape=(224, 224, 3), num_classes=202, growth_rate=32):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Initial conv\n",
        "    x = Conv2D(64, (7, 7), strides=2, padding='same', kernel_regularizer=l2(1e-4))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = AveragePooling2D((3, 3), strides=2, padding='same')(x)\n",
        "\n",
        "    # Dense Block 1\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "    x = transition_layer(x)\n",
        "\n",
        "    # Dense Block 2\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "    x = transition_layer(x)\n",
        "\n",
        "    # Dense Block 3\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "    x = transition_layer(x)\n",
        "\n",
        "    # Dense Block 4\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "\n",
        "    # Classification\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "model = build_densenet()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "JjXUDvfdXEXz",
        "outputId": "5a2e39aa-48e4-4601-94e8-68f25d162a25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │      \u001b[38;5;34m9,472\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m18,464\u001b[0m │ re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m96\u001b[0m)               │            │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m27,680\u001b[0m │ re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m36,896\u001b[0m │ re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m160\u001b[0m)              │            │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m640\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m46,112\u001b[0m │ re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m192\u001b[0m)              │            │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m768\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m18,528\u001b[0m │ re_lu_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m27,680\u001b[0m │ re_lu_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_7 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m36,896\u001b[0m │ re_lu_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m160\u001b[0m)              │            │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m640\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_8 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m46,112\u001b[0m │ re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m192\u001b[0m)              │            │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m768\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_9 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m55,328\u001b[0m │ re_lu_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m224\u001b[0m)              │            │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m896\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m224\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_10 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m224\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m25,200\u001b[0m │ re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m448\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_11 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m32,288\u001b[0m │ re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m144\u001b[0m)              │            │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m576\u001b[0m │ concatenate_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m144\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_12 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m144\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m41,504\u001b[0m │ re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m176\u001b[0m)              │            │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m704\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m176\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_13 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m176\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m50,720\u001b[0m │ re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m208\u001b[0m)              │            │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m832\u001b[0m │ concatenate_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m208\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_14 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m208\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m59,936\u001b[0m │ re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m240\u001b[0m)              │            │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m960\u001b[0m │ concatenate_11[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m240\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_15 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m240\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m28,920\u001b[0m │ re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m120\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_3 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m120\u001b[0m) │        \u001b[38;5;34m480\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_16 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m34,592\u001b[0m │ re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m152\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m152\u001b[0m) │        \u001b[38;5;34m608\u001b[0m │ concatenate_12[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_17 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m152\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m43,808\u001b[0m │ re_lu_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m184\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ concatenate_12[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m184\u001b[0m) │        \u001b[38;5;34m736\u001b[0m │ concatenate_13[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_18 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m184\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m53,024\u001b[0m │ re_lu_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m216\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ concatenate_13[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m216\u001b[0m) │        \u001b[38;5;34m864\u001b[0m │ concatenate_14[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_19 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m216\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m62,240\u001b[0m │ re_lu_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m248\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ concatenate_14[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m248\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_15[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m202\u001b[0m)       │     \u001b[38;5;34m50,298\u001b[0m │ global_average_p… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,472</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │ re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,680</span> │ re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,896</span> │ re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">46,112</span> │ re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,528</span> │ re_lu_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,680</span> │ re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,896</span> │ re_lu_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">46,112</span> │ re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">55,328</span> │ re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │            │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">25,200</span> │ re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,288</span> │ re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              │            │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,504</span> │ re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>)              │            │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">50,720</span> │ re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)              │            │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │ concatenate_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">59,936</span> │ re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)              │            │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> │ concatenate_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">28,920</span> │ re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_3 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">34,592</span> │ re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> │ concatenate_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">43,808</span> │ re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">736</span> │ concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">53,024</span> │ re_lu_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span> │ concatenate_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">62,240</span> │ re_lu_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">248</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">248</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">50,298</span> │ global_average_p… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m817,922\u001b[0m (3.12 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">817,922</span> (3.12 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m811,810\u001b[0m (3.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">811,810</span> (3.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6,112\u001b[0m (23.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,112</span> (23.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the preprocessor\n",
        "batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "image_size = (224, 224)\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "print(f\"\\nTraining with augmentation: medium\")\n",
        "\n",
        "model = build_densenet()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment='medium', oversampling=True, shuffle=True)\n",
        "train_ds_sampled, class_names = preprocess.load_img(data_dir=\"data/rare_species/train_sampled\", minority_class=minority_class, augment='medium', oversampling=True, shuffle=True)\n",
        "val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "test_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/test\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "# Initialize the experiment\n",
        "experiment = Experiment(\n",
        "    model=model,\n",
        "    train_ds=train_ds_sampled,\n",
        "    val_ds=val_ds,\n",
        "    experiment_name=f\"densenet_with_medium_oversampling_2\", # MUDAR NOME!!!!!!!!!!!!\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    save_model = False\n",
        ")\n",
        "\n",
        "# Run the experiment\n",
        "history = experiment.run_experiment(callbacks=callbacks, epochs=40)\n",
        "\n",
        "# Predict entire validation set at once\n",
        "preds = model.predict(val_ds)\n",
        "y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "# Extract true labels in order\n",
        "y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "# Compute metrics\n",
        "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# Store in results\n",
        "results['medium'] = {\n",
        "    \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "    \"f1_macro\": f1_macro,\n",
        "    \"f1_weighted\": f1_weighted,\n",
        "    \"precision\": precision,\n",
        "    \"recall\": recall\n",
        "}\n",
        "\n",
        "print(f\"Finished '{'medium'}'\")\n",
        "print(f\"  Accuracy:      {results['medium']['accuracy']:.4f}\")\n",
        "print(f\"  F1 (macro):    {results['medium']['f1_macro']:.4f}\")\n",
        "print(f\"  F1 (weighted): {results['medium']['f1_weighted']:.4f}\")\n",
        "print(f\"  Precision:     {results['medium']['precision']:.4f}\")\n",
        "print(f\"  Recall:        {results['medium']['recall']:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9uS1-SFqXJr-",
        "outputId": "c645ff10-1c8d-492e-b65a-56fd525f3870",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: medium\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 4194 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Found 749 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 182ms/step - accuracy: 0.0311 - auc: 0.6101 - f1_macro: 0.0075 - f1_weighted: 0.0166 - loss: 8.4322 - top5_accuracy: 0.1012 - val_accuracy: 0.0250 - val_auc: 0.6342 - val_f1_macro: 4.5263e-04 - val_f1_weighted: 0.0019 - val_loss: 6.3260 - val_top5_accuracy: 0.1180 - learning_rate: 0.0100\n",
            "Epoch 2/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0211 - auc: 0.6098 - f1_macro: 0.0015 - f1_weighted: 0.0043 - loss: 5.6566 - top5_accuracy: 0.0832 - val_accuracy: 0.0312 - val_auc: 0.6271 - val_f1_macro: 0.0016 - val_f1_weighted: 0.0066 - val_loss: 5.6758 - val_top5_accuracy: 0.1263 - learning_rate: 0.0100\n",
            "Epoch 3/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0254 - auc: 0.6192 - f1_macro: 0.0029 - f1_weighted: 0.0085 - loss: 5.4892 - top5_accuracy: 0.1003 - val_accuracy: 0.0250 - val_auc: 0.5828 - val_f1_macro: 0.0022 - val_f1_weighted: 0.0085 - val_loss: 5.7223 - val_top5_accuracy: 0.0684 - learning_rate: 0.0100\n",
            "Epoch 4/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0303 - auc: 0.6473 - f1_macro: 0.0035 - f1_weighted: 0.0089 - loss: 5.2918 - top5_accuracy: 0.1203 - val_accuracy: 0.0339 - val_auc: 0.6562 - val_f1_macro: 0.0010 - val_f1_weighted: 0.0044 - val_loss: 5.2153 - val_top5_accuracy: 0.1258 - learning_rate: 0.0100\n",
            "Epoch 5/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0366 - auc: 0.6571 - f1_macro: 0.0052 - f1_weighted: 0.0129 - loss: 5.2122 - top5_accuracy: 0.1330 - val_accuracy: 0.0384 - val_auc: 0.6479 - val_f1_macro: 0.0024 - val_f1_weighted: 0.0104 - val_loss: 5.2158 - val_top5_accuracy: 0.1475 - learning_rate: 0.0100\n",
            "Epoch 6/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0439 - auc: 0.6709 - f1_macro: 0.0056 - f1_weighted: 0.0152 - loss: 5.1245 - top5_accuracy: 0.1298 - val_accuracy: 0.0423 - val_auc: 0.6597 - val_f1_macro: 0.0035 - val_f1_weighted: 0.0152 - val_loss: 5.5254 - val_top5_accuracy: 0.1419 - learning_rate: 0.0100\n",
            "Epoch 7/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0388 - auc: 0.6827 - f1_macro: 0.0049 - f1_weighted: 0.0127 - loss: 5.0804 - top5_accuracy: 0.1365 - val_accuracy: 0.0167 - val_auc: 0.5449 - val_f1_macro: 0.0020 - val_f1_weighted: 0.0067 - val_loss: 13.9278 - val_top5_accuracy: 0.0640 - learning_rate: 0.0100\n",
            "Epoch 8/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0426 - auc: 0.6905 - f1_macro: 0.0061 - f1_weighted: 0.0144 - loss: 5.0367 - top5_accuracy: 0.1404 - val_accuracy: 0.0145 - val_auc: 0.5856 - val_f1_macro: 0.0015 - val_f1_weighted: 0.0052 - val_loss: 6.7554 - val_top5_accuracy: 0.0556 - learning_rate: 0.0100\n",
            "Epoch 9/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.0432 - auc: 0.6962 - f1_macro: 0.0050 - f1_weighted: 0.0135 - loss: 4.9996 - top5_accuracy: 0.1440\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0432 - auc: 0.6962 - f1_macro: 0.0050 - f1_weighted: 0.0135 - loss: 4.9994 - top5_accuracy: 0.1440 - val_accuracy: 0.0178 - val_auc: 0.5547 - val_f1_macro: 0.0048 - val_f1_weighted: 0.0150 - val_loss: 8.9745 - val_top5_accuracy: 0.0612 - learning_rate: 0.0100\n",
            "Epoch 10/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0476 - auc: 0.7131 - f1_macro: 0.0062 - f1_weighted: 0.0152 - loss: 4.9228 - top5_accuracy: 0.1470 - val_accuracy: 0.0490 - val_auc: 0.6651 - val_f1_macro: 0.0060 - val_f1_weighted: 0.0208 - val_loss: 5.1812 - val_top5_accuracy: 0.1608 - learning_rate: 0.0050\n",
            "Epoch 11/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0548 - auc: 0.7162 - f1_macro: 0.0084 - f1_weighted: 0.0195 - loss: 4.8769 - top5_accuracy: 0.1561 - val_accuracy: 0.0712 - val_auc: 0.6824 - val_f1_macro: 0.0066 - val_f1_weighted: 0.0244 - val_loss: 5.0503 - val_top5_accuracy: 0.1608 - learning_rate: 0.0050\n",
            "Epoch 12/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0573 - auc: 0.7294 - f1_macro: 0.0089 - f1_weighted: 0.0200 - loss: 4.8290 - top5_accuracy: 0.1562 - val_accuracy: 0.0696 - val_auc: 0.6652 - val_f1_macro: 0.0089 - val_f1_weighted: 0.0308 - val_loss: 5.1409 - val_top5_accuracy: 0.1658 - learning_rate: 0.0050\n",
            "Epoch 13/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0573 - auc: 0.7311 - f1_macro: 0.0097 - f1_weighted: 0.0214 - loss: 4.8114 - top5_accuracy: 0.1618 - val_accuracy: 0.0245 - val_auc: 0.5885 - val_f1_macro: 0.0029 - val_f1_weighted: 0.0095 - val_loss: 8.0931 - val_top5_accuracy: 0.0846 - learning_rate: 0.0050\n",
            "Epoch 14/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0590 - auc: 0.7381 - f1_macro: 0.0093 - f1_weighted: 0.0211 - loss: 4.7934 - top5_accuracy: 0.1682 - val_accuracy: 0.0401 - val_auc: 0.6227 - val_f1_macro: 0.0045 - val_f1_weighted: 0.0152 - val_loss: 5.4768 - val_top5_accuracy: 0.1224 - learning_rate: 0.0050\n",
            "Epoch 15/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0606 - auc: 0.7398 - f1_macro: 0.0101 - f1_weighted: 0.0236 - loss: 4.7826 - top5_accuracy: 0.1666 - val_accuracy: 0.0351 - val_auc: 0.6116 - val_f1_macro: 0.0034 - val_f1_weighted: 0.0135 - val_loss: 5.6377 - val_top5_accuracy: 0.0974 - learning_rate: 0.0050\n",
            "Epoch 16/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.0569 - auc: 0.7442 - f1_macro: 0.0101 - f1_weighted: 0.0226 - loss: 4.7634 - top5_accuracy: 0.1654\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0569 - auc: 0.7442 - f1_macro: 0.0101 - f1_weighted: 0.0226 - loss: 4.7633 - top5_accuracy: 0.1654 - val_accuracy: 0.0412 - val_auc: 0.6163 - val_f1_macro: 0.0068 - val_f1_weighted: 0.0205 - val_loss: 5.6010 - val_top5_accuracy: 0.1063 - learning_rate: 0.0050\n",
            "Epoch 17/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0698 - auc: 0.7567 - f1_macro: 0.0123 - f1_weighted: 0.0281 - loss: 4.6994 - top5_accuracy: 0.1921 - val_accuracy: 0.0390 - val_auc: 0.6295 - val_f1_macro: 0.0042 - val_f1_weighted: 0.0167 - val_loss: 5.4584 - val_top5_accuracy: 0.1080 - learning_rate: 0.0025\n",
            "Epoch 18/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0669 - auc: 0.7680 - f1_macro: 0.0154 - f1_weighted: 0.0296 - loss: 4.6484 - top5_accuracy: 0.2001 - val_accuracy: 0.0423 - val_auc: 0.6221 - val_f1_macro: 0.0064 - val_f1_weighted: 0.0185 - val_loss: 5.5113 - val_top5_accuracy: 0.1152 - learning_rate: 0.0025\n",
            "Epoch 19/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0714 - auc: 0.7756 - f1_macro: 0.0191 - f1_weighted: 0.0342 - loss: 4.6081 - top5_accuracy: 0.2051 - val_accuracy: 0.0351 - val_auc: 0.6150 - val_f1_macro: 0.0067 - val_f1_weighted: 0.0189 - val_loss: 5.7050 - val_top5_accuracy: 0.1080 - learning_rate: 0.0025\n",
            "Epoch 20/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0739 - auc: 0.7825 - f1_macro: 0.0240 - f1_weighted: 0.0393 - loss: 4.5641 - top5_accuracy: 0.2095 - val_accuracy: 0.0317 - val_auc: 0.6084 - val_f1_macro: 0.0054 - val_f1_weighted: 0.0173 - val_loss: 5.8578 - val_top5_accuracy: 0.1185 - learning_rate: 0.0025\n",
            "Epoch 21/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.0760 - auc: 0.7886 - f1_macro: 0.0262 - f1_weighted: 0.0421 - loss: 4.5385 - top5_accuracy: 0.2131\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0760 - auc: 0.7886 - f1_macro: 0.0262 - f1_weighted: 0.0421 - loss: 4.5384 - top5_accuracy: 0.2132 - val_accuracy: 0.0362 - val_auc: 0.6497 - val_f1_macro: 0.0080 - val_f1_weighted: 0.0185 - val_loss: 5.8269 - val_top5_accuracy: 0.1074 - learning_rate: 0.0025\n",
            "Epoch 22/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0754 - auc: 0.7912 - f1_macro: 0.0237 - f1_weighted: 0.0392 - loss: 4.5168 - top5_accuracy: 0.2261 - val_accuracy: 0.0512 - val_auc: 0.7063 - val_f1_macro: 0.0135 - val_f1_weighted: 0.0280 - val_loss: 5.1329 - val_top5_accuracy: 0.1647 - learning_rate: 0.0012\n",
            "Epoch 23/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0828 - auc: 0.8025 - f1_macro: 0.0327 - f1_weighted: 0.0491 - loss: 4.4574 - top5_accuracy: 0.2347 - val_accuracy: 0.0623 - val_auc: 0.7170 - val_f1_macro: 0.0182 - val_f1_weighted: 0.0352 - val_loss: 5.0533 - val_top5_accuracy: 0.1692 - learning_rate: 0.0012\n",
            "Epoch 24/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0828 - auc: 0.8093 - f1_macro: 0.0338 - f1_weighted: 0.0496 - loss: 4.4045 - top5_accuracy: 0.2452 - val_accuracy: 0.0646 - val_auc: 0.7180 - val_f1_macro: 0.0190 - val_f1_weighted: 0.0370 - val_loss: 5.0456 - val_top5_accuracy: 0.1636 - learning_rate: 0.0012\n",
            "Epoch 25/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0846 - auc: 0.8155 - f1_macro: 0.0375 - f1_weighted: 0.0538 - loss: 4.3628 - top5_accuracy: 0.2588 - val_accuracy: 0.0607 - val_auc: 0.7200 - val_f1_macro: 0.0174 - val_f1_weighted: 0.0380 - val_loss: 5.0579 - val_top5_accuracy: 0.1608 - learning_rate: 0.0012\n",
            "Epoch 26/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0912 - auc: 0.8198 - f1_macro: 0.0446 - f1_weighted: 0.0611 - loss: 4.3249 - top5_accuracy: 0.2681 - val_accuracy: 0.0545 - val_auc: 0.7158 - val_f1_macro: 0.0212 - val_f1_weighted: 0.0371 - val_loss: 5.1303 - val_top5_accuracy: 0.1603 - learning_rate: 0.0012\n",
            "Epoch 27/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.0957 - auc: 0.8250 - f1_macro: 0.0514 - f1_weighted: 0.0672 - loss: 4.2853 - top5_accuracy: 0.2741 - val_accuracy: 0.0584 - val_auc: 0.7179 - val_f1_macro: 0.0192 - val_f1_weighted: 0.0361 - val_loss: 5.0655 - val_top5_accuracy: 0.1625 - learning_rate: 0.0012\n",
            "Epoch 28/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0999 - auc: 0.8285 - f1_macro: 0.0556 - f1_weighted: 0.0717 - loss: 4.2484 - top5_accuracy: 0.2778 - val_accuracy: 0.0556 - val_auc: 0.7177 - val_f1_macro: 0.0191 - val_f1_weighted: 0.0356 - val_loss: 5.1171 - val_top5_accuracy: 0.1636 - learning_rate: 0.0012\n",
            "Epoch 29/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1033 - auc: 0.8327 - f1_macro: 0.0603 - f1_weighted: 0.0765 - loss: 4.2127 - top5_accuracy: 0.2865\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.1034 - auc: 0.8327 - f1_macro: 0.0603 - f1_weighted: 0.0765 - loss: 4.2126 - top5_accuracy: 0.2865 - val_accuracy: 0.0529 - val_auc: 0.7056 - val_f1_macro: 0.0206 - val_f1_weighted: 0.0358 - val_loss: 5.2159 - val_top5_accuracy: 0.1558 - learning_rate: 0.0012\n",
            "Epoch 30/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.1062 - auc: 0.8411 - f1_macro: 0.0621 - f1_weighted: 0.0794 - loss: 4.1727 - top5_accuracy: 0.3024 - val_accuracy: 0.0684 - val_auc: 0.7291 - val_f1_macro: 0.0276 - val_f1_weighted: 0.0461 - val_loss: 5.0527 - val_top5_accuracy: 0.1820 - learning_rate: 6.2500e-04\n",
            "Epoch 31/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.1211 - auc: 0.8455 - f1_macro: 0.0780 - f1_weighted: 0.0948 - loss: 4.1217 - top5_accuracy: 0.3182 - val_accuracy: 0.0729 - val_auc: 0.7311 - val_f1_macro: 0.0336 - val_f1_weighted: 0.0520 - val_loss: 5.0788 - val_top5_accuracy: 0.1998 - learning_rate: 6.2500e-04\n",
            "Epoch 32/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.1230 - auc: 0.8495 - f1_macro: 0.0819 - f1_weighted: 0.0976 - loss: 4.0813 - top5_accuracy: 0.3257 - val_accuracy: 0.0851 - val_auc: 0.7300 - val_f1_macro: 0.0387 - val_f1_weighted: 0.0589 - val_loss: 5.1120 - val_top5_accuracy: 0.2003 - learning_rate: 6.2500e-04\n",
            "Epoch 33/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.1334 - auc: 0.8534 - f1_macro: 0.0929 - f1_weighted: 0.1079 - loss: 4.0433 - top5_accuracy: 0.3369 - val_accuracy: 0.0812 - val_auc: 0.7309 - val_f1_macro: 0.0358 - val_f1_weighted: 0.0548 - val_loss: 5.1438 - val_top5_accuracy: 0.1970 - learning_rate: 6.2500e-04\n",
            "Epoch 34/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1373 - auc: 0.8581 - f1_macro: 0.0995 - f1_weighted: 0.1145 - loss: 4.0055 - top5_accuracy: 0.3453\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.1373 - auc: 0.8581 - f1_macro: 0.0996 - f1_weighted: 0.1145 - loss: 4.0054 - top5_accuracy: 0.3453 - val_accuracy: 0.0818 - val_auc: 0.7273 - val_f1_macro: 0.0365 - val_f1_weighted: 0.0570 - val_loss: 5.1783 - val_top5_accuracy: 0.1998 - learning_rate: 6.2500e-04\n",
            "Epoch 35/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.1425 - auc: 0.8615 - f1_macro: 0.1054 - f1_weighted: 0.1192 - loss: 3.9797 - top5_accuracy: 0.3536 - val_accuracy: 0.0885 - val_auc: 0.7393 - val_f1_macro: 0.0385 - val_f1_weighted: 0.0620 - val_loss: 5.1423 - val_top5_accuracy: 0.2326 - learning_rate: 3.1250e-04\n",
            "Epoch 36/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.1524 - auc: 0.8646 - f1_macro: 0.1163 - f1_weighted: 0.1303 - loss: 3.9354 - top5_accuracy: 0.3637 - val_accuracy: 0.0874 - val_auc: 0.7386 - val_f1_macro: 0.0386 - val_f1_weighted: 0.0615 - val_loss: 5.2133 - val_top5_accuracy: 0.2321 - learning_rate: 3.1250e-04\n",
            "Epoch 37/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.1601 - auc: 0.8678 - f1_macro: 0.1267 - f1_weighted: 0.1393 - loss: 3.9026 - top5_accuracy: 0.3714 - val_accuracy: 0.0890 - val_auc: 0.7412 - val_f1_macro: 0.0405 - val_f1_weighted: 0.0631 - val_loss: 5.1841 - val_top5_accuracy: 0.2337 - learning_rate: 3.1250e-04\n",
            "Epoch 38/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.1655 - auc: 0.8708 - f1_macro: 0.1316 - f1_weighted: 0.1453 - loss: 3.8745 - top5_accuracy: 0.3805 - val_accuracy: 0.0946 - val_auc: 0.7408 - val_f1_macro: 0.0438 - val_f1_weighted: 0.0674 - val_loss: 5.1768 - val_top5_accuracy: 0.2365 - learning_rate: 3.1250e-04\n",
            "Epoch 39/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1700 - auc: 0.8732 - f1_macro: 0.1374 - f1_weighted: 0.1503 - loss: 3.8475 - top5_accuracy: 0.3876\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.1700 - auc: 0.8732 - f1_macro: 0.1374 - f1_weighted: 0.1503 - loss: 3.8474 - top5_accuracy: 0.3876 - val_accuracy: 0.0935 - val_auc: 0.7406 - val_f1_macro: 0.0441 - val_f1_weighted: 0.0683 - val_loss: 5.2177 - val_top5_accuracy: 0.2354 - learning_rate: 3.1250e-04\n",
            "Epoch 40/40\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.1754 - auc: 0.8756 - f1_macro: 0.1444 - f1_weighted: 0.1557 - loss: 3.8309 - top5_accuracy: 0.3921 - val_accuracy: 0.0957 - val_auc: 0.7423 - val_f1_macro: 0.0479 - val_f1_weighted: 0.0695 - val_loss: 5.2203 - val_top5_accuracy: 0.2371 - learning_rate: 1.5625e-04\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step\n",
            "Finished 'medium'\n",
            "  Accuracy:      0.0957\n",
            "  F1 (macro):    0.0479\n",
            "  F1 (weighted): 0.0695\n",
            "  Precision:     0.0687\n",
            "  Recall:        0.0957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# Display the table\n",
        "display(results_df.round(4))"
      ],
      "metadata": {
        "id": "TS3MRTMvXfnZ",
        "outputId": "88873c5a-a6e7-425a-a283-8a5109503264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  augmentation  accuracy  f1_macro  f1_weighted  precision  recall\n",
              "0       medium    0.0957    0.0479       0.0695     0.0687  0.0957"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90e9ecc9-aca8-44df-a133-15eab0704d27\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>augmentation</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>f1_weighted</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>medium</td>\n",
              "      <td>0.0957</td>\n",
              "      <td>0.0479</td>\n",
              "      <td>0.0695</td>\n",
              "      <td>0.0687</td>\n",
              "      <td>0.0957</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90e9ecc9-aca8-44df-a133-15eab0704d27')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-90e9ecc9-aca8-44df-a133-15eab0704d27 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-90e9ecc9-aca8-44df-a133-15eab0704d27');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(results_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"augmentation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"medium\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0957,\n        \"max\": 0.0957,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0957\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0479,\n        \"max\": 0.0479,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0479\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_weighted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0695,\n        \"max\": 0.0695,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0695\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0687,\n        \"max\": 0.0687,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0687\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0957,\n        \"max\": 0.0957,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0957\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AoWaQSjNeBIp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}