{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgalao/deep-learning-project/blob/main/project/DL_Models_from_scratch_carolina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3bjYHBh_0P7"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "# **1.** Environment Setup\n",
        "\n",
        "<div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4eVeTgT_0P8"
      },
      "source": [
        "## 1.1 Connect Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "Yxqw_U7bDfHp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "inRBOfwJCH__",
        "outputId": "b9958619-a83f-4fcf-9771-5d4813573e17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8eNKnktQ_0P8",
        "outputId": "e5035137-37f8-4aa3-e664-86ee9dd116dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DKPRL-y9_0P8",
        "outputId": "e1b46ce4-8c6f-4ebb-a486-2d39b41d2720",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changed directory to: /content/drive/MyDrive/FACULDADE/mestrado\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# # Change to the directory where project is located\n",
        "# os.chdir('/content/drive/MyDrive/College/MSc/2nd Semester/Deep Learning/project')\n",
        "\n",
        "# Change to the directory where project is located\n",
        "os.chdir('/content/drive/MyDrive/FACULDADE/mestrado/')\n",
        "\n",
        "# # Verify that we changed the directory\n",
        "print(\"Changed directory to:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkAMUAzd_0P9"
      },
      "source": [
        "## 1.2 Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras_cv"
      ],
      "metadata": {
        "id": "UBenYuNIAH9P",
        "outputId": "41952d64-b371-432a-ac77-6e55238e7b9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_cv\n",
            "  Downloading keras_cv-0.9.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras_cv) (24.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras_cv) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from keras_cv) (2024.11.6)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (from keras_cv) (4.9.8)\n",
            "Collecting keras-core (from keras_cv)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from keras_cv) (0.3.11)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras_cv) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras_cv) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras_cv) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras-core->keras_cv) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras-core->keras_cv) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras-core->keras_cv) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras-core->keras_cv) (3.13.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from keras-core->keras_cv) (0.1.9)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (0.7.1)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (1.12.2)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (4.2.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (5.29.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (18.1.0)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (1.17.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (3.0.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (0.10.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras_cv) (1.17.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (0.8.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (6.5.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (4.13.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_cv) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_cv) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_cv) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_cv) (2025.1.31)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->keras-core->keras_cv) (25.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from promise->tensorflow-datasets->keras_cv) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-core->keras_cv) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-core->keras_cv) (2.18.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple_parsing->tensorflow-datasets->keras_cv) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras_cv) (1.70.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras_cv) (0.1.2)\n",
            "Downloading keras_cv-0.9.0-py3-none-any.whl (650 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m650.7/650.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras-core, keras_cv\n",
            "Successfully installed keras-core-0.1.7 keras_cv-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "agKI1Ihd_0P9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "from classes import *\n",
        "from functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "f83iix03_0P9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Dropout, Input, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from keras.metrics import AUC, F1Score, CategoricalAccuracy, TopKCategoricalAccuracy\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from keras import optimizers\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D,\n",
        "                                     Dense, Dropout, Concatenate, BatchNormalization)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import tensorflow.keras.backend as K\n",
        "import gc\n",
        "from tensorflow.keras.layers import ReLU\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYIGXzBp_0P9"
      },
      "source": [
        "## 1.3 Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7_AQhPw1_0P-"
      },
      "outputs": [],
      "source": [
        "# #Load the DataFrames from the .pkl files\n",
        "# with open(\"../data/train_df.pkl\", \"rb\") as f:\n",
        "#      train_df = pickle.load(f)\n",
        "\n",
        "# with open(\"../data/val_df.pkl\", \"rb\") as f:\n",
        "#      val_df = pickle.load(f)\n",
        "\n",
        "# with open(\"../data/test_df.pkl\", \"rb\") as f:\n",
        "#      test_df = pickle.load(f)\n",
        "\n",
        "# with open(\"../data/train_df_sampled.pkl\", \"rb\") as f:\n",
        "#      train_df_sampled = pickle.load(f)\n",
        "\n",
        "# with open(\"../data/family_encoder.pkl\", \"rb\") as f:\n",
        "#      family_encoder = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR COLLAB\n",
        "# Load the DataFrames from the .pkl files\n",
        "with open(\"data/train_df.pkl\", \"rb\") as f:\n",
        "     train_df = pickle.load(f)\n",
        "\n",
        "with open(\"data/val_df.pkl\", \"rb\") as f:\n",
        "     val_df = pickle.load(f)\n",
        "\n",
        "with open(\"data/test_df.pkl\", \"rb\") as f:\n",
        "     test_df = pickle.load(f)\n",
        "\n",
        "with open(\"data/train_df_sampled.pkl\", \"rb\") as f:\n",
        "     train_df_sampled = pickle.load(f)\n",
        "\n",
        "with open(\"data/family_encoder.pkl\", \"rb\") as f:\n",
        "     family_encoder = pickle.load(f)"
      ],
      "metadata": {
        "id": "HIZBjHq-A4oZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZODkTZPw_0P-"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "# **2.** Preprocessing\n",
        "\n",
        "<div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddZt7EeY_0P-"
      },
      "source": [
        "- Normalizes pixel values (e.g., rescaling from [0,255] to [0,1]).\n",
        "- Resizes images to a fixed size (e.g., 224x224 pixels).\n",
        "- Applies augmentation (only during training).\n",
        "- Converts images to batches (e.g., batch_size=32 loads 32 images at a time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Z81TS63u_0P-"
      },
      "outputs": [],
      "source": [
        "minority_class = train_df['family'].value_counts()[train_df['family'].value_counts() < 25].index\n",
        "minority_class=minority_class.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XymCw7-D_0P-"
      },
      "outputs": [],
      "source": [
        "# batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "# image_size = (224, 224)\n",
        "\n",
        "# preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment='mixup', oversampling=True, shuffle=True)\n",
        "# train_ds_sampled, class_names = preprocess.load_img(data_dir=\"data/rare_species/train_sampled\", minority_class=minority_class, augment='medium', oversampling=True, shuffle=True)\n",
        "# val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "# test_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/test\", minority_class=minority_class, augment=None, oversampling=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aSj2ljMl_0P-"
      },
      "outputs": [],
      "source": [
        "# num_images = 32 ##\n",
        "# rows, cols = 8, 4 ##\n",
        "\n",
        "# plot_batch(train_ds, class_names=class_names, num_images=num_images, rows=rows, cols=cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqN0S9Vx_0P-"
      },
      "source": [
        "## (augmentations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "twyFsEKG_0P_"
      },
      "outputs": [],
      "source": [
        "# augmentations_to_test = [\n",
        "#     # \"none\",\n",
        "#     # \"light\",\n",
        "#     # \"medium\",\n",
        "#     # \"heavy\",\n",
        "#     # \"grayscale\",\n",
        "#     # \"randaugment\",\n",
        "#     \"mixup\",\n",
        "#     \"cutmix\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrMH2Fd4_0P_"
      },
      "source": [
        "<!-- ##### Simple model do test augmentations -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PVH2ESr8_0P_"
      },
      "outputs": [],
      "source": [
        "# def build_model(num_classes):\n",
        "#     base = keras.applications.EfficientNetB0(\n",
        "#         input_shape=(224, 224, 3),\n",
        "#         include_top=False,\n",
        "#         weights=\"imagenet\",\n",
        "#         pooling=\"avg\"\n",
        "#     )\n",
        "#     base.trainable = False  # You can fine-tune later\n",
        "\n",
        "#     inputs = keras.Input(shape=(224, 224, 3))\n",
        "#     x = base(inputs, training=False)\n",
        "#     x = keras.layers.Dropout(0.2)(x)\n",
        "#     outputs = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "#     return keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_rzVdlX-_0P_"
      },
      "outputs": [],
      "source": [
        "# def sample_dataset(dataset, fraction=None, num_batches=None, seed=42):\n",
        "#     \"\"\"Return a sampled subset of the dataset.\"\"\"\n",
        "#     if fraction:\n",
        "#         dataset = dataset.shuffle(1000, seed=seed)\n",
        "#         dataset = dataset.take(int(fraction * tf.data.experimental.cardinality(dataset).numpy()))\n",
        "#     elif num_batches:\n",
        "#         dataset = dataset.take(num_batches)\n",
        "#     return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o84WT0Dp_0P_"
      },
      "source": [
        "<!-- ##### Loop -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RW-Wj9Ek_0P_"
      },
      "outputs": [],
      "source": [
        "# # Initialize the preprocessor\n",
        "# pre = Preprocessor(image_size=(224, 224), batch_size=32)\n",
        "\n",
        "# # Store results\n",
        "# results = {}\n",
        "\n",
        "# # Loop through each augmentation\n",
        "# for aug in augmentations_to_test:\n",
        "#     print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "#     # Load datasets\n",
        "#     train_ds, class_names = pre.load_img(\n",
        "#         data_dir=\"../data/rare_species/train\",\n",
        "#         augment=aug\n",
        "#     )\n",
        "\n",
        "#     val_ds, _ = pre.load_img(\n",
        "#         data_dir=\"../data/rare_species/val\",\n",
        "#         augment=None\n",
        "#     )\n",
        "\n",
        "#     # Sample a subset of training data\n",
        "#     train_ds = sample_dataset(train_ds, fraction=0.5)\n",
        "\n",
        "#     # Build a fresh model (you should define this function)\n",
        "#     model = build_sequential_model(list_of_layers=layers)\n",
        "\n",
        "#     # Compile\n",
        "#     model.compile(\n",
        "#         optimizer=\"adam\",\n",
        "#         loss=\"categorical_crossentropy\",\n",
        "#         metrics=[\"accuracy\"]\n",
        "#     )\n",
        "\n",
        "#     # Train\n",
        "#     history = model.fit(\n",
        "#         train_ds,\n",
        "#         validation_data=val_ds,\n",
        "#         epochs=5,\n",
        "#         verbose=1\n",
        "#     )\n",
        "\n",
        "#     # Predict entire validation set at once\n",
        "#     preds = model.predict(val_ds)\n",
        "#     y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "#     # Extract true labels in order\n",
        "#     y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "#     # Compute metrics\n",
        "#     f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "#     f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "#     precision = precision_score(y_true, y_pred, average='weighted')\n",
        "#     recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "#     # Store in results\n",
        "#     results[aug] = {\n",
        "#         \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "#         \"f1_macro\": f1_macro,\n",
        "#         \"f1_weighted\": f1_weighted,\n",
        "#         \"precision\": precision,\n",
        "#         \"recall\": recall\n",
        "#     }\n",
        "\n",
        "#     print(f\"Finished '{aug}'\")\n",
        "#     print(f\"  Accuracy:      {results[aug]['val_accuracy']:.4f}\")\n",
        "#     print(f\"  F1 (macro):    {results[aug]['f1_macro']:.4f}\")\n",
        "#     print(f\"  F1 (weighted): {results[aug]['f1_weighted']:.4f}\")\n",
        "#     print(f\"  Precision:     {results[aug]['precision']:.4f}\")\n",
        "#     print(f\"  Recall:        {results[aug]['recall']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZqLt45IX_0P_"
      },
      "outputs": [],
      "source": [
        "# augmentations_to_test = [\n",
        "#     \"none\",\n",
        "#     \"light\",\n",
        "#     \"medium\",\n",
        "#     \"heavy\",\n",
        "#     \"grayscale\",\n",
        "#     \"randaugment\",\n",
        "#     \"mixup\",\n",
        "#     \"cutmix\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "V8kfR66V_0P_"
      },
      "outputs": [],
      "source": [
        "# # Initialize the preprocessor\n",
        "# pre = Preprocessor(image_size=(224, 224), batch_size=32)\n",
        "\n",
        "# # Store results\n",
        "# results = {}\n",
        "\n",
        "# # Loop through each augmentation\n",
        "# for aug in augmentations_to_test:\n",
        "#     print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "#     # Load datasets\n",
        "#     train_ds, class_names = pre.load_img(\n",
        "#         data_dir=\"../data/rare_species/train\",\n",
        "#         augment=aug\n",
        "#     )\n",
        "\n",
        "#     val_ds, _ = pre.load_img(\n",
        "#         data_dir=\"../data/rare_species/val\",\n",
        "#         augment=None\n",
        "#     )\n",
        "\n",
        "#     # Sample a subset of training data\n",
        "#     train_ds = sample_dataset(train_ds, fraction=0.5)\n",
        "\n",
        "#     # Build a fresh model (you should define this function)\n",
        "#     model = build_sequential_model(list_of_layers=layers)\n",
        "\n",
        "#     # Compile\n",
        "#     model.compile(\n",
        "#         optimizer=\"adam\",\n",
        "#         loss=\"categorical_crossentropy\",\n",
        "#         metrics=[\"accuracy\"]\n",
        "#     )\n",
        "\n",
        "#     # Train\n",
        "#     history = model.fit(\n",
        "#         train_ds,\n",
        "#         validation_data=val_ds,\n",
        "#         epochs=15,\n",
        "#         verbose=1\n",
        "#     )\n",
        "\n",
        "#     # Predict entire validation set at once\n",
        "#     preds = model.predict(val_ds)\n",
        "#     y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "#     # Extract true labels in order\n",
        "#     y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "#     # Compute metrics\n",
        "#     f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "#     f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "#     precision = precision_score(y_true, y_pred, average='weighted')\n",
        "#     recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "#     # Store in results\n",
        "#     results[aug] = {\n",
        "#         \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "#         \"f1_macro\": f1_macro,\n",
        "#         \"f1_weighted\": f1_weighted,\n",
        "#         \"precision\": precision,\n",
        "#         \"recall\": recall\n",
        "#     }\n",
        "\n",
        "#     print(f\"Finished '{aug}'\")\n",
        "#     print(f\"  Accuracy:      {results[aug]['val_accuracy']:.4f}\")\n",
        "#     print(f\"  F1 (macro):    {results[aug]['f1_macro']:.4f}\")\n",
        "#     print(f\"  F1 (weighted): {results[aug]['f1_weighted']:.4f}\")\n",
        "#     print(f\"  Precision:     {results[aug]['precision']:.4f}\")\n",
        "#     print(f\"  Recall:        {results[aug]['recall']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1yrcIQb_0P_"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "# **3.** Parameters\n",
        "\n",
        "<div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3GDURq8Z_0P_"
      },
      "outputs": [],
      "source": [
        "# Add callbacks\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    )\n",
        "    ,EarlyStopping(patience=7, restore_best_weights=True, monitor=\"val_loss\", verbose=1)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AQPZikTL_0QA"
      },
      "outputs": [],
      "source": [
        "metrics = [\n",
        "    CategoricalAccuracy(name=\"accuracy\"),\n",
        "    AUC(name=\"auc\"),\n",
        "    F1Score(average=\"macro\", name=\"f1_macro\"),\n",
        "    F1Score(average=\"weighted\", name=\"f1_weighted\"),\n",
        "    TopKCategoricalAccuracy(k=5, name=\"top5_accuracy\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "S7H9evt8_0QA"
      },
      "outputs": [],
      "source": [
        "augmentations_to_test = [\n",
        "    \"none\",\n",
        "    \"light\",\n",
        "    \"mixup\",\n",
        "    \"medium\",\n",
        "    \"heavy\",\n",
        "    \"grayscale_plus\",\n",
        "    \"randaugment\",\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGIiWxn__0QA"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "# **4.** Models\n",
        "\n",
        "<div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1FL-tGd_0QA"
      },
      "source": [
        "## 4.2 AlexNet - No oversampling\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_alexnet(input_shape=(224, 224, 3), num_classes=202):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer 1\n",
        "    model.add(Conv2D(96, (11, 11), strides=4, activation='relu', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
        "\n",
        "    # Layer 2\n",
        "    model.add(Conv2D(256, (5, 5), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
        "\n",
        "    # Layer 3\n",
        "    model.add(Conv2D(384, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "    # Layer 4\n",
        "    model.add(Conv2D(384, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "    # Layer 5\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
        "\n",
        "    # Flatten and FC\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_alexnet()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "c-ay7_o1FbmW",
        "outputId": "2de09e04-25a2-42d3-89d9-b61a33b239b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │        \u001b[38;5;34m34,944\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │           \u001b[38;5;34m384\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m614,656\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │       \u001b[38;5;34m885,120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,327,488\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m884,992\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6400\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m26,218,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m16,781,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m202\u001b[0m)            │       \u001b[38;5;34m827,594\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">34,944</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">614,656</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">885,120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,327,488</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">884,992</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">26,218,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">827,594</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m47,576,010\u001b[0m (181.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,576,010</span> (181.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m47,575,306\u001b[0m (181.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,575,306</span> (181.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the preprocessor\n",
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Loop through each augmentation\n",
        "for aug in augmentations_to_test:\n",
        "    print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "    model = build_alexnet()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment='mixup', oversampling=False, shuffle=True)\n",
        "    val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "    # Initialize the experiment\n",
        "    experiment = Experiment(\n",
        "        model=model,\n",
        "        train_ds=train_ds,\n",
        "        val_ds=val_ds,\n",
        "        experiment_name=f\"alexnet_with_{aug}_no_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "        batch_size=32,\n",
        "        image_size=(224, 224),\n",
        "        save_model = False\n",
        "    )\n",
        "\n",
        "    # Run the experiment\n",
        "    history = experiment.run_experiment(callbacks=callbacks, epochs=30)\n",
        "\n",
        "    # Predict entire validation set at once\n",
        "    preds = model.predict(val_ds)\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Extract true labels in order\n",
        "    y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "    # Compute metrics\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Store in results\n",
        "    train_eval = model.evaluate(train_ds, verbose=0)\n",
        "    val_eval = model.evaluate(val_ds, verbose=0)\n",
        "\n",
        "    metric_names = [\"loss\", \"accuracy\", \"auc\", \"f1_macro\", \"f1_weighted\", \"top5_accuracy\"]\n",
        "\n",
        "    train_metrics = dict(zip(metric_names, train_eval))\n",
        "    val_metrics = dict(zip(metric_names, val_eval))\n",
        "\n",
        "    # Results\n",
        "    results[aug] = {\n",
        "        \"train_loss\": train_metrics[\"loss\"],\n",
        "        \"val_loss\": val_metrics[\"loss\"],\n",
        "\n",
        "        \"train_accuracy\": train_metrics[\"accuracy\"],\n",
        "        \"val_accuracy\": val_metrics[\"accuracy\"],\n",
        "\n",
        "        \"train_f1_macro\": train_metrics.get(\"f1_macro\"),\n",
        "        \"val_f1_macro\": val_metrics.get(\"f1_macro\"),\n",
        "\n",
        "        \"val_f1_weighted\": val_metrics.get(\"f1_weighted\")\n",
        "    }"
      ],
      "metadata": {
        "id": "HnaM4e1njKJp",
        "outputId": "f8110539-bcf9-41a9-abd6-556ba0b5b020",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: none\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 207ms/step - accuracy: 0.0243 - auc: 0.6244 - f1_macro: 0.0018 - f1_weighted: 0.0053 - loss: 5.5546 - top5_accuracy: 0.1011 - val_accuracy: 0.0239 - val_auc: 0.6652 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0437 - val_top5_accuracy: 0.1135 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0243 - auc: 0.6614 - f1_macro: 0.0011 - f1_weighted: 0.0049 - loss: 5.0596 - top5_accuracy: 0.1174 - val_accuracy: 0.0239 - val_auc: 0.6643 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0425 - val_top5_accuracy: 0.1157 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0236 - auc: 0.6608 - f1_macro: 8.8843e-04 - f1_weighted: 0.0043 - loss: 5.0590 - top5_accuracy: 0.1120 - val_accuracy: 0.0239 - val_auc: 0.6641 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0413 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0248 - auc: 0.6636 - f1_macro: 8.8695e-04 - f1_weighted: 0.0043 - loss: 5.0544 - top5_accuracy: 0.1097 - val_accuracy: 0.0239 - val_auc: 0.6635 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0391 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0249 - auc: 0.6613 - f1_macro: 8.9879e-04 - f1_weighted: 0.0043 - loss: 5.0511 - top5_accuracy: 0.1095 - val_accuracy: 0.0250 - val_auc: 0.6638 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0379 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0239 - auc: 0.6580 - f1_macro: 8.2943e-04 - f1_weighted: 0.0040 - loss: 5.0523 - top5_accuracy: 0.1101 - val_accuracy: 0.0239 - val_auc: 0.6644 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0367 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0242 - auc: 0.6590 - f1_macro: 8.0151e-04 - f1_weighted: 0.0039 - loss: 5.0493 - top5_accuracy: 0.1119 - val_accuracy: 0.0239 - val_auc: 0.6654 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0361 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0242 - auc: 0.6598 - f1_macro: 8.1289e-04 - f1_weighted: 0.0040 - loss: 5.0462 - top5_accuracy: 0.1151 - val_accuracy: 0.0239 - val_auc: 0.6640 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0355 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0262 - auc: 0.6606 - f1_macro: 9.6836e-04 - f1_weighted: 0.0047 - loss: 5.0467 - top5_accuracy: 0.1159 - val_accuracy: 0.0250 - val_auc: 0.6639 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0352 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0210 - auc: 0.6595 - f1_macro: 6.7630e-04 - f1_weighted: 0.0033 - loss: 5.0471 - top5_accuracy: 0.1098 - val_accuracy: 0.0239 - val_auc: 0.6630 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0351 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0224 - auc: 0.6600 - f1_macro: 6.0843e-04 - f1_weighted: 0.0030 - loss: 5.0466 - top5_accuracy: 0.1132 - val_accuracy: 0.0250 - val_auc: 0.6631 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0349 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0217 - auc: 0.6596 - f1_macro: 7.3924e-04 - f1_weighted: 0.0036 - loss: 5.0452 - top5_accuracy: 0.1146 - val_accuracy: 0.0250 - val_auc: 0.6631 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0348 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0205 - auc: 0.6594 - f1_macro: 5.8170e-04 - f1_weighted: 0.0029 - loss: 5.0477 - top5_accuracy: 0.1112 - val_accuracy: 0.0239 - val_auc: 0.6634 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0347 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0252 - auc: 0.6595 - f1_macro: 7.3545e-04 - f1_weighted: 0.0036 - loss: 5.0423 - top5_accuracy: 0.1101 - val_accuracy: 0.0250 - val_auc: 0.6634 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0346 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.0207 - auc: 0.6579 - f1_macro: 6.6517e-04 - f1_weighted: 0.0032 - loss: 5.0456 - top5_accuracy: 0.1134 - val_accuracy: 0.0239 - val_auc: 0.6630 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0346 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0211 - auc: 0.6592 - f1_macro: 5.9884e-04 - f1_weighted: 0.0029 - loss: 5.0449 - top5_accuracy: 0.1122 - val_accuracy: 0.0250 - val_auc: 0.6640 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0344 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0244 - auc: 0.6586 - f1_macro: 7.7783e-04 - f1_weighted: 0.0038 - loss: 5.0447 - top5_accuracy: 0.1130 - val_accuracy: 0.0250 - val_auc: 0.6641 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0344 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0208 - auc: 0.6580 - f1_macro: 7.2244e-04 - f1_weighted: 0.0035 - loss: 5.0445 - top5_accuracy: 0.1104 - val_accuracy: 0.0250 - val_auc: 0.6634 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0344 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0267 - auc: 0.6589 - f1_macro: 8.0905e-04 - f1_weighted: 0.0039 - loss: 5.0425 - top5_accuracy: 0.1119 - val_accuracy: 0.0250 - val_auc: 0.6634 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0342 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0232 - auc: 0.6584 - f1_macro: 7.1851e-04 - f1_weighted: 0.0035 - loss: 5.0442 - top5_accuracy: 0.1092 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0342 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0237 - auc: 0.6616 - f1_macro: 7.5716e-04 - f1_weighted: 0.0037 - loss: 5.0433 - top5_accuracy: 0.1129 - val_accuracy: 0.0250 - val_auc: 0.6634 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0341 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.0234 - auc: 0.6592 - f1_macro: 8.5423e-04 - f1_weighted: 0.0041 - loss: 5.0443 - top5_accuracy: 0.1088 - val_accuracy: 0.0250 - val_auc: 0.6634 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0342 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0213 - auc: 0.6590 - f1_macro: 7.2142e-04 - f1_weighted: 0.0035 - loss: 5.0423 - top5_accuracy: 0.1134 - val_accuracy: 0.0250 - val_auc: 0.6640 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0340 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.0244 - auc: 0.6591 - f1_macro: 7.9289e-04 - f1_weighted: 0.0039 - loss: 5.0429 - top5_accuracy: 0.1103 - val_accuracy: 0.0250 - val_auc: 0.6633 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0341 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0224 - auc: 0.6618 - f1_macro: 8.4161e-04 - f1_weighted: 0.0039 - loss: 5.0420 - top5_accuracy: 0.1111 - val_accuracy: 0.0250 - val_auc: 0.6623 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0340 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.0241 - auc: 0.6611 - f1_macro: 6.9684e-04 - f1_weighted: 0.0034 - loss: 5.0410 - top5_accuracy: 0.1121 - val_accuracy: 0.0250 - val_auc: 0.6640 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0341 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.0229 - auc: 0.6579 - f1_macro: 7.5299e-04 - f1_weighted: 0.0037 - loss: 5.0438 - top5_accuracy: 0.1158 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0340 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0200 - auc: 0.6602 - f1_macro: 6.3788e-04 - f1_weighted: 0.0031 - loss: 5.0435 - top5_accuracy: 0.1110 - val_accuracy: 0.0239 - val_auc: 0.6641 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0340 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.0229 - auc: 0.6594 - f1_macro: 7.0049e-04 - f1_weighted: 0.0034 - loss: 5.0400 - top5_accuracy: 0.1100 - val_accuracy: 0.0250 - val_auc: 0.6631 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0340 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 30/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.0233 - auc: 0.6602 - f1_macro: 8.2098e-04 - f1_weighted: 0.0040 - loss: 5.0421 - top5_accuracy: 0.1109\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.0233 - auc: 0.6602 - f1_macro: 8.2181e-04 - f1_weighted: 0.0040 - loss: 5.0421 - top5_accuracy: 0.1109 - val_accuracy: 0.0250 - val_auc: 0.6634 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0340 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 28.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: light\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 281ms/step - accuracy: 0.0220 - auc: 0.6440 - f1_macro: 0.0011 - f1_weighted: 0.0048 - loss: 6.0177 - top5_accuracy: 0.1053 - val_accuracy: 0.0239 - val_auc: 0.6637 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0414 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0250 - auc: 0.6638 - f1_macro: 6.3757e-04 - f1_weighted: 0.0032 - loss: 5.0527 - top5_accuracy: 0.1135 - val_accuracy: 0.0239 - val_auc: 0.6656 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0395 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0243 - auc: 0.6627 - f1_macro: 8.0741e-04 - f1_weighted: 0.0040 - loss: 5.0491 - top5_accuracy: 0.1187 - val_accuracy: 0.0223 - val_auc: 0.6662 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0388 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0279 - auc: 0.6624 - f1_macro: 9.9871e-04 - f1_weighted: 0.0052 - loss: 5.0461 - top5_accuracy: 0.1163 - val_accuracy: 0.0223 - val_auc: 0.6663 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0380 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0235 - auc: 0.6618 - f1_macro: 0.0010 - f1_weighted: 0.0050 - loss: 5.0463 - top5_accuracy: 0.1179 - val_accuracy: 0.0223 - val_auc: 0.6663 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0368 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0244 - auc: 0.6621 - f1_macro: 8.6577e-04 - f1_weighted: 0.0044 - loss: 5.0439 - top5_accuracy: 0.1186 - val_accuracy: 0.0250 - val_auc: 0.6669 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0363 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0258 - auc: 0.6621 - f1_macro: 0.0010 - f1_weighted: 0.0053 - loss: 5.0402 - top5_accuracy: 0.1185 - val_accuracy: 0.0223 - val_auc: 0.6674 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0357 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0211 - auc: 0.6594 - f1_macro: 7.8256e-04 - f1_weighted: 0.0039 - loss: 5.0412 - top5_accuracy: 0.1173 - val_accuracy: 0.0250 - val_auc: 0.6663 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0351 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0240 - auc: 0.6599 - f1_macro: 9.9817e-04 - f1_weighted: 0.0048 - loss: 5.0389 - top5_accuracy: 0.1221 - val_accuracy: 0.0250 - val_auc: 0.6652 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0348 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0205 - auc: 0.6612 - f1_macro: 8.0520e-04 - f1_weighted: 0.0040 - loss: 5.0405 - top5_accuracy: 0.1169 - val_accuracy: 0.0223 - val_auc: 0.6652 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0347 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0262 - auc: 0.6615 - f1_macro: 0.0010 - f1_weighted: 0.0051 - loss: 5.0400 - top5_accuracy: 0.1157 - val_accuracy: 0.0250 - val_auc: 0.6641 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0346 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0248 - auc: 0.6602 - f1_macro: 0.0011 - f1_weighted: 0.0057 - loss: 5.0398 - top5_accuracy: 0.1182 - val_accuracy: 0.0250 - val_auc: 0.6635 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0345 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0245 - auc: 0.6602 - f1_macro: 0.0010 - f1_weighted: 0.0055 - loss: 5.0374 - top5_accuracy: 0.1181 - val_accuracy: 0.0250 - val_auc: 0.6646 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0344 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0221 - auc: 0.6618 - f1_macro: 8.2292e-04 - f1_weighted: 0.0041 - loss: 5.0356 - top5_accuracy: 0.1163 - val_accuracy: 0.0250 - val_auc: 0.6657 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0343 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0219 - auc: 0.6625 - f1_macro: 0.0010 - f1_weighted: 0.0053 - loss: 5.0378 - top5_accuracy: 0.1155 - val_accuracy: 0.0250 - val_auc: 0.6657 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0343 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0248 - auc: 0.6615 - f1_macro: 9.4146e-04 - f1_weighted: 0.0050 - loss: 5.0361 - top5_accuracy: 0.1174 - val_accuracy: 0.0250 - val_auc: 0.6660 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0342 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0213 - auc: 0.6618 - f1_macro: 9.3401e-04 - f1_weighted: 0.0048 - loss: 5.0390 - top5_accuracy: 0.1155 - val_accuracy: 0.0250 - val_auc: 0.6652 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0342 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0244 - auc: 0.6596 - f1_macro: 0.0010 - f1_weighted: 0.0051 - loss: 5.0394 - top5_accuracy: 0.1168 - val_accuracy: 0.0250 - val_auc: 0.6667 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0341 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0228 - auc: 0.6625 - f1_macro: 0.0011 - f1_weighted: 0.0053 - loss: 5.0388 - top5_accuracy: 0.1155 - val_accuracy: 0.0250 - val_auc: 0.6641 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0341 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0235 - auc: 0.6615 - f1_macro: 9.2280e-04 - f1_weighted: 0.0045 - loss: 5.0376 - top5_accuracy: 0.1191 - val_accuracy: 0.0250 - val_auc: 0.6644 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0341 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0247 - auc: 0.6624 - f1_macro: 0.0011 - f1_weighted: 0.0054 - loss: 5.0367 - top5_accuracy: 0.1190 - val_accuracy: 0.0250 - val_auc: 0.6624 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0341 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0189 - auc: 0.6609 - f1_macro: 6.7731e-04 - f1_weighted: 0.0035 - loss: 5.0372 - top5_accuracy: 0.1140 - val_accuracy: 0.0250 - val_auc: 0.6656 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0341 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m262/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.0210 - auc: 0.6628 - f1_macro: 9.0265e-04 - f1_weighted: 0.0044 - loss: 5.0361 - top5_accuracy: 0.1145\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0210 - auc: 0.6628 - f1_macro: 9.0302e-04 - f1_weighted: 0.0044 - loss: 5.0361 - top5_accuracy: 0.1145 - val_accuracy: 0.0250 - val_auc: 0.6643 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0340 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0247 - auc: 0.6614 - f1_macro: 9.7135e-04 - f1_weighted: 0.0048 - loss: 5.0350 - top5_accuracy: 0.1187 - val_accuracy: 0.0250 - val_auc: 0.6639 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0339 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0248 - auc: 0.6640 - f1_macro: 9.4223e-04 - f1_weighted: 0.0048 - loss: 5.0326 - top5_accuracy: 0.1191 - val_accuracy: 0.0250 - val_auc: 0.6624 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0337 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0236 - auc: 0.6619 - f1_macro: 8.2844e-04 - f1_weighted: 0.0042 - loss: 5.0332 - top5_accuracy: 0.1224 - val_accuracy: 0.0250 - val_auc: 0.6628 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0338 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0248 - auc: 0.6623 - f1_macro: 8.2889e-04 - f1_weighted: 0.0042 - loss: 5.0335 - top5_accuracy: 0.1185 - val_accuracy: 0.0250 - val_auc: 0.6630 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0336 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0241 - auc: 0.6624 - f1_macro: 7.4247e-04 - f1_weighted: 0.0038 - loss: 5.0319 - top5_accuracy: 0.1163 - val_accuracy: 0.0250 - val_auc: 0.6624 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0337 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0209 - auc: 0.6605 - f1_macro: 6.8429e-04 - f1_weighted: 0.0034 - loss: 5.0335 - top5_accuracy: 0.1197 - val_accuracy: 0.0250 - val_auc: 0.6616 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0337 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0228 - auc: 0.6639 - f1_macro: 7.2199e-04 - f1_weighted: 0.0036 - loss: 5.0320 - top5_accuracy: 0.1164 - val_accuracy: 0.0250 - val_auc: 0.6628 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0336 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 30.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: mixup\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 180ms/step - accuracy: 0.0242 - auc: 0.6444 - f1_macro: 0.0015 - f1_weighted: 0.0051 - loss: 5.7208 - top5_accuracy: 0.1060 - val_accuracy: 0.0239 - val_auc: 0.6579 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0467 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 48ms/step - accuracy: 0.0249 - auc: 0.6600 - f1_macro: 9.9389e-04 - f1_weighted: 0.0046 - loss: 5.0682 - top5_accuracy: 0.1117 - val_accuracy: 0.0239 - val_auc: 0.6579 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0495 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 49ms/step - accuracy: 0.0231 - auc: 0.6583 - f1_macro: 8.5052e-04 - f1_weighted: 0.0040 - loss: 5.0667 - top5_accuracy: 0.1113 - val_accuracy: 0.0239 - val_auc: 0.6580 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0463 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 49ms/step - accuracy: 0.0221 - auc: 0.6583 - f1_macro: 8.4603e-04 - f1_weighted: 0.0039 - loss: 5.0631 - top5_accuracy: 0.1088 - val_accuracy: 0.0239 - val_auc: 0.6574 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0428 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.0237 - auc: 0.6577 - f1_macro: 9.1138e-04 - f1_weighted: 0.0043 - loss: 5.0577 - top5_accuracy: 0.1080 - val_accuracy: 0.0239 - val_auc: 0.6574 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0417 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.0216 - auc: 0.6579 - f1_macro: 7.3059e-04 - f1_weighted: 0.0034 - loss: 5.0577 - top5_accuracy: 0.1082 - val_accuracy: 0.0239 - val_auc: 0.6580 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0407 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.0215 - auc: 0.6580 - f1_macro: 7.7120e-04 - f1_weighted: 0.0036 - loss: 5.0565 - top5_accuracy: 0.1085 - val_accuracy: 0.0239 - val_auc: 0.6574 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0396 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.0216 - auc: 0.6561 - f1_macro: 7.3805e-04 - f1_weighted: 0.0035 - loss: 5.0548 - top5_accuracy: 0.1110 - val_accuracy: 0.0239 - val_auc: 0.6580 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0387 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.0217 - auc: 0.6567 - f1_macro: 7.6497e-04 - f1_weighted: 0.0036 - loss: 5.0554 - top5_accuracy: 0.1095 - val_accuracy: 0.0239 - val_auc: 0.6576 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0387 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.0214 - auc: 0.6561 - f1_macro: 7.1195e-04 - f1_weighted: 0.0033 - loss: 5.0536 - top5_accuracy: 0.1069 - val_accuracy: 0.0239 - val_auc: 0.6580 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0387 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.0228 - auc: 0.6564 - f1_macro: 8.0761e-04 - f1_weighted: 0.0038 - loss: 5.0549 - top5_accuracy: 0.1084 - val_accuracy: 0.0239 - val_auc: 0.6580 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0381 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.0226 - auc: 0.6562 - f1_macro: 8.0494e-04 - f1_weighted: 0.0038 - loss: 5.0537 - top5_accuracy: 0.1080 - val_accuracy: 0.0239 - val_auc: 0.6580 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0382 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0224 - auc: 0.6567 - f1_macro: 8.3479e-04 - f1_weighted: 0.0039 - loss: 5.0531 - top5_accuracy: 0.1080 - val_accuracy: 0.0239 - val_auc: 0.6580 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0382 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.0211 - auc: 0.6563 - f1_macro: 7.5503e-04 - f1_weighted: 0.0036 - loss: 5.0523 - top5_accuracy: 0.1117 - val_accuracy: 0.0239 - val_auc: 0.6580 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0379 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0222 - auc: 0.6560 - f1_macro: 8.5662e-04 - f1_weighted: 0.0039 - loss: 5.0521 - top5_accuracy: 0.1073 - val_accuracy: 0.0239 - val_auc: 0.6581 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0380 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0225 - auc: 0.6560 - f1_macro: 7.0514e-04 - f1_weighted: 0.0033 - loss: 5.0527 - top5_accuracy: 0.1072 - val_accuracy: 0.0239 - val_auc: 0.6577 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0381 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.0180 - auc: 0.6560 - f1_macro: 6.5342e-04 - f1_weighted: 0.0031 - loss: 5.0526 - top5_accuracy: 0.1072 - val_accuracy: 0.0239 - val_auc: 0.6580 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0380 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0193 - auc: 0.6566 - f1_macro: 6.5410e-04 - f1_weighted: 0.0031 - loss: 5.0525 - top5_accuracy: 0.1091 - val_accuracy: 0.0239 - val_auc: 0.6583 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0380 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.0229 - auc: 0.6565 - f1_macro: 7.6146e-04 - f1_weighted: 0.0036 - loss: 5.0505 - top5_accuracy: 0.1077 - val_accuracy: 0.0239 - val_auc: 0.6583 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0376 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.0230 - auc: 0.6565 - f1_macro: 7.8182e-04 - f1_weighted: 0.0036 - loss: 5.0515 - top5_accuracy: 0.1088 - val_accuracy: 0.0239 - val_auc: 0.6577 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0377 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.0201 - auc: 0.6552 - f1_macro: 7.5654e-04 - f1_weighted: 0.0035 - loss: 5.0516 - top5_accuracy: 0.1090 - val_accuracy: 0.0239 - val_auc: 0.6583 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0379 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0224 - auc: 0.6563 - f1_macro: 8.0747e-04 - f1_weighted: 0.0038 - loss: 5.0492 - top5_accuracy: 0.1107 - val_accuracy: 0.0239 - val_auc: 0.6577 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0378 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.0195 - auc: 0.6554 - f1_macro: 7.8197e-04 - f1_weighted: 0.0036 - loss: 5.0518 - top5_accuracy: 0.1094 - val_accuracy: 0.0239 - val_auc: 0.6571 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0373 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0234 - auc: 0.6563 - f1_macro: 9.3952e-04 - f1_weighted: 0.0043 - loss: 5.0510 - top5_accuracy: 0.1079 - val_accuracy: 0.0239 - val_auc: 0.6575 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0375 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.0221 - auc: 0.6549 - f1_macro: 8.0218e-04 - f1_weighted: 0.0037 - loss: 5.0507 - top5_accuracy: 0.1076 - val_accuracy: 0.0239 - val_auc: 0.6583 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0373 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.0201 - auc: 0.6551 - f1_macro: 7.4936e-04 - f1_weighted: 0.0035 - loss: 5.0505 - top5_accuracy: 0.1107 - val_accuracy: 0.0239 - val_auc: 0.6577 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0373 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0200 - auc: 0.6541 - f1_macro: 7.1838e-04 - f1_weighted: 0.0034 - loss: 5.0515 - top5_accuracy: 0.1082 - val_accuracy: 0.0239 - val_auc: 0.6577 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0378 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0217 - auc: 0.6568 - f1_macro: 8.8808e-04 - f1_weighted: 0.0041 - loss: 5.0494 - top5_accuracy: 0.1094\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.0217 - auc: 0.6568 - f1_macro: 8.8803e-04 - f1_weighted: 0.0041 - loss: 5.0494 - top5_accuracy: 0.1095 - val_accuracy: 0.0239 - val_auc: 0.6577 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0374 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.0188 - auc: 0.6552 - f1_macro: 5.1805e-04 - f1_weighted: 0.0024 - loss: 5.0494 - top5_accuracy: 0.1092 - val_accuracy: 0.0239 - val_auc: 0.6589 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0360 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.0226 - auc: 0.6555 - f1_macro: 7.0355e-04 - f1_weighted: 0.0033 - loss: 5.0473 - top5_accuracy: 0.1096 - val_accuracy: 0.0250 - val_auc: 0.6571 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0357 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 30.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: medium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 295ms/step - accuracy: 0.0260 - auc: 0.6462 - f1_macro: 0.0013 - f1_weighted: 0.0060 - loss: 5.4774 - top5_accuracy: 0.1146 - val_accuracy: 0.0223 - val_auc: 0.6616 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0437 - val_top5_accuracy: 0.1157 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0246 - auc: 0.6580 - f1_macro: 8.2555e-04 - f1_weighted: 0.0042 - loss: 5.0597 - top5_accuracy: 0.1186 - val_accuracy: 0.0223 - val_auc: 0.6621 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0420 - val_top5_accuracy: 0.1157 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - accuracy: 0.0264 - auc: 0.6595 - f1_macro: 9.3470e-04 - f1_weighted: 0.0047 - loss: 5.0544 - top5_accuracy: 0.1199 - val_accuracy: 0.0223 - val_auc: 0.6616 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0410 - val_top5_accuracy: 0.1157 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - accuracy: 0.0262 - auc: 0.6579 - f1_macro: 0.0011 - f1_weighted: 0.0055 - loss: 5.0538 - top5_accuracy: 0.1179 - val_accuracy: 0.0223 - val_auc: 0.6622 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0404 - val_top5_accuracy: 0.1157 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0252 - auc: 0.6586 - f1_macro: 7.9969e-04 - f1_weighted: 0.0040 - loss: 5.0513 - top5_accuracy: 0.1160 - val_accuracy: 0.0223 - val_auc: 0.6617 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0386 - val_top5_accuracy: 0.1157 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0264 - auc: 0.6580 - f1_macro: 9.5849e-04 - f1_weighted: 0.0046 - loss: 5.0491 - top5_accuracy: 0.1175 - val_accuracy: 0.0223 - val_auc: 0.6620 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0373 - val_top5_accuracy: 0.1157 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0263 - auc: 0.6602 - f1_macro: 8.8007e-04 - f1_weighted: 0.0045 - loss: 5.0455 - top5_accuracy: 0.1185 - val_accuracy: 0.0223 - val_auc: 0.6608 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0370 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0230 - auc: 0.6589 - f1_macro: 7.1557e-04 - f1_weighted: 0.0036 - loss: 5.0471 - top5_accuracy: 0.1185 - val_accuracy: 0.0239 - val_auc: 0.6608 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0367 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0261 - auc: 0.6582 - f1_macro: 0.0011 - f1_weighted: 0.0052 - loss: 5.0449 - top5_accuracy: 0.1181 - val_accuracy: 0.0239 - val_auc: 0.6597 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0361 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0232 - auc: 0.6588 - f1_macro: 8.0457e-04 - f1_weighted: 0.0041 - loss: 5.0458 - top5_accuracy: 0.1150 - val_accuracy: 0.0239 - val_auc: 0.6602 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0361 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0248 - auc: 0.6576 - f1_macro: 8.8791e-04 - f1_weighted: 0.0045 - loss: 5.0453 - top5_accuracy: 0.1155 - val_accuracy: 0.0239 - val_auc: 0.6603 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0357 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0261 - auc: 0.6588 - f1_macro: 0.0010 - f1_weighted: 0.0051 - loss: 5.0435 - top5_accuracy: 0.1162 - val_accuracy: 0.0239 - val_auc: 0.6606 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0358 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0242 - auc: 0.6603 - f1_macro: 8.7280e-04 - f1_weighted: 0.0045 - loss: 5.0427 - top5_accuracy: 0.1190 - val_accuracy: 0.0239 - val_auc: 0.6603 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0355 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0250 - auc: 0.6603 - f1_macro: 9.1065e-04 - f1_weighted: 0.0046 - loss: 5.0418 - top5_accuracy: 0.1190 - val_accuracy: 0.0239 - val_auc: 0.6608 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0354 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0254 - auc: 0.6586 - f1_macro: 9.0832e-04 - f1_weighted: 0.0046 - loss: 5.0422 - top5_accuracy: 0.1196 - val_accuracy: 0.0239 - val_auc: 0.6603 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0354 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0228 - auc: 0.6595 - f1_macro: 9.5054e-04 - f1_weighted: 0.0047 - loss: 5.0426 - top5_accuracy: 0.1156 - val_accuracy: 0.0239 - val_auc: 0.6603 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0353 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0243 - auc: 0.6601 - f1_macro: 9.2656e-04 - f1_weighted: 0.0045 - loss: 5.0420 - top5_accuracy: 0.1197 - val_accuracy: 0.0239 - val_auc: 0.6603 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0352 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0236 - auc: 0.6603 - f1_macro: 0.0011 - f1_weighted: 0.0052 - loss: 5.0420 - top5_accuracy: 0.1173 - val_accuracy: 0.0239 - val_auc: 0.6603 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0351 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0230 - auc: 0.6580 - f1_macro: 0.0012 - f1_weighted: 0.0054 - loss: 5.0398 - top5_accuracy: 0.1184 - val_accuracy: 0.0239 - val_auc: 0.6608 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0351 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0250 - auc: 0.6593 - f1_macro: 8.8323e-04 - f1_weighted: 0.0045 - loss: 5.0406 - top5_accuracy: 0.1174 - val_accuracy: 0.0239 - val_auc: 0.6591 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0348 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0225 - auc: 0.6602 - f1_macro: 9.4709e-04 - f1_weighted: 0.0046 - loss: 5.0431 - top5_accuracy: 0.1189 - val_accuracy: 0.0239 - val_auc: 0.6591 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0348 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0229 - auc: 0.6580 - f1_macro: 8.6918e-04 - f1_weighted: 0.0043 - loss: 5.0425 - top5_accuracy: 0.1150 - val_accuracy: 0.0239 - val_auc: 0.6608 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0347 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0263 - auc: 0.6602 - f1_macro: 0.0010 - f1_weighted: 0.0052 - loss: 5.0400 - top5_accuracy: 0.1155 - val_accuracy: 0.0239 - val_auc: 0.6605 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0348 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0264 - auc: 0.6573 - f1_macro: 0.0010 - f1_weighted: 0.0052 - loss: 5.0397 - top5_accuracy: 0.1187 - val_accuracy: 0.0239 - val_auc: 0.6608 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0348 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0244 - auc: 0.6570 - f1_macro: 9.2547e-04 - f1_weighted: 0.0048 - loss: 5.0412 - top5_accuracy: 0.1193 - val_accuracy: 0.0239 - val_auc: 0.6611 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0348 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0232 - auc: 0.6595 - f1_macro: 7.8870e-04 - f1_weighted: 0.0040 - loss: 5.0411 - top5_accuracy: 0.1188 - val_accuracy: 0.0239 - val_auc: 0.6608 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0347 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m262/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0224 - auc: 0.6597 - f1_macro: 7.5541e-04 - f1_weighted: 0.0038 - loss: 5.0398 - top5_accuracy: 0.1225\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0224 - auc: 0.6597 - f1_macro: 7.5627e-04 - f1_weighted: 0.0038 - loss: 5.0398 - top5_accuracy: 0.1224 - val_accuracy: 0.0239 - val_auc: 0.6602 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0348 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0217 - auc: 0.6574 - f1_macro: 8.8288e-04 - f1_weighted: 0.0043 - loss: 5.0411 - top5_accuracy: 0.1134 - val_accuracy: 0.0239 - val_auc: 0.6605 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0342 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0255 - auc: 0.6577 - f1_macro: 0.0010 - f1_weighted: 0.0052 - loss: 5.0382 - top5_accuracy: 0.1178 - val_accuracy: 0.0239 - val_auc: 0.6624 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0340 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0254 - auc: 0.6622 - f1_macro: 9.2913e-04 - f1_weighted: 0.0048 - loss: 5.0347 - top5_accuracy: 0.1207 - val_accuracy: 0.0239 - val_auc: 0.6613 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0339 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 30.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: heavy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 299ms/step - accuracy: 0.0247 - auc: 0.6493 - f1_macro: 0.0013 - f1_weighted: 0.0058 - loss: 5.6406 - top5_accuracy: 0.1126 - val_accuracy: 0.0239 - val_auc: 0.6640 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0451 - val_top5_accuracy: 0.1135 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0229 - auc: 0.6685 - f1_macro: 0.0011 - f1_weighted: 0.0055 - loss: 5.0387 - top5_accuracy: 0.1173 - val_accuracy: 0.0239 - val_auc: 0.6632 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0433 - val_top5_accuracy: 0.1135 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0247 - auc: 0.6699 - f1_macro: 0.0011 - f1_weighted: 0.0056 - loss: 5.0321 - top5_accuracy: 0.1187 - val_accuracy: 0.0239 - val_auc: 0.6637 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0409 - val_top5_accuracy: 0.1107 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0237 - auc: 0.6682 - f1_macro: 9.9104e-04 - f1_weighted: 0.0050 - loss: 5.0312 - top5_accuracy: 0.1169 - val_accuracy: 0.0239 - val_auc: 0.6637 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0408 - val_top5_accuracy: 0.1135 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0235 - auc: 0.6674 - f1_macro: 9.5493e-04 - f1_weighted: 0.0048 - loss: 5.0292 - top5_accuracy: 0.1194 - val_accuracy: 0.0239 - val_auc: 0.6649 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0403 - val_top5_accuracy: 0.1135 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0226 - auc: 0.6682 - f1_macro: 9.0083e-04 - f1_weighted: 0.0046 - loss: 5.0234 - top5_accuracy: 0.1218 - val_accuracy: 0.0239 - val_auc: 0.6651 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0390 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0236 - auc: 0.6660 - f1_macro: 8.9905e-04 - f1_weighted: 0.0046 - loss: 5.0244 - top5_accuracy: 0.1185 - val_accuracy: 0.0239 - val_auc: 0.6645 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0379 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0211 - auc: 0.6659 - f1_macro: 8.3330e-04 - f1_weighted: 0.0042 - loss: 5.0245 - top5_accuracy: 0.1209 - val_accuracy: 0.0239 - val_auc: 0.6662 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0379 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0258 - auc: 0.6677 - f1_macro: 0.0010 - f1_weighted: 0.0053 - loss: 5.0230 - top5_accuracy: 0.1247 - val_accuracy: 0.0250 - val_auc: 0.6647 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0379 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0261 - auc: 0.6648 - f1_macro: 9.7516e-04 - f1_weighted: 0.0049 - loss: 5.0238 - top5_accuracy: 0.1197 - val_accuracy: 0.0239 - val_auc: 0.6647 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0371 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0253 - auc: 0.6655 - f1_macro: 0.0011 - f1_weighted: 0.0053 - loss: 5.0216 - top5_accuracy: 0.1201 - val_accuracy: 0.0250 - val_auc: 0.6647 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0372 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0275 - auc: 0.6645 - f1_macro: 0.0011 - f1_weighted: 0.0057 - loss: 5.0201 - top5_accuracy: 0.1243 - val_accuracy: 0.0239 - val_auc: 0.6636 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0370 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0228 - auc: 0.6647 - f1_macro: 8.4242e-04 - f1_weighted: 0.0042 - loss: 5.0209 - top5_accuracy: 0.1214 - val_accuracy: 0.0250 - val_auc: 0.6658 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0371 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0227 - auc: 0.6655 - f1_macro: 8.3009e-04 - f1_weighted: 0.0042 - loss: 5.0215 - top5_accuracy: 0.1233 - val_accuracy: 0.0239 - val_auc: 0.6657 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0365 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0197 - auc: 0.6651 - f1_macro: 6.5914e-04 - f1_weighted: 0.0034 - loss: 5.0202 - top5_accuracy: 0.1219 - val_accuracy: 0.0250 - val_auc: 0.6664 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0366 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0245 - auc: 0.6640 - f1_macro: 9.1245e-04 - f1_weighted: 0.0048 - loss: 5.0201 - top5_accuracy: 0.1240 - val_accuracy: 0.0239 - val_auc: 0.6658 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0363 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0226 - auc: 0.6649 - f1_macro: 8.3664e-04 - f1_weighted: 0.0042 - loss: 5.0221 - top5_accuracy: 0.1237 - val_accuracy: 0.0239 - val_auc: 0.6653 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0364 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0236 - auc: 0.6656 - f1_macro: 9.5540e-04 - f1_weighted: 0.0049 - loss: 5.0194 - top5_accuracy: 0.1208 - val_accuracy: 0.0239 - val_auc: 0.6650 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0363 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0245 - auc: 0.6664 - f1_macro: 9.8470e-04 - f1_weighted: 0.0050 - loss: 5.0181 - top5_accuracy: 0.1235 - val_accuracy: 0.0250 - val_auc: 0.6654 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0364 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0248 - auc: 0.6657 - f1_macro: 9.6772e-04 - f1_weighted: 0.0049 - loss: 5.0186 - top5_accuracy: 0.1214 - val_accuracy: 0.0250 - val_auc: 0.6653 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0368 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m262/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0257 - auc: 0.6676 - f1_macro: 9.1413e-04 - f1_weighted: 0.0047 - loss: 5.0176 - top5_accuracy: 0.1250\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0257 - auc: 0.6675 - f1_macro: 9.1403e-04 - f1_weighted: 0.0047 - loss: 5.0178 - top5_accuracy: 0.1250 - val_accuracy: 0.0250 - val_auc: 0.6659 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0363 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0223 - auc: 0.6658 - f1_macro: 7.0289e-04 - f1_weighted: 0.0036 - loss: 5.0172 - top5_accuracy: 0.1226 - val_accuracy: 0.0239 - val_auc: 0.6634 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0344 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0227 - auc: 0.6685 - f1_macro: 8.0262e-04 - f1_weighted: 0.0040 - loss: 5.0150 - top5_accuracy: 0.1246 - val_accuracy: 0.0250 - val_auc: 0.6634 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0343 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0220 - auc: 0.6668 - f1_macro: 8.0989e-04 - f1_weighted: 0.0042 - loss: 5.0140 - top5_accuracy: 0.1263 - val_accuracy: 0.0250 - val_auc: 0.6618 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0343 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0210 - auc: 0.6684 - f1_macro: 7.7011e-04 - f1_weighted: 0.0039 - loss: 5.0152 - top5_accuracy: 0.1217 - val_accuracy: 0.0250 - val_auc: 0.6634 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0342 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0219 - auc: 0.6661 - f1_macro: 7.6593e-04 - f1_weighted: 0.0041 - loss: 5.0141 - top5_accuracy: 0.1243 - val_accuracy: 0.0250 - val_auc: 0.6634 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0342 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0253 - auc: 0.6642 - f1_macro: 9.9827e-04 - f1_weighted: 0.0052 - loss: 5.0153 - top5_accuracy: 0.1234 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0341 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0234 - auc: 0.6684 - f1_macro: 8.8143e-04 - f1_weighted: 0.0045 - loss: 5.0111 - top5_accuracy: 0.1242 - val_accuracy: 0.0250 - val_auc: 0.6645 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0342 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0251 - auc: 0.6678 - f1_macro: 8.6572e-04 - f1_weighted: 0.0045 - loss: 5.0139 - top5_accuracy: 0.1242 - val_accuracy: 0.0250 - val_auc: 0.6662 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0342 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m262/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0257 - auc: 0.6656 - f1_macro: 7.9838e-04 - f1_weighted: 0.0043 - loss: 5.0142 - top5_accuracy: 0.1237\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0257 - auc: 0.6656 - f1_macro: 7.9791e-04 - f1_weighted: 0.0043 - loss: 5.0143 - top5_accuracy: 0.1236 - val_accuracy: 0.0250 - val_auc: 0.6667 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0342 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 27.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: grayscale_plus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 276ms/step - accuracy: 0.0243 - auc: 0.6482 - f1_macro: 0.0012 - f1_weighted: 0.0054 - loss: 5.6674 - top5_accuracy: 0.1116 - val_accuracy: 0.0239 - val_auc: 0.6611 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0435 - val_top5_accuracy: 0.1163 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - accuracy: 0.0267 - auc: 0.6609 - f1_macro: 9.2212e-04 - f1_weighted: 0.0045 - loss: 5.0569 - top5_accuracy: 0.1064 - val_accuracy: 0.0239 - val_auc: 0.6607 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0421 - val_top5_accuracy: 0.1163 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - accuracy: 0.0251 - auc: 0.6597 - f1_macro: 8.2337e-04 - f1_weighted: 0.0041 - loss: 5.0538 - top5_accuracy: 0.1090 - val_accuracy: 0.0239 - val_auc: 0.6597 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0407 - val_top5_accuracy: 0.1163 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - accuracy: 0.0258 - auc: 0.6607 - f1_macro: 8.4061e-04 - f1_weighted: 0.0042 - loss: 5.0503 - top5_accuracy: 0.1090 - val_accuracy: 0.0239 - val_auc: 0.6589 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0396 - val_top5_accuracy: 0.1163 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.0260 - auc: 0.6589 - f1_macro: 8.6005e-04 - f1_weighted: 0.0042 - loss: 5.0497 - top5_accuracy: 0.1078 - val_accuracy: 0.0239 - val_auc: 0.6591 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0386 - val_top5_accuracy: 0.1163 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - accuracy: 0.0255 - auc: 0.6579 - f1_macro: 7.8081e-04 - f1_weighted: 0.0039 - loss: 5.0483 - top5_accuracy: 0.1094 - val_accuracy: 0.0239 - val_auc: 0.6589 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0381 - val_top5_accuracy: 0.1163 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - accuracy: 0.0241 - auc: 0.6594 - f1_macro: 7.4691e-04 - f1_weighted: 0.0037 - loss: 5.0487 - top5_accuracy: 0.1099 - val_accuracy: 0.0239 - val_auc: 0.6581 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0369 - val_top5_accuracy: 0.1163 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - accuracy: 0.0226 - auc: 0.6588 - f1_macro: 6.5905e-04 - f1_weighted: 0.0033 - loss: 5.0459 - top5_accuracy: 0.1108 - val_accuracy: 0.0239 - val_auc: 0.6580 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0362 - val_top5_accuracy: 0.1163 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - accuracy: 0.0240 - auc: 0.6582 - f1_macro: 7.5696e-04 - f1_weighted: 0.0037 - loss: 5.0452 - top5_accuracy: 0.1082 - val_accuracy: 0.0239 - val_auc: 0.6580 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0359 - val_top5_accuracy: 0.1163 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - accuracy: 0.0257 - auc: 0.6588 - f1_macro: 8.5050e-04 - f1_weighted: 0.0041 - loss: 5.0432 - top5_accuracy: 0.1115 - val_accuracy: 0.0239 - val_auc: 0.6592 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0357 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 51ms/step - accuracy: 0.0218 - auc: 0.6577 - f1_macro: 6.7021e-04 - f1_weighted: 0.0033 - loss: 5.0433 - top5_accuracy: 0.1107 - val_accuracy: 0.0250 - val_auc: 0.6570 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0355 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0223 - auc: 0.6604 - f1_macro: 6.7748e-04 - f1_weighted: 0.0033 - loss: 5.0436 - top5_accuracy: 0.1129 - val_accuracy: 0.0250 - val_auc: 0.6586 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0356 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0231 - auc: 0.6593 - f1_macro: 8.8931e-04 - f1_weighted: 0.0042 - loss: 5.0434 - top5_accuracy: 0.1120 - val_accuracy: 0.0250 - val_auc: 0.6581 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0355 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - accuracy: 0.0251 - auc: 0.6585 - f1_macro: 8.1573e-04 - f1_weighted: 0.0039 - loss: 5.0420 - top5_accuracy: 0.1124 - val_accuracy: 0.0250 - val_auc: 0.6581 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0354 - val_top5_accuracy: 0.1163 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - accuracy: 0.0225 - auc: 0.6598 - f1_macro: 6.9768e-04 - f1_weighted: 0.0034 - loss: 5.0440 - top5_accuracy: 0.1097 - val_accuracy: 0.0250 - val_auc: 0.6581 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0353 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - accuracy: 0.0220 - auc: 0.6598 - f1_macro: 7.2932e-04 - f1_weighted: 0.0035 - loss: 5.0421 - top5_accuracy: 0.1112 - val_accuracy: 0.0250 - val_auc: 0.6576 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0352 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - accuracy: 0.0189 - auc: 0.6552 - f1_macro: 6.3096e-04 - f1_weighted: 0.0031 - loss: 5.0423 - top5_accuracy: 0.1115 - val_accuracy: 0.0250 - val_auc: 0.6581 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0352 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.0228 - auc: 0.6593 - f1_macro: 7.4364e-04 - f1_weighted: 0.0036 - loss: 5.0409 - top5_accuracy: 0.1135 - val_accuracy: 0.0250 - val_auc: 0.6570 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0351 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - accuracy: 0.0228 - auc: 0.6573 - f1_macro: 7.3085e-04 - f1_weighted: 0.0036 - loss: 5.0418 - top5_accuracy: 0.1075 - val_accuracy: 0.0250 - val_auc: 0.6570 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0350 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - accuracy: 0.0230 - auc: 0.6591 - f1_macro: 6.7574e-04 - f1_weighted: 0.0033 - loss: 5.0427 - top5_accuracy: 0.1096 - val_accuracy: 0.0250 - val_auc: 0.6576 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0349 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - accuracy: 0.0246 - auc: 0.6569 - f1_macro: 9.5733e-04 - f1_weighted: 0.0046 - loss: 5.0417 - top5_accuracy: 0.1110 - val_accuracy: 0.0250 - val_auc: 0.6581 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0349 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0229 - auc: 0.6593 - f1_macro: 8.4124e-04 - f1_weighted: 0.0041 - loss: 5.0413 - top5_accuracy: 0.1109 - val_accuracy: 0.0250 - val_auc: 0.6587 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0349 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0217 - auc: 0.6589 - f1_macro: 6.9044e-04 - f1_weighted: 0.0033 - loss: 5.0419 - top5_accuracy: 0.1124 - val_accuracy: 0.0250 - val_auc: 0.6587 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0348 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0214 - auc: 0.6574 - f1_macro: 6.3766e-04 - f1_weighted: 0.0031 - loss: 5.0391 - top5_accuracy: 0.1127 - val_accuracy: 0.0250 - val_auc: 0.6581 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0348 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0205 - auc: 0.6575 - f1_macro: 6.9841e-04 - f1_weighted: 0.0034 - loss: 5.0402 - top5_accuracy: 0.1130 - val_accuracy: 0.0250 - val_auc: 0.6584 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0350 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0202 - auc: 0.6607 - f1_macro: 7.8228e-04 - f1_weighted: 0.0038 - loss: 5.0415 - top5_accuracy: 0.1103 - val_accuracy: 0.0250 - val_auc: 0.6565 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0349 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0220 - auc: 0.6586 - f1_macro: 7.2097e-04 - f1_weighted: 0.0035 - loss: 5.0386 - top5_accuracy: 0.1109 - val_accuracy: 0.0250 - val_auc: 0.6587 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0347 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0193 - auc: 0.6599 - f1_macro: 6.4688e-04 - f1_weighted: 0.0032 - loss: 5.0401 - top5_accuracy: 0.1107 - val_accuracy: 0.0250 - val_auc: 0.6581 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0347 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0203 - auc: 0.6609 - f1_macro: 6.9732e-04 - f1_weighted: 0.0034 - loss: 5.0397 - top5_accuracy: 0.1096 - val_accuracy: 0.0250 - val_auc: 0.6578 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0345 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 30/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0213 - auc: 0.6578 - f1_macro: 6.6386e-04 - f1_weighted: 0.0032 - loss: 5.0404 - top5_accuracy: 0.1099 - val_accuracy: 0.0250 - val_auc: 0.6584 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0347 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 29.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: randaugment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 231ms/step - accuracy: 0.0248 - auc: 0.6416 - f1_macro: 0.0013 - f1_weighted: 0.0050 - loss: 5.6328 - top5_accuracy: 0.1083 - val_accuracy: 0.0223 - val_auc: 0.6636 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0430 - val_top5_accuracy: 0.1157 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0215 - auc: 0.6651 - f1_macro: 0.0011 - f1_weighted: 0.0053 - loss: 5.0471 - top5_accuracy: 0.1130 - val_accuracy: 0.0223 - val_auc: 0.6633 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0409 - val_top5_accuracy: 0.1157 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - accuracy: 0.0201 - auc: 0.6645 - f1_macro: 9.2040e-04 - f1_weighted: 0.0045 - loss: 5.0430 - top5_accuracy: 0.1193 - val_accuracy: 0.0223 - val_auc: 0.6633 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0389 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0229 - auc: 0.6649 - f1_macro: 9.7026e-04 - f1_weighted: 0.0048 - loss: 5.0405 - top5_accuracy: 0.1187 - val_accuracy: 0.0223 - val_auc: 0.6627 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0378 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0205 - auc: 0.6657 - f1_macro: 8.6812e-04 - f1_weighted: 0.0042 - loss: 5.0390 - top5_accuracy: 0.1188 - val_accuracy: 0.0223 - val_auc: 0.6638 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0369 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0183 - auc: 0.6633 - f1_macro: 8.0451e-04 - f1_weighted: 0.0044 - loss: 5.0364 - top5_accuracy: 0.1209 - val_accuracy: 0.0223 - val_auc: 0.6638 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0362 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0235 - auc: 0.6638 - f1_macro: 8.7471e-04 - f1_weighted: 0.0043 - loss: 5.0357 - top5_accuracy: 0.1204 - val_accuracy: 0.0223 - val_auc: 0.6638 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0357 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0224 - auc: 0.6625 - f1_macro: 8.3996e-04 - f1_weighted: 0.0041 - loss: 5.0349 - top5_accuracy: 0.1205 - val_accuracy: 0.0223 - val_auc: 0.6627 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0353 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0232 - auc: 0.6623 - f1_macro: 9.3561e-04 - f1_weighted: 0.0048 - loss: 5.0330 - top5_accuracy: 0.1210 - val_accuracy: 0.0223 - val_auc: 0.6630 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0352 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0231 - auc: 0.6631 - f1_macro: 0.0011 - f1_weighted: 0.0055 - loss: 5.0317 - top5_accuracy: 0.1200 - val_accuracy: 0.0223 - val_auc: 0.6636 - val_f1_macro: 2.1559e-04 - val_f1_weighted: 9.6938e-04 - val_loss: 5.0349 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0250 - auc: 0.6634 - f1_macro: 9.3898e-04 - f1_weighted: 0.0046 - loss: 5.0305 - top5_accuracy: 0.1214 - val_accuracy: 0.0250 - val_auc: 0.6642 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0347 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0224 - auc: 0.6629 - f1_macro: 8.6514e-04 - f1_weighted: 0.0045 - loss: 5.0299 - top5_accuracy: 0.1191 - val_accuracy: 0.0250 - val_auc: 0.6633 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0346 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0246 - auc: 0.6610 - f1_macro: 9.5545e-04 - f1_weighted: 0.0050 - loss: 5.0310 - top5_accuracy: 0.1208 - val_accuracy: 0.0250 - val_auc: 0.6630 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0346 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0207 - auc: 0.6617 - f1_macro: 7.8525e-04 - f1_weighted: 0.0040 - loss: 5.0300 - top5_accuracy: 0.1216 - val_accuracy: 0.0250 - val_auc: 0.6636 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0345 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0214 - auc: 0.6636 - f1_macro: 8.5627e-04 - f1_weighted: 0.0043 - loss: 5.0307 - top5_accuracy: 0.1202 - val_accuracy: 0.0250 - val_auc: 0.6630 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0344 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0229 - auc: 0.6623 - f1_macro: 8.4027e-04 - f1_weighted: 0.0044 - loss: 5.0291 - top5_accuracy: 0.1194 - val_accuracy: 0.0250 - val_auc: 0.6633 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0344 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0220 - auc: 0.6633 - f1_macro: 8.7331e-04 - f1_weighted: 0.0046 - loss: 5.0293 - top5_accuracy: 0.1188 - val_accuracy: 0.0250 - val_auc: 0.6642 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0343 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0246 - auc: 0.6623 - f1_macro: 9.9117e-04 - f1_weighted: 0.0050 - loss: 5.0283 - top5_accuracy: 0.1211 - val_accuracy: 0.0250 - val_auc: 0.6624 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0343 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.0251 - auc: 0.6625 - f1_macro: 9.8014e-04 - f1_weighted: 0.0050 - loss: 5.0293 - top5_accuracy: 0.1175 - val_accuracy: 0.0250 - val_auc: 0.6653 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0342 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0239 - auc: 0.6642 - f1_macro: 9.5808e-04 - f1_weighted: 0.0050 - loss: 5.0297 - top5_accuracy: 0.1205 - val_accuracy: 0.0250 - val_auc: 0.6633 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0342 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 49ms/step - accuracy: 0.0217 - auc: 0.6638 - f1_macro: 7.9356e-04 - f1_weighted: 0.0044 - loss: 5.0290 - top5_accuracy: 0.1200 - val_accuracy: 0.0250 - val_auc: 0.6630 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0342 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0261 - auc: 0.6623 - f1_macro: 8.9011e-04 - f1_weighted: 0.0045 - loss: 5.0292 - top5_accuracy: 0.1210 - val_accuracy: 0.0250 - val_auc: 0.6642 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0341 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0220 - auc: 0.6630 - f1_macro: 8.9240e-04 - f1_weighted: 0.0046 - loss: 5.0292 - top5_accuracy: 0.1205 - val_accuracy: 0.0250 - val_auc: 0.6642 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0340 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0278 - auc: 0.6632 - f1_macro: 0.0010 - f1_weighted: 0.0052 - loss: 5.0275 - top5_accuracy: 0.1225 - val_accuracy: 0.0250 - val_auc: 0.6642 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0341 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0241 - auc: 0.6612 - f1_macro: 9.0663e-04 - f1_weighted: 0.0046 - loss: 5.0289 - top5_accuracy: 0.1228 - val_accuracy: 0.0250 - val_auc: 0.6630 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0341 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0236 - auc: 0.6639 - f1_macro: 0.0010 - f1_weighted: 0.0052 - loss: 5.0267 - top5_accuracy: 0.1192 - val_accuracy: 0.0250 - val_auc: 0.6627 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0340 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0222 - auc: 0.6648 - f1_macro: 9.2702e-04 - f1_weighted: 0.0047 - loss: 5.0268 - top5_accuracy: 0.1202 - val_accuracy: 0.0250 - val_auc: 0.6633 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0339 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 49ms/step - accuracy: 0.0248 - auc: 0.6624 - f1_macro: 9.8915e-04 - f1_weighted: 0.0052 - loss: 5.0281 - top5_accuracy: 0.1232 - val_accuracy: 0.0250 - val_auc: 0.6621 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0339 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0282 - auc: 0.6620 - f1_macro: 0.0010 - f1_weighted: 0.0053 - loss: 5.0254 - top5_accuracy: 0.1215 - val_accuracy: 0.0250 - val_auc: 0.6638 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0339 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 30/30\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 49ms/step - accuracy: 0.0220 - auc: 0.6623 - f1_macro: 7.3925e-04 - f1_weighted: 0.0038 - loss: 5.0282 - top5_accuracy: 0.1199 - val_accuracy: 0.0250 - val_auc: 0.6621 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0339 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 29.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# Display the table\n",
        "display(results_df.round(4))\n"
      ],
      "metadata": {
        "id": "QRO3OpRbkN8E",
        "outputId": "54ac3e0c-ac3d-4eba-b42f-ab28cc028017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     augmentation  train_loss  val_loss  train_accuracy  val_accuracy  \\\n",
              "0            none      5.0235    5.0340          0.0243        0.0239   \n",
              "1           light      5.0227    5.0336          0.0250        0.0250   \n",
              "2           mixup      5.0240    5.0357          0.0250        0.0250   \n",
              "3          medium      5.0229    5.0339          0.0243        0.0239   \n",
              "4           heavy      5.0237    5.0341          0.0250        0.0250   \n",
              "5  grayscale_plus      5.0235    5.0345          0.0250        0.0250   \n",
              "6     randaugment      5.0232    5.0339          0.0250        0.0250   \n",
              "\n",
              "   train_f1_macro  val_f1_macro  val_f1_weighted  \n",
              "0          0.0002        0.0002           0.0011  \n",
              "1          0.0002        0.0002           0.0012  \n",
              "2          0.0002        0.0002           0.0012  \n",
              "3          0.0002        0.0002           0.0011  \n",
              "4          0.0002        0.0002           0.0012  \n",
              "5          0.0002        0.0002           0.0012  \n",
              "6          0.0002        0.0002           0.0012  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fdbff456-1882-4cb9-9f39-84d306b5cfaa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>augmentation</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>train_f1_macro</th>\n",
              "      <th>val_f1_macro</th>\n",
              "      <th>val_f1_weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>none</td>\n",
              "      <td>5.0235</td>\n",
              "      <td>5.0340</td>\n",
              "      <td>0.0243</td>\n",
              "      <td>0.0239</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>light</td>\n",
              "      <td>5.0227</td>\n",
              "      <td>5.0336</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mixup</td>\n",
              "      <td>5.0240</td>\n",
              "      <td>5.0357</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>medium</td>\n",
              "      <td>5.0229</td>\n",
              "      <td>5.0339</td>\n",
              "      <td>0.0243</td>\n",
              "      <td>0.0239</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>heavy</td>\n",
              "      <td>5.0237</td>\n",
              "      <td>5.0341</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>grayscale_plus</td>\n",
              "      <td>5.0235</td>\n",
              "      <td>5.0345</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>randaugment</td>\n",
              "      <td>5.0232</td>\n",
              "      <td>5.0339</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdbff456-1882-4cb9-9f39-84d306b5cfaa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fdbff456-1882-4cb9-9f39-84d306b5cfaa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fdbff456-1882-4cb9-9f39-84d306b5cfaa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-92aa74a1-3e1e-4997-ad97-cb06034f8dbc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-92aa74a1-3e1e-4997-ad97-cb06034f8dbc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-92aa74a1-3e1e-4997-ad97-cb06034f8dbc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(results_df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"augmentation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"none\",\n          \"light\",\n          \"grayscale_plus\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0004540820148281715,\n        \"min\": 5.0227,\n        \"max\": 5.024,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          5.0235,\n          5.0227,\n          5.0232\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0006972736021037291,\n        \"min\": 5.0336,\n        \"max\": 5.0357,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          5.034,\n          5.0336,\n          5.0345\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00034156502553198793,\n        \"min\": 0.0243,\n        \"max\": 0.025,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.025,\n          0.0243\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0005367450401216933,\n        \"min\": 0.0239,\n        \"max\": 0.025,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.025,\n          0.0239\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.927680476887095e-20,\n        \"min\": 0.0002,\n        \"max\": 0.0002,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.927680476887095e-20,\n        \"min\": 0.0002,\n        \"max\": 0.0002,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_f1_weighted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.879500364742658e-05,\n        \"min\": 0.0011,\n        \"max\": 0.0012,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0012\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melt the DataFrame for seaborn plotting\n",
        "metrics_to_plot = ['train_accuracy', 'val_accuracy']\n",
        "melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "                            var_name='metric', value_name='value')\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "plt.title(\"Comparison of Accuracy Across Augmentation Strategies\")\n",
        "plt.ylim(0, 0.4)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MRXufZX6kPMf",
        "outputId": "57657f63-7309-4e39-832a-7fac58eb74cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1U6g861_0QB"
      },
      "outputs": [],
      "source": [
        "# # Initialize the preprocessor\n",
        "# batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "# image_size = (224, 224)\n",
        "\n",
        "# preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# # Store results\n",
        "# results = {}\n",
        "\n",
        "# # Loop through each augmentation\n",
        "# for aug in augmentations_to_test:\n",
        "#     print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "#     model = build_alexnet()\n",
        "\n",
        "#     model.compile(\n",
        "#         optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "#         loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "#         metrics=metrics\n",
        "#     )\n",
        "\n",
        "#     train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "#     train_ds_sampled, class_names = preprocess.load_img(data_dir=\"data/rare_species/train_sampled\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "#     val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "#     test_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/test\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "\n",
        "#     # Initialize the experiment\n",
        "#     experiment = Experiment(\n",
        "#         model=model,\n",
        "#         train_ds=train_ds_sampled,\n",
        "#         val_ds=val_ds,\n",
        "#         experiment_name=f\"alexnet_with_{aug}_no_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "#         batch_size=32,\n",
        "#         image_size=(224, 224),\n",
        "#         resume=False,\n",
        "#         save_model = False\n",
        "#     )\n",
        "\n",
        "#     # Run the experiment\n",
        "#     history = experiment.run_experiment(callbacks=callbacks, epochs=40)\n",
        "\n",
        "#     # Predict entire validation set at once\n",
        "#     preds = model.predict(val_ds)\n",
        "#     y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "#     # Extract true labels in order\n",
        "#     y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "#     # Compute metrics\n",
        "#     f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "#     f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "#     precision = precision_score(y_true, y_pred, average='weighted')\n",
        "#     recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "#     # Store in results\n",
        "#     results[aug] = {\n",
        "#         \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "#         \"f1_macro\": f1_macro,\n",
        "#         \"f1_weighted\": f1_weighted,\n",
        "#         \"precision\": precision,\n",
        "#         \"recall\": recall\n",
        "#     }\n",
        "\n",
        "#     print(f\"Finished '{aug}'\")\n",
        "#     print(f\"  Accuracy:      {results[aug]['accuracy']:.4f}\")\n",
        "#     print(f\"  F1 (macro):    {results[aug]['f1_macro']:.4f}\")\n",
        "#     print(f\"  F1 (weighted): {results[aug]['f1_weighted']:.4f}\")\n",
        "#     print(f\"  Precision:     {results[aug]['precision']:.4f}\")\n",
        "#     print(f\"  Recall:        {results[aug]['recall']:.4f}\")\n",
        "\n",
        "\n",
        "#     # Clear memory to avoid OOM\n",
        "#     del model\n",
        "#     del experiment\n",
        "#     K.clear_session()\n",
        "#     gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mB8LVp0f_0QB"
      },
      "outputs": [],
      "source": [
        "# # Convert results to a DataFrame\n",
        "# results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "# results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# # Display the table\n",
        "# display(results_df.round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRsSJqtR_0QB"
      },
      "outputs": [],
      "source": [
        "# # Melt the DataFrame for seaborn plotting\n",
        "# metrics_to_plot = ['accuracy', 'f1_macro', 'f1_weighted', 'precision', 'recall']\n",
        "# melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "#                             var_name='metric', value_name='value')\n",
        "\n",
        "# # Plot using seaborn\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "# plt.title(\"Comparison of Metrics Across Augmentation Strategies\")\n",
        "# plt.ylim(0, 0.4)\n",
        "# plt.xticks(rotation=45)\n",
        "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AlexNet with oversampling"
      ],
      "metadata": {
        "id": "tQjmkS3knO0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the preprocessor\n",
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Loop through each augmentation\n",
        "for aug in augmentations_to_test:\n",
        "    print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "    model = build_alexnet()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=True, shuffle=True)\n",
        "    if aug==\"grayscale_plus\":\n",
        "      val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment='grayscale', oversampling=False)\n",
        "    else:\n",
        "      val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "    # Initialize the experiment\n",
        "    experiment = Experiment(\n",
        "        model=model,\n",
        "        train_ds=train_ds,\n",
        "        val_ds=val_ds,\n",
        "        experiment_name=f\"alexnet_with_{aug}_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "        batch_size=32,\n",
        "        image_size=(224, 224),\n",
        "        save_model = False\n",
        "    )\n",
        "\n",
        "    # Run the experiment\n",
        "    history = experiment.run_experiment(callbacks=callbacks, epochs=30)\n",
        "\n",
        "    # Predict entire validation set at once\n",
        "    preds = model.predict(val_ds)\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Extract true labels in order\n",
        "    y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "    # Compute metrics\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Store in results\n",
        "    train_eval = model.evaluate(train_ds, verbose=0)\n",
        "    val_eval = model.evaluate(val_ds, verbose=0)\n",
        "\n",
        "    metric_names = [\"loss\", \"accuracy\", \"auc\", \"f1_macro\", \"f1_weighted\", \"top5_accuracy\"]\n",
        "\n",
        "    train_metrics = dict(zip(metric_names, train_eval))\n",
        "    val_metrics = dict(zip(metric_names, val_eval))\n",
        "\n",
        "    # Results\n",
        "    results[aug] = {\n",
        "        \"train_loss\": train_metrics[\"loss\"],\n",
        "        \"val_loss\": val_metrics[\"loss\"],\n",
        "\n",
        "        \"train_accuracy\": train_metrics[\"accuracy\"],\n",
        "        \"val_accuracy\": val_metrics[\"accuracy\"],\n",
        "\n",
        "        \"train_f1_macro\": train_metrics.get(\"f1_macro\"),\n",
        "        \"val_f1_macro\": val_metrics.get(\"f1_macro\"),\n",
        "\n",
        "        \"val_f1_weighted\": val_metrics.get(\"f1_weighted\")\n",
        "    }"
      ],
      "metadata": {
        "id": "0q8rqZgRnSHS",
        "outputId": "56c1df48-e2d7-49db-a592-3a04fa22d48f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training with augmentation: none\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 128ms/step - accuracy: 0.0197 - auc: 0.6016 - f1_macro: 0.0011 - f1_weighted: 0.0039 - loss: 5.8542 - top5_accuracy: 0.0917 - val_accuracy: 0.0239 - val_auc: 0.6495 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0751 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 50ms/step - accuracy: 0.0171 - auc: 0.5989 - f1_macro: 5.3936e-04 - f1_weighted: 0.0021 - loss: 5.1943 - top5_accuracy: 0.0904 - val_accuracy: 0.0239 - val_auc: 0.6500 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0725 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 50ms/step - accuracy: 0.0190 - auc: 0.6020 - f1_macro: 6.1285e-04 - f1_weighted: 0.0024 - loss: 5.1940 - top5_accuracy: 0.0905 - val_accuracy: 0.0239 - val_auc: 0.6497 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0707 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0184 - auc: 0.6019 - f1_macro: 5.4946e-04 - f1_weighted: 0.0021 - loss: 5.1933 - top5_accuracy: 0.0917 - val_accuracy: 0.0239 - val_auc: 0.6503 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0710 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0178 - auc: 0.6030 - f1_macro: 5.4366e-04 - f1_weighted: 0.0021 - loss: 5.1907 - top5_accuracy: 0.0911 - val_accuracy: 0.0239 - val_auc: 0.6503 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0705 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0164 - auc: 0.6030 - f1_macro: 4.1904e-04 - f1_weighted: 0.0016 - loss: 5.1881 - top5_accuracy: 0.0900 - val_accuracy: 0.0239 - val_auc: 0.6503 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0692 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0182 - auc: 0.6037 - f1_macro: 4.3703e-04 - f1_weighted: 0.0017 - loss: 5.1874 - top5_accuracy: 0.0912 - val_accuracy: 0.0239 - val_auc: 0.6505 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0692 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0172 - auc: 0.6035 - f1_macro: 4.0268e-04 - f1_weighted: 0.0016 - loss: 5.1862 - top5_accuracy: 0.0925 - val_accuracy: 0.0239 - val_auc: 0.6505 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0694 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0182 - auc: 0.6036 - f1_macro: 5.1453e-04 - f1_weighted: 0.0020 - loss: 5.1857 - top5_accuracy: 0.0927 - val_accuracy: 0.0239 - val_auc: 0.6505 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0690 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0189 - auc: 0.6034 - f1_macro: 6.3623e-04 - f1_weighted: 0.0025 - loss: 5.1851 - top5_accuracy: 0.0924 - val_accuracy: 0.0239 - val_auc: 0.6505 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0688 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0181 - auc: 0.6035 - f1_macro: 5.0796e-04 - f1_weighted: 0.0020 - loss: 5.1848 - top5_accuracy: 0.0916 - val_accuracy: 0.0239 - val_auc: 0.6505 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0685 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0176 - auc: 0.6037 - f1_macro: 5.8525e-04 - f1_weighted: 0.0023 - loss: 5.1854 - top5_accuracy: 0.0928 - val_accuracy: 0.0239 - val_auc: 0.6503 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0688 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0179 - auc: 0.6035 - f1_macro: 4.9901e-04 - f1_weighted: 0.0020 - loss: 5.1845 - top5_accuracy: 0.0929 - val_accuracy: 0.0239 - val_auc: 0.6505 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0679 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0184 - auc: 0.6037 - f1_macro: 5.4508e-04 - f1_weighted: 0.0022 - loss: 5.1843 - top5_accuracy: 0.0926 - val_accuracy: 0.0239 - val_auc: 0.6505 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0677 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0190 - auc: 0.6037 - f1_macro: 5.7333e-04 - f1_weighted: 0.0024 - loss: 5.1840 - top5_accuracy: 0.0920 - val_accuracy: 0.0239 - val_auc: 0.6505 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0678 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0171 - auc: 0.6037 - f1_macro: 4.7666e-04 - f1_weighted: 0.0019 - loss: 5.1829 - top5_accuracy: 0.0920 - val_accuracy: 0.0239 - val_auc: 0.6507 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0667 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0166 - auc: 0.6039 - f1_macro: 5.5560e-04 - f1_weighted: 0.0021 - loss: 5.1827 - top5_accuracy: 0.0915 - val_accuracy: 0.0239 - val_auc: 0.6507 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0665 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0181 - auc: 0.6037 - f1_macro: 5.2422e-04 - f1_weighted: 0.0021 - loss: 5.1832 - top5_accuracy: 0.0932 - val_accuracy: 0.0239 - val_auc: 0.6505 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0673 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0179 - auc: 0.6038 - f1_macro: 4.8558e-04 - f1_weighted: 0.0019 - loss: 5.1827 - top5_accuracy: 0.0918 - val_accuracy: 0.0239 - val_auc: 0.6507 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0668 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0193 - auc: 0.6039 - f1_macro: 6.3700e-04 - f1_weighted: 0.0025 - loss: 5.1820 - top5_accuracy: 0.0924 - val_accuracy: 0.0239 - val_auc: 0.6507 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0663 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0193 - auc: 0.6039 - f1_macro: 5.6440e-04 - f1_weighted: 0.0022 - loss: 5.1820 - top5_accuracy: 0.0921 - val_accuracy: 0.0239 - val_auc: 0.6507 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0667 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0186 - auc: 0.6037 - f1_macro: 5.4169e-04 - f1_weighted: 0.0021 - loss: 5.1828 - top5_accuracy: 0.0929 - val_accuracy: 0.0239 - val_auc: 0.6505 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0672 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0177 - auc: 0.6039 - f1_macro: 5.1496e-04 - f1_weighted: 0.0021 - loss: 5.1813 - top5_accuracy: 0.0915 - val_accuracy: 0.0239 - val_auc: 0.6505 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0665 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0179 - auc: 0.6038 - f1_macro: 5.0290e-04 - f1_weighted: 0.0020 - loss: 5.1808 - top5_accuracy: 0.0922 - val_accuracy: 0.0239 - val_auc: 0.6507 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0669 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m349/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.0190 - auc: 0.6040 - f1_macro: 6.6992e-04 - f1_weighted: 0.0026 - loss: 5.1804 - top5_accuracy: 0.0949\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0190 - auc: 0.6040 - f1_macro: 6.7008e-04 - f1_weighted: 0.0026 - loss: 5.1804 - top5_accuracy: 0.0950 - val_accuracy: 0.0239 - val_auc: 0.6507 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0667 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0193 - auc: 0.6038 - f1_macro: 6.1486e-04 - f1_weighted: 0.0025 - loss: 5.1803 - top5_accuracy: 0.0918 - val_accuracy: 0.0239 - val_auc: 0.6505 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0680 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0182 - auc: 0.6040 - f1_macro: 6.1503e-04 - f1_weighted: 0.0025 - loss: 5.1789 - top5_accuracy: 0.0938 - val_accuracy: 0.0239 - val_auc: 0.6505 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0684 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 27: early stopping\n",
            "Restoring model weights from the end of the best epoch: 20.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training with augmentation: light\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 226ms/step - accuracy: 0.0188 - auc: 0.5967 - f1_macro: 7.6700e-04 - f1_weighted: 0.0030 - loss: 5.5809 - top5_accuracy: 0.0923 - val_accuracy: 0.0250 - val_auc: 0.6486 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0835 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0172 - auc: 0.5970 - f1_macro: 6.1926e-04 - f1_weighted: 0.0023 - loss: 5.1960 - top5_accuracy: 0.0918 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0774 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0174 - auc: 0.5998 - f1_macro: 4.9406e-04 - f1_weighted: 0.0019 - loss: 5.1917 - top5_accuracy: 0.0966 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0797 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0186 - auc: 0.6012 - f1_macro: 5.4059e-04 - f1_weighted: 0.0021 - loss: 5.1902 - top5_accuracy: 0.0939 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0761 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0169 - auc: 0.6021 - f1_macro: 5.9950e-04 - f1_weighted: 0.0023 - loss: 5.1881 - top5_accuracy: 0.0935 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0731 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0169 - auc: 0.6020 - f1_macro: 4.9168e-04 - f1_weighted: 0.0019 - loss: 5.1865 - top5_accuracy: 0.0936 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0729 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0186 - auc: 0.6023 - f1_macro: 6.2581e-04 - f1_weighted: 0.0024 - loss: 5.1862 - top5_accuracy: 0.0944 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0717 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0170 - auc: 0.6022 - f1_macro: 4.9682e-04 - f1_weighted: 0.0019 - loss: 5.1858 - top5_accuracy: 0.0917 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0717 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0184 - auc: 0.6025 - f1_macro: 4.4642e-04 - f1_weighted: 0.0017 - loss: 5.1846 - top5_accuracy: 0.0924 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0715 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0160 - auc: 0.6025 - f1_macro: 3.9480e-04 - f1_weighted: 0.0015 - loss: 5.1837 - top5_accuracy: 0.0932 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0709 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0165 - auc: 0.6022 - f1_macro: 4.0457e-04 - f1_weighted: 0.0016 - loss: 5.1839 - top5_accuracy: 0.0956 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0710 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0183 - auc: 0.6023 - f1_macro: 4.9689e-04 - f1_weighted: 0.0019 - loss: 5.1833 - top5_accuracy: 0.0915 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0708 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0175 - auc: 0.6023 - f1_macro: 4.4112e-04 - f1_weighted: 0.0018 - loss: 5.1845 - top5_accuracy: 0.0949 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0694 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 48ms/step - accuracy: 0.0180 - auc: 0.6025 - f1_macro: 5.7724e-04 - f1_weighted: 0.0023 - loss: 5.1830 - top5_accuracy: 0.0932 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0696 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0177 - auc: 0.6025 - f1_macro: 5.3918e-04 - f1_weighted: 0.0021 - loss: 5.1835 - top5_accuracy: 0.0930 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0696 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0181 - auc: 0.6023 - f1_macro: 5.7262e-04 - f1_weighted: 0.0023 - loss: 5.1834 - top5_accuracy: 0.0926 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0688 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0172 - auc: 0.6026 - f1_macro: 5.3154e-04 - f1_weighted: 0.0021 - loss: 5.1804 - top5_accuracy: 0.0953 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0692 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0184 - auc: 0.6024 - f1_macro: 5.1606e-04 - f1_weighted: 0.0021 - loss: 5.1818 - top5_accuracy: 0.0953 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0688 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0156 - auc: 0.6025 - f1_macro: 4.6296e-04 - f1_weighted: 0.0018 - loss: 5.1817 - top5_accuracy: 0.0927 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0694 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0169 - auc: 0.6026 - f1_macro: 3.2764e-04 - f1_weighted: 0.0013 - loss: 5.1810 - top5_accuracy: 0.0933 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0685 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0186 - auc: 0.6024 - f1_macro: 4.8893e-04 - f1_weighted: 0.0019 - loss: 5.1808 - top5_accuracy: 0.0931 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0683 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0184 - auc: 0.6023 - f1_macro: 5.9584e-04 - f1_weighted: 0.0023 - loss: 5.1818 - top5_accuracy: 0.0946 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0679 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 48ms/step - accuracy: 0.0170 - auc: 0.6025 - f1_macro: 5.3679e-04 - f1_weighted: 0.0021 - loss: 5.1815 - top5_accuracy: 0.0951 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0692 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0168 - auc: 0.6024 - f1_macro: 4.8359e-04 - f1_weighted: 0.0019 - loss: 5.1805 - top5_accuracy: 0.0965 - val_accuracy: 0.0250 - val_auc: 0.6503 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0676 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 48ms/step - accuracy: 0.0170 - auc: 0.6024 - f1_macro: 4.6313e-04 - f1_weighted: 0.0018 - loss: 5.1815 - top5_accuracy: 0.0931 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0679 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0170 - auc: 0.6028 - f1_macro: 4.7227e-04 - f1_weighted: 0.0019 - loss: 5.1805 - top5_accuracy: 0.0938 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0676 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0175 - auc: 0.6023 - f1_macro: 4.1482e-04 - f1_weighted: 0.0017 - loss: 5.1803 - top5_accuracy: 0.0930 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0679 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0178 - auc: 0.6025 - f1_macro: 4.8870e-04 - f1_weighted: 0.0019 - loss: 5.1803 - top5_accuracy: 0.0918 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0672 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0173 - auc: 0.6024 - f1_macro: 3.6512e-04 - f1_weighted: 0.0015 - loss: 5.1791 - top5_accuracy: 0.0928 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0681 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 30/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0195 - auc: 0.6024 - f1_macro: 4.4722e-04 - f1_weighted: 0.0018 - loss: 5.1806 - top5_accuracy: 0.0934 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0671 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 30.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training with augmentation: mixup\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 130ms/step - accuracy: 0.0198 - auc: 0.5931 - f1_macro: 0.0010 - f1_weighted: 0.0037 - loss: 5.5747 - top5_accuracy: 0.0944 - val_accuracy: 0.0250 - val_auc: 0.6492 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0819 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 50ms/step - accuracy: 0.0150 - auc: 0.5971 - f1_macro: 5.8468e-04 - f1_weighted: 0.0023 - loss: 5.1987 - top5_accuracy: 0.0913 - val_accuracy: 0.0250 - val_auc: 0.6491 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0811 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0153 - auc: 0.5999 - f1_macro: 5.7526e-04 - f1_weighted: 0.0022 - loss: 5.1960 - top5_accuracy: 0.0901 - val_accuracy: 0.0250 - val_auc: 0.6491 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0814 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0167 - auc: 0.6016 - f1_macro: 5.9451e-04 - f1_weighted: 0.0023 - loss: 5.1924 - top5_accuracy: 0.0916 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0807 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0174 - auc: 0.6023 - f1_macro: 5.8235e-04 - f1_weighted: 0.0023 - loss: 5.1907 - top5_accuracy: 0.0944 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0791 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0196 - auc: 0.6022 - f1_macro: 7.3572e-04 - f1_weighted: 0.0028 - loss: 5.1906 - top5_accuracy: 0.0918 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0786 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0168 - auc: 0.6027 - f1_macro: 4.3115e-04 - f1_weighted: 0.0017 - loss: 5.1893 - top5_accuracy: 0.0913 - val_accuracy: 0.0250 - val_auc: 0.6504 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0770 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0198 - auc: 0.6024 - f1_macro: 5.7744e-04 - f1_weighted: 0.0023 - loss: 5.1889 - top5_accuracy: 0.0905 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0769 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0193 - auc: 0.6026 - f1_macro: 5.5655e-04 - f1_weighted: 0.0022 - loss: 5.1888 - top5_accuracy: 0.0940 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0755 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0213 - auc: 0.6026 - f1_macro: 7.6783e-04 - f1_weighted: 0.0029 - loss: 5.1877 - top5_accuracy: 0.0929 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0763 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0184 - auc: 0.6027 - f1_macro: 5.2491e-04 - f1_weighted: 0.0021 - loss: 5.1871 - top5_accuracy: 0.0936 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0760 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0185 - auc: 0.6025 - f1_macro: 5.0384e-04 - f1_weighted: 0.0020 - loss: 5.1872 - top5_accuracy: 0.0923 - val_accuracy: 0.0250 - val_auc: 0.6504 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0753 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0195 - auc: 0.6026 - f1_macro: 5.6044e-04 - f1_weighted: 0.0022 - loss: 5.1868 - top5_accuracy: 0.0933 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0754 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0192 - auc: 0.6024 - f1_macro: 4.8159e-04 - f1_weighted: 0.0019 - loss: 5.1872 - top5_accuracy: 0.0952 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0760 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0172 - auc: 0.6026 - f1_macro: 4.6172e-04 - f1_weighted: 0.0019 - loss: 5.1866 - top5_accuracy: 0.0926 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0747 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0202 - auc: 0.6027 - f1_macro: 5.4782e-04 - f1_weighted: 0.0022 - loss: 5.1861 - top5_accuracy: 0.0940 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0757 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0169 - auc: 0.6026 - f1_macro: 4.4229e-04 - f1_weighted: 0.0018 - loss: 5.1869 - top5_accuracy: 0.0928 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0765 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0178 - auc: 0.6026 - f1_macro: 5.2563e-04 - f1_weighted: 0.0021 - loss: 5.1859 - top5_accuracy: 0.0914 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0753 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0174 - auc: 0.6027 - f1_macro: 5.0786e-04 - f1_weighted: 0.0020 - loss: 5.1854 - top5_accuracy: 0.0928 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0745 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0202 - auc: 0.6027 - f1_macro: 4.5961e-04 - f1_weighted: 0.0019 - loss: 5.1856 - top5_accuracy: 0.0938 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0744 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0200 - auc: 0.6026 - f1_macro: 5.1891e-04 - f1_weighted: 0.0021 - loss: 5.1852 - top5_accuracy: 0.0933 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0745 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0210 - auc: 0.6026 - f1_macro: 6.3423e-04 - f1_weighted: 0.0025 - loss: 5.1848 - top5_accuracy: 0.0928 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0753 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0203 - auc: 0.6027 - f1_macro: 5.0632e-04 - f1_weighted: 0.0020 - loss: 5.1854 - top5_accuracy: 0.0940 - val_accuracy: 0.0250 - val_auc: 0.6504 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0744 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0162 - auc: 0.6027 - f1_macro: 4.0372e-04 - f1_weighted: 0.0016 - loss: 5.1839 - top5_accuracy: 0.0940 - val_accuracy: 0.0250 - val_auc: 0.6504 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0736 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0179 - auc: 0.6027 - f1_macro: 5.0808e-04 - f1_weighted: 0.0020 - loss: 5.1852 - top5_accuracy: 0.0944 - val_accuracy: 0.0250 - val_auc: 0.6504 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0735 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0211 - auc: 0.6026 - f1_macro: 5.7246e-04 - f1_weighted: 0.0023 - loss: 5.1852 - top5_accuracy: 0.0933 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0748 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 48ms/step - accuracy: 0.0183 - auc: 0.6027 - f1_macro: 4.9593e-04 - f1_weighted: 0.0020 - loss: 5.1840 - top5_accuracy: 0.0927 - val_accuracy: 0.0250 - val_auc: 0.6504 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0736 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0171 - auc: 0.6027 - f1_macro: 4.5866e-04 - f1_weighted: 0.0018 - loss: 5.1849 - top5_accuracy: 0.0929 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0739 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0190 - auc: 0.6028 - f1_macro: 5.0135e-04 - f1_weighted: 0.0020 - loss: 5.1852 - top5_accuracy: 0.0932 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0740 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 30/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.0223 - auc: 0.6028 - f1_macro: 5.9555e-04 - f1_weighted: 0.0024 - loss: 5.1835 - top5_accuracy: 0.0930\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0223 - auc: 0.6028 - f1_macro: 5.9557e-04 - f1_weighted: 0.0024 - loss: 5.1835 - top5_accuracy: 0.0931 - val_accuracy: 0.0250 - val_auc: 0.6504 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0738 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 25.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training with augmentation: medium\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 238ms/step - accuracy: 0.0191 - auc: 0.5986 - f1_macro: 9.0356e-04 - f1_weighted: 0.0032 - loss: 5.6224 - top5_accuracy: 0.0988 - val_accuracy: 0.0239 - val_auc: 0.6501 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0724 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0184 - auc: 0.5991 - f1_macro: 8.6106e-04 - f1_weighted: 0.0034 - loss: 5.1878 - top5_accuracy: 0.0947 - val_accuracy: 0.0250 - val_auc: 0.6510 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0690 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0182 - auc: 0.6010 - f1_macro: 7.0046e-04 - f1_weighted: 0.0029 - loss: 5.1859 - top5_accuracy: 0.0950 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0661 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0186 - auc: 0.6029 - f1_macro: 9.0011e-04 - f1_weighted: 0.0036 - loss: 5.1832 - top5_accuracy: 0.0950 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0660 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0199 - auc: 0.6039 - f1_macro: 7.1089e-04 - f1_weighted: 0.0028 - loss: 5.1823 - top5_accuracy: 0.0974 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0659 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0191 - auc: 0.6041 - f1_macro: 6.5348e-04 - f1_weighted: 0.0026 - loss: 5.1812 - top5_accuracy: 0.0957 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0657 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0200 - auc: 0.6043 - f1_macro: 6.6304e-04 - f1_weighted: 0.0028 - loss: 5.1782 - top5_accuracy: 0.0961 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0653 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0194 - auc: 0.6042 - f1_macro: 6.5420e-04 - f1_weighted: 0.0026 - loss: 5.1790 - top5_accuracy: 0.0973 - val_accuracy: 0.0250 - val_auc: 0.6501 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0649 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0212 - auc: 0.6042 - f1_macro: 8.0876e-04 - f1_weighted: 0.0033 - loss: 5.1783 - top5_accuracy: 0.0951 - val_accuracy: 0.0250 - val_auc: 0.6503 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0645 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0195 - auc: 0.6043 - f1_macro: 9.2419e-04 - f1_weighted: 0.0036 - loss: 5.1780 - top5_accuracy: 0.0956 - val_accuracy: 0.0250 - val_auc: 0.6505 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0645 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0188 - auc: 0.6045 - f1_macro: 8.1059e-04 - f1_weighted: 0.0033 - loss: 5.1765 - top5_accuracy: 0.0960 - val_accuracy: 0.0250 - val_auc: 0.6505 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0647 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0217 - auc: 0.6043 - f1_macro: 7.7896e-04 - f1_weighted: 0.0032 - loss: 5.1772 - top5_accuracy: 0.0959 - val_accuracy: 0.0250 - val_auc: 0.6505 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0641 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0203 - auc: 0.6043 - f1_macro: 7.6944e-04 - f1_weighted: 0.0032 - loss: 5.1768 - top5_accuracy: 0.0961 - val_accuracy: 0.0250 - val_auc: 0.6505 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0641 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0193 - auc: 0.6045 - f1_macro: 5.6515e-04 - f1_weighted: 0.0023 - loss: 5.1767 - top5_accuracy: 0.0958 - val_accuracy: 0.0250 - val_auc: 0.6505 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0639 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0197 - auc: 0.6044 - f1_macro: 6.1149e-04 - f1_weighted: 0.0025 - loss: 5.1764 - top5_accuracy: 0.0975 - val_accuracy: 0.0250 - val_auc: 0.6503 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0639 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0219 - auc: 0.6044 - f1_macro: 8.0592e-04 - f1_weighted: 0.0032 - loss: 5.1758 - top5_accuracy: 0.0966 - val_accuracy: 0.0250 - val_auc: 0.6507 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0641 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0197 - auc: 0.6044 - f1_macro: 7.0144e-04 - f1_weighted: 0.0028 - loss: 5.1751 - top5_accuracy: 0.0974 - val_accuracy: 0.0250 - val_auc: 0.6505 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0640 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0200 - auc: 0.6043 - f1_macro: 6.2765e-04 - f1_weighted: 0.0025 - loss: 5.1751 - top5_accuracy: 0.0965 - val_accuracy: 0.0250 - val_auc: 0.6507 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0635 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0185 - auc: 0.6045 - f1_macro: 5.1836e-04 - f1_weighted: 0.0021 - loss: 5.1741 - top5_accuracy: 0.0949 - val_accuracy: 0.0250 - val_auc: 0.6507 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0637 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0225 - auc: 0.6045 - f1_macro: 7.6957e-04 - f1_weighted: 0.0031 - loss: 5.1740 - top5_accuracy: 0.0976 - val_accuracy: 0.0250 - val_auc: 0.6509 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0640 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0183 - auc: 0.6044 - f1_macro: 5.9770e-04 - f1_weighted: 0.0024 - loss: 5.1768 - top5_accuracy: 0.0959 - val_accuracy: 0.0250 - val_auc: 0.6507 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0638 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0189 - auc: 0.6044 - f1_macro: 6.1834e-04 - f1_weighted: 0.0025 - loss: 5.1738 - top5_accuracy: 0.0959 - val_accuracy: 0.0250 - val_auc: 0.6505 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0638 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m349/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.0195 - auc: 0.6043 - f1_macro: 7.9093e-04 - f1_weighted: 0.0031 - loss: 5.1755 - top5_accuracy: 0.0986\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0195 - auc: 0.6043 - f1_macro: 7.9094e-04 - f1_weighted: 0.0031 - loss: 5.1755 - top5_accuracy: 0.0986 - val_accuracy: 0.0250 - val_auc: 0.6507 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0641 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0192 - auc: 0.6047 - f1_macro: 5.3295e-04 - f1_weighted: 0.0022 - loss: 5.1714 - top5_accuracy: 0.0968 - val_accuracy: 0.0250 - val_auc: 0.6503 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0669 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0215 - auc: 0.6047 - f1_macro: 6.2141e-04 - f1_weighted: 0.0026 - loss: 5.1698 - top5_accuracy: 0.0977 - val_accuracy: 0.0250 - val_auc: 0.6505 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0666 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 25: early stopping\n",
            "Restoring model weights from the end of the best epoch: 18.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training with augmentation: heavy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 247ms/step - accuracy: 0.0196 - auc: 0.6005 - f1_macro: 9.1333e-04 - f1_weighted: 0.0036 - loss: 5.6320 - top5_accuracy: 0.0984 - val_accuracy: 0.0250 - val_auc: 0.6474 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0755 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0181 - auc: 0.6062 - f1_macro: 5.9423e-04 - f1_weighted: 0.0025 - loss: 5.1797 - top5_accuracy: 0.0983 - val_accuracy: 0.0250 - val_auc: 0.6456 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0744 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0166 - auc: 0.6076 - f1_macro: 5.4869e-04 - f1_weighted: 0.0023 - loss: 5.1765 - top5_accuracy: 0.1002 - val_accuracy: 0.0250 - val_auc: 0.6504 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0746 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0177 - auc: 0.6088 - f1_macro: 5.6405e-04 - f1_weighted: 0.0024 - loss: 5.1750 - top5_accuracy: 0.0967 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0746 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 48ms/step - accuracy: 0.0163 - auc: 0.6099 - f1_macro: 4.9737e-04 - f1_weighted: 0.0020 - loss: 5.1724 - top5_accuracy: 0.0952 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0753 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 48ms/step - accuracy: 0.0173 - auc: 0.6097 - f1_macro: 5.2398e-04 - f1_weighted: 0.0022 - loss: 5.1736 - top5_accuracy: 0.0987 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0750 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m349/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.0180 - auc: 0.6104 - f1_macro: 5.3301e-04 - f1_weighted: 0.0022 - loss: 5.1701 - top5_accuracy: 0.0992\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0180 - auc: 0.6104 - f1_macro: 5.3415e-04 - f1_weighted: 0.0022 - loss: 5.1702 - top5_accuracy: 0.0992 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0749 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0187 - auc: 0.6109 - f1_macro: 4.1662e-04 - f1_weighted: 0.0017 - loss: 5.1664 - top5_accuracy: 0.0997 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0743 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0180 - auc: 0.6109 - f1_macro: 5.2171e-04 - f1_weighted: 0.0022 - loss: 5.1657 - top5_accuracy: 0.0986 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0745 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0179 - auc: 0.6109 - f1_macro: 4.7613e-04 - f1_weighted: 0.0020 - loss: 5.1650 - top5_accuracy: 0.0980 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0743 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0180 - auc: 0.6108 - f1_macro: 4.4515e-04 - f1_weighted: 0.0019 - loss: 5.1642 - top5_accuracy: 0.1023 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0746 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0193 - auc: 0.6108 - f1_macro: 7.1149e-04 - f1_weighted: 0.0029 - loss: 5.1637 - top5_accuracy: 0.0975 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0741 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0189 - auc: 0.6109 - f1_macro: 5.2482e-04 - f1_weighted: 0.0022 - loss: 5.1638 - top5_accuracy: 0.0968 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0744 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0190 - auc: 0.6109 - f1_macro: 5.2133e-04 - f1_weighted: 0.0022 - loss: 5.1633 - top5_accuracy: 0.0960 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0743 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0182 - auc: 0.6110 - f1_macro: 5.2901e-04 - f1_weighted: 0.0023 - loss: 5.1633 - top5_accuracy: 0.0982 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0748 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0180 - auc: 0.6109 - f1_macro: 5.6755e-04 - f1_weighted: 0.0022 - loss: 5.1624 - top5_accuracy: 0.0975 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0743 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.0176 - auc: 0.6108 - f1_macro: 3.9822e-04 - f1_weighted: 0.0016 - loss: 5.1641 - top5_accuracy: 0.0982\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0176 - auc: 0.6108 - f1_macro: 3.9856e-04 - f1_weighted: 0.0016 - loss: 5.1641 - top5_accuracy: 0.0982 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0743 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0176 - auc: 0.6110 - f1_macro: 3.3879e-04 - f1_weighted: 0.0014 - loss: 5.1614 - top5_accuracy: 0.0993 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0731 - val_top5_accuracy: 0.1185 - learning_rate: 2.5000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0167 - auc: 0.6108 - f1_macro: 3.4340e-04 - f1_weighted: 0.0015 - loss: 5.1615 - top5_accuracy: 0.1003 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0731 - val_top5_accuracy: 0.1185 - learning_rate: 2.5000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0183 - auc: 0.6109 - f1_macro: 4.2269e-04 - f1_weighted: 0.0018 - loss: 5.1612 - top5_accuracy: 0.0993 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0731 - val_top5_accuracy: 0.1185 - learning_rate: 2.5000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0185 - auc: 0.6109 - f1_macro: 3.7766e-04 - f1_weighted: 0.0016 - loss: 5.1604 - top5_accuracy: 0.0984 - val_accuracy: 0.0250 - val_auc: 0.6500 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0731 - val_top5_accuracy: 0.1185 - learning_rate: 2.5000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0205 - auc: 0.6109 - f1_macro: 6.5186e-04 - f1_weighted: 0.0029 - loss: 5.1610 - top5_accuracy: 0.0993 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0730 - val_top5_accuracy: 0.1185 - learning_rate: 2.5000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0185 - auc: 0.6109 - f1_macro: 3.9277e-04 - f1_weighted: 0.0016 - loss: 5.1609 - top5_accuracy: 0.0988 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0728 - val_top5_accuracy: 0.1185 - learning_rate: 2.5000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0195 - auc: 0.6108 - f1_macro: 6.2063e-04 - f1_weighted: 0.0028 - loss: 5.1610 - top5_accuracy: 0.0987 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0728 - val_top5_accuracy: 0.1185 - learning_rate: 2.5000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0185 - auc: 0.6109 - f1_macro: 4.5138e-04 - f1_weighted: 0.0019 - loss: 5.1600 - top5_accuracy: 0.0995 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0729 - val_top5_accuracy: 0.1185 - learning_rate: 2.5000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.0196 - auc: 0.6109 - f1_macro: 4.8233e-04 - f1_weighted: 0.0020 - loss: 5.1604 - top5_accuracy: 0.0994 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0728 - val_top5_accuracy: 0.1185 - learning_rate: 2.5000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0182 - auc: 0.6111 - f1_macro: 4.0558e-04 - f1_weighted: 0.0017 - loss: 5.1590 - top5_accuracy: 0.0991 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0730 - val_top5_accuracy: 0.1185 - learning_rate: 2.5000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.0184 - auc: 0.6108 - f1_macro: 4.7085e-04 - f1_weighted: 0.0020 - loss: 5.1605 - top5_accuracy: 0.0986\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0184 - auc: 0.6108 - f1_macro: 4.7120e-04 - f1_weighted: 0.0020 - loss: 5.1606 - top5_accuracy: 0.0986 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0732 - val_top5_accuracy: 0.1185 - learning_rate: 2.5000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0172 - auc: 0.6109 - f1_macro: 3.0686e-04 - f1_weighted: 0.0012 - loss: 5.1597 - top5_accuracy: 0.0984 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0719 - val_top5_accuracy: 0.1185 - learning_rate: 1.2500e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0186 - auc: 0.6109 - f1_macro: 5.0394e-04 - f1_weighted: 0.0022 - loss: 5.1592 - top5_accuracy: 0.0981 - val_accuracy: 0.0250 - val_auc: 0.6502 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0717 - val_top5_accuracy: 0.1185 - learning_rate: 1.2500e-04\n",
            "Restoring model weights from the end of the best epoch: 30.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training with augmentation: grayscale_plus\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 221ms/step - accuracy: 0.0223 - auc: 0.5956 - f1_macro: 0.0010 - f1_weighted: 0.0040 - loss: 5.7103 - top5_accuracy: 0.0949 - val_accuracy: 0.0250 - val_auc: 0.6509 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0679 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 51ms/step - accuracy: 0.0223 - auc: 0.5992 - f1_macro: 7.5033e-04 - f1_weighted: 0.0030 - loss: 5.1957 - top5_accuracy: 0.0900 - val_accuracy: 0.0250 - val_auc: 0.6509 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0684 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 50ms/step - accuracy: 0.0215 - auc: 0.6022 - f1_macro: 5.1596e-04 - f1_weighted: 0.0021 - loss: 5.1908 - top5_accuracy: 0.0923 - val_accuracy: 0.0250 - val_auc: 0.6507 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0716 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0201 - auc: 0.6025 - f1_macro: 4.9034e-04 - f1_weighted: 0.0020 - loss: 5.1891 - top5_accuracy: 0.0923 - val_accuracy: 0.0250 - val_auc: 0.6507 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0716 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0226 - auc: 0.6030 - f1_macro: 5.9696e-04 - f1_weighted: 0.0024 - loss: 5.1871 - top5_accuracy: 0.0922 - val_accuracy: 0.0250 - val_auc: 0.6506 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0716 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m349/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0203 - auc: 0.6033 - f1_macro: 4.1785e-04 - f1_weighted: 0.0017 - loss: 5.1845 - top5_accuracy: 0.0955\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0203 - auc: 0.6033 - f1_macro: 4.1794e-04 - f1_weighted: 0.0017 - loss: 5.1845 - top5_accuracy: 0.0955 - val_accuracy: 0.0250 - val_auc: 0.6504 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0721 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0204 - auc: 0.6036 - f1_macro: 5.6144e-04 - f1_weighted: 0.0022 - loss: 5.1820 - top5_accuracy: 0.0921 - val_accuracy: 0.0250 - val_auc: 0.6504 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0715 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0217 - auc: 0.6037 - f1_macro: 4.1339e-04 - f1_weighted: 0.0018 - loss: 5.1801 - top5_accuracy: 0.0911 - val_accuracy: 0.0250 - val_auc: 0.6505 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0715 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training with augmentation: randaugment\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 179ms/step - accuracy: 0.0188 - auc: 0.6012 - f1_macro: 9.8815e-04 - f1_weighted: 0.0030 - loss: 5.7420 - top5_accuracy: 0.0960 - val_accuracy: 0.0250 - val_auc: 0.6483 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.1026 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 50ms/step - accuracy: 0.0211 - auc: 0.6033 - f1_macro: 6.5851e-04 - f1_weighted: 0.0027 - loss: 5.1877 - top5_accuracy: 0.0953 - val_accuracy: 0.0250 - val_auc: 0.6493 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0934 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 50ms/step - accuracy: 0.0184 - auc: 0.6060 - f1_macro: 5.7472e-04 - f1_weighted: 0.0023 - loss: 5.1830 - top5_accuracy: 0.0972 - val_accuracy: 0.0250 - val_auc: 0.6494 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0891 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0180 - auc: 0.6065 - f1_macro: 6.3150e-04 - f1_weighted: 0.0026 - loss: 5.1820 - top5_accuracy: 0.0980 - val_accuracy: 0.0250 - val_auc: 0.6494 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0895 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0162 - auc: 0.6067 - f1_macro: 5.5347e-04 - f1_weighted: 0.0022 - loss: 5.1790 - top5_accuracy: 0.0974 - val_accuracy: 0.0250 - val_auc: 0.6494 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0881 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0194 - auc: 0.6069 - f1_macro: 5.9385e-04 - f1_weighted: 0.0024 - loss: 5.1781 - top5_accuracy: 0.0968 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0854 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0200 - auc: 0.6073 - f1_macro: 7.1537e-04 - f1_weighted: 0.0030 - loss: 5.1779 - top5_accuracy: 0.0965 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0850 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0197 - auc: 0.6073 - f1_macro: 6.5241e-04 - f1_weighted: 0.0028 - loss: 5.1762 - top5_accuracy: 0.0936 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0847 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0193 - auc: 0.6075 - f1_macro: 5.9507e-04 - f1_weighted: 0.0024 - loss: 5.1765 - top5_accuracy: 0.0985 - val_accuracy: 0.0250 - val_auc: 0.6494 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0863 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0177 - auc: 0.6075 - f1_macro: 6.6505e-04 - f1_weighted: 0.0027 - loss: 5.1766 - top5_accuracy: 0.0966 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0846 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0158 - auc: 0.6076 - f1_macro: 5.5214e-04 - f1_weighted: 0.0023 - loss: 5.1750 - top5_accuracy: 0.0973 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0850 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0215 - auc: 0.6072 - f1_macro: 6.6412e-04 - f1_weighted: 0.0028 - loss: 5.1763 - top5_accuracy: 0.0948 - val_accuracy: 0.0250 - val_auc: 0.6494 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0850 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0204 - auc: 0.6076 - f1_macro: 5.9534e-04 - f1_weighted: 0.0026 - loss: 5.1740 - top5_accuracy: 0.0971 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0842 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0188 - auc: 0.6077 - f1_macro: 5.2991e-04 - f1_weighted: 0.0022 - loss: 5.1758 - top5_accuracy: 0.0963 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0844 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0201 - auc: 0.6074 - f1_macro: 6.4793e-04 - f1_weighted: 0.0028 - loss: 5.1751 - top5_accuracy: 0.0978 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0845 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0170 - auc: 0.6076 - f1_macro: 5.0674e-04 - f1_weighted: 0.0021 - loss: 5.1744 - top5_accuracy: 0.0993 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0839 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0216 - auc: 0.6069 - f1_macro: 7.5307e-04 - f1_weighted: 0.0032 - loss: 5.1747 - top5_accuracy: 0.0989 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0841 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0192 - auc: 0.6076 - f1_macro: 6.3027e-04 - f1_weighted: 0.0026 - loss: 5.1748 - top5_accuracy: 0.0984 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0842 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0188 - auc: 0.6075 - f1_macro: 6.1982e-04 - f1_weighted: 0.0026 - loss: 5.1750 - top5_accuracy: 0.0950 - val_accuracy: 0.0239 - val_auc: 0.6498 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0844 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0192 - auc: 0.6074 - f1_macro: 7.4756e-04 - f1_weighted: 0.0030 - loss: 5.1726 - top5_accuracy: 0.0973 - val_accuracy: 0.0239 - val_auc: 0.6498 - val_f1_macro: 2.3138e-04 - val_f1_weighted: 0.0011 - val_loss: 5.0851 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0207 - auc: 0.6075 - f1_macro: 6.9253e-04 - f1_weighted: 0.0029 - loss: 5.1750 - top5_accuracy: 0.0982\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0207 - auc: 0.6075 - f1_macro: 6.9266e-04 - f1_weighted: 0.0029 - loss: 5.1750 - top5_accuracy: 0.0982 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0843 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0182 - auc: 0.6076 - f1_macro: 6.0186e-04 - f1_weighted: 0.0025 - loss: 5.1712 - top5_accuracy: 0.0975 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0773 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0194 - auc: 0.6076 - f1_macro: 5.9086e-04 - f1_weighted: 0.0024 - loss: 5.1712 - top5_accuracy: 0.0985 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0772 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0188 - auc: 0.6075 - f1_macro: 5.2214e-04 - f1_weighted: 0.0022 - loss: 5.1715 - top5_accuracy: 0.0954 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0773 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0203 - auc: 0.6077 - f1_macro: 5.9017e-04 - f1_weighted: 0.0026 - loss: 5.1719 - top5_accuracy: 0.0964 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0769 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0193 - auc: 0.6078 - f1_macro: 5.5671e-04 - f1_weighted: 0.0024 - loss: 5.1704 - top5_accuracy: 0.0967 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0764 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0189 - auc: 0.6077 - f1_macro: 4.9173e-04 - f1_weighted: 0.0020 - loss: 5.1715 - top5_accuracy: 0.0976 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0765 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0197 - auc: 0.6079 - f1_macro: 4.8728e-04 - f1_weighted: 0.0021 - loss: 5.1698 - top5_accuracy: 0.0964 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0767 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0214 - auc: 0.6076 - f1_macro: 4.9031e-04 - f1_weighted: 0.0021 - loss: 5.1704 - top5_accuracy: 0.0986 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0770 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0199 - auc: 0.6077 - f1_macro: 5.0306e-04 - f1_weighted: 0.0021 - loss: 5.1707 - top5_accuracy: 0.0974 - val_accuracy: 0.0250 - val_auc: 0.6498 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.0764 - val_top5_accuracy: 0.1185 - learning_rate: 5.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 26.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# Display the table\n",
        "display(results_df.round(4))\n"
      ],
      "metadata": {
        "id": "bIiHloxBzOgf",
        "outputId": "25cfddea-f9d1-4474-a674-31f75f5415ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     augmentation  train_loss  val_loss  train_accuracy  val_accuracy  \\\n",
              "0            none      5.1698    5.0663          0.0203        0.0239   \n",
              "1           light      5.1700    5.0671          0.0204        0.0250   \n",
              "2           mixup      5.1701    5.0735          0.0204        0.0250   \n",
              "3          medium      5.1694    5.0635          0.0199        0.0250   \n",
              "4           heavy      5.1673    5.0717          0.0208        0.0250   \n",
              "5  grayscale_plus      5.1755    5.0679          0.0204        0.0250   \n",
              "6     randaugment      5.1685    5.0764          0.0206        0.0250   \n",
              "\n",
              "   train_f1_macro  val_f1_macro  val_f1_weighted  \n",
              "0          0.0002        0.0002           0.0011  \n",
              "1          0.0002        0.0002           0.0012  \n",
              "2          0.0002        0.0002           0.0012  \n",
              "3          0.0002        0.0002           0.0012  \n",
              "4          0.0002        0.0002           0.0012  \n",
              "5          0.0002        0.0002           0.0012  \n",
              "6          0.0002        0.0002           0.0012  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3615f8dd-0b3c-4d39-a12d-e05e4d1c8b2c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>augmentation</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>train_f1_macro</th>\n",
              "      <th>val_f1_macro</th>\n",
              "      <th>val_f1_weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>none</td>\n",
              "      <td>5.1698</td>\n",
              "      <td>5.0663</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0239</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>light</td>\n",
              "      <td>5.1700</td>\n",
              "      <td>5.0671</td>\n",
              "      <td>0.0204</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mixup</td>\n",
              "      <td>5.1701</td>\n",
              "      <td>5.0735</td>\n",
              "      <td>0.0204</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>medium</td>\n",
              "      <td>5.1694</td>\n",
              "      <td>5.0635</td>\n",
              "      <td>0.0199</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>heavy</td>\n",
              "      <td>5.1673</td>\n",
              "      <td>5.0717</td>\n",
              "      <td>0.0208</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>grayscale_plus</td>\n",
              "      <td>5.1755</td>\n",
              "      <td>5.0679</td>\n",
              "      <td>0.0204</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>randaugment</td>\n",
              "      <td>5.1685</td>\n",
              "      <td>5.0764</td>\n",
              "      <td>0.0206</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3615f8dd-0b3c-4d39-a12d-e05e4d1c8b2c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3615f8dd-0b3c-4d39-a12d-e05e4d1c8b2c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3615f8dd-0b3c-4d39-a12d-e05e4d1c8b2c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-904ca6a1-9d2f-4197-9eaf-993031aa7658\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-904ca6a1-9d2f-4197-9eaf-993031aa7658')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-904ca6a1-9d2f-4197-9eaf-993031aa7658 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(results_df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"augmentation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"none\",\n          \"light\",\n          \"grayscale_plus\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0025867795753463955,\n        \"min\": 5.1673,\n        \"max\": 5.1755,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          5.1698,\n          5.17,\n          5.1755\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004527850325643186,\n        \"min\": 5.0635,\n        \"max\": 5.0764,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          5.0663,\n          5.0671,\n          5.0679\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00027688746209726873,\n        \"min\": 0.0199,\n        \"max\": 0.0208,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0204,\n          0.0206,\n          0.0199\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00041576092031015,\n        \"min\": 0.0239,\n        \"max\": 0.025,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.025,\n          0.0239\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.927680476887095e-20,\n        \"min\": 0.0002,\n        \"max\": 0.0002,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.927680476887095e-20,\n        \"min\": 0.0002,\n        \"max\": 0.0002,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_f1_weighted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.779644730092266e-05,\n        \"min\": 0.0011,\n        \"max\": 0.0012,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0012\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melt the DataFrame for seaborn plotting\n",
        "metrics_to_plot = ['train_accuracy', 'val_accuracy']\n",
        "melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "                            var_name='metric', value_name='value')\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "plt.title(\"Comparison of Accuracy Across Augmentation Strategies\")\n",
        "plt.ylim(0, 0.4)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "36Ae5s5DzRC2",
        "outputId": "c013fb1f-b242-4ea6-fc2b-8af08d34a66a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhI2UMVt_0QB"
      },
      "source": [
        "## 4.3 ZF net - No oversampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud-PuFlY_0QB"
      },
      "source": [
        "It’s very similar to AlexNet but with:\n",
        "\n",
        "Smaller initial filters (7×7 instead of 11×11),\n",
        "Smaller strides,\n",
        "Overall more fine-grained feature extraction early on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z39N7eUo_0QB",
        "outputId": "b19d6b02-9664-4fa6-e8e5-05e66698e558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m14,208\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │           \u001b[38;5;34m384\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m614,656\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │       \u001b[38;5;34m885,120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,327,488\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m884,992\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36864\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │   \u001b[38;5;34m150,999,040\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m16,781,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m202\u001b[0m)            │       \u001b[38;5;34m827,594\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,208</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">614,656</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">885,120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,327,488</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">884,992</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36864</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │   <span style=\"color: #00af00; text-decoration-color: #00af00\">150,999,040</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">827,594</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m172,335,818\u001b[0m (657.41 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">172,335,818</span> (657.41 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m172,335,114\u001b[0m (657.41 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">172,335,114</span> (657.41 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def build_zfnet(input_shape=(224, 224, 3), num_classes=202):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Conv Layer 1\n",
        "    model.add(Conv2D(96, (7, 7), strides=2, activation='relu', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
        "\n",
        "    # Conv Layer 2\n",
        "    model.add(Conv2D(256, (5, 5), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
        "\n",
        "    # Conv Layer 3\n",
        "    model.add(Conv2D(384, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "    # Conv Layer 4\n",
        "    model.add(Conv2D(384, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "    # Conv Layer 5\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
        "\n",
        "    # Fully connected layers\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(1e-4)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu', kernel_regularizer=l2(1e-4)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_zfnet()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the preprocessor\n",
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Loop through each augmentation\n",
        "for aug in augmentations_to_test:\n",
        "    print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "    model = build_zfnet()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "    if aug==\"grayscale_plus\":\n",
        "      val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment='grayscale', oversampling=False)\n",
        "    else:\n",
        "      val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "    # Initialize the experiment\n",
        "    experiment = Experiment(\n",
        "        model=model,\n",
        "        train_ds=train_ds,\n",
        "        val_ds=val_ds,\n",
        "        experiment_name=f\"zfnet_with_{aug}_no_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "        batch_size=32,\n",
        "        image_size=(224, 224),\n",
        "        save_model = False\n",
        "    )\n",
        "\n",
        "    # Run the experiment\n",
        "    history = experiment.run_experiment(callbacks=callbacks, epochs=30)\n",
        "\n",
        "    # Predict entire validation set at once\n",
        "    preds = model.predict(val_ds)\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Extract true labels in order\n",
        "    y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "    # Compute metrics\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Store in results\n",
        "    train_eval = model.evaluate(train_ds, verbose=0)\n",
        "    val_eval = model.evaluate(val_ds, verbose=0)\n",
        "\n",
        "    metric_names = [\"loss\", \"accuracy\", \"auc\", \"f1_macro\", \"f1_weighted\", \"top5_accuracy\"]\n",
        "\n",
        "    train_metrics = dict(zip(metric_names, train_eval))\n",
        "    val_metrics = dict(zip(metric_names, val_eval))\n",
        "\n",
        "    # Results\n",
        "    results[aug] = {\n",
        "        \"train_loss\": train_metrics[\"loss\"],\n",
        "        \"val_loss\": val_metrics[\"loss\"],\n",
        "\n",
        "        \"train_accuracy\": train_metrics[\"accuracy\"],\n",
        "        \"val_accuracy\": val_metrics[\"accuracy\"],\n",
        "\n",
        "        \"train_f1_macro\": train_metrics.get(\"f1_macro\"),\n",
        "        \"val_f1_macro\": val_metrics.get(\"f1_macro\"),\n",
        "\n",
        "        \"val_f1_weighted\": val_metrics.get(\"f1_weighted\")\n",
        "    }"
      ],
      "metadata": {
        "id": "yvxMRqF4ljNM",
        "outputId": "9f64fc7e-dd30-4a5f-f1ec-1b016e00e862",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: none\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-33-0be3b651fde0>\", line 40, in <cell line: 0>\n\n  File \"/content/drive/MyDrive/FACULDADE/mestrado/classes.py\", line 708, in run_experiment\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nOut of memory while trying to allocate 2112389904 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_multi_step_on_iterator_3677140]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-0be3b651fde0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Run the experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Predict entire validation set at once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/FACULDADE/mestrado/classes.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, epochs, callbacks)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         history = self.model.fit(\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-33-0be3b651fde0>\", line 40, in <cell line: 0>\n\n  File \"/content/drive/MyDrive/FACULDADE/mestrado/classes.py\", line 708, in run_experiment\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nOut of memory while trying to allocate 2112389904 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_multi_step_on_iterator_3677140]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# Display the table\n",
        "display(results_df.round(4))\n"
      ],
      "metadata": {
        "id": "YSKxChIFzByE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melt the DataFrame for seaborn plotting\n",
        "metrics_to_plot = ['train_accuracy', 'val_accuracy']\n",
        "melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "                            var_name='metric', value_name='value')\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "plt.title(\"Comparison of Accuracy Across Augmentation Strategies\")\n",
        "plt.ylim(0, 0.4)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zw4VWRptzCJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyWCYHW4_0QF"
      },
      "outputs": [],
      "source": [
        "# # Initialize the preprocessor\n",
        "# batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "# image_size = (224, 224)\n",
        "\n",
        "# preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# # Store results\n",
        "# results = {}\n",
        "\n",
        "# # Loop through each augmentation\n",
        "# for aug in augmentations_to_test:\n",
        "#     print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "#     model = build_zfnet()\n",
        "\n",
        "#     model.compile(\n",
        "#         optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "#         loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "#         metrics=metrics\n",
        "#     )\n",
        "\n",
        "#     train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "#     train_ds_sampled, class_names = preprocess.load_img(data_dir=\"data/rare_species/train_sampled\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "#     val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "#     test_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/test\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "#     # Initialize the experiment\n",
        "#     experiment = Experiment(\n",
        "#         model=model,\n",
        "#         train_ds=train_ds_sampled,\n",
        "#         val_ds=val_ds,\n",
        "#         experiment_name=f\"zfnet_with_{aug}_no_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "#         batch_size=32,\n",
        "#         image_size=(224, 224),\n",
        "#         save_model=False\n",
        "#     )\n",
        "\n",
        "#     # Run the experiment\n",
        "#     history = experiment.run_experiment(callbacks=callbacks, epochs=40)\n",
        "\n",
        "#     # Predict entire validation set at once\n",
        "#     preds = model.predict(val_ds)\n",
        "#     y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "#     # Extract true labels in order\n",
        "#     y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "#     # Compute metrics\n",
        "#     f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "#     f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "#     precision = precision_score(y_true, y_pred, average='weighted')\n",
        "#     recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "#     # Store in results\n",
        "#     results[aug] = {\n",
        "#         \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "#         \"f1_macro\": f1_macro,\n",
        "#         \"f1_weighted\": f1_weighted,\n",
        "#         \"precision\": precision,\n",
        "#         \"recall\": recall\n",
        "#     }\n",
        "\n",
        "#     print(f\"Finished '{aug}'\")\n",
        "#     print(f\"  Accuracy:      {results[aug]['accuracy']:.4f}\")\n",
        "#     print(f\"  F1 (macro):    {results[aug]['f1_macro']:.4f}\")\n",
        "#     print(f\"  F1 (weighted): {results[aug]['f1_weighted']:.4f}\")\n",
        "#     print(f\"  Precision:     {results[aug]['precision']:.4f}\")\n",
        "#     print(f\"  Recall:        {results[aug]['recall']:.4f}\")\n",
        "\n",
        "#     # Clear memory to avoid OOM\n",
        "#     del model\n",
        "#     del experiment\n",
        "#     K.clear_session()\n",
        "#     gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJ9DH3AK_0QF"
      },
      "outputs": [],
      "source": [
        "# # Convert results to a DataFrame\n",
        "# results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "# results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# # Display the table\n",
        "# display(results_df.round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gatsKB-M_0QF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Melt the DataFrame for seaborn plotting\n",
        "# metrics_to_plot = ['accuracy', 'f1_macro', 'f1_weighted', 'precision', 'recall']\n",
        "# melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "#                             var_name='metric', value_name='value')\n",
        "\n",
        "# # Plot using seaborn\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "# plt.title(\"Comparison of Metrics Across Augmentation Strategies\")\n",
        "# plt.ylim(0, 0.4)\n",
        "# plt.xticks(rotation=45)\n",
        "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-8J9F9vSmznr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ZFNet with oversampling"
      ],
      "metadata": {
        "id": "FfJJ4K8MyfH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the preprocessor\n",
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Loop through each augmentation\n",
        "for aug in augmentations_to_test:\n",
        "    print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "    model = build_zfnet()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=True, shuffle=True)\n",
        "    if aug==\"grayscale_plus\":\n",
        "      val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment='grayscale', oversampling=False)\n",
        "    else:\n",
        "      val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "    # Initialize the experiment\n",
        "    experiment = Experiment(\n",
        "        model=model,\n",
        "        train_ds=train_ds,\n",
        "        val_ds=val_ds,\n",
        "        experiment_name=f\"zfnet_with_{aug}_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "        batch_size=32,\n",
        "        image_size=(224, 224),\n",
        "        save_model = False\n",
        "    )\n",
        "\n",
        "    # Run the experiment\n",
        "    history = experiment.run_experiment(callbacks=callbacks, epochs=30)\n",
        "\n",
        "    # Predict entire validation set at once\n",
        "    preds = model.predict(val_ds)\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Extract true labels in order\n",
        "    y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "    # Compute metrics\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Store in results\n",
        "    train_eval = model.evaluate(train_ds, verbose=0)\n",
        "    val_eval = model.evaluate(val_ds, verbose=0)\n",
        "\n",
        "    metric_names = [\"loss\", \"accuracy\", \"auc\", \"f1_macro\", \"f1_weighted\", \"top5_accuracy\"]\n",
        "\n",
        "    train_metrics = dict(zip(metric_names, train_eval))\n",
        "    val_metrics = dict(zip(metric_names, val_eval))\n",
        "\n",
        "    # Results\n",
        "    results[aug] = {\n",
        "        \"train_loss\": train_metrics[\"loss\"],\n",
        "        \"val_loss\": val_metrics[\"loss\"],\n",
        "\n",
        "        \"train_accuracy\": train_metrics[\"accuracy\"],\n",
        "        \"val_accuracy\": val_metrics[\"accuracy\"],\n",
        "\n",
        "        \"train_f1_macro\": train_metrics.get(\"f1_macro\"),\n",
        "        \"val_f1_macro\": val_metrics.get(\"f1_macro\"),\n",
        "\n",
        "        \"val_f1_weighted\": val_metrics.get(\"f1_weighted\")\n",
        "    }"
      ],
      "metadata": {
        "id": "-BxLO8lKyhbV",
        "outputId": "827fcf5d-d7b9-4303-e80a-844994f4a8ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: none\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 196ms/step - accuracy: 0.0173 - auc: 0.5604 - f1_macro: 7.5039e-04 - f1_weighted: 0.0025 - loss: 9.6009 - top5_accuracy: 0.0769 - val_accuracy: 0.0250 - val_auc: 0.6488 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.7478 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 160ms/step - accuracy: 0.0193 - auc: 0.5958 - f1_macro: 6.9779e-04 - f1_weighted: 0.0028 - loss: 5.7808 - top5_accuracy: 0.0920 - val_accuracy: 0.0250 - val_auc: 0.6499 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.4728 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 161ms/step - accuracy: 0.0207 - auc: 0.5986 - f1_macro: 6.9869e-04 - f1_weighted: 0.0028 - loss: 5.5533 - top5_accuracy: 0.0929 - val_accuracy: 0.0250 - val_auc: 0.6494 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.3409 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 161ms/step - accuracy: 0.0193 - auc: 0.6006 - f1_macro: 9.8207e-04 - f1_weighted: 0.0040 - loss: 5.4386 - top5_accuracy: 0.0936 - val_accuracy: 0.0250 - val_auc: 0.6489 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.2653 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 160ms/step - accuracy: 0.0162 - auc: 0.6011 - f1_macro: 5.0309e-04 - f1_weighted: 0.0020 - loss: 5.3746 - top5_accuracy: 0.0941 - val_accuracy: 0.0250 - val_auc: 0.6505 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.2181 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 160ms/step - accuracy: 0.0191 - auc: 0.6015 - f1_macro: 6.5219e-04 - f1_weighted: 0.0027 - loss: 5.3311 - top5_accuracy: 0.0936 - val_accuracy: 0.0250 - val_auc: 0.6505 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.1876 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 161ms/step - accuracy: 0.0199 - auc: 0.6018 - f1_macro: 7.1680e-04 - f1_weighted: 0.0029 - loss: 5.3034 - top5_accuracy: 0.0936 - val_accuracy: 0.0250 - val_auc: 0.6505 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.1656 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 161ms/step - accuracy: 0.0192 - auc: 0.6018 - f1_macro: 5.9674e-04 - f1_weighted: 0.0024 - loss: 5.2811 - top5_accuracy: 0.0965 - val_accuracy: 0.0250 - val_auc: 0.6505 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.1486 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 160ms/step - accuracy: 0.0186 - auc: 0.6025 - f1_macro: 6.7492e-04 - f1_weighted: 0.0028 - loss: 5.2650 - top5_accuracy: 0.0935 - val_accuracy: 0.0250 - val_auc: 0.6505 - val_f1_macro: 2.4188e-04 - val_f1_weighted: 0.0012 - val_loss: 5.1354 - val_top5_accuracy: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m 93/350\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 151ms/step - accuracy: 0.0169 - auc: 0.5971 - f1_macro: 4.0700e-04 - f1_weighted: 0.0017 - loss: 5.2644 - top5_accuracy: 0.0920"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-eda0d5727dfc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Run the experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Predict entire validation set at once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/FACULDADE/mestrado/classes.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, epochs, callbacks)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         history = self.model.fit(\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[1;32m    219\u001b[0m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\u001b[0m in \u001b[0;36mhas_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       return gen_optional_ops.optional_has_value(\n\u001b[0m\u001b[1;32m    177\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\u001b[0m in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    173\u001b[0m         _ctx, \"OptionalHasValue\", name, optional)\n\u001b[1;32m    174\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# Display the table\n",
        "display(results_df.round(4))\n"
      ],
      "metadata": {
        "id": "7pz2oVf1yrxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melt the DataFrame for seaborn plotting\n",
        "metrics_to_plot = ['train_accuracy', 'val_accuracy']\n",
        "melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "                            var_name='metric', value_name='value')\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "plt.title(\"Comparison of Accuracy Across Augmentation Strategies\")\n",
        "plt.ylim(0, 0.4)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Am6e6sw4y2Pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK5Cf7QY_0QG"
      },
      "source": [
        "## 4.5 VGGNet - No oversampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUQltkeB_0QG"
      },
      "source": [
        "inspired by VGG16 — a deep and uniform architecture with 3x3 convolutions and max pooling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuhVLEkt_0QG"
      },
      "outputs": [],
      "source": [
        "def build_vgg_model(input_shape=(224, 224, 3), num_classes=202):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Block 4 (optional to reduce overfitting)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_vgg_model()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the preprocessor\n",
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Loop through each augmentation\n",
        "for aug in augmentations_to_test:\n",
        "    print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "    model = build_vgg_model()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "    if aug==\"grayscale_plus\":\n",
        "      val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment='grayscale', oversampling=False)\n",
        "    else:\n",
        "      val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "    # Initialize the experiment\n",
        "    experiment = Experiment(\n",
        "        model=model,\n",
        "        train_ds=train_ds,\n",
        "        val_ds=val_ds,\n",
        "        experiment_name=f\"vgg_with_{aug}_no_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "        batch_size=32,\n",
        "        image_size=(224, 224),\n",
        "        save_model = False\n",
        "    )\n",
        "\n",
        "    # Run the experiment\n",
        "    history = experiment.run_experiment(callbacks=callbacks, epochs=30)\n",
        "\n",
        "    # Predict entire validation set at once\n",
        "    preds = model.predict(val_ds)\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Extract true labels in order\n",
        "    y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "    # Compute metrics\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Store in results\n",
        "    train_eval = model.evaluate(train_ds, verbose=0)\n",
        "    val_eval = model.evaluate(val_ds, verbose=0)\n",
        "\n",
        "    metric_names = [\"loss\", \"accuracy\", \"auc\", \"f1_macro\", \"f1_weighted\", \"top5_accuracy\"]\n",
        "\n",
        "    train_metrics = dict(zip(metric_names, train_eval))\n",
        "    val_metrics = dict(zip(metric_names, val_eval))\n",
        "\n",
        "    # Results\n",
        "    results[aug] = {\n",
        "        \"train_loss\": train_metrics[\"loss\"],\n",
        "        \"val_loss\": val_metrics[\"loss\"],\n",
        "\n",
        "        \"train_accuracy\": train_metrics[\"accuracy\"],\n",
        "        \"val_accuracy\": val_metrics[\"accuracy\"],\n",
        "\n",
        "        \"train_f1_macro\": train_metrics.get(\"f1_macro\"),\n",
        "        \"val_f1_macro\": val_metrics.get(\"f1_macro\"),\n",
        "\n",
        "        \"val_f1_weighted\": val_metrics.get(\"f1_weighted\")\n",
        "    }"
      ],
      "metadata": {
        "id": "wwJKDON60Mzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# Display the table\n",
        "display(results_df.round(4))\n"
      ],
      "metadata": {
        "id": "fu2qRSGTGB8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melt the DataFrame for seaborn plotting\n",
        "metrics_to_plot = ['train_accuracy', 'val_accuracy']\n",
        "melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "                            var_name='metric', value_name='value')\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "plt.title(\"Comparison of Accuracy Across Augmentation Strategies\")\n",
        "plt.ylim(0, 0.4)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JZnGoFZXGCTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXEV9N8g_0QG"
      },
      "outputs": [],
      "source": [
        "# # Initialize the preprocessor\n",
        "# batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "# image_size = (224, 224)\n",
        "\n",
        "# preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# # Store results\n",
        "# results = {}\n",
        "\n",
        "# # Loop through each augmentation\n",
        "# for aug in augmentations_to_test:\n",
        "#     print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "#     model = build_vgg_model()\n",
        "\n",
        "#     model.compile(\n",
        "#         optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "#         loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "#         metrics=metrics\n",
        "#     )\n",
        "\n",
        "#     train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "#     train_ds_sampled, class_names = preprocess.load_img(data_dir=\"data/rare_species/train_sampled\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "#     val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "#     test_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/test\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "#     # Initialize the experiment\n",
        "#     experiment = Experiment(\n",
        "#         model=model,\n",
        "#         train_ds=train_ds_sampled,\n",
        "#         val_ds=val_ds,\n",
        "#         experiment_name=f\"vggnet_with_{aug}_no_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "#         batch_size=32,\n",
        "#         image_size=(224, 224),\n",
        "#         save_model = False\n",
        "#     )\n",
        "\n",
        "#     # Run the experiment\n",
        "#     history = experiment.run_experiment(callbacks=callbacks, epochs=40)\n",
        "\n",
        "#     # Predict entire validation set at once\n",
        "#     preds = model.predict(val_ds)\n",
        "#     y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "#     # Extract true labels in order\n",
        "#     y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "#     # Compute metrics\n",
        "#     f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "#     f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "#     precision = precision_score(y_true, y_pred, average='weighted')\n",
        "#     recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "#     # Store in results\n",
        "#     results[aug] = {\n",
        "#         \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "#         \"f1_macro\": f1_macro,\n",
        "#         \"f1_weighted\": f1_weighted,\n",
        "#         \"precision\": precision,\n",
        "#         \"recall\": recall\n",
        "#     }\n",
        "\n",
        "#     print(f\"Finished '{aug}'\")\n",
        "#     print(f\"  Accuracy:      {results[aug]['accuracy']:.4f}\")\n",
        "#     print(f\"  F1 (macro):    {results[aug]['f1_macro']:.4f}\")\n",
        "#     print(f\"  F1 (weighted): {results[aug]['f1_weighted']:.4f}\")\n",
        "#     print(f\"  Precision:     {results[aug]['precision']:.4f}\")\n",
        "#     print(f\"  Recall:        {results[aug]['recall']:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "#     # Clear memory to avoid OOM\n",
        "#     del model\n",
        "#     del experiment\n",
        "#     K.clear_session()\n",
        "#     gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZAbCMzH_0QG"
      },
      "outputs": [],
      "source": [
        "# # Convert results to a DataFrame\n",
        "# results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "# results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# # Display the table\n",
        "# display(results_df.round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zakvyghM_0QG"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Melt the DataFrame for seaborn plotting\n",
        "# metrics_to_plot = ['accuracy', 'f1_macro', 'f1_weighted', 'precision', 'recall']\n",
        "# melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "#                             var_name='metric', value_name='value')\n",
        "\n",
        "# # Plot using seaborn\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "# plt.title(\"Comparison of Metrics Across Augmentation Strategies\")\n",
        "# plt.ylim(0, 0.4)\n",
        "# plt.xticks(rotation=45)\n",
        "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGGNet2 - With oversampling"
      ],
      "metadata": {
        "id": "rnh9jUYNEhri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vgg_model(input_shape=(224, 224, 3), num_classes=202):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Block 4 (optional to reduce overfitting)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_vgg_model()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "inKrTDPGEkIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the preprocessor\n",
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Loop through each augmentation\n",
        "for aug in augmentations_to_test:\n",
        "    print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "    model = build_vgg_model()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=True, shuffle=True)\n",
        "    if aug==\"grayscale_plus\":\n",
        "      val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment='grayscale', oversampling=False)\n",
        "    else:\n",
        "      val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "    # Initialize the experiment\n",
        "    experiment = Experiment(\n",
        "        model=model,\n",
        "        train_ds=train_ds,\n",
        "        val_ds=val_ds,\n",
        "        experiment_name=f\"vgg_with_{aug}_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "        batch_size=32,\n",
        "        image_size=(224, 224),\n",
        "        save_model = False\n",
        "    )\n",
        "\n",
        "    # Run the experiment\n",
        "    history = experiment.run_experiment(callbacks=callbacks, epochs=30)\n",
        "\n",
        "    # Predict entire validation set at once\n",
        "    preds = model.predict(val_ds)\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Extract true labels in order\n",
        "    y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "    # Compute metrics\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Store in results\n",
        "    train_eval = model.evaluate(train_ds, verbose=0)\n",
        "    val_eval = model.evaluate(val_ds, verbose=0)\n",
        "\n",
        "    metric_names = [\"loss\", \"accuracy\", \"auc\", \"f1_macro\", \"f1_weighted\", \"top5_accuracy\"]\n",
        "\n",
        "    train_metrics = dict(zip(metric_names, train_eval))\n",
        "    val_metrics = dict(zip(metric_names, val_eval))\n",
        "\n",
        "    # Results\n",
        "    results[aug] = {\n",
        "        \"train_loss\": train_metrics[\"loss\"],\n",
        "        \"val_loss\": val_metrics[\"loss\"],\n",
        "\n",
        "        \"train_accuracy\": train_metrics[\"accuracy\"],\n",
        "        \"val_accuracy\": val_metrics[\"accuracy\"],\n",
        "\n",
        "        \"train_f1_macro\": train_metrics.get(\"f1_macro\"),\n",
        "        \"val_f1_macro\": val_metrics.get(\"f1_macro\"),\n",
        "\n",
        "        \"val_f1_weighted\": val_metrics.get(\"f1_weighted\")\n",
        "    }"
      ],
      "metadata": {
        "id": "WLiMH9MtGVF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# Display the table\n",
        "display(results_df.round(4))\n"
      ],
      "metadata": {
        "id": "pgiAPYY3Gij7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melt the DataFrame for seaborn plotting\n",
        "metrics_to_plot = ['train_accuracy', 'val_accuracy']\n",
        "melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "                            var_name='metric', value_name='value')\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "plt.title(\"Comparison of Accuracy Across Augmentation Strategies\")\n",
        "plt.ylim(0, 0.4)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LLKPWJrvGjMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Initialize the preprocessor\n",
        "# batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "# image_size = (224, 224)\n",
        "\n",
        "# preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# # Store results\n",
        "# results = {}\n",
        "\n",
        "# # Loop through each augmentation\n",
        "# for aug in augmentations_to_test:\n",
        "#     print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "#     model = build_vgg_model()\n",
        "\n",
        "#     model.compile(\n",
        "#         optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "#         loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "#         metrics=metrics\n",
        "#     )\n",
        "\n",
        "#     train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=True, shuffle=True)\n",
        "#     train_ds_sampled, class_names = preprocess.load_img(data_dir=\"data/rare_species/train_sampled\", minority_class=minority_class, augment=aug, oversampling=True, shuffle=True)\n",
        "#     val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "#     test_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/test\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "#     # Initialize the experiment\n",
        "#     experiment = Experiment(\n",
        "#         model=model,\n",
        "#         train_ds=train_ds_sampled,\n",
        "#         val_ds=val_ds,\n",
        "#         experiment_name=f\"vggnet_with_{aug}_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "#         batch_size=32,\n",
        "#         image_size=(224, 224),\n",
        "#         save_model = False\n",
        "#     )\n",
        "\n",
        "#     # Run the experiment\n",
        "#     history = experiment.run_experiment(callbacks=callbacks, epochs=40)\n",
        "\n",
        "#     # Predict entire validation set at once\n",
        "#     preds = model.predict(val_ds)\n",
        "#     y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "#     # Extract true labels in order\n",
        "#     y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "#     # Compute metrics\n",
        "#     f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "#     f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "#     precision = precision_score(y_true, y_pred, average='weighted')\n",
        "#     recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "#     # Store in results\n",
        "#     results[aug] = {\n",
        "#         \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "#         \"f1_macro\": f1_macro,\n",
        "#         \"f1_weighted\": f1_weighted,\n",
        "#         \"precision\": precision,\n",
        "#         \"recall\": recall\n",
        "#     }\n",
        "\n",
        "#     print(f\"Finished '{aug}'\")\n",
        "#     print(f\"  Accuracy:      {results[aug]['accuracy']:.4f}\")\n",
        "#     print(f\"  F1 (macro):    {results[aug]['f1_macro']:.4f}\")\n",
        "#     print(f\"  F1 (weighted): {results[aug]['f1_weighted']:.4f}\")\n",
        "#     print(f\"  Precision:     {results[aug]['precision']:.4f}\")\n",
        "#     print(f\"  Recall:        {results[aug]['recall']:.4f}\")\n",
        "\n",
        "\n",
        "#     # Clear memory to avoid OOM\n",
        "#     del model\n",
        "#     del experiment\n",
        "#     K.clear_session()\n",
        "#     gc.collect()\n"
      ],
      "metadata": {
        "id": "ZponFmi3EmXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Convert results to a DataFrame\n",
        "# results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "# results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# # Display the table\n",
        "# display(results_df.round(4))"
      ],
      "metadata": {
        "id": "M-JsROiWFoBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Melt the DataFrame for seaborn plotting\n",
        "# metrics_to_plot = ['accuracy', 'f1_macro', 'f1_weighted', 'precision', 'recall']\n",
        "# melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "#                             var_name='metric', value_name='value')\n",
        "\n",
        "# # Plot using seaborn\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "# plt.title(\"Comparison of Metrics Across Augmentation Strategies\")\n",
        "# plt.ylim(0, 0.4)\n",
        "# plt.xticks(rotation=45)\n",
        "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "0vmKh3YHFub9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dbov_G3v_0QH"
      },
      "source": [
        "## 4.7 DenseNet - No Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohHuNN5T_0QH"
      },
      "outputs": [],
      "source": [
        "\n",
        "def dense_layer(x, growth_rate):\n",
        "    \"\"\"Single layer inside a dense block.\"\"\"\n",
        "    out = BatchNormalization()(x)\n",
        "    out = ReLU()(out)\n",
        "    out = Conv2D(growth_rate, (3, 3), padding='same', kernel_regularizer=l2(1e-4))(out)\n",
        "    x = Concatenate()([x, out])  # Concatenate input and output (dense connection)\n",
        "    return x\n",
        "\n",
        "def dense_block(x, num_layers, growth_rate):\n",
        "    \"\"\"Dense block with several dense layers.\"\"\"\n",
        "    for _ in range(num_layers):\n",
        "        x = dense_layer(x, growth_rate)\n",
        "    return x\n",
        "\n",
        "def transition_layer(x, reduction=0.5):\n",
        "    \"\"\"Reduces spatial size and number of filters.\"\"\"\n",
        "    filters = int(tf.keras.backend.int_shape(x)[-1] * reduction)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=l2(1e-4))(x)\n",
        "    x = AveragePooling2D((2, 2), strides=2)(x)\n",
        "    return x\n",
        "\n",
        "def build_densenet(input_shape=(224, 224, 3), num_classes=202, growth_rate=32):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Initial conv\n",
        "    x = Conv2D(64, (7, 7), strides=2, padding='same', kernel_regularizer=l2(1e-4))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = AveragePooling2D((3, 3), strides=2, padding='same')(x)\n",
        "\n",
        "    # Dense Block 1\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "    x = transition_layer(x)\n",
        "\n",
        "    # Dense Block 2\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "    x = transition_layer(x)\n",
        "\n",
        "    # Dense Block 3\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "    x = transition_layer(x)\n",
        "\n",
        "    # Dense Block 4\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "\n",
        "    # Classification\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "model = build_densenet()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the preprocessor\n",
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Loop through each augmentation\n",
        "for aug in augmentations_to_test:\n",
        "    print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "    model = build_densenet()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "    if aug==\"grayscale_plus\":\n",
        "      val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment='grayscale', oversampling=False)\n",
        "    else:\n",
        "      val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "    # Initialize the experiment\n",
        "    experiment = Experiment(\n",
        "        model=model,\n",
        "        train_ds=train_ds,\n",
        "        val_ds=val_ds,\n",
        "        experiment_name=f\"densenet_with_{aug}_no_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "        batch_size=32,\n",
        "        image_size=(224, 224),\n",
        "        save_model = False\n",
        "    )\n",
        "\n",
        "    # Run the experiment\n",
        "    history = experiment.run_experiment(callbacks=callbacks, epochs=30)\n",
        "\n",
        "    # Predict entire validation set at once\n",
        "    preds = model.predict(val_ds)\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Extract true labels in order\n",
        "    y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "    # Compute metrics\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Store in results\n",
        "    train_eval = model.evaluate(train_ds, verbose=0)\n",
        "    val_eval = model.evaluate(val_ds, verbose=0)\n",
        "\n",
        "    metric_names = [\"loss\", \"accuracy\", \"auc\", \"f1_macro\", \"f1_weighted\", \"top5_accuracy\"]\n",
        "\n",
        "    train_metrics = dict(zip(metric_names, train_eval))\n",
        "    val_metrics = dict(zip(metric_names, val_eval))\n",
        "\n",
        "    # Results\n",
        "    results[aug] = {\n",
        "        \"train_loss\": train_metrics[\"loss\"],\n",
        "        \"val_loss\": val_metrics[\"loss\"],\n",
        "\n",
        "        \"train_accuracy\": train_metrics[\"accuracy\"],\n",
        "        \"val_accuracy\": val_metrics[\"accuracy\"],\n",
        "\n",
        "        \"train_f1_macro\": train_metrics.get(\"f1_macro\"),\n",
        "        \"val_f1_macro\": val_metrics.get(\"f1_macro\"),\n",
        "\n",
        "        \"val_f1_weighted\": val_metrics.get(\"f1_weighted\")\n",
        "    }"
      ],
      "metadata": {
        "id": "L1vl4zNbGyGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# Display the table\n",
        "display(results_df.round(4))\n"
      ],
      "metadata": {
        "id": "zccqbSHCG_Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melt the DataFrame for seaborn plotting\n",
        "metrics_to_plot = ['train_accuracy', 'val_accuracy']\n",
        "melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "                            var_name='metric', value_name='value')\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "plt.title(\"Comparison of Accuracy Across Augmentation Strategies\")\n",
        "plt.ylim(0, 0.4)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ghu23vRPG_9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2CDiw1d_0QH"
      },
      "outputs": [],
      "source": [
        "# # Initialize the preprocessor\n",
        "# batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "# image_size = (224, 224)\n",
        "\n",
        "# preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# # Store results\n",
        "# results = {}\n",
        "\n",
        "# # Loop through each augmentation\n",
        "# for aug in augmentations_to_test:\n",
        "#     print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "#     model = build_densenet()\n",
        "\n",
        "#     model.compile(\n",
        "#         optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "#         loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "#         metrics=metrics\n",
        "#     )\n",
        "\n",
        "#     train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "#     train_ds_sampled, class_names = preprocess.load_img(data_dir=\"data/rare_species/train_sampled\", minority_class=minority_class, augment=aug, oversampling=False, shuffle=True)\n",
        "#     val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "#     test_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/test\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "#     # Initialize the experiment\n",
        "#     experiment = Experiment(\n",
        "#         model=model,\n",
        "#         train_ds=train_ds_sampled,\n",
        "#         val_ds=val_ds,\n",
        "#         experiment_name=f\"densenet_with_{aug}_no_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "#         batch_size=32,\n",
        "#         image_size=(224, 224),\n",
        "#         save_model = False\n",
        "#     )\n",
        "\n",
        "#     # Run the experiment\n",
        "#     history = experiment.run_experiment(callbacks=callbacks, epochs=40)\n",
        "\n",
        "#     # Predict entire validation set at once\n",
        "#     preds = model.predict(val_ds)\n",
        "#     y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "#     # Extract true labels in order\n",
        "#     y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "#     # Compute metrics\n",
        "#     f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "#     f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "#     precision = precision_score(y_true, y_pred, average='weighted')\n",
        "#     recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "#     # Store in results\n",
        "#     results[aug] = {\n",
        "#         \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "#         \"f1_macro\": f1_macro,\n",
        "#         \"f1_weighted\": f1_weighted,\n",
        "#         \"precision\": precision,\n",
        "#         \"recall\": recall\n",
        "#     }\n",
        "\n",
        "#     print(f\"Finished '{aug}'\")\n",
        "#     print(f\"  Accuracy:      {results[aug]['accuracy']:.4f}\")\n",
        "#     print(f\"  F1 (macro):    {results[aug]['f1_macro']:.4f}\")\n",
        "#     print(f\"  F1 (weighted): {results[aug]['f1_weighted']:.4f}\")\n",
        "#     print(f\"  Precision:     {results[aug]['precision']:.4f}\")\n",
        "#     print(f\"  Recall:        {results[aug]['recall']:.4f}\")\n",
        "\n",
        "#     # Clear memory to avoid OOM\n",
        "#     del model\n",
        "#     del experiment\n",
        "#     K.clear_session()\n",
        "#     gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJO872qA_0QI"
      },
      "outputs": [],
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# Display the table\n",
        "display(results_df.round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSX0pOmD_0QI"
      },
      "outputs": [],
      "source": [
        "# Melt the DataFrame for seaborn plotting\n",
        "metrics_to_plot = ['accuracy', 'f1_macro', 'f1_weighted', 'precision', 'recall']\n",
        "melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "                            var_name='metric', value_name='value')\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "plt.title(\"Comparison of Metrics Across Augmentation Strategies\")\n",
        "plt.ylim(0, 0.4)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet 2 - With Oversampling"
      ],
      "metadata": {
        "id": "336DD3hE782A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def dense_layer(x, growth_rate):\n",
        "    \"\"\"Single layer inside a dense block.\"\"\"\n",
        "    out = BatchNormalization()(x)\n",
        "    out = ReLU()(out)\n",
        "    out = Conv2D(growth_rate, (3, 3), padding='same', kernel_regularizer=l2(1e-4))(out)\n",
        "    x = Concatenate()([x, out])  # Concatenate input and output (dense connection)\n",
        "    return x\n",
        "\n",
        "def dense_block(x, num_layers, growth_rate):\n",
        "    \"\"\"Dense block with several dense layers.\"\"\"\n",
        "    for _ in range(num_layers):\n",
        "        x = dense_layer(x, growth_rate)\n",
        "    return x\n",
        "\n",
        "def transition_layer(x, reduction=0.5):\n",
        "    \"\"\"Reduces spatial size and number of filters.\"\"\"\n",
        "    filters = int(tf.keras.backend.int_shape(x)[-1] * reduction)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=l2(1e-4))(x)\n",
        "    x = AveragePooling2D((2, 2), strides=2)(x)\n",
        "    return x\n",
        "\n",
        "def build_densenet(input_shape=(224, 224, 3), num_classes=202, growth_rate=32):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Initial conv\n",
        "    x = Conv2D(64, (7, 7), strides=2, padding='same', kernel_regularizer=l2(1e-4))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = AveragePooling2D((3, 3), strides=2, padding='same')(x)\n",
        "\n",
        "    # Dense Block 1\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "    x = transition_layer(x)\n",
        "\n",
        "    # Dense Block 2\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "    x = transition_layer(x)\n",
        "\n",
        "    # Dense Block 3\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "    x = transition_layer(x)\n",
        "\n",
        "    # Dense Block 4\n",
        "    x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "\n",
        "    # Classification\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "model = build_densenet()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "390TQdSy7-st",
        "outputId": "5d9fbdb9-2e50-4b5e-a1ba-65d4691d148f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_36\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_36\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │      \u001b[38;5;34m9,472\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m18,464\u001b[0m │ re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m96\u001b[0m)               │            │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m27,680\u001b[0m │ re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m36,896\u001b[0m │ re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m160\u001b[0m)              │            │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m640\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m46,112\u001b[0m │ re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m192\u001b[0m)              │            │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m768\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m18,528\u001b[0m │ re_lu_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m27,680\u001b[0m │ re_lu_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_7 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m36,896\u001b[0m │ re_lu_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m160\u001b[0m)              │            │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m640\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_8 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m160\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m46,112\u001b[0m │ re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m192\u001b[0m)              │            │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m768\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_9 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m55,328\u001b[0m │ re_lu_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m224\u001b[0m)              │            │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m896\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m224\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_10 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m224\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m25,200\u001b[0m │ re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m448\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_11 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m112\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m32,288\u001b[0m │ re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m144\u001b[0m)              │            │ conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m576\u001b[0m │ concatenate_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m144\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_12 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m144\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m41,504\u001b[0m │ re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m176\u001b[0m)              │            │ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m704\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m176\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_13 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m176\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m50,720\u001b[0m │ re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m208\u001b[0m)              │            │ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m832\u001b[0m │ concatenate_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m208\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_14 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m208\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m59,936\u001b[0m │ re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ concatenate_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m240\u001b[0m)              │            │ conv2d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m960\u001b[0m │ concatenate_11[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m240\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_15 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m240\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m28,920\u001b[0m │ re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m120\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_3 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m120\u001b[0m) │        \u001b[38;5;34m480\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_16 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m34,592\u001b[0m │ re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m152\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m152\u001b[0m) │        \u001b[38;5;34m608\u001b[0m │ concatenate_12[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_17 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m152\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m43,808\u001b[0m │ re_lu_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m184\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ concatenate_12[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m184\u001b[0m) │        \u001b[38;5;34m736\u001b[0m │ concatenate_13[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_18 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m184\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m53,024\u001b[0m │ re_lu_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m216\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ concatenate_13[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m216\u001b[0m) │        \u001b[38;5;34m864\u001b[0m │ concatenate_14[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_19 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m216\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m62,240\u001b[0m │ re_lu_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m248\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ concatenate_14[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv2d_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m248\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_15[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m202\u001b[0m)       │     \u001b[38;5;34m50,298\u001b[0m │ global_average_p… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,472</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │ re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,680</span> │ re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,896</span> │ re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">46,112</span> │ re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,528</span> │ re_lu_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,680</span> │ re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,896</span> │ re_lu_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">46,112</span> │ re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">55,328</span> │ re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │            │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">25,200</span> │ re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,288</span> │ re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              │            │ conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,504</span> │ re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>)              │            │ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">50,720</span> │ re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)              │            │ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │ concatenate_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">59,936</span> │ re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)              │            │ conv2d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> │ concatenate_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">28,920</span> │ re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ average_pooling2d_3 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">34,592</span> │ re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> │ concatenate_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">43,808</span> │ re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">736</span> │ concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">53,024</span> │ re_lu_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span> │ concatenate_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ re_lu_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">62,240</span> │ re_lu_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">248</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv2d_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">248</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">50,298</span> │ global_average_p… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m817,922\u001b[0m (3.12 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">817,922</span> (3.12 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m811,810\u001b[0m (3.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">811,810</span> (3.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6,112\u001b[0m (23.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,112</span> (23.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the preprocessor\n",
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Loop through each augmentation\n",
        "for aug in augmentations_to_test:\n",
        "    print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "    model = build_densenet()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=True, shuffle=True)\n",
        "    if aug==\"grayscale_plus\":\n",
        "      val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment='grayscale', oversampling=False)\n",
        "    else:\n",
        "      val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "    # Initialize the experiment\n",
        "    experiment = Experiment(\n",
        "        model=model,\n",
        "        train_ds=train_ds,\n",
        "        val_ds=val_ds,\n",
        "        experiment_name=f\"densenet_with_{aug}_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "        batch_size=32,\n",
        "        image_size=(224, 224),\n",
        "        save_model = False\n",
        "    )\n",
        "\n",
        "    # Run the experiment\n",
        "    history = experiment.run_experiment(callbacks=callbacks, epochs=30)\n",
        "\n",
        "    # Predict entire validation set at once\n",
        "    preds = model.predict(val_ds)\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Extract true labels in order\n",
        "    y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "    # Compute metrics\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Store in results\n",
        "    train_eval = model.evaluate(train_ds, verbose=0)\n",
        "    val_eval = model.evaluate(val_ds, verbose=0)\n",
        "\n",
        "    metric_names = [\"loss\", \"accuracy\", \"auc\", \"f1_macro\", \"f1_weighted\", \"top5_accuracy\"]\n",
        "\n",
        "    train_metrics = dict(zip(metric_names, train_eval))\n",
        "    val_metrics = dict(zip(metric_names, val_eval))\n",
        "\n",
        "    # Results\n",
        "    results[aug] = {\n",
        "        \"train_loss\": train_metrics[\"loss\"],\n",
        "        \"val_loss\": val_metrics[\"loss\"],\n",
        "\n",
        "        \"train_accuracy\": train_metrics[\"accuracy\"],\n",
        "        \"val_accuracy\": val_metrics[\"accuracy\"],\n",
        "\n",
        "        \"train_f1_macro\": train_metrics.get(\"f1_macro\"),\n",
        "        \"val_f1_macro\": val_metrics.get(\"f1_macro\"),\n",
        "\n",
        "        \"val_f1_weighted\": val_metrics.get(\"f1_weighted\")\n",
        "    }"
      ],
      "metadata": {
        "id": "zC0Xk9m4HG00",
        "outputId": "3b09b78d-7ccd-4c14-8d3b-8d6e2dbc158d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: none\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 149ms/step - accuracy: 0.0285 - auc: 0.6050 - f1_macro: 0.0056 - f1_weighted: 0.0120 - loss: 5.4695 - top5_accuracy: 0.0989 - val_accuracy: 0.0373 - val_auc: 0.6489 - val_f1_macro: 0.0054 - val_f1_weighted: 0.0134 - val_loss: 5.2895 - val_top5_accuracy: 0.1252 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 78ms/step - accuracy: 0.0514 - auc: 0.6916 - f1_macro: 0.0139 - f1_weighted: 0.0271 - loss: 5.0577 - top5_accuracy: 0.1519 - val_accuracy: 0.0540 - val_auc: 0.6826 - val_f1_macro: 0.0138 - val_f1_weighted: 0.0232 - val_loss: 5.0897 - val_top5_accuracy: 0.1692 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0630 - auc: 0.7407 - f1_macro: 0.0238 - f1_weighted: 0.0381 - loss: 4.8120 - top5_accuracy: 0.1977 - val_accuracy: 0.0211 - val_auc: 0.6245 - val_f1_macro: 0.0153 - val_f1_weighted: 0.0181 - val_loss: 5.9679 - val_top5_accuracy: 0.1336 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.0720 - auc: 0.7669 - f1_macro: 0.0330 - f1_weighted: 0.0476 - loss: 4.6543 - top5_accuracy: 0.2269 - val_accuracy: 0.0779 - val_auc: 0.6700 - val_f1_macro: 0.0241 - val_f1_weighted: 0.0453 - val_loss: 5.2929 - val_top5_accuracy: 0.1725 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0864 - auc: 0.7878 - f1_macro: 0.0465 - f1_weighted: 0.0622 - loss: 4.5188 - top5_accuracy: 0.2497 - val_accuracy: 0.0662 - val_auc: 0.6546 - val_f1_macro: 0.0226 - val_f1_weighted: 0.0400 - val_loss: 5.4501 - val_top5_accuracy: 0.1619 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1025 - auc: 0.8060 - f1_macro: 0.0586 - f1_weighted: 0.0770 - loss: 4.3986 - top5_accuracy: 0.2704 - val_accuracy: 0.0723 - val_auc: 0.7155 - val_f1_macro: 0.0276 - val_f1_weighted: 0.0484 - val_loss: 5.0472 - val_top5_accuracy: 0.1964 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1098 - auc: 0.8207 - f1_macro: 0.0662 - f1_weighted: 0.0851 - loss: 4.2826 - top5_accuracy: 0.2972 - val_accuracy: 0.0729 - val_auc: 0.7161 - val_f1_macro: 0.0295 - val_f1_weighted: 0.0461 - val_loss: 5.0822 - val_top5_accuracy: 0.2009 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1271 - auc: 0.8343 - f1_macro: 0.0823 - f1_weighted: 0.1015 - loss: 4.1721 - top5_accuracy: 0.3172 - val_accuracy: 0.0757 - val_auc: 0.7157 - val_f1_macro: 0.0341 - val_f1_weighted: 0.0534 - val_loss: 5.1944 - val_top5_accuracy: 0.2137 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1408 - auc: 0.8456 - f1_macro: 0.0976 - f1_weighted: 0.1170 - loss: 4.0722 - top5_accuracy: 0.3440 - val_accuracy: 0.0595 - val_auc: 0.6993 - val_f1_macro: 0.0272 - val_f1_weighted: 0.0377 - val_loss: 5.3968 - val_top5_accuracy: 0.1809 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.1536 - auc: 0.8610 - f1_macro: 0.1119 - f1_weighted: 0.1304 - loss: 3.9682 - top5_accuracy: 0.3732 - val_accuracy: 0.0696 - val_auc: 0.7068 - val_f1_macro: 0.0407 - val_f1_weighted: 0.0490 - val_loss: 5.2789 - val_top5_accuracy: 0.1859 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.1686 - auc: 0.8696 - f1_macro: 0.1297 - f1_weighted: 0.1483 - loss: 3.8762 - top5_accuracy: 0.3970\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1686 - auc: 0.8696 - f1_macro: 0.1297 - f1_weighted: 0.1484 - loss: 3.8761 - top5_accuracy: 0.3970 - val_accuracy: 0.0790 - val_auc: 0.7110 - val_f1_macro: 0.0485 - val_f1_weighted: 0.0716 - val_loss: 5.2892 - val_top5_accuracy: 0.2042 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.2082 - auc: 0.8867 - f1_macro: 0.1657 - f1_weighted: 0.1857 - loss: 3.6807 - top5_accuracy: 0.4515 - val_accuracy: 0.0940 - val_auc: 0.7314 - val_f1_macro: 0.0569 - val_f1_weighted: 0.0806 - val_loss: 5.1366 - val_top5_accuracy: 0.2343 - learning_rate: 5.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.2367 - auc: 0.9005 - f1_macro: 0.1965 - f1_weighted: 0.2159 - loss: 3.5154 - top5_accuracy: 0.4979 - val_accuracy: 0.0735 - val_auc: 0.6905 - val_f1_macro: 0.0413 - val_f1_weighted: 0.0665 - val_loss: 5.8728 - val_top5_accuracy: 0.1948 - learning_rate: 5.0000e-04\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: light\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 240ms/step - accuracy: 0.0472 - auc: 0.6434 - f1_macro: 0.0167 - f1_weighted: 0.0295 - loss: 5.4679 - top5_accuracy: 0.1388 - val_accuracy: 0.0273 - val_auc: 0.5945 - val_f1_macro: 0.0030 - val_f1_weighted: 0.0100 - val_loss: 6.5941 - val_top5_accuracy: 0.0935 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0548 - auc: 0.6959 - f1_macro: 0.0152 - f1_weighted: 0.0290 - loss: 5.0112 - top5_accuracy: 0.1620 - val_accuracy: 0.0390 - val_auc: 0.6536 - val_f1_macro: 0.0065 - val_f1_weighted: 0.0189 - val_loss: 5.6280 - val_top5_accuracy: 0.1224 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0679 - auc: 0.7398 - f1_macro: 0.0251 - f1_weighted: 0.0400 - loss: 4.8009 - top5_accuracy: 0.1868 - val_accuracy: 0.0306 - val_auc: 0.5811 - val_f1_macro: 0.0063 - val_f1_weighted: 0.0148 - val_loss: 6.4550 - val_top5_accuracy: 0.0846 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0768 - auc: 0.7652 - f1_macro: 0.0321 - f1_weighted: 0.0484 - loss: 4.6589 - top5_accuracy: 0.2124 - val_accuracy: 0.0423 - val_auc: 0.6288 - val_f1_macro: 0.0102 - val_f1_weighted: 0.0238 - val_loss: 5.7575 - val_top5_accuracy: 0.1191 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0860 - auc: 0.7881 - f1_macro: 0.0408 - f1_weighted: 0.0573 - loss: 4.5368 - top5_accuracy: 0.2368 - val_accuracy: 0.0618 - val_auc: 0.7133 - val_f1_macro: 0.0233 - val_f1_weighted: 0.0383 - val_loss: 5.0589 - val_top5_accuracy: 0.1681 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0959 - auc: 0.8040 - f1_macro: 0.0506 - f1_weighted: 0.0678 - loss: 4.4284 - top5_accuracy: 0.2521 - val_accuracy: 0.0534 - val_auc: 0.6804 - val_f1_macro: 0.0174 - val_f1_weighted: 0.0307 - val_loss: 5.5369 - val_top5_accuracy: 0.1553 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1044 - auc: 0.8205 - f1_macro: 0.0594 - f1_weighted: 0.0775 - loss: 4.3191 - top5_accuracy: 0.2776 - val_accuracy: 0.0790 - val_auc: 0.7339 - val_f1_macro: 0.0356 - val_f1_weighted: 0.0527 - val_loss: 4.9299 - val_top5_accuracy: 0.2014 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1196 - auc: 0.8340 - f1_macro: 0.0722 - f1_weighted: 0.0917 - loss: 4.2207 - top5_accuracy: 0.3038 - val_accuracy: 0.0673 - val_auc: 0.7090 - val_f1_macro: 0.0235 - val_f1_weighted: 0.0386 - val_loss: 5.1997 - val_top5_accuracy: 0.1842 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.1299 - auc: 0.8469 - f1_macro: 0.0843 - f1_weighted: 0.1038 - loss: 4.1273 - top5_accuracy: 0.3227 - val_accuracy: 0.0796 - val_auc: 0.7308 - val_f1_macro: 0.0359 - val_f1_weighted: 0.0618 - val_loss: 5.0153 - val_top5_accuracy: 0.2098 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1437 - auc: 0.8597 - f1_macro: 0.0986 - f1_weighted: 0.1187 - loss: 4.0349 - top5_accuracy: 0.3513 - val_accuracy: 0.0779 - val_auc: 0.7171 - val_f1_macro: 0.0334 - val_f1_weighted: 0.0561 - val_loss: 5.2328 - val_top5_accuracy: 0.2026 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1592 - auc: 0.8686 - f1_macro: 0.1141 - f1_weighted: 0.1340 - loss: 3.9424 - top5_accuracy: 0.3855 - val_accuracy: 0.0562 - val_auc: 0.6714 - val_f1_macro: 0.0283 - val_f1_weighted: 0.0380 - val_loss: 6.0871 - val_top5_accuracy: 0.1747 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.1745 - auc: 0.8737 - f1_macro: 0.1313 - f1_weighted: 0.1504 - loss: 3.8640 - top5_accuracy: 0.4081\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1745 - auc: 0.8737 - f1_macro: 0.1313 - f1_weighted: 0.1504 - loss: 3.8639 - top5_accuracy: 0.4081 - val_accuracy: 0.0373 - val_auc: 0.6259 - val_f1_macro: 0.0223 - val_f1_weighted: 0.0284 - val_loss: 6.9671 - val_top5_accuracy: 0.1464 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1991 - auc: 0.8866 - f1_macro: 0.1594 - f1_weighted: 0.1764 - loss: 3.7216 - top5_accuracy: 0.4422 - val_accuracy: 0.0657 - val_auc: 0.6464 - val_f1_macro: 0.0337 - val_f1_weighted: 0.0473 - val_loss: 6.6645 - val_top5_accuracy: 0.1781 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.2267 - auc: 0.8994 - f1_macro: 0.1894 - f1_weighted: 0.2046 - loss: 3.5625 - top5_accuracy: 0.4847 - val_accuracy: 0.0701 - val_auc: 0.6637 - val_f1_macro: 0.0391 - val_f1_weighted: 0.0569 - val_loss: 6.3415 - val_top5_accuracy: 0.1909 - learning_rate: 5.0000e-04\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: mixup\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 143ms/step - accuracy: 0.0463 - auc: 0.6109 - f1_macro: 0.0179 - f1_weighted: 0.0277 - loss: 5.5215 - top5_accuracy: 0.1309 - val_accuracy: 0.0334 - val_auc: 0.6054 - val_f1_macro: 0.0025 - val_f1_weighted: 0.0112 - val_loss: 7.5946 - val_top5_accuracy: 0.1096 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0522 - auc: 0.6305 - f1_macro: 0.0074 - f1_weighted: 0.0171 - loss: 5.1687 - top5_accuracy: 0.1496 - val_accuracy: 0.0401 - val_auc: 0.6333 - val_f1_macro: 0.0052 - val_f1_weighted: 0.0187 - val_loss: 7.9011 - val_top5_accuracy: 0.1141 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.0619 - auc: 0.6501 - f1_macro: 0.0120 - f1_weighted: 0.0232 - loss: 5.0524 - top5_accuracy: 0.1682 - val_accuracy: 0.0484 - val_auc: 0.6605 - val_f1_macro: 0.0079 - val_f1_weighted: 0.0214 - val_loss: 5.5035 - val_top5_accuracy: 0.1269 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.0709 - auc: 0.6611 - f1_macro: 0.0164 - f1_weighted: 0.0294 - loss: 4.9623 - top5_accuracy: 0.1837 - val_accuracy: 0.0501 - val_auc: 0.6807 - val_f1_macro: 0.0057 - val_f1_weighted: 0.0212 - val_loss: 5.8430 - val_top5_accuracy: 0.1564 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.0752 - auc: 0.6716 - f1_macro: 0.0220 - f1_weighted: 0.0346 - loss: 4.8871 - top5_accuracy: 0.2020 - val_accuracy: 0.0623 - val_auc: 0.7103 - val_f1_macro: 0.0129 - val_f1_weighted: 0.0298 - val_loss: 5.5358 - val_top5_accuracy: 0.1803 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.0812 - auc: 0.6808 - f1_macro: 0.0251 - f1_weighted: 0.0383 - loss: 4.8135 - top5_accuracy: 0.2201 - val_accuracy: 0.0623 - val_auc: 0.6972 - val_f1_macro: 0.0158 - val_f1_weighted: 0.0313 - val_loss: 5.6200 - val_top5_accuracy: 0.1675 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.0928 - auc: 0.6885 - f1_macro: 0.0338 - f1_weighted: 0.0476 - loss: 4.7483 - top5_accuracy: 0.2364 - val_accuracy: 0.0623 - val_auc: 0.6976 - val_f1_macro: 0.0173 - val_f1_weighted: 0.0296 - val_loss: 5.6617 - val_top5_accuracy: 0.1697 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.0969 - auc: 0.6951 - f1_macro: 0.0383 - f1_weighted: 0.0515 - loss: 4.6931 - top5_accuracy: 0.2573 - val_accuracy: 0.0568 - val_auc: 0.6855 - val_f1_macro: 0.0143 - val_f1_weighted: 0.0287 - val_loss: 5.2783 - val_top5_accuracy: 0.1464 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.1111 - auc: 0.7022 - f1_macro: 0.0472 - f1_weighted: 0.0626 - loss: 4.6252 - top5_accuracy: 0.2783 - val_accuracy: 0.0590 - val_auc: 0.7048 - val_f1_macro: 0.0138 - val_f1_weighted: 0.0332 - val_loss: 5.2647 - val_top5_accuracy: 0.1525 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1204 - auc: 0.7076 - f1_macro: 0.0551 - f1_weighted: 0.0707 - loss: 4.5674 - top5_accuracy: 0.2996 - val_accuracy: 0.0673 - val_auc: 0.7320 - val_f1_macro: 0.0219 - val_f1_weighted: 0.0398 - val_loss: 5.1924 - val_top5_accuracy: 0.1892 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1297 - auc: 0.7124 - f1_macro: 0.0639 - f1_weighted: 0.0791 - loss: 4.5183 - top5_accuracy: 0.3143 - val_accuracy: 0.0829 - val_auc: 0.7373 - val_f1_macro: 0.0290 - val_f1_weighted: 0.0543 - val_loss: 5.5655 - val_top5_accuracy: 0.1959 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1432 - auc: 0.7173 - f1_macro: 0.0761 - f1_weighted: 0.0914 - loss: 4.4675 - top5_accuracy: 0.3387 - val_accuracy: 0.0779 - val_auc: 0.7359 - val_f1_macro: 0.0325 - val_f1_weighted: 0.0523 - val_loss: 5.7310 - val_top5_accuracy: 0.1998 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1546 - auc: 0.7234 - f1_macro: 0.0857 - f1_weighted: 0.1009 - loss: 4.4089 - top5_accuracy: 0.3584 - val_accuracy: 0.1018 - val_auc: 0.7418 - val_f1_macro: 0.0463 - val_f1_weighted: 0.0711 - val_loss: 6.0952 - val_top5_accuracy: 0.2287 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.1668 - auc: 0.7282 - f1_macro: 0.0971 - f1_weighted: 0.1128 - loss: 4.3505 - top5_accuracy: 0.3771 - val_accuracy: 0.0818 - val_auc: 0.7363 - val_f1_macro: 0.0442 - val_f1_weighted: 0.0640 - val_loss: 5.8918 - val_top5_accuracy: 0.2037 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.1788 - auc: 0.7323 - f1_macro: 0.1078 - f1_weighted: 0.1235 - loss: 4.3012 - top5_accuracy: 0.3970\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1788 - auc: 0.7323 - f1_macro: 0.1079 - f1_weighted: 0.1235 - loss: 4.3013 - top5_accuracy: 0.3970 - val_accuracy: 0.0924 - val_auc: 0.7580 - val_f1_macro: 0.0509 - val_f1_weighted: 0.0745 - val_loss: 5.3809 - val_top5_accuracy: 0.2449 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.2111 - auc: 0.7415 - f1_macro: 0.1357 - f1_weighted: 0.1477 - loss: 4.1816 - top5_accuracy: 0.4463 - val_accuracy: 0.1258 - val_auc: 0.7852 - val_f1_macro: 0.0611 - val_f1_weighted: 0.0963 - val_loss: 4.7194 - val_top5_accuracy: 0.2855 - learning_rate: 5.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.2337 - auc: 0.7471 - f1_macro: 0.1536 - f1_weighted: 0.1679 - loss: 4.0895 - top5_accuracy: 0.4768 - val_accuracy: 0.1324 - val_auc: 0.7833 - val_f1_macro: 0.0717 - val_f1_weighted: 0.1050 - val_loss: 4.7037 - val_top5_accuracy: 0.2938 - learning_rate: 5.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.2507 - auc: 0.7521 - f1_macro: 0.1692 - f1_weighted: 0.1827 - loss: 4.0129 - top5_accuracy: 0.5061 - val_accuracy: 0.1263 - val_auc: 0.7800 - val_f1_macro: 0.0718 - val_f1_weighted: 0.1045 - val_loss: 4.7505 - val_top5_accuracy: 0.2922 - learning_rate: 5.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.2692 - auc: 0.7575 - f1_macro: 0.1839 - f1_weighted: 0.1984 - loss: 3.9371 - top5_accuracy: 0.5300 - val_accuracy: 0.1241 - val_auc: 0.7729 - val_f1_macro: 0.0711 - val_f1_weighted: 0.1012 - val_loss: 4.8666 - val_top5_accuracy: 0.2866 - learning_rate: 5.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.2841 - auc: 0.7611 - f1_macro: 0.1969 - f1_weighted: 0.2126 - loss: 3.8615 - top5_accuracy: 0.5554 - val_accuracy: 0.1157 - val_auc: 0.7669 - val_f1_macro: 0.0661 - val_f1_weighted: 0.0969 - val_loss: 5.2569 - val_top5_accuracy: 0.2832 - learning_rate: 5.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.3087 - auc: 0.7637 - f1_macro: 0.2203 - f1_weighted: 0.2341 - loss: 3.7882 - top5_accuracy: 0.5876 - val_accuracy: 0.1130 - val_auc: 0.7613 - val_f1_macro: 0.0633 - val_f1_weighted: 0.0952 - val_loss: 6.1118 - val_top5_accuracy: 0.2782 - learning_rate: 5.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3269 - auc: 0.7661 - f1_macro: 0.2371 - f1_weighted: 0.2503 - loss: 3.7296 - top5_accuracy: 0.6063\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.3269 - auc: 0.7661 - f1_macro: 0.2371 - f1_weighted: 0.2503 - loss: 3.7296 - top5_accuracy: 0.6063 - val_accuracy: 0.1141 - val_auc: 0.7512 - val_f1_macro: 0.0691 - val_f1_weighted: 0.0986 - val_loss: 6.2940 - val_top5_accuracy: 0.2738 - learning_rate: 5.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.3582 - auc: 0.7692 - f1_macro: 0.2643 - f1_weighted: 0.2768 - loss: 3.6635 - top5_accuracy: 0.6333 - val_accuracy: 0.1430 - val_auc: 0.7684 - val_f1_macro: 0.0809 - val_f1_weighted: 0.1178 - val_loss: 5.8539 - val_top5_accuracy: 0.2983 - learning_rate: 2.5000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.3856 - auc: 0.7730 - f1_macro: 0.2909 - f1_weighted: 0.3010 - loss: 3.5794 - top5_accuracy: 0.6672 - val_accuracy: 0.1486 - val_auc: 0.7679 - val_f1_macro: 0.0846 - val_f1_weighted: 0.1247 - val_loss: 5.9103 - val_top5_accuracy: 0.3011 - learning_rate: 2.5000e-04\n",
            "Epoch 24: early stopping\n",
            "Restoring model weights from the end of the best epoch: 17.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: medium\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 254ms/step - accuracy: 0.0640 - auc: 0.6638 - f1_macro: 0.0289 - f1_weighted: 0.0429 - loss: 5.4961 - top5_accuracy: 0.1625 - val_accuracy: 0.0328 - val_auc: 0.6641 - val_f1_macro: 0.0047 - val_f1_weighted: 0.0097 - val_loss: 5.2354 - val_top5_accuracy: 0.1308 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0493 - auc: 0.6835 - f1_macro: 0.0126 - f1_weighted: 0.0252 - loss: 5.0639 - top5_accuracy: 0.1532 - val_accuracy: 0.0473 - val_auc: 0.6329 - val_f1_macro: 0.0143 - val_f1_weighted: 0.0205 - val_loss: 5.4859 - val_top5_accuracy: 0.1219 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0630 - auc: 0.7262 - f1_macro: 0.0200 - f1_weighted: 0.0353 - loss: 4.8704 - top5_accuracy: 0.1827 - val_accuracy: 0.0351 - val_auc: 0.6344 - val_f1_macro: 0.0132 - val_f1_weighted: 0.0203 - val_loss: 5.6957 - val_top5_accuracy: 0.1124 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0716 - auc: 0.7521 - f1_macro: 0.0253 - f1_weighted: 0.0420 - loss: 4.7364 - top5_accuracy: 0.2000 - val_accuracy: 0.0551 - val_auc: 0.6688 - val_f1_macro: 0.0195 - val_f1_weighted: 0.0393 - val_loss: 5.2429 - val_top5_accuracy: 0.1608 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0807 - auc: 0.7703 - f1_macro: 0.0338 - f1_weighted: 0.0520 - loss: 4.6239 - top5_accuracy: 0.2275 - val_accuracy: 0.0696 - val_auc: 0.7168 - val_f1_macro: 0.0196 - val_f1_weighted: 0.0366 - val_loss: 4.9743 - val_top5_accuracy: 0.1903 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0948 - auc: 0.7862 - f1_macro: 0.0439 - f1_weighted: 0.0650 - loss: 4.5169 - top5_accuracy: 0.2483 - val_accuracy: 0.0595 - val_auc: 0.6683 - val_f1_macro: 0.0176 - val_f1_weighted: 0.0373 - val_loss: 5.3393 - val_top5_accuracy: 0.1580 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1037 - auc: 0.7994 - f1_macro: 0.0519 - f1_weighted: 0.0752 - loss: 4.4285 - top5_accuracy: 0.2663 - val_accuracy: 0.0740 - val_auc: 0.7041 - val_f1_macro: 0.0203 - val_f1_weighted: 0.0402 - val_loss: 5.1317 - val_top5_accuracy: 0.1909 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1121 - auc: 0.8110 - f1_macro: 0.0625 - f1_weighted: 0.0858 - loss: 4.3418 - top5_accuracy: 0.2888 - val_accuracy: 0.0712 - val_auc: 0.7159 - val_f1_macro: 0.0253 - val_f1_weighted: 0.0453 - val_loss: 5.0818 - val_top5_accuracy: 0.1987 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.1211 - auc: 0.8229 - f1_macro: 0.0733 - f1_weighted: 0.0964 - loss: 4.2592 - top5_accuracy: 0.3074 - val_accuracy: 0.0568 - val_auc: 0.6915 - val_f1_macro: 0.0208 - val_f1_weighted: 0.0347 - val_loss: 5.3508 - val_top5_accuracy: 0.1892 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.1334 - auc: 0.8336 - f1_macro: 0.0850 - f1_weighted: 0.1092 - loss: 4.1753 - top5_accuracy: 0.3254\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.1334 - auc: 0.8337 - f1_macro: 0.0851 - f1_weighted: 0.1093 - loss: 4.1751 - top5_accuracy: 0.3254 - val_accuracy: 0.0523 - val_auc: 0.6896 - val_f1_macro: 0.0242 - val_f1_weighted: 0.0367 - val_loss: 5.5905 - val_top5_accuracy: 0.1597 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.1597 - auc: 0.8520 - f1_macro: 0.1103 - f1_weighted: 0.1341 - loss: 4.0041 - top5_accuracy: 0.3787 - val_accuracy: 0.0506 - val_auc: 0.6807 - val_f1_macro: 0.0302 - val_f1_weighted: 0.0461 - val_loss: 5.8815 - val_top5_accuracy: 0.1541 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1800 - auc: 0.8660 - f1_macro: 0.1289 - f1_weighted: 0.1547 - loss: 3.8913 - top5_accuracy: 0.4018 - val_accuracy: 0.0529 - val_auc: 0.6797 - val_f1_macro: 0.0294 - val_f1_weighted: 0.0474 - val_loss: 6.0119 - val_top5_accuracy: 0.1553 - learning_rate: 5.0000e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: heavy\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 261ms/step - accuracy: 0.0429 - auc: 0.6366 - f1_macro: 0.0128 - f1_weighted: 0.0238 - loss: 5.5085 - top5_accuracy: 0.1256 - val_accuracy: 0.0362 - val_auc: 0.6229 - val_f1_macro: 0.0048 - val_f1_weighted: 0.0143 - val_loss: 5.4059 - val_top5_accuracy: 0.1119 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0389 - auc: 0.6760 - f1_macro: 0.0083 - f1_weighted: 0.0186 - loss: 5.1063 - top5_accuracy: 0.1398 - val_accuracy: 0.0562 - val_auc: 0.6482 - val_f1_macro: 0.0073 - val_f1_weighted: 0.0213 - val_loss: 5.2119 - val_top5_accuracy: 0.1425 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0517 - auc: 0.7128 - f1_macro: 0.0134 - f1_weighted: 0.0267 - loss: 4.9332 - top5_accuracy: 0.1631 - val_accuracy: 0.0556 - val_auc: 0.6619 - val_f1_macro: 0.0080 - val_f1_weighted: 0.0235 - val_loss: 5.2604 - val_top5_accuracy: 0.1380 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.0587 - auc: 0.7342 - f1_macro: 0.0180 - f1_weighted: 0.0325 - loss: 4.8222 - top5_accuracy: 0.1816 - val_accuracy: 0.0573 - val_auc: 0.6966 - val_f1_macro: 0.0115 - val_f1_weighted: 0.0279 - val_loss: 5.0080 - val_top5_accuracy: 0.1625 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.0622 - auc: 0.7531 - f1_macro: 0.0221 - f1_weighted: 0.0370 - loss: 4.7387 - top5_accuracy: 0.1959 - val_accuracy: 0.0529 - val_auc: 0.6853 - val_f1_macro: 0.0131 - val_f1_weighted: 0.0226 - val_loss: 5.0978 - val_top5_accuracy: 0.1580 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.0680 - auc: 0.7662 - f1_macro: 0.0270 - f1_weighted: 0.0421 - loss: 4.6577 - top5_accuracy: 0.2121 - val_accuracy: 0.0501 - val_auc: 0.6748 - val_f1_macro: 0.0126 - val_f1_weighted: 0.0280 - val_loss: 5.3085 - val_top5_accuracy: 0.1514 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0749 - auc: 0.7759 - f1_macro: 0.0329 - f1_weighted: 0.0492 - loss: 4.5854 - top5_accuracy: 0.2289 - val_accuracy: 0.0467 - val_auc: 0.6656 - val_f1_macro: 0.0117 - val_f1_weighted: 0.0266 - val_loss: 5.4878 - val_top5_accuracy: 0.1469 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.0801 - auc: 0.7882 - f1_macro: 0.0403 - f1_weighted: 0.0572 - loss: 4.5201 - top5_accuracy: 0.2392 - val_accuracy: 0.0679 - val_auc: 0.7271 - val_f1_macro: 0.0182 - val_f1_weighted: 0.0353 - val_loss: 5.0311 - val_top5_accuracy: 0.1875 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0887 - auc: 0.8003 - f1_macro: 0.0440 - f1_weighted: 0.0636 - loss: 4.4594 - top5_accuracy: 0.2527\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0888 - auc: 0.8003 - f1_macro: 0.0441 - f1_weighted: 0.0636 - loss: 4.4593 - top5_accuracy: 0.2527 - val_accuracy: 0.0679 - val_auc: 0.7028 - val_f1_macro: 0.0193 - val_f1_weighted: 0.0393 - val_loss: 5.2144 - val_top5_accuracy: 0.1764 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1084 - auc: 0.8182 - f1_macro: 0.0619 - f1_weighted: 0.0805 - loss: 4.3297 - top5_accuracy: 0.2885 - val_accuracy: 0.0979 - val_auc: 0.7635 - val_f1_macro: 0.0424 - val_f1_weighted: 0.0680 - val_loss: 4.6762 - val_top5_accuracy: 0.2449 - learning_rate: 5.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1203 - auc: 0.8308 - f1_macro: 0.0742 - f1_weighted: 0.0920 - loss: 4.2265 - top5_accuracy: 0.3118 - val_accuracy: 0.0924 - val_auc: 0.7607 - val_f1_macro: 0.0369 - val_f1_weighted: 0.0664 - val_loss: 4.7141 - val_top5_accuracy: 0.2471 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.1315 - auc: 0.8411 - f1_macro: 0.0865 - f1_weighted: 0.1050 - loss: 4.1483 - top5_accuracy: 0.3256 - val_accuracy: 0.0846 - val_auc: 0.7539 - val_f1_macro: 0.0339 - val_f1_weighted: 0.0583 - val_loss: 4.7654 - val_top5_accuracy: 0.2376 - learning_rate: 5.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1401 - auc: 0.8502 - f1_macro: 0.0949 - f1_weighted: 0.1139 - loss: 4.0780 - top5_accuracy: 0.3434 - val_accuracy: 0.0807 - val_auc: 0.7322 - val_f1_macro: 0.0336 - val_f1_weighted: 0.0591 - val_loss: 5.0075 - val_top5_accuracy: 0.2204 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1471 - auc: 0.8578 - f1_macro: 0.1020 - f1_weighted: 0.1217 - loss: 4.0142 - top5_accuracy: 0.3583 - val_accuracy: 0.0824 - val_auc: 0.7384 - val_f1_macro: 0.0372 - val_f1_weighted: 0.0630 - val_loss: 4.9834 - val_top5_accuracy: 0.2304 - learning_rate: 5.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.1550 - auc: 0.8642 - f1_macro: 0.1120 - f1_weighted: 0.1308 - loss: 3.9490 - top5_accuracy: 0.3687\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1551 - auc: 0.8642 - f1_macro: 0.1120 - f1_weighted: 0.1308 - loss: 3.9488 - top5_accuracy: 0.3688 - val_accuracy: 0.0807 - val_auc: 0.7392 - val_f1_macro: 0.0357 - val_f1_weighted: 0.0595 - val_loss: 5.0356 - val_top5_accuracy: 0.2287 - learning_rate: 5.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.1772 - auc: 0.8752 - f1_macro: 0.1326 - f1_weighted: 0.1528 - loss: 3.8409 - top5_accuracy: 0.4017 - val_accuracy: 0.0723 - val_auc: 0.7029 - val_f1_macro: 0.0356 - val_f1_weighted: 0.0574 - val_loss: 5.3607 - val_top5_accuracy: 0.2137 - learning_rate: 2.5000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.1942 - auc: 0.8815 - f1_macro: 0.1532 - f1_weighted: 0.1715 - loss: 3.7495 - top5_accuracy: 0.4300 - val_accuracy: 0.0740 - val_auc: 0.7015 - val_f1_macro: 0.0372 - val_f1_weighted: 0.0585 - val_loss: 5.3828 - val_top5_accuracy: 0.2087 - learning_rate: 2.5000e-04\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: grayscale_plus\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 236ms/step - accuracy: 0.0491 - auc: 0.6441 - f1_macro: 0.0203 - f1_weighted: 0.0307 - loss: 5.5267 - top5_accuracy: 0.1399 - val_accuracy: 0.0189 - val_auc: 0.5567 - val_f1_macro: 6.4173e-04 - val_f1_weighted: 0.0022 - val_loss: 5.9653 - val_top5_accuracy: 0.0662 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 76ms/step - accuracy: 0.0426 - auc: 0.6518 - f1_macro: 0.0080 - f1_weighted: 0.0170 - loss: 5.1893 - top5_accuracy: 0.1224 - val_accuracy: 0.0367 - val_auc: 0.6172 - val_f1_macro: 0.0054 - val_f1_weighted: 0.0176 - val_loss: 5.4087 - val_top5_accuracy: 0.1119 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0483 - auc: 0.6836 - f1_macro: 0.0102 - f1_weighted: 0.0198 - loss: 5.0573 - top5_accuracy: 0.1347 - val_accuracy: 0.0223 - val_auc: 0.5769 - val_f1_macro: 0.0061 - val_f1_weighted: 0.0112 - val_loss: 6.3453 - val_top5_accuracy: 0.0785 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0522 - auc: 0.7035 - f1_macro: 0.0130 - f1_weighted: 0.0229 - loss: 4.9692 - top5_accuracy: 0.1495 - val_accuracy: 0.0328 - val_auc: 0.6153 - val_f1_macro: 0.0091 - val_f1_weighted: 0.0174 - val_loss: 5.4712 - val_top5_accuracy: 0.1018 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0586 - auc: 0.7207 - f1_macro: 0.0176 - f1_weighted: 0.0293 - loss: 4.8915 - top5_accuracy: 0.1636 - val_accuracy: 0.0412 - val_auc: 0.6342 - val_f1_macro: 0.0063 - val_f1_weighted: 0.0173 - val_loss: 5.3323 - val_top5_accuracy: 0.1241 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0650 - auc: 0.7365 - f1_macro: 0.0244 - f1_weighted: 0.0352 - loss: 4.8092 - top5_accuracy: 0.1743 - val_accuracy: 0.0473 - val_auc: 0.6157 - val_f1_macro: 0.0132 - val_f1_weighted: 0.0195 - val_loss: 5.5282 - val_top5_accuracy: 0.1235 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0728 - auc: 0.7473 - f1_macro: 0.0303 - f1_weighted: 0.0426 - loss: 4.7295 - top5_accuracy: 0.1938 - val_accuracy: 0.0479 - val_auc: 0.6283 - val_f1_macro: 0.0127 - val_f1_weighted: 0.0229 - val_loss: 5.6053 - val_top5_accuracy: 0.1258 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0758 - auc: 0.7637 - f1_macro: 0.0359 - f1_weighted: 0.0470 - loss: 4.6532 - top5_accuracy: 0.2088 - val_accuracy: 0.0618 - val_auc: 0.6704 - val_f1_macro: 0.0170 - val_f1_weighted: 0.0285 - val_loss: 5.2339 - val_top5_accuracy: 0.1630 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0850 - auc: 0.7720 - f1_macro: 0.0443 - f1_weighted: 0.0572 - loss: 4.5751 - top5_accuracy: 0.2343 - val_accuracy: 0.0428 - val_auc: 0.6380 - val_f1_macro: 0.0099 - val_f1_weighted: 0.0163 - val_loss: 5.7814 - val_top5_accuracy: 0.1452 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0969 - auc: 0.7873 - f1_macro: 0.0567 - f1_weighted: 0.0692 - loss: 4.4922 - top5_accuracy: 0.2500 - val_accuracy: 0.0523 - val_auc: 0.6882 - val_f1_macro: 0.0124 - val_f1_weighted: 0.0255 - val_loss: 5.1925 - val_top5_accuracy: 0.1658 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1082 - auc: 0.7998 - f1_macro: 0.0688 - f1_weighted: 0.0813 - loss: 4.4090 - top5_accuracy: 0.2714 - val_accuracy: 0.0473 - val_auc: 0.6623 - val_f1_macro: 0.0123 - val_f1_weighted: 0.0251 - val_loss: 5.4727 - val_top5_accuracy: 0.1402 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1184 - auc: 0.8119 - f1_macro: 0.0768 - f1_weighted: 0.0914 - loss: 4.3180 - top5_accuracy: 0.2895 - val_accuracy: 0.0618 - val_auc: 0.7005 - val_f1_macro: 0.0197 - val_f1_weighted: 0.0342 - val_loss: 5.2010 - val_top5_accuracy: 0.1714 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1297 - auc: 0.8246 - f1_macro: 0.0874 - f1_weighted: 0.1021 - loss: 4.2407 - top5_accuracy: 0.3067 - val_accuracy: 0.0657 - val_auc: 0.7069 - val_f1_macro: 0.0243 - val_f1_weighted: 0.0372 - val_loss: 5.2175 - val_top5_accuracy: 0.1814 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.1390 - auc: 0.8346 - f1_macro: 0.0977 - f1_weighted: 0.1119 - loss: 4.1639 - top5_accuracy: 0.3268 - val_accuracy: 0.0556 - val_auc: 0.6777 - val_f1_macro: 0.0214 - val_f1_weighted: 0.0388 - val_loss: 5.5749 - val_top5_accuracy: 0.1603 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.1492 - auc: 0.8452 - f1_macro: 0.1074 - f1_weighted: 0.1237 - loss: 4.0842 - top5_accuracy: 0.3542\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1492 - auc: 0.8452 - f1_macro: 0.1074 - f1_weighted: 0.1237 - loss: 4.0842 - top5_accuracy: 0.3542 - val_accuracy: 0.0395 - val_auc: 0.6497 - val_f1_macro: 0.0166 - val_f1_weighted: 0.0286 - val_loss: 6.0716 - val_top5_accuracy: 0.1380 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1795 - auc: 0.8595 - f1_macro: 0.1331 - f1_weighted: 0.1516 - loss: 3.9369 - top5_accuracy: 0.3910 - val_accuracy: 0.0707 - val_auc: 0.6899 - val_f1_macro: 0.0408 - val_f1_weighted: 0.0603 - val_loss: 5.5311 - val_top5_accuracy: 0.1775 - learning_rate: 5.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1973 - auc: 0.8684 - f1_macro: 0.1551 - f1_weighted: 0.1711 - loss: 3.8218 - top5_accuracy: 0.4225 - val_accuracy: 0.0612 - val_auc: 0.6875 - val_f1_macro: 0.0341 - val_f1_weighted: 0.0512 - val_loss: 5.6327 - val_top5_accuracy: 0.1781 - learning_rate: 5.0000e-04\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with augmentation: randaugment\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 198ms/step - accuracy: 0.0330 - auc: 0.6105 - f1_macro: 0.0085 - f1_weighted: 0.0174 - loss: 5.5949 - top5_accuracy: 0.1059 - val_accuracy: 0.0301 - val_auc: 0.6310 - val_f1_macro: 0.0023 - val_f1_weighted: 0.0103 - val_loss: 5.2756 - val_top5_accuracy: 0.0952 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0355 - auc: 0.6270 - f1_macro: 0.0056 - f1_weighted: 0.0147 - loss: 5.2869 - top5_accuracy: 0.1111 - val_accuracy: 0.0356 - val_auc: 0.6792 - val_f1_macro: 0.0058 - val_f1_weighted: 0.0146 - val_loss: 5.2697 - val_top5_accuracy: 0.1491 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.0453 - auc: 0.6650 - f1_macro: 0.0084 - f1_weighted: 0.0184 - loss: 5.1408 - top5_accuracy: 0.1302 - val_accuracy: 0.0607 - val_auc: 0.7066 - val_f1_macro: 0.0114 - val_f1_weighted: 0.0277 - val_loss: 4.9495 - val_top5_accuracy: 0.1786 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.0470 - auc: 0.6858 - f1_macro: 0.0098 - f1_weighted: 0.0208 - loss: 5.0581 - top5_accuracy: 0.1404 - val_accuracy: 0.0562 - val_auc: 0.6867 - val_f1_macro: 0.0142 - val_f1_weighted: 0.0302 - val_loss: 5.0748 - val_top5_accuracy: 0.1742 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.0491 - auc: 0.7074 - f1_macro: 0.0118 - f1_weighted: 0.0232 - loss: 4.9756 - top5_accuracy: 0.1501 - val_accuracy: 0.0518 - val_auc: 0.6787 - val_f1_macro: 0.0099 - val_f1_weighted: 0.0247 - val_loss: 5.2688 - val_top5_accuracy: 0.1592 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.0518 - auc: 0.7219 - f1_macro: 0.0162 - f1_weighted: 0.0280 - loss: 4.9111 - top5_accuracy: 0.1633 - val_accuracy: 0.0573 - val_auc: 0.7298 - val_f1_macro: 0.0188 - val_f1_weighted: 0.0378 - val_loss: 4.9275 - val_top5_accuracy: 0.1937 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.0560 - auc: 0.7353 - f1_macro: 0.0189 - f1_weighted: 0.0311 - loss: 4.8403 - top5_accuracy: 0.1725 - val_accuracy: 0.0779 - val_auc: 0.7265 - val_f1_macro: 0.0241 - val_f1_weighted: 0.0468 - val_loss: 4.9821 - val_top5_accuracy: 0.2053 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.0635 - auc: 0.7451 - f1_macro: 0.0239 - f1_weighted: 0.0374 - loss: 4.7839 - top5_accuracy: 0.1807 - val_accuracy: 0.0851 - val_auc: 0.7450 - val_f1_macro: 0.0284 - val_f1_weighted: 0.0535 - val_loss: 4.8277 - val_top5_accuracy: 0.2193 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.0694 - auc: 0.7595 - f1_macro: 0.0288 - f1_weighted: 0.0430 - loss: 4.7108 - top5_accuracy: 0.1957 - val_accuracy: 0.0657 - val_auc: 0.6968 - val_f1_macro: 0.0243 - val_f1_weighted: 0.0452 - val_loss: 5.1301 - val_top5_accuracy: 0.1831 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.0732 - auc: 0.7714 - f1_macro: 0.0320 - f1_weighted: 0.0476 - loss: 4.6399 - top5_accuracy: 0.2154 - val_accuracy: 0.0712 - val_auc: 0.7102 - val_f1_macro: 0.0321 - val_f1_weighted: 0.0499 - val_loss: 5.1325 - val_top5_accuracy: 0.1875 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0818 - auc: 0.7808 - f1_macro: 0.0395 - f1_weighted: 0.0553 - loss: 4.5683 - top5_accuracy: 0.2323 - val_accuracy: 0.0696 - val_auc: 0.7169 - val_f1_macro: 0.0319 - val_f1_weighted: 0.0518 - val_loss: 5.1636 - val_top5_accuracy: 0.2053 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0893 - auc: 0.7931 - f1_macro: 0.0467 - f1_weighted: 0.0632 - loss: 4.5055 - top5_accuracy: 0.2430 - val_accuracy: 0.0890 - val_auc: 0.7224 - val_f1_macro: 0.0489 - val_f1_weighted: 0.0671 - val_loss: 5.2654 - val_top5_accuracy: 0.2159 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.0981 - auc: 0.8027 - f1_macro: 0.0558 - f1_weighted: 0.0727 - loss: 4.4406 - top5_accuracy: 0.2657\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.0981 - auc: 0.8027 - f1_macro: 0.0559 - f1_weighted: 0.0727 - loss: 4.4406 - top5_accuracy: 0.2657 - val_accuracy: 0.0812 - val_auc: 0.7197 - val_f1_macro: 0.0403 - val_f1_weighted: 0.0577 - val_loss: 5.3438 - val_top5_accuracy: 0.2148 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.1169 - auc: 0.8184 - f1_macro: 0.0706 - f1_weighted: 0.0897 - loss: 4.3315 - top5_accuracy: 0.2878 - val_accuracy: 0.0963 - val_auc: 0.7372 - val_f1_macro: 0.0508 - val_f1_weighted: 0.0765 - val_loss: 5.0482 - val_top5_accuracy: 0.2376 - learning_rate: 5.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1341 - auc: 0.8323 - f1_macro: 0.0890 - f1_weighted: 0.1082 - loss: 4.2102 - top5_accuracy: 0.3204 - val_accuracy: 0.0929 - val_auc: 0.7232 - val_f1_macro: 0.0486 - val_f1_weighted: 0.0739 - val_loss: 5.2260 - val_top5_accuracy: 0.2298 - learning_rate: 5.0000e-04\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# Display the table\n",
        "display(results_df.round(4))\n"
      ],
      "metadata": {
        "id": "KjVU7FT3HQgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melt the DataFrame for seaborn plotting\n",
        "metrics_to_plot = ['train_accuracy', 'val_accuracy']\n",
        "melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "                            var_name='metric', value_name='value')\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "plt.title(\"Comparison of Accuracy Across Augmentation Strategies\")\n",
        "plt.ylim(0, 0.4)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-NJCem1yHXaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Initialize the preprocessor\n",
        "# batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "# image_size = (224, 224)\n",
        "\n",
        "# preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# # Store results\n",
        "# results = {}\n",
        "\n",
        "# # Loop through each augmentation\n",
        "# for aug in augmentations_to_test:\n",
        "#     print(f\"\\nTraining with augmentation: {aug}\")\n",
        "\n",
        "#     model = build_densenet()\n",
        "\n",
        "#     model.compile(\n",
        "#         optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "#         loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "#         metrics=metrics\n",
        "#     )\n",
        "\n",
        "#     train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment=aug, oversampling=True, shuffle=True)\n",
        "#     train_ds_sampled, class_names = preprocess.load_img(data_dir=\"data/rare_species/train_sampled\", minority_class=minority_class, augment=aug, oversampling=True, shuffle=True)\n",
        "#     val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "#     test_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/test\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "#     # Initialize the experiment\n",
        "#     experiment = Experiment(\n",
        "#         model=model,\n",
        "#         train_ds=train_ds_sampled,\n",
        "#         val_ds=val_ds,\n",
        "#         experiment_name=f\"densenet_with_{aug}_oversampling\", # MUDAR NOME!!!!!!!!!!!!\n",
        "#         batch_size=32,\n",
        "#         image_size=(224, 224),\n",
        "#         save_model = False\n",
        "#     )\n",
        "\n",
        "#     # Run the experiment\n",
        "#     history = experiment.run_experiment(callbacks=callbacks, epochs=40)\n",
        "\n",
        "#     # Predict entire validation set at once\n",
        "#     preds = model.predict(val_ds)\n",
        "#     y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "#     # Extract true labels in order\n",
        "#     y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "#     # Compute metrics\n",
        "#     f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "#     f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "#     precision = precision_score(y_true, y_pred, average='weighted')\n",
        "#     recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "#     # Store in results\n",
        "#     results[aug] = {\n",
        "#         \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "#         \"f1_macro\": f1_macro,\n",
        "#         \"f1_weighted\": f1_weighted,\n",
        "#         \"precision\": precision,\n",
        "#         \"recall\": recall\n",
        "#     }\n",
        "\n",
        "#     print(f\"Finished '{aug}'\")\n",
        "#     print(f\"  Accuracy:      {results[aug]['accuracy']:.4f}\")\n",
        "#     print(f\"  F1 (macro):    {results[aug]['f1_macro']:.4f}\")\n",
        "#     print(f\"  F1 (weighted): {results[aug]['f1_weighted']:.4f}\")\n",
        "#     print(f\"  Precision:     {results[aug]['precision']:.4f}\")\n",
        "#     print(f\"  Recall:        {results[aug]['recall']:.4f}\")\n",
        "\n",
        "#     # Clear memory to avoid OOM\n",
        "#     del model\n",
        "#     del experiment\n",
        "#     K.clear_session()\n",
        "#     gc.collect()\n"
      ],
      "metadata": {
        "id": "-yc3nOJp8DX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Convert results to a DataFrame\n",
        "# results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "# results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# # Display the table\n",
        "# display(results_df.round(4))\n"
      ],
      "metadata": {
        "id": "-RP620dL8F2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Melt the DataFrame for seaborn plotting\n",
        "# metrics_to_plot = ['accuracy', 'f1_macro', 'f1_weighted', 'precision', 'recall']\n",
        "# melted_df = results_df.melt(id_vars='augmentation', value_vars=metrics_to_plot,\n",
        "#                             var_name='metric', value_name='value')\n",
        "\n",
        "# # Plot using seaborn\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# sns.barplot(data=melted_df, x='augmentation', y='value', hue='metric')\n",
        "# plt.title(\"Comparison of Metrics Across Augmentation Strategies\")\n",
        "# plt.ylim(0, 0.4)\n",
        "# plt.xticks(rotation=45)\n",
        "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "bvRJlfXq8IS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing DenseNet different architectures"
      ],
      "metadata": {
        "id": "YyfBBtZjE2l7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "# import pandas as pd\n",
        "\n",
        "# # DenseNet components (bottleneck always included)\n",
        "# def dense_layer(x, growth_rate):\n",
        "#     out = tf.keras.layers.BatchNormalization()(x)\n",
        "#     out = tf.keras.layers.ReLU()(out)\n",
        "#     out = tf.keras.layers.Conv2D(4 * growth_rate, (1, 1), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(out)\n",
        "#     out = tf.keras.layers.BatchNormalization()(out)\n",
        "#     out = tf.keras.layers.ReLU()(out)\n",
        "#     out = tf.keras.layers.Conv2D(growth_rate, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(out)\n",
        "#     x = tf.keras.layers.Concatenate()([x, out])\n",
        "#     return x\n",
        "\n",
        "# def dense_block(x, num_layers, growth_rate):\n",
        "#     for _ in range(num_layers):\n",
        "#         x = dense_layer(x, growth_rate)\n",
        "#     return x\n",
        "\n",
        "# def transition_layer(x, compression=0.5):\n",
        "#     filters = int(tf.keras.backend.int_shape(x)[-1] * compression)\n",
        "#     x = tf.keras.layers.BatchNormalization()(x)\n",
        "#     x = tf.keras.layers.ReLU()(x)\n",
        "#     x = tf.keras.layers.Conv2D(filters, (1, 1), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
        "#     x = tf.keras.layers.AveragePooling2D((2, 2), strides=2)(x)\n",
        "#     return x\n",
        "\n",
        "# def build_densenet(input_shape=(224, 224, 3),\n",
        "#                    num_classes=202,\n",
        "#                    block_layers=[6, 12, 24, 16],\n",
        "#                    growth_rate=32,\n",
        "#                    compression=0.5,\n",
        "#                    dropout_rate=0.0):\n",
        "#     inputs = tf.keras.Input(shape=input_shape)\n",
        "#     x = tf.keras.layers.Conv2D(64, (7, 7), strides=2, padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(inputs)\n",
        "#     x = tf.keras.layers.BatchNormalization()(x)\n",
        "#     x = tf.keras.layers.ReLU()(x)\n",
        "#     x = tf.keras.layers.AveragePooling2D((3, 3), strides=2, padding='same')(x)\n",
        "\n",
        "#     for i, num_layers in enumerate(block_layers):\n",
        "#         x = dense_block(x, num_layers, growth_rate)\n",
        "#         if i < len(block_layers) - 1:\n",
        "#             x = transition_layer(x, compression)\n",
        "\n",
        "#     x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "#     if dropout_rate > 0:\n",
        "#         x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "#     outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "#     return tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# # Define model variants - dropmout, learog rate, lqbel somothing, 30 ecpochs, callbacks\n",
        "# def build_densenet_light():\n",
        "#     return build_densenet(block_layers=[4, 4, 4, 4], growth_rate=12, compression=0.5, dropout_rate=0.0)\n",
        "\n",
        "# def build_densenet_medium():\n",
        "#     return build_densenet(block_layers=[6, 12, 8, 6], growth_rate=24, compression=0.5, dropout_rate=0.3)\n",
        "\n",
        "# def build_densenet_heavy():\n",
        "#     return build_densenet(block_layers=[6, 12, 24, 16], growth_rate=32, compression=0.8, dropout_rate=0.5)\n",
        "\n",
        "# # Prepare model builders\n",
        "# densenet_models = {\n",
        "#     \"densenet_light\": build_densenet_light,\n",
        "#     \"densenet_medium\": build_densenet_medium,\n",
        "#     \"densenet_heavy\": build_densenet_heavy,\n",
        "# }\n",
        "\n",
        "# # Hyperparameters\n",
        "# batch_size = 32\n",
        "# image_size = (224, 224)\n",
        "# all_results = []\n",
        "\n",
        "# # Data and callbacks should be defined outside (placeholders here)\n",
        "# preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# # Loop to train each variant\n",
        "# for arch_name, build_fn in densenet_models.items():\n",
        "#     print(f\"\\nTraining architecture: {arch_name}\")\n",
        "#     model = build_fn()\n",
        "#     model.compile(\n",
        "#         optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "#         loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.01),\n",
        "#         metrics=metrics\n",
        "#     )\n",
        "\n",
        "#     train_ds, class_names = preprocess.load_img(\n",
        "#         data_dir=\"data/rare_species/train\",\n",
        "#         minority_class=minority_class,\n",
        "#         augment=\"mixup\",\n",
        "#         oversampling=True,\n",
        "#         shuffle=True\n",
        "#     )\n",
        "\n",
        "#     val_ds, _ = preprocess.load_img(\n",
        "#         data_dir=\"data/rare_species/val\",\n",
        "#         minority_class=minority_class,\n",
        "#         augment=None,\n",
        "#         oversampling=False\n",
        "#     )\n",
        "\n",
        "#     experiment = Experiment(\n",
        "#         model=model,\n",
        "#         train_ds=train_ds,\n",
        "#         val_ds=val_ds,\n",
        "#         experiment_name=f\"{arch_name}\",\n",
        "#         batch_size=batch_size,\n",
        "#         image_size=image_size,\n",
        "#         save_model=False\n",
        "#     )\n",
        "\n",
        "#     history = experiment.run_experiment(callbacks=callbacks, epochs=30)\n",
        "\n",
        "#     val_losses = history.history[\"val_loss\"]\n",
        "#     best_epoch = np.argmin(val_losses) + 1\n",
        "\n",
        "#     preds = model.predict(val_ds)\n",
        "#     y_pred = np.argmax(preds, axis=1)\n",
        "#     y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "#     f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "#     f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "#     precision = precision_score(y_true, y_pred, average='weighted')\n",
        "#     recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "#     train_eval = model.evaluate(train_ds, verbose=0)\n",
        "#     val_eval = model.evaluate(val_ds, verbose=0)\n",
        "\n",
        "#     metric_names = [\"loss\", \"accuracy\", \"auc\", \"top5_accuracy\"]\n",
        "#     train_metrics = dict(zip(metric_names, train_eval))\n",
        "#     val_metrics = dict(zip(metric_names, val_eval))\n",
        "\n",
        "#     all_results.append({\n",
        "#         \"architecture\": arch_name,\n",
        "#         \"best epoch\": best_epoch,\n",
        "#         \"train_loss\": train_metrics[\"loss\"],\n",
        "#         \"val_loss\": val_metrics[\"loss\"],\n",
        "#         \"train_accuracy\": train_metrics[\"accuracy\"],\n",
        "#         \"val_accuracy\": val_metrics[\"accuracy\"],\n",
        "#         \"val_f1_macro\": f1_macro,\n",
        "#         \"val_f1_weighted\": f1_weighted,\n",
        "#         \"val_precision\": precision,\n",
        "#         \"val_recall\": recall\n",
        "#     })\n",
        "\n",
        "# # Show results as DataFrame\n",
        "# results_df = pd.DataFrame(all_results)\n",
        "# print(results_df.round(4))\n"
      ],
      "metadata": {
        "id": "ZXU9jvysE86Z",
        "outputId": "e0246e29-0f12-4bb4-8d4b-decfd6f6aa1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training architecture: densenet_light\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1005s\u001b[0m 3s/step - accuracy: 0.0135 - auc: 0.5408 - f1_macro: 0.0019 - f1_weighted: 0.0036 - loss: 5.4445 - top5_accuracy: 0.0585 - val_accuracy: 0.0200 - val_auc: 0.6091 - val_f1_macro: 0.0023 - val_f1_weighted: 0.0074 - val_loss: 5.3124 - val_top5_accuracy: 0.1096 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training architecture: densenet_medium\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 252ms/step - accuracy: 0.0339 - auc: 0.5778 - f1_macro: 0.0042 - f1_weighted: 0.0123 - loss: 5.9029 - top5_accuracy: 0.1054 - val_accuracy: 0.0184 - val_auc: 0.5967 - val_f1_macro: 0.0015 - val_f1_weighted: 0.0065 - val_loss: 5.8440 - val_top5_accuracy: 0.0824 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 145ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training architecture: densenet_heavy\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 463ms/step - accuracy: 0.0341 - auc: 0.5839 - f1_macro: 0.0065 - f1_weighted: 0.0155 - loss: 7.0479 - top5_accuracy: 0.1044 - val_accuracy: 0.0184 - val_auc: 0.5734 - val_f1_macro: 9.7968e-04 - val_f1_weighted: 0.0037 - val_loss: 7.1256 - val_top5_accuracy: 0.0740 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 296ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      architecture  best epoch  train_loss  val_loss  train_accuracy  \\\n",
            "0   densenet_light           1      5.3915    5.3124          0.0141   \n",
            "1  densenet_medium           1      5.9831    5.8440          0.0154   \n",
            "2   densenet_heavy           1      7.2905    7.1256          0.0170   \n",
            "\n",
            "   val_accuracy  val_f1_macro  val_f1_weighted  val_precision  val_recall  \n",
            "0        0.0200        0.0023           0.0074         0.0064      0.0200  \n",
            "1        0.0184        0.0015           0.0065         0.0088      0.0184  \n",
            "2        0.0184        0.0010           0.0037         0.0023      0.0184  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# results_df = pd.DataFrame(all_results)\n",
        "# results_df = results_df.sort_values(by=\"val_f1_macro\", ascending=False).reset_index(drop=True)\n",
        "# display(results_df.round(4))"
      ],
      "metadata": {
        "id": "ojrU1rncO1P8",
        "outputId": "2d8fb260-6186-4230-dabb-6d01ee4d1b05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      architecture  best epoch  train_loss  val_loss  train_accuracy  \\\n",
              "0   densenet_light           1      5.3915    5.3124          0.0141   \n",
              "1  densenet_medium           1      5.9831    5.8440          0.0154   \n",
              "2   densenet_heavy           1      7.2905    7.1256          0.0170   \n",
              "\n",
              "   val_accuracy  val_f1_macro  val_f1_weighted  val_precision  val_recall  \n",
              "0        0.0200        0.0023           0.0074         0.0064      0.0200  \n",
              "1        0.0184        0.0015           0.0065         0.0088      0.0184  \n",
              "2        0.0184        0.0010           0.0037         0.0023      0.0184  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f375768c-36de-4581-8361-8f966df219ce\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>architecture</th>\n",
              "      <th>best epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_f1_macro</th>\n",
              "      <th>val_f1_weighted</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>densenet_light</td>\n",
              "      <td>1</td>\n",
              "      <td>5.3915</td>\n",
              "      <td>5.3124</td>\n",
              "      <td>0.0141</td>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0023</td>\n",
              "      <td>0.0074</td>\n",
              "      <td>0.0064</td>\n",
              "      <td>0.0200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>densenet_medium</td>\n",
              "      <td>1</td>\n",
              "      <td>5.9831</td>\n",
              "      <td>5.8440</td>\n",
              "      <td>0.0154</td>\n",
              "      <td>0.0184</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0088</td>\n",
              "      <td>0.0184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>densenet_heavy</td>\n",
              "      <td>1</td>\n",
              "      <td>7.2905</td>\n",
              "      <td>7.1256</td>\n",
              "      <td>0.0170</td>\n",
              "      <td>0.0184</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.0023</td>\n",
              "      <td>0.0184</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f375768c-36de-4581-8361-8f966df219ce')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f375768c-36de-4581-8361-8f966df219ce button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f375768c-36de-4581-8361-8f966df219ce');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-11022099-9605-48be-801c-dc6b6e3f4b9b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11022099-9605-48be-801c-dc6b6e3f4b9b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-11022099-9605-48be-801c-dc6b6e3f4b9b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(results_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"architecture\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"densenet_light\",\n          \"densenet_medium\",\n          \"densenet_heavy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9717240966447214,\n        \"min\": 5.3915,\n        \"max\": 7.2905,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5.3915\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9320936433642277,\n        \"min\": 5.3124,\n        \"max\": 7.1256,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5.3124\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0014525839046333959,\n        \"min\": 0.0141,\n        \"max\": 0.017,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0141\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009237604307034016,\n        \"min\": 0.0184,\n        \"max\": 0.02,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0184\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0006557438524302001,\n        \"min\": 0.001,\n        \"max\": 0.0023,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0023\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_f1_weighted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0019295940851208405,\n        \"min\": 0.0037,\n        \"max\": 0.0074,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0074\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0032868424564212587,\n        \"min\": 0.0023,\n        \"max\": 0.0088,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0064\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009237604307034016,\n        \"min\": 0.0184,\n        \"max\": 0.02,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0184\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import pandas as pd\n",
        "\n",
        "# CBAM Block (Convolutional Block Attention Module)\n",
        "def cbam_block(input_feature, ratio=8):\n",
        "    channel = input_feature.shape[-1]\n",
        "\n",
        "    # Channel attention\n",
        "    avg_pool = tf.keras.layers.GlobalAveragePooling2D()(input_feature)\n",
        "    max_pool = tf.keras.layers.GlobalMaxPooling2D()(input_feature)\n",
        "    shared_dense_one = tf.keras.layers.Dense(channel // ratio, activation='relu', kernel_initializer='he_normal', use_bias=True)\n",
        "    shared_dense_two = tf.keras.layers.Dense(channel, kernel_initializer='he_normal', use_bias=True)\n",
        "\n",
        "    avg_out = shared_dense_two(shared_dense_one(avg_pool))\n",
        "    max_out = shared_dense_two(shared_dense_one(max_pool))\n",
        "    channel_attention = tf.keras.layers.Add()([avg_out, max_out])\n",
        "    channel_attention = tf.keras.layers.Activation('sigmoid')(channel_attention)\n",
        "    channel_attention = tf.keras.layers.Multiply()([input_feature, tf.keras.layers.Reshape((1, 1, channel))(channel_attention)])\n",
        "\n",
        "    # Spatial attention\n",
        "    avg_pool = tf.reduce_mean(channel_attention, axis=-1, keepdims=True)\n",
        "    max_pool = tf.reduce_max(channel_attention, axis=-1, keepdims=True)\n",
        "    concat = tf.concat([avg_pool, max_pool], axis=-1)\n",
        "    spatial_attention = tf.keras.layers.Conv2D(1, kernel_size=7, strides=1, padding='same', activation='sigmoid')(concat)\n",
        "    refined_feature = tf.keras.layers.Multiply()([channel_attention, spatial_attention])\n",
        "\n",
        "    return refined_feature\n",
        "\n",
        "# DenseNet components (bottleneck sempre incluído)\n",
        "def dense_layer(x, growth_rate):\n",
        "    out = tf.keras.layers.BatchNormalization()(x)\n",
        "    out = tf.keras.layers.ReLU()(out)\n",
        "    out = tf.keras.layers.Conv2D(4 * growth_rate, (1, 1), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(out)\n",
        "    out = tf.keras.layers.BatchNormalization()(out)\n",
        "    out = tf.keras.layers.ReLU()(out)\n",
        "    out = tf.keras.layers.Conv2D(growth_rate, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(out)\n",
        "    x = tf.keras.layers.Concatenate()([x, out])\n",
        "    return x\n",
        "\n",
        "def dense_block(x, num_layers, growth_rate, use_cbam=False):\n",
        "    for _ in range(num_layers):\n",
        "        x = dense_layer(x, growth_rate)\n",
        "    if use_cbam:\n",
        "        x = cbam_block(x)\n",
        "    return x\n",
        "\n",
        "def transition_layer(x, compression=0.5):\n",
        "    filters = int(tf.keras.backend.int_shape(x)[-1] * compression)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Conv2D(filters, (1, 1), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
        "    x = tf.keras.layers.AveragePooling2D((2, 2), strides=2)(x)\n",
        "    return x\n",
        "\n",
        "def build_densenet(input_shape=(224, 224, 3),\n",
        "                   num_classes=202,\n",
        "                   block_layers=[6, 12, 24, 16],\n",
        "                   growth_rate=32,\n",
        "                   compression=0.5,\n",
        "                   dropout_rate=0.3,\n",
        "                   use_cbam=False):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Conv2D(64, (7, 7), strides=2, padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.AveragePooling2D((3, 3), strides=2, padding='same')(x)\n",
        "\n",
        "    for i, num_layers in enumerate(block_layers):\n",
        "        x = dense_block(x, num_layers, growth_rate, use_cbam=use_cbam)\n",
        "        if i < len(block_layers) - 1:\n",
        "            x = transition_layer(x, compression)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    if dropout_rate > 0:\n",
        "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "LHdvR_YKamgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Três arquiteturas formais + CBAM personalizada\n",
        "densenet_variants = {\n",
        "    \"DenseNet-121\": lambda: build_densenet(block_layers=[6, 12, 24, 16], growth_rate=32, compression=0.5, dropout_rate=0.3),\n",
        "    \"DenseNet-169\": lambda: build_densenet(block_layers=[6, 12, 32, 32], growth_rate=32, compression=0.5, dropout_rate=0.3),\n",
        "    \"DenseNet-201\": lambda: build_densenet(block_layers=[6, 12, 48, 32], growth_rate=32, compression=0.5, dropout_rate=0.3),\n",
        "    \"DenseNet-CBAM-Light\": lambda: build_densenet(block_layers=[4, 6, 8, 6], growth_rate=24, compression=0.5, dropout_rate=0.3, use_cbam=True),\n",
        "}\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "all_results = []\n",
        "\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# Loop para treinar cada arquitetura\n",
        "for arch_name, build_fn in densenet_variants.items():\n",
        "    print(f\"\\nTraining architecture: {arch_name}\")\n",
        "    model = build_fn()\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.01),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    train_ds, class_names = preprocess.load_img(\n",
        "        data_dir=\"data/rare_species/train\",\n",
        "        minority_class=minority_class,\n",
        "        augment=\"mixup\",\n",
        "        oversampling=True,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_ds, _ = preprocess.load_img(\n",
        "        data_dir=\"data/rare_species/val\",\n",
        "        minority_class=minority_class,\n",
        "        augment=None,\n",
        "        oversampling=False\n",
        "    )\n",
        "\n",
        "    experiment = Experiment(\n",
        "        model=model,\n",
        "        train_ds=train_ds,\n",
        "        val_ds=val_ds,\n",
        "        experiment_name=f\"{arch_name}\",\n",
        "        batch_size=batch_size,\n",
        "        image_size=image_size,\n",
        "        save_model=False\n",
        "    )\n",
        "\n",
        "    history = experiment.run_experiment(callbacks=callbacks, epochs=30)\n",
        "\n",
        "    val_losses = history.history[\"val_loss\"]\n",
        "    best_epoch = np.argmin(val_losses) + 1\n",
        "\n",
        "    preds = model.predict(val_ds)\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "    y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    train_eval = model.evaluate(train_ds, verbose=0)\n",
        "    val_eval = model.evaluate(val_ds, verbose=0)\n",
        "\n",
        "    metric_names = [\"loss\", \"accuracy\", \"auc\", \"top5_accuracy\"]\n",
        "    train_metrics = dict(zip(metric_names, train_eval))\n",
        "    val_metrics = dict(zip(metric_names, val_eval))\n",
        "\n",
        "    all_results.append({\n",
        "        \"architecture\": arch_name,\n",
        "        \"best epoch\": best_epoch,\n",
        "        \"train_loss\": train_metrics[\"loss\"],\n",
        "        \"val_loss\": val_metrics[\"loss\"],\n",
        "        \"train_accuracy\": train_metrics[\"accuracy\"],\n",
        "        \"val_accuracy\": val_metrics[\"accuracy\"],\n",
        "        \"val_f1_macro\": f1_macro,\n",
        "        \"val_f1_weighted\": f1_weighted,\n",
        "        \"val_precision\": precision,\n",
        "        \"val_recall\": recall\n",
        "    })\n",
        "\n",
        "# Mostrar resultados finais\n",
        "results_df = pd.DataFrame(all_results)\n",
        "print(results_df.round(4))\n"
      ],
      "metadata": {
        "id": "xHzQ_yfZjgZe",
        "outputId": "c9798041-f496-44ec-b638-b5f635721511",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training architecture: DenseNet-121\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1061s\u001b[0m 2s/step - accuracy: 0.0277 - auc: 0.5724 - f1_macro: 0.0052 - f1_weighted: 0.0116 - loss: 7.1770 - top5_accuracy: 0.0948 - val_accuracy: 0.0161 - val_auc: 0.5583 - val_f1_macro: 8.9211e-04 - val_f1_weighted: 0.0035 - val_loss: 30.7373 - val_top5_accuracy: 0.0746 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 282ms/step - accuracy: 0.0531 - auc: 0.6236 - f1_macro: 0.0056 - f1_weighted: 0.0164 - loss: 6.2278 - top5_accuracy: 0.1425 - val_accuracy: 0.0501 - val_auc: 0.6383 - val_f1_macro: 0.0040 - val_f1_weighted: 0.0116 - val_loss: 5.9746 - val_top5_accuracy: 0.1224 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 281ms/step - accuracy: 0.0587 - auc: 0.6387 - f1_macro: 0.0081 - f1_weighted: 0.0201 - loss: 5.8281 - top5_accuracy: 0.1638 - val_accuracy: 0.0484 - val_auc: 0.6421 - val_f1_macro: 0.0032 - val_f1_weighted: 0.0105 - val_loss: 5.7665 - val_top5_accuracy: 0.1113 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 281ms/step - accuracy: 0.0623 - auc: 0.6480 - f1_macro: 0.0094 - f1_weighted: 0.0226 - loss: 5.5825 - top5_accuracy: 0.1658 - val_accuracy: 0.0551 - val_auc: 0.6968 - val_f1_macro: 0.0050 - val_f1_weighted: 0.0166 - val_loss: 5.4287 - val_top5_accuracy: 0.1592 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 280ms/step - accuracy: 0.0646 - auc: 0.6564 - f1_macro: 0.0120 - f1_weighted: 0.0249 - loss: 5.3987 - top5_accuracy: 0.1803 - val_accuracy: 0.0373 - val_auc: 0.6101 - val_f1_macro: 0.0065 - val_f1_weighted: 0.0166 - val_loss: 6.8253 - val_top5_accuracy: 0.1080 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 280ms/step - accuracy: 0.0694 - auc: 0.6617 - f1_macro: 0.0138 - f1_weighted: 0.0270 - loss: 5.2835 - top5_accuracy: 0.1940 - val_accuracy: 0.0456 - val_auc: 0.6869 - val_f1_macro: 0.0082 - val_f1_weighted: 0.0186 - val_loss: 5.4540 - val_top5_accuracy: 0.1558 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 280ms/step - accuracy: 0.0678 - auc: 0.6619 - f1_macro: 0.0150 - f1_weighted: 0.0279 - loss: 5.2632 - top5_accuracy: 0.1943 - val_accuracy: 0.0334 - val_auc: 0.6436 - val_f1_macro: 0.0057 - val_f1_weighted: 0.0175 - val_loss: 5.6786 - val_top5_accuracy: 0.1291 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 281ms/step - accuracy: 0.0675 - auc: 0.6620 - f1_macro: 0.0132 - f1_weighted: 0.0267 - loss: 5.2347 - top5_accuracy: 0.1962 - val_accuracy: 0.0812 - val_auc: 0.7370 - val_f1_macro: 0.0198 - val_f1_weighted: 0.0381 - val_loss: 5.0804 - val_top5_accuracy: 0.2076 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 280ms/step - accuracy: 0.0743 - auc: 0.6688 - f1_macro: 0.0180 - f1_weighted: 0.0318 - loss: 5.1543 - top5_accuracy: 0.2071 - val_accuracy: 0.0501 - val_auc: 0.7209 - val_f1_macro: 0.0105 - val_f1_weighted: 0.0201 - val_loss: 5.2143 - val_top5_accuracy: 0.1697 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 279ms/step - accuracy: 0.0833 - auc: 0.6754 - f1_macro: 0.0217 - f1_weighted: 0.0365 - loss: 5.0808 - top5_accuracy: 0.2160 - val_accuracy: 0.0718 - val_auc: 0.7126 - val_f1_macro: 0.0222 - val_f1_weighted: 0.0378 - val_loss: 5.4457 - val_top5_accuracy: 0.1953 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 279ms/step - accuracy: 0.0786 - auc: 0.6795 - f1_macro: 0.0225 - f1_weighted: 0.0357 - loss: 5.0275 - top5_accuracy: 0.2248 - val_accuracy: 0.0529 - val_auc: 0.7263 - val_f1_macro: 0.0165 - val_f1_weighted: 0.0230 - val_loss: 5.1039 - val_top5_accuracy: 0.1714 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 279ms/step - accuracy: 0.0849 - auc: 0.6807 - f1_macro: 0.0256 - f1_weighted: 0.0392 - loss: 5.0095 - top5_accuracy: 0.2304 - val_accuracy: 0.0607 - val_auc: 0.7245 - val_f1_macro: 0.0162 - val_f1_weighted: 0.0309 - val_loss: 5.0686 - val_top5_accuracy: 0.1853 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 279ms/step - accuracy: 0.0863 - auc: 0.6849 - f1_macro: 0.0267 - f1_weighted: 0.0418 - loss: 4.9576 - top5_accuracy: 0.2327 - val_accuracy: 0.0445 - val_auc: 0.6913 - val_f1_macro: 0.0133 - val_f1_weighted: 0.0215 - val_loss: 5.5505 - val_top5_accuracy: 0.1547 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 279ms/step - accuracy: 0.0889 - auc: 0.6894 - f1_macro: 0.0295 - f1_weighted: 0.0444 - loss: 4.9235 - top5_accuracy: 0.2446 - val_accuracy: 0.0139 - val_auc: 0.6066 - val_f1_macro: 0.0039 - val_f1_weighted: 0.0085 - val_loss: 6.0886 - val_top5_accuracy: 0.0651 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 279ms/step - accuracy: 0.0906 - auc: 0.6942 - f1_macro: 0.0327 - f1_weighted: 0.0474 - loss: 4.8684 - top5_accuracy: 0.2556 - val_accuracy: 0.0462 - val_auc: 0.6750 - val_f1_macro: 0.0132 - val_f1_weighted: 0.0277 - val_loss: 5.7731 - val_top5_accuracy: 0.1469 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 279ms/step - accuracy: 0.1010 - auc: 0.6954 - f1_macro: 0.0390 - f1_weighted: 0.0550 - loss: 4.8450 - top5_accuracy: 0.2640 - val_accuracy: 0.0223 - val_auc: 0.6266 - val_f1_macro: 0.0093 - val_f1_weighted: 0.0161 - val_loss: 11.3019 - val_top5_accuracy: 0.0885 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.1013 - auc: 0.6992 - f1_macro: 0.0402 - f1_weighted: 0.0554 - loss: 4.8548 - top5_accuracy: 0.2685\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 279ms/step - accuracy: 0.1013 - auc: 0.6992 - f1_macro: 0.0403 - f1_weighted: 0.0554 - loss: 4.8547 - top5_accuracy: 0.2685 - val_accuracy: 0.0295 - val_auc: 0.6454 - val_f1_macro: 0.0184 - val_f1_weighted: 0.0238 - val_loss: 6.8310 - val_top5_accuracy: 0.1096 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 279ms/step - accuracy: 0.1164 - auc: 0.7057 - f1_macro: 0.0484 - f1_weighted: 0.0657 - loss: 4.7649 - top5_accuracy: 0.2905 - val_accuracy: 0.0384 - val_auc: 0.7044 - val_f1_macro: 0.0169 - val_f1_weighted: 0.0279 - val_loss: 5.2754 - val_top5_accuracy: 0.1647 - learning_rate: 5.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 279ms/step - accuracy: 0.1276 - auc: 0.7114 - f1_macro: 0.0587 - f1_weighted: 0.0754 - loss: 4.6620 - top5_accuracy: 0.3151 - val_accuracy: 0.0440 - val_auc: 0.7123 - val_f1_macro: 0.0192 - val_f1_weighted: 0.0318 - val_loss: 5.2054 - val_top5_accuracy: 0.1742 - learning_rate: 5.0000e-04\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training architecture: DenseNet-169\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 475ms/step - accuracy: 0.0392 - auc: 0.6038 - f1_macro: 0.0099 - f1_weighted: 0.0195 - loss: 8.0660 - top5_accuracy: 0.1181 - val_accuracy: 0.0328 - val_auc: 0.6652 - val_f1_macro: 0.0021 - val_f1_weighted: 0.0094 - val_loss: 6.9056 - val_top5_accuracy: 0.1480 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 354ms/step - accuracy: 0.0461 - auc: 0.6187 - f1_macro: 0.0056 - f1_weighted: 0.0150 - loss: 6.7188 - top5_accuracy: 0.1316 - val_accuracy: 0.0529 - val_auc: 0.6747 - val_f1_macro: 0.0053 - val_f1_weighted: 0.0198 - val_loss: 6.4329 - val_top5_accuracy: 0.1503 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 353ms/step - accuracy: 0.0551 - auc: 0.6363 - f1_macro: 0.0095 - f1_weighted: 0.0202 - loss: 6.1310 - top5_accuracy: 0.1573 - val_accuracy: 0.0551 - val_auc: 0.6627 - val_f1_macro: 0.0086 - val_f1_weighted: 0.0238 - val_loss: 5.8984 - val_top5_accuracy: 0.1525 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 353ms/step - accuracy: 0.0579 - auc: 0.6452 - f1_macro: 0.0108 - f1_weighted: 0.0222 - loss: 5.8525 - top5_accuracy: 0.1583 - val_accuracy: 0.0562 - val_auc: 0.6891 - val_f1_macro: 0.0075 - val_f1_weighted: 0.0211 - val_loss: 5.8067 - val_top5_accuracy: 0.1458 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 353ms/step - accuracy: 0.0588 - auc: 0.6540 - f1_macro: 0.0120 - f1_weighted: 0.0232 - loss: 5.6910 - top5_accuracy: 0.1712 - val_accuracy: 0.0378 - val_auc: 0.6576 - val_f1_macro: 0.0055 - val_f1_weighted: 0.0149 - val_loss: 6.0629 - val_top5_accuracy: 0.1285 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 353ms/step - accuracy: 0.0634 - auc: 0.6572 - f1_macro: 0.0148 - f1_weighted: 0.0267 - loss: 5.5855 - top5_accuracy: 0.1788 - val_accuracy: 0.0512 - val_auc: 0.7092 - val_f1_macro: 0.0122 - val_f1_weighted: 0.0246 - val_loss: 5.4764 - val_top5_accuracy: 0.1603 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 352ms/step - accuracy: 0.0624 - auc: 0.6631 - f1_macro: 0.0163 - f1_weighted: 0.0273 - loss: 5.4669 - top5_accuracy: 0.1898 - val_accuracy: 0.0501 - val_auc: 0.6677 - val_f1_macro: 0.0118 - val_f1_weighted: 0.0279 - val_loss: 14.1760 - val_top5_accuracy: 0.1608 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 353ms/step - accuracy: 0.0685 - auc: 0.6691 - f1_macro: 0.0173 - f1_weighted: 0.0302 - loss: 5.3612 - top5_accuracy: 0.2014 - val_accuracy: 0.0640 - val_auc: 0.7330 - val_f1_macro: 0.0155 - val_f1_weighted: 0.0320 - val_loss: 5.2599 - val_top5_accuracy: 0.1981 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 352ms/step - accuracy: 0.0719 - auc: 0.6722 - f1_macro: 0.0212 - f1_weighted: 0.0345 - loss: 5.2578 - top5_accuracy: 0.2086 - val_accuracy: 0.0601 - val_auc: 0.7199 - val_f1_macro: 0.0134 - val_f1_weighted: 0.0290 - val_loss: 5.3326 - val_top5_accuracy: 0.1686 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 352ms/step - accuracy: 0.0746 - auc: 0.6787 - f1_macro: 0.0244 - f1_weighted: 0.0378 - loss: 5.1754 - top5_accuracy: 0.2219 - val_accuracy: 0.0623 - val_auc: 0.7280 - val_f1_macro: 0.0217 - val_f1_weighted: 0.0401 - val_loss: 5.2738 - val_top5_accuracy: 0.1937 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 352ms/step - accuracy: 0.0802 - auc: 0.6825 - f1_macro: 0.0269 - f1_weighted: 0.0409 - loss: 5.1174 - top5_accuracy: 0.2368 - val_accuracy: 0.0562 - val_auc: 0.7245 - val_f1_macro: 0.0153 - val_f1_weighted: 0.0329 - val_loss: 5.6139 - val_top5_accuracy: 0.1825 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 352ms/step - accuracy: 0.0887 - auc: 0.6866 - f1_macro: 0.0330 - f1_weighted: 0.0469 - loss: 5.0440 - top5_accuracy: 0.2370 - val_accuracy: 0.0634 - val_auc: 0.7422 - val_f1_macro: 0.0186 - val_f1_weighted: 0.0388 - val_loss: 5.0753 - val_top5_accuracy: 0.1914 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 352ms/step - accuracy: 0.0931 - auc: 0.6890 - f1_macro: 0.0358 - f1_weighted: 0.0507 - loss: 4.9948 - top5_accuracy: 0.2515 - val_accuracy: 0.0378 - val_auc: 0.6629 - val_f1_macro: 0.0135 - val_f1_weighted: 0.0228 - val_loss: 5.8582 - val_top5_accuracy: 0.1469 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 351ms/step - accuracy: 0.0879 - auc: 0.6885 - f1_macro: 0.0349 - f1_weighted: 0.0473 - loss: 4.9953 - top5_accuracy: 0.2489 - val_accuracy: 0.0679 - val_auc: 0.7191 - val_f1_macro: 0.0226 - val_f1_weighted: 0.0429 - val_loss: 5.5229 - val_top5_accuracy: 0.1792 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 351ms/step - accuracy: 0.0950 - auc: 0.6955 - f1_macro: 0.0369 - f1_weighted: 0.0516 - loss: 4.9134 - top5_accuracy: 0.2625 - val_accuracy: 0.0111 - val_auc: 0.5297 - val_f1_macro: 0.0082 - val_f1_weighted: 0.0068 - val_loss: 16.2974 - val_top5_accuracy: 0.0501 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 351ms/step - accuracy: 0.0923 - auc: 0.6934 - f1_macro: 0.0374 - f1_weighted: 0.0521 - loss: 4.9393 - top5_accuracy: 0.2642 - val_accuracy: 0.0757 - val_auc: 0.7540 - val_f1_macro: 0.0286 - val_f1_weighted: 0.0537 - val_loss: 4.9182 - val_top5_accuracy: 0.2332 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 351ms/step - accuracy: 0.1048 - auc: 0.6971 - f1_macro: 0.0434 - f1_weighted: 0.0602 - loss: 4.8519 - top5_accuracy: 0.2732 - val_accuracy: 0.0712 - val_auc: 0.7473 - val_f1_macro: 0.0282 - val_f1_weighted: 0.0488 - val_loss: 5.1106 - val_top5_accuracy: 0.2120 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 350ms/step - accuracy: 0.1091 - auc: 0.7015 - f1_macro: 0.0493 - f1_weighted: 0.0658 - loss: 4.8411 - top5_accuracy: 0.2863 - val_accuracy: 0.0339 - val_auc: 0.6750 - val_f1_macro: 0.0129 - val_f1_weighted: 0.0242 - val_loss: 7.7459 - val_top5_accuracy: 0.1430 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 351ms/step - accuracy: 0.1083 - auc: 0.7005 - f1_macro: 0.0457 - f1_weighted: 0.0626 - loss: 4.8624 - top5_accuracy: 0.2892 - val_accuracy: 0.0634 - val_auc: 0.7165 - val_f1_macro: 0.0244 - val_f1_weighted: 0.0427 - val_loss: 5.1277 - val_top5_accuracy: 0.1948 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 352ms/step - accuracy: 0.1277 - auc: 0.7069 - f1_macro: 0.0610 - f1_weighted: 0.0793 - loss: 4.7615 - top5_accuracy: 0.3076 - val_accuracy: 0.0957 - val_auc: 0.7581 - val_f1_macro: 0.0396 - val_f1_weighted: 0.0697 - val_loss: 4.9075 - val_top5_accuracy: 0.2571 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 350ms/step - accuracy: 0.1276 - auc: 0.7107 - f1_macro: 0.0643 - f1_weighted: 0.0819 - loss: 4.7530 - top5_accuracy: 0.3182 - val_accuracy: 0.0584 - val_auc: 0.7071 - val_f1_macro: 0.0305 - val_f1_weighted: 0.0493 - val_loss: 14.3210 - val_top5_accuracy: 0.2020 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m308/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14s\u001b[0m 337ms/step - accuracy: 0.1335 - auc: 0.7158 - f1_macro: 0.0669 - f1_weighted: 0.0862 - loss: 4.7024 - top5_accuracy: 0.3364"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(all_results)\n",
        "results_df = results_df.sort_values(by=\"val_f1_macro\", ascending=False).reset_index(drop=True)\n",
        "display(results_df.round(4))"
      ],
      "metadata": {
        "id": "8eMLnYv-j_1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet do chat boss"
      ],
      "metadata": {
        "id": "opbj_VwtdvKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dense_layer(x, growth_rate, dropout_rate, bottleneck):\n",
        "    # ‑‑ Optionally add a 1×1 bottleneck (DenseNet‑B)\n",
        "    if bottleneck:\n",
        "        x1 = BatchNormalization()(x)\n",
        "        x1 = ReLU()(x1)\n",
        "        x1 = Conv2D(4 * growth_rate, (1, 1), padding='same',\n",
        "                    kernel_regularizer=l2(1e-4))(x1)\n",
        "        x1 = BatchNormalization()(x1)\n",
        "        x1 = ReLU()(x1)\n",
        "        x1 = Conv2D(growth_rate, (3, 3), padding='same',\n",
        "                    kernel_regularizer=l2(1e-4))(x1)\n",
        "    else:\n",
        "        x1 = BatchNormalization()(x)\n",
        "        x1 = ReLU()(x1)\n",
        "        x1 = Conv2D(growth_rate, (3, 3), padding='same',\n",
        "                    kernel_regularizer=l2(1e-4))(x1)\n",
        "\n",
        "    if dropout_rate:                    # dropout depois do conv\n",
        "        x1 = Dropout(dropout_rate)(x1)\n",
        "    return Concatenate()([x, x1])       # dense connection\n",
        "\n",
        "\n",
        "def dense_block(x, n_layers, growth_rate, dropout_rate, bottleneck):\n",
        "    for _ in range(n_layers):\n",
        "        x = dense_layer(x, growth_rate, dropout_rate, bottleneck)\n",
        "    return x\n",
        "\n",
        "\n",
        "def transition_layer(x, compression, dropout_rate):\n",
        "    filters = int(tf.keras.backend.int_shape(x)[-1] * compression)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(filters, (1, 1), padding='same',\n",
        "               kernel_regularizer=l2(1e-4))(x)\n",
        "    if dropout_rate:\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "    return AveragePooling2D((2, 2), strides=2)(x)\n",
        "\n",
        "\n",
        "def build_densenet(input_shape=(224, 224, 3),\n",
        "                   num_classes=202,\n",
        "                   layers_per_block=(6, 12, 24, 16),\n",
        "                   growth_rate=32,\n",
        "                   compression=0.5,\n",
        "                   bottleneck=True,\n",
        "                   dropout_rate=0.3):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Stem\n",
        "    x = Conv2D(64, (7, 7), strides=2, padding='same',\n",
        "               kernel_regularizer=l2(1e-4))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = AveragePooling2D((3, 3), strides=2, padding='same')(x)\n",
        "\n",
        "    # Dense blocks\n",
        "    for i, n_layers in enumerate(layers_per_block):\n",
        "        x = dense_block(x, n_layers, growth_rate, dropout_rate, bottleneck)\n",
        "        if i != len(layers_per_block) - 1:          # no transition after last\n",
        "            x = transition_layer(x, compression, dropout_rate)\n",
        "\n",
        "    # Classifier\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    return Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "yiWR820ydasw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "# 1) Definição das 4 arquiteturas -------------------------------\n",
        "densenet_variants = {\n",
        "    \"DenseNet-Tiny\": lambda: build_densenet(\n",
        "        layers_per_block=[4, 8, 12, 8],  # mudou de block_layers para layers_per_block\n",
        "        growth_rate=12,\n",
        "        compression=0.5,\n",
        "        dropout_rate=0.3,\n",
        "        bottleneck=False\n",
        "    ),\n",
        "    \"DenseNet-S\": lambda: build_densenet(\n",
        "        layers_per_block=[6, 12, 24, 16],\n",
        "        growth_rate=12,\n",
        "        compression=0.5,\n",
        "        dropout_rate=0.3,\n",
        "        bottleneck=True\n",
        "    ),\n",
        "    \"DenseNet-M\": lambda: build_densenet(\n",
        "        layers_per_block=[6, 12, 32, 32],\n",
        "        growth_rate=24,\n",
        "        compression=0.5,\n",
        "        dropout_rate=0.3,\n",
        "        bottleneck=True\n",
        "    ),\n",
        "}\n",
        "\n",
        "# 2) Hiper‑parâmetros e loaders --------------------------------\n",
        "batch_size  = 32\n",
        "image_size  = (224, 224)\n",
        "num_epochs  = 30\n",
        "all_results = []\n",
        "\n",
        "preprocess  = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# 3) Loop principal --------------------------------------------\n",
        "for arch_name, build_fn in densenet_variants.items():\n",
        "    print(f\"\\n Training architecture: {arch_name}\")\n",
        "\n",
        "    model = build_fn()\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.01),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    # --- datasets\n",
        "    train_ds, class_names = preprocess.load_img(\n",
        "        data_dir=\"data/rare_species/train\",\n",
        "        minority_class=minority_class,\n",
        "        augment=\"mixup\",\n",
        "        oversampling=True,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_ds, _ = preprocess.load_img(\n",
        "        data_dir=\"data/rare_species/val\",\n",
        "        minority_class=minority_class,\n",
        "        augment=None,\n",
        "        oversampling=False\n",
        "    )\n",
        "\n",
        "    # --- treino\n",
        "    experiment = Experiment(\n",
        "        model=model,\n",
        "        train_ds=train_ds,\n",
        "        val_ds=val_ds,\n",
        "        experiment_name=arch_name,\n",
        "        batch_size=batch_size,\n",
        "        image_size=image_size,\n",
        "        save_model=False\n",
        "    )\n",
        "\n",
        "    history = experiment.run_experiment(\n",
        "        callbacks=callbacks,\n",
        "        epochs=num_epochs\n",
        "    )\n",
        "\n",
        "    # 4) Métricas extra ----------------------------------------\n",
        "    # ---> PREDICTIONS\n",
        "    y_val_pred = np.argmax(model.predict(val_ds), axis=1)\n",
        "    y_val_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "    y_train_pred = np.argmax(model.predict(train_ds), axis=1)\n",
        "    y_train_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in train_ds])\n",
        "\n",
        "    # ---> F1 & cia\n",
        "    f1_macro_train = f1_score(y_train_true, y_train_pred, average='macro')\n",
        "    f1_macro_val   = f1_score(y_val_true,   y_val_pred,   average='macro')\n",
        "    f1_weighted_val= f1_score(y_val_true,   y_val_pred,   average='weighted')\n",
        "    precision_val  = precision_score(y_val_true, y_val_pred, average='weighted')\n",
        "    recall_val     = recall_score(y_val_true,    y_val_pred, average='weighted')\n",
        "\n",
        "    # ---> melhor epoch por val_loss\n",
        "    best_epoch = int(np.argmin(history.history[\"val_loss\"]) + 1)\n",
        "\n",
        "    # ---> avaliação Keras (loss, accuracy, etc.)\n",
        "    metric_names = [\"loss\", \"accuracy\", \"auc\", \"top5_accuracy\"]\n",
        "    train_metrics = dict(zip(metric_names, model.evaluate(train_ds, verbose=0)))\n",
        "    val_metrics   = dict(zip(metric_names, model.evaluate(val_ds,   verbose=0)))\n",
        "\n",
        "    # 5) Acumular resultados -----------------------------------\n",
        "    all_results.append({\n",
        "        \"architecture\"   : arch_name,\n",
        "        \"best_epoch\"     : best_epoch,\n",
        "        \"train_loss\"     : train_metrics[\"loss\"],\n",
        "        \"val_loss\"       : val_metrics[\"loss\"],\n",
        "        \"train_accuracy\" : train_metrics[\"accuracy\"],\n",
        "        \"val_accuracy\"   : val_metrics[\"accuracy\"],\n",
        "        \"train_f1_macro\" : f1_macro_train,   # <‑‑ adicionado\n",
        "        \"val_f1_macro\"   : f1_macro_val,\n",
        "        \"val_f1_weighted\": f1_weighted_val,\n",
        "        \"val_precision\"  : precision_val,\n",
        "        \"val_recall\"     : recall_val\n",
        "    })\n",
        "\n",
        "# 6) Mostrar tabela final --------------------------------------\n",
        "results_df = pd.DataFrame(all_results)\n",
        "print(results_df.round(4))\n"
      ],
      "metadata": {
        "id": "5iJkDXOkdbpf",
        "outputId": "8ab5e3f4-7746-4fa6-bbed-f6a24ed914c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Training architecture: DenseNet-Tiny\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 180ms/step - accuracy: 0.0337 - auc: 0.5970 - f1_macro: 0.0058 - f1_weighted: 0.0147 - loss: 5.4202 - top5_accuracy: 0.1152 - val_accuracy: 0.0417 - val_auc: 0.6592 - val_f1_macro: 0.0035 - val_f1_weighted: 0.0117 - val_loss: 5.1668 - val_top5_accuracy: 0.1102 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0448 - auc: 0.6296 - f1_macro: 0.0072 - f1_weighted: 0.0162 - loss: 5.1408 - top5_accuracy: 0.1463 - val_accuracy: 0.0423 - val_auc: 0.6195 - val_f1_macro: 0.0062 - val_f1_weighted: 0.0121 - val_loss: 5.6504 - val_top5_accuracy: 0.1013 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 78ms/step - accuracy: 0.0510 - auc: 0.6519 - f1_macro: 0.0100 - f1_weighted: 0.0203 - loss: 5.0224 - top5_accuracy: 0.1640 - val_accuracy: 0.0339 - val_auc: 0.6549 - val_f1_macro: 0.0050 - val_f1_weighted: 0.0123 - val_loss: 5.3293 - val_top5_accuracy: 0.1091 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0639 - auc: 0.6665 - f1_macro: 0.0164 - f1_weighted: 0.0287 - loss: 4.9413 - top5_accuracy: 0.1912 - val_accuracy: 0.0618 - val_auc: 0.7081 - val_f1_macro: 0.0143 - val_f1_weighted: 0.0263 - val_loss: 4.9634 - val_top5_accuracy: 0.1825 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0709 - auc: 0.6755 - f1_macro: 0.0195 - f1_weighted: 0.0327 - loss: 4.8786 - top5_accuracy: 0.2025 - val_accuracy: 0.0851 - val_auc: 0.7370 - val_f1_macro: 0.0224 - val_f1_weighted: 0.0375 - val_loss: 4.8097 - val_top5_accuracy: 0.2131 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 78ms/step - accuracy: 0.0797 - auc: 0.6805 - f1_macro: 0.0252 - f1_weighted: 0.0394 - loss: 4.8241 - top5_accuracy: 0.2211 - val_accuracy: 0.0673 - val_auc: 0.7222 - val_f1_macro: 0.0193 - val_f1_weighted: 0.0339 - val_loss: 4.9492 - val_top5_accuracy: 0.2076 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 78ms/step - accuracy: 0.0843 - auc: 0.6870 - f1_macro: 0.0273 - f1_weighted: 0.0415 - loss: 4.7745 - top5_accuracy: 0.2277 - val_accuracy: 0.0623 - val_auc: 0.6965 - val_f1_macro: 0.0168 - val_f1_weighted: 0.0280 - val_loss: 5.2045 - val_top5_accuracy: 0.1653 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0899 - auc: 0.6935 - f1_macro: 0.0317 - f1_weighted: 0.0456 - loss: 4.7237 - top5_accuracy: 0.2437 - val_accuracy: 0.0790 - val_auc: 0.7353 - val_f1_macro: 0.0267 - val_f1_weighted: 0.0458 - val_loss: 4.8435 - val_top5_accuracy: 0.2131 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0989 - auc: 0.6991 - f1_macro: 0.0391 - f1_weighted: 0.0532 - loss: 4.6716 - top5_accuracy: 0.2592 - val_accuracy: 0.0762 - val_auc: 0.7487 - val_f1_macro: 0.0310 - val_f1_weighted: 0.0450 - val_loss: 4.8124 - val_top5_accuracy: 0.2265 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.1063 - auc: 0.7030 - f1_macro: 0.0440 - f1_weighted: 0.0593 - loss: 4.6320 - top5_accuracy: 0.2745\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 78ms/step - accuracy: 0.1064 - auc: 0.7030 - f1_macro: 0.0440 - f1_weighted: 0.0593 - loss: 4.6320 - top5_accuracy: 0.2745 - val_accuracy: 0.0551 - val_auc: 0.6643 - val_f1_macro: 0.0146 - val_f1_weighted: 0.0286 - val_loss: 5.7169 - val_top5_accuracy: 0.1664 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 79ms/step - accuracy: 0.1253 - auc: 0.7111 - f1_macro: 0.0590 - f1_weighted: 0.0736 - loss: 4.5389 - top5_accuracy: 0.3060 - val_accuracy: 0.0935 - val_auc: 0.7429 - val_f1_macro: 0.0315 - val_f1_weighted: 0.0601 - val_loss: 4.9611 - val_top5_accuracy: 0.2226 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 79ms/step - accuracy: 0.1381 - auc: 0.7169 - f1_macro: 0.0695 - f1_weighted: 0.0842 - loss: 4.4768 - top5_accuracy: 0.3238 - val_accuracy: 0.0807 - val_auc: 0.7283 - val_f1_macro: 0.0282 - val_f1_weighted: 0.0494 - val_loss: 5.1491 - val_top5_accuracy: 0.1970 - learning_rate: 5.0000e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Training architecture: DenseNet-S\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 277ms/step - accuracy: 0.0537 - auc: 0.6201 - f1_macro: 0.0119 - f1_weighted: 0.0231 - loss: 5.8961 - top5_accuracy: 0.1445 - val_accuracy: 0.0306 - val_auc: 0.5324 - val_f1_macro: 0.0052 - val_f1_weighted: 0.0109 - val_loss: 56.5910 - val_top5_accuracy: 0.0651 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 154ms/step - accuracy: 0.0558 - auc: 0.6360 - f1_macro: 0.0073 - f1_weighted: 0.0184 - loss: 5.4914 - top5_accuracy: 0.1633 - val_accuracy: 0.0495 - val_auc: 0.6433 - val_f1_macro: 0.0110 - val_f1_weighted: 0.0240 - val_loss: 7.2693 - val_top5_accuracy: 0.1330 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 152ms/step - accuracy: 0.0656 - auc: 0.6550 - f1_macro: 0.0106 - f1_weighted: 0.0237 - loss: 5.2947 - top5_accuracy: 0.1800 - val_accuracy: 0.0267 - val_auc: 0.6068 - val_f1_macro: 0.0083 - val_f1_weighted: 0.0146 - val_loss: 5.8673 - val_top5_accuracy: 0.1119 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 153ms/step - accuracy: 0.0727 - auc: 0.6634 - f1_macro: 0.0158 - f1_weighted: 0.0296 - loss: 5.1489 - top5_accuracy: 0.2046 - val_accuracy: 0.0262 - val_auc: 0.6527 - val_f1_macro: 0.0083 - val_f1_weighted: 0.0137 - val_loss: 5.5606 - val_top5_accuracy: 0.1274 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 153ms/step - accuracy: 0.0807 - auc: 0.6727 - f1_macro: 0.0211 - f1_weighted: 0.0362 - loss: 5.0310 - top5_accuracy: 0.2153 - val_accuracy: 0.0518 - val_auc: 0.7225 - val_f1_macro: 0.0147 - val_f1_weighted: 0.0271 - val_loss: 5.0795 - val_top5_accuracy: 0.1859 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 152ms/step - accuracy: 0.0821 - auc: 0.6783 - f1_macro: 0.0248 - f1_weighted: 0.0390 - loss: 4.9414 - top5_accuracy: 0.2338 - val_accuracy: 0.0657 - val_auc: 0.7311 - val_f1_macro: 0.0228 - val_f1_weighted: 0.0350 - val_loss: 4.9863 - val_top5_accuracy: 0.2115 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 151ms/step - accuracy: 0.0892 - auc: 0.6838 - f1_macro: 0.0298 - f1_weighted: 0.0452 - loss: 4.8638 - top5_accuracy: 0.2481 - val_accuracy: 0.0445 - val_auc: 0.6978 - val_f1_macro: 0.0153 - val_f1_weighted: 0.0246 - val_loss: 5.1992 - val_top5_accuracy: 0.1664 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 151ms/step - accuracy: 0.0939 - auc: 0.6909 - f1_macro: 0.0333 - f1_weighted: 0.0491 - loss: 4.8025 - top5_accuracy: 0.2628 - val_accuracy: 0.0612 - val_auc: 0.7333 - val_f1_macro: 0.0267 - val_f1_weighted: 0.0395 - val_loss: 4.9949 - val_top5_accuracy: 0.1959 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 152ms/step - accuracy: 0.0999 - auc: 0.6962 - f1_macro: 0.0397 - f1_weighted: 0.0557 - loss: 4.7359 - top5_accuracy: 0.2782 - val_accuracy: 0.0829 - val_auc: 0.7607 - val_f1_macro: 0.0379 - val_f1_weighted: 0.0613 - val_loss: 4.7710 - val_top5_accuracy: 0.2354 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 152ms/step - accuracy: 0.1106 - auc: 0.7030 - f1_macro: 0.0492 - f1_weighted: 0.0653 - loss: 4.6808 - top5_accuracy: 0.2916 - val_accuracy: 0.0979 - val_auc: 0.7692 - val_f1_macro: 0.0487 - val_f1_weighted: 0.0761 - val_loss: 4.6987 - val_top5_accuracy: 0.2538 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 151ms/step - accuracy: 0.1211 - auc: 0.7093 - f1_macro: 0.0568 - f1_weighted: 0.0734 - loss: 4.6196 - top5_accuracy: 0.3042 - val_accuracy: 0.0979 - val_auc: 0.7615 - val_f1_macro: 0.0494 - val_f1_weighted: 0.0755 - val_loss: 4.7498 - val_top5_accuracy: 0.2554 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 149ms/step - accuracy: 0.1342 - auc: 0.7150 - f1_macro: 0.0673 - f1_weighted: 0.0846 - loss: 4.5555 - top5_accuracy: 0.3267 - val_accuracy: 0.1024 - val_auc: 0.7577 - val_f1_macro: 0.0558 - val_f1_weighted: 0.0808 - val_loss: 4.7556 - val_top5_accuracy: 0.2515 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 148ms/step - accuracy: 0.1457 - auc: 0.7201 - f1_macro: 0.0783 - f1_weighted: 0.0960 - loss: 4.4983 - top5_accuracy: 0.3509 - val_accuracy: 0.0957 - val_auc: 0.7619 - val_f1_macro: 0.0571 - val_f1_weighted: 0.0818 - val_loss: 4.8064 - val_top5_accuracy: 0.2482 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 151ms/step - accuracy: 0.1531 - auc: 0.7255 - f1_macro: 0.0866 - f1_weighted: 0.1027 - loss: 4.4386 - top5_accuracy: 0.3753 - val_accuracy: 0.0846 - val_auc: 0.7524 - val_f1_macro: 0.0484 - val_f1_weighted: 0.0696 - val_loss: 4.8476 - val_top5_accuracy: 0.2332 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.1693 - auc: 0.7315 - f1_macro: 0.0994 - f1_weighted: 0.1177 - loss: 4.3826 - top5_accuracy: 0.3998\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 152ms/step - accuracy: 0.1693 - auc: 0.7315 - f1_macro: 0.0994 - f1_weighted: 0.1177 - loss: 4.3826 - top5_accuracy: 0.3998 - val_accuracy: 0.0868 - val_auc: 0.7534 - val_f1_macro: 0.0503 - val_f1_weighted: 0.0681 - val_loss: 4.8898 - val_top5_accuracy: 0.2231 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 149ms/step - accuracy: 0.2026 - auc: 0.7429 - f1_macro: 0.1274 - f1_weighted: 0.1450 - loss: 4.2409 - top5_accuracy: 0.4534 - val_accuracy: 0.1146 - val_auc: 0.7632 - val_f1_macro: 0.0647 - val_f1_weighted: 0.1005 - val_loss: 4.8011 - val_top5_accuracy: 0.2749 - learning_rate: 5.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 151ms/step - accuracy: 0.2289 - auc: 0.7498 - f1_macro: 0.1498 - f1_weighted: 0.1662 - loss: 4.1268 - top5_accuracy: 0.4928 - val_accuracy: 0.1124 - val_auc: 0.7408 - val_f1_macro: 0.0553 - val_f1_weighted: 0.0946 - val_loss: 4.9944 - val_top5_accuracy: 0.2487 - learning_rate: 5.0000e-04\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 240ms/step\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Training architecture: DenseNet-M\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m474s\u001b[0m 473ms/step - accuracy: 0.0494 - auc: 0.6210 - f1_macro: 0.0211 - f1_weighted: 0.0324 - loss: 7.2844 - top5_accuracy: 0.1410 - val_accuracy: 0.0289 - val_auc: 0.6165 - val_f1_macro: 0.0023 - val_f1_weighted: 0.0108 - val_loss: 6.3976 - val_top5_accuracy: 0.1330 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 322ms/step - accuracy: 0.0504 - auc: 0.6289 - f1_macro: 0.0063 - f1_weighted: 0.0162 - loss: 6.1768 - top5_accuracy: 0.1390 - val_accuracy: 0.0484 - val_auc: 0.6371 - val_f1_macro: 0.0042 - val_f1_weighted: 0.0177 - val_loss: 6.0479 - val_top5_accuracy: 0.1330 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 320ms/step - accuracy: 0.0562 - auc: 0.6518 - f1_macro: 0.0092 - f1_weighted: 0.0200 - loss: 5.6870 - top5_accuracy: 0.1705 - val_accuracy: 0.0668 - val_auc: 0.6866 - val_f1_macro: 0.0110 - val_f1_weighted: 0.0317 - val_loss: 5.5471 - val_top5_accuracy: 0.1720 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 320ms/step - accuracy: 0.0635 - auc: 0.6601 - f1_macro: 0.0121 - f1_weighted: 0.0240 - loss: 5.4078 - top5_accuracy: 0.1820 - val_accuracy: 0.0562 - val_auc: 0.6885 - val_f1_macro: 0.0081 - val_f1_weighted: 0.0252 - val_loss: 5.3608 - val_top5_accuracy: 0.1642 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 319ms/step - accuracy: 0.0662 - auc: 0.6708 - f1_macro: 0.0148 - f1_weighted: 0.0269 - loss: 5.2314 - top5_accuracy: 0.1917 - val_accuracy: 0.0495 - val_auc: 0.6636 - val_f1_macro: 0.0138 - val_f1_weighted: 0.0297 - val_loss: 5.5804 - val_top5_accuracy: 0.1530 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 321ms/step - accuracy: 0.0725 - auc: 0.6792 - f1_macro: 0.0198 - f1_weighted: 0.0328 - loss: 5.1127 - top5_accuracy: 0.2110 - val_accuracy: 0.0684 - val_auc: 0.7255 - val_f1_macro: 0.0096 - val_f1_weighted: 0.0274 - val_loss: 5.0608 - val_top5_accuracy: 0.1948 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 319ms/step - accuracy: 0.0762 - auc: 0.6849 - f1_macro: 0.0239 - f1_weighted: 0.0370 - loss: 5.0423 - top5_accuracy: 0.2197 - val_accuracy: 0.0657 - val_auc: 0.7062 - val_f1_macro: 0.0130 - val_f1_weighted: 0.0334 - val_loss: 5.1913 - val_top5_accuracy: 0.1970 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 318ms/step - accuracy: 0.0784 - auc: 0.6877 - f1_macro: 0.0267 - f1_weighted: 0.0393 - loss: 5.0016 - top5_accuracy: 0.2284 - val_accuracy: 0.0657 - val_auc: 0.6991 - val_f1_macro: 0.0115 - val_f1_weighted: 0.0335 - val_loss: 5.1675 - val_top5_accuracy: 0.1825 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 319ms/step - accuracy: 0.0847 - auc: 0.6943 - f1_macro: 0.0306 - f1_weighted: 0.0439 - loss: 4.9364 - top5_accuracy: 0.2435 - val_accuracy: 0.0902 - val_auc: 0.7368 - val_f1_macro: 0.0251 - val_f1_weighted: 0.0524 - val_loss: 4.9303 - val_top5_accuracy: 0.2209 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 318ms/step - accuracy: 0.0895 - auc: 0.6956 - f1_macro: 0.0331 - f1_weighted: 0.0485 - loss: 4.9037 - top5_accuracy: 0.2539 - val_accuracy: 0.0751 - val_auc: 0.7219 - val_f1_macro: 0.0195 - val_f1_weighted: 0.0425 - val_loss: 5.0414 - val_top5_accuracy: 0.2070 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 319ms/step - accuracy: 0.0959 - auc: 0.7004 - f1_macro: 0.0374 - f1_weighted: 0.0527 - loss: 4.8555 - top5_accuracy: 0.2652 - val_accuracy: 0.0612 - val_auc: 0.6947 - val_f1_macro: 0.0151 - val_f1_weighted: 0.0330 - val_loss: 5.7584 - val_top5_accuracy: 0.1742 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 320ms/step - accuracy: 0.1025 - auc: 0.7045 - f1_macro: 0.0434 - f1_weighted: 0.0588 - loss: 4.8443 - top5_accuracy: 0.2751 - val_accuracy: 0.0735 - val_auc: 0.7188 - val_f1_macro: 0.0181 - val_f1_weighted: 0.0435 - val_loss: 5.1946 - val_top5_accuracy: 0.2037 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 318ms/step - accuracy: 0.1088 - auc: 0.7076 - f1_macro: 0.0451 - f1_weighted: 0.0629 - loss: 4.7897 - top5_accuracy: 0.2860 - val_accuracy: 0.0818 - val_auc: 0.7191 - val_f1_macro: 0.0263 - val_f1_weighted: 0.0478 - val_loss: 5.1040 - val_top5_accuracy: 0.2037 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.1174 - auc: 0.7119 - f1_macro: 0.0526 - f1_weighted: 0.0687 - loss: 4.7491 - top5_accuracy: 0.3023\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 318ms/step - accuracy: 0.1174 - auc: 0.7119 - f1_macro: 0.0527 - f1_weighted: 0.0687 - loss: 4.7491 - top5_accuracy: 0.3022 - val_accuracy: 0.0506 - val_auc: 0.6355 - val_f1_macro: 0.0132 - val_f1_weighted: 0.0248 - val_loss: 5.8467 - val_top5_accuracy: 0.1452 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 318ms/step - accuracy: 0.1337 - auc: 0.7161 - f1_macro: 0.0644 - f1_weighted: 0.0813 - loss: 4.7089 - top5_accuracy: 0.3239 - val_accuracy: 0.0751 - val_auc: 0.6815 - val_f1_macro: 0.0231 - val_f1_weighted: 0.0458 - val_loss: 5.5332 - val_top5_accuracy: 0.1775 - learning_rate: 5.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 318ms/step - accuracy: 0.1506 - auc: 0.7251 - f1_macro: 0.0794 - f1_weighted: 0.0960 - loss: 4.5783 - top5_accuracy: 0.3593 - val_accuracy: 0.0846 - val_auc: 0.7161 - val_f1_macro: 0.0344 - val_f1_weighted: 0.0554 - val_loss: 5.2047 - val_top5_accuracy: 0.2070 - learning_rate: 5.0000e-04\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 368ms/step\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    architecture  best_epoch  train_loss  val_loss  train_accuracy  \\\n",
            "0  DenseNet-Tiny           5      5.0118    4.8097          0.0621   \n",
            "1     DenseNet-S          10      4.8652    4.6987          0.0911   \n",
            "2     DenseNet-M           9      5.0306    4.9303          0.0873   \n",
            "\n",
            "   val_accuracy  train_f1_macro  val_f1_macro  val_f1_weighted  val_precision  \\\n",
            "0        0.0851          0.0136        0.0224           0.0375         0.0294   \n",
            "1        0.0979          0.0514        0.0487           0.0761         0.0902   \n",
            "2        0.0902          0.0325        0.0251           0.0524         0.0682   \n",
            "\n",
            "   val_recall  \n",
            "0      0.0851  \n",
            "1      0.0979  \n",
            "2      0.0902  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df"
      ],
      "metadata": {
        "id": "lQtc6O5a2tGJ",
        "outputId": "6d236a4e-a395-4368-a76b-19d2cabebb81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    architecture  best_epoch  train_loss  val_loss  train_accuracy  \\\n",
              "0  DenseNet-Tiny           5    5.011802  4.809731        0.062143   \n",
              "1     DenseNet-S          10    4.865248  4.698685        0.091071   \n",
              "2     DenseNet-M           9    5.030558  4.930261        0.087321   \n",
              "\n",
              "   val_accuracy  train_f1_macro  val_f1_macro  val_f1_weighted  val_precision  \\\n",
              "0      0.085142        0.013650      0.022375         0.037527       0.029410   \n",
              "1      0.097941        0.051417      0.048703         0.076120       0.090212   \n",
              "2      0.090150        0.032539      0.025085         0.052425       0.068242   \n",
              "\n",
              "   val_recall  \n",
              "0    0.085142  \n",
              "1    0.097941  \n",
              "2    0.090150  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2852a735-fe9f-4bc5-ae41-72e49efc2deb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>architecture</th>\n",
              "      <th>best_epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>train_f1_macro</th>\n",
              "      <th>val_f1_macro</th>\n",
              "      <th>val_f1_weighted</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DenseNet-Tiny</td>\n",
              "      <td>5</td>\n",
              "      <td>5.011802</td>\n",
              "      <td>4.809731</td>\n",
              "      <td>0.062143</td>\n",
              "      <td>0.085142</td>\n",
              "      <td>0.013650</td>\n",
              "      <td>0.022375</td>\n",
              "      <td>0.037527</td>\n",
              "      <td>0.029410</td>\n",
              "      <td>0.085142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DenseNet-S</td>\n",
              "      <td>10</td>\n",
              "      <td>4.865248</td>\n",
              "      <td>4.698685</td>\n",
              "      <td>0.091071</td>\n",
              "      <td>0.097941</td>\n",
              "      <td>0.051417</td>\n",
              "      <td>0.048703</td>\n",
              "      <td>0.076120</td>\n",
              "      <td>0.090212</td>\n",
              "      <td>0.097941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DenseNet-M</td>\n",
              "      <td>9</td>\n",
              "      <td>5.030558</td>\n",
              "      <td>4.930261</td>\n",
              "      <td>0.087321</td>\n",
              "      <td>0.090150</td>\n",
              "      <td>0.032539</td>\n",
              "      <td>0.025085</td>\n",
              "      <td>0.052425</td>\n",
              "      <td>0.068242</td>\n",
              "      <td>0.090150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2852a735-fe9f-4bc5-ae41-72e49efc2deb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2852a735-fe9f-4bc5-ae41-72e49efc2deb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2852a735-fe9f-4bc5-ae41-72e49efc2deb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-44446e2a-1652-41a2-b0fe-f7fb0baacb40\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-44446e2a-1652-41a2-b0fe-f7fb0baacb40')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-44446e2a-1652-41a2-b0fe-f7fb0baacb40 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5c71ff11-0ce0-473d-bb48-4d426c803e78\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5c71ff11-0ce0-473d-bb48-4d426c803e78 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"architecture\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"DenseNet-Tiny\",\n          \"DenseNet-S\",\n          \"DenseNet-M\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 5,\n        \"max\": 10,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5,\n          10,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09051447602283254,\n        \"min\": 4.865248203277588,\n        \"max\": 5.030558109283447,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5.0118021965026855,\n          4.865248203277588,\n          5.030558109283447\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11582034784486421,\n        \"min\": 4.698685169219971,\n        \"max\": 4.930261135101318,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4.8097310066223145,\n          4.698685169219971,\n          4.930261135101318\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015731524885746865,\n        \"min\": 0.062142856419086456,\n        \"max\": 0.09107142686843872,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.062142856419086456,\n          0.09107142686843872,\n          0.08732143044471741\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006449762271903525,\n        \"min\": 0.08514190465211868,\n        \"max\": 0.09794101119041443,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.08514190465211868,\n          0.09794101119041443,\n          0.09015025198459625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.018883571931510596,\n        \"min\": 0.013649893075336086,\n        \"max\": 0.05141703632043846,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.013649893075336086,\n          0.05141703632043846,\n          0.03253938124615053\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014481547821833874,\n        \"min\": 0.022374672809363463,\n        \"max\": 0.04870267474386565,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.022374672809363463,\n          0.04870267474386565,\n          0.025085305058788653\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_f1_weighted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.019463138273872374,\n        \"min\": 0.03752651121613789,\n        \"max\": 0.07612006259178594,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.03752651121613789,\n          0.07612006259178594,\n          0.052425037415240544\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.030788328233654887,\n        \"min\": 0.029409990575886627,\n        \"max\": 0.090212293107196,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.029409990575886627,\n          0.090212293107196,\n          0.06824165021518992\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006449763921615177,\n        \"min\": 0.08514190317195326,\n        \"max\": 0.09794101279910963,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.08514190317195326,\n          0.09794101279910963,\n          0.09015025041736227\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline DenseNet"
      ],
      "metadata": {
        "id": "Tu1z7HVwWeGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dense_layer(x, growth_rate, dropout_rate, bottleneck):\n",
        "    # ‑‑ Optionally add a 1×1 bottleneck (DenseNet‑B)\n",
        "    if bottleneck:\n",
        "        x1 = BatchNormalization()(x)\n",
        "        x1 = ReLU()(x1)\n",
        "        x1 = Conv2D(4 * growth_rate, (1, 1), padding='same',\n",
        "                    kernel_regularizer=l2(1e-4))(x1)\n",
        "        x1 = BatchNormalization()(x1)\n",
        "        x1 = ReLU()(x1)\n",
        "        x1 = Conv2D(growth_rate, (3, 3), padding='same',\n",
        "                    kernel_regularizer=l2(1e-4))(x1)\n",
        "    else:\n",
        "        x1 = BatchNormalization()(x)\n",
        "        x1 = ReLU()(x1)\n",
        "        x1 = Conv2D(growth_rate, (3, 3), padding='same',\n",
        "                    kernel_regularizer=l2(1e-4))(x1)\n",
        "\n",
        "    if dropout_rate:                    # dropout depois do conv\n",
        "        x1 = Dropout(dropout_rate)(x1)\n",
        "    return Concatenate()([x, x1])       # dense connection\n",
        "\n",
        "\n",
        "def dense_block(x, n_layers, growth_rate, dropout_rate, bottleneck):\n",
        "    for _ in range(n_layers):\n",
        "        x = dense_layer(x, growth_rate, dropout_rate, bottleneck)\n",
        "    return x\n",
        "\n",
        "\n",
        "def transition_layer(x, compression, dropout_rate):\n",
        "    filters = int(tf.keras.backend.int_shape(x)[-1] * compression)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(filters, (1, 1), padding='same',\n",
        "               kernel_regularizer=l2(1e-4))(x)\n",
        "    if dropout_rate:\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "    return AveragePooling2D((2, 2), strides=2)(x)\n",
        "\n",
        "\n",
        "def build_densenet(input_shape=(224, 224, 3),\n",
        "                   num_classes=202,\n",
        "                   layers_per_block=(6, 12, 24, 16),\n",
        "                   growth_rate=32,\n",
        "                   compression=0.5,\n",
        "                   bottleneck=True,\n",
        "                   dropout_rate=0.3):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Stem\n",
        "    x = Conv2D(64, (7, 7), strides=2, padding='same',\n",
        "               kernel_regularizer=l2(1e-4))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = AveragePooling2D((3, 3), strides=2, padding='same')(x)\n",
        "\n",
        "    # Dense blocks\n",
        "    for i, n_layers in enumerate(layers_per_block):\n",
        "        x = dense_block(x, n_layers, growth_rate, dropout_rate, bottleneck)\n",
        "        if i != len(layers_per_block) - 1:          # no transition after last\n",
        "            x = transition_layer(x, compression, dropout_rate)\n",
        "\n",
        "    # Classifier\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    return Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "K2MWpYG3vPBY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DenseNet testing script - Phase 1 and 2 (with/without MixUp)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "# DenseNet definition remains unchanged (already provided by user)\n",
        "\n",
        "# Architectures to test (Fase 1 e 2)\n",
        "densenet_variants = {\n",
        "    \"DenseNet-Tiny\": lambda: build_densenet(\n",
        "        layers_per_block=[4, 8, 12, 8],\n",
        "        growth_rate=12,\n",
        "        compression=0.5,\n",
        "        dropout_rate=0.1,  # Menor dropout para baseline\n",
        "        bottleneck=False\n",
        "    ),\n",
        "    \"DenseNet-S\": lambda: build_densenet(\n",
        "        layers_per_block=[6, 12, 24, 16],\n",
        "        growth_rate=12,\n",
        "        compression=0.5,\n",
        "        dropout_rate=0.1,\n",
        "        bottleneck=True\n",
        "    )\n",
        "}\n",
        "\n",
        "# Hiperparâmetros\n",
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "num_epochs = 30\n",
        "augment_modes = [\"none\", \"medium\", \"mixup\"]\n",
        "\n",
        "# Preprocessador\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "all_results = []\n",
        "\n",
        "# Loop principal\n",
        "for augment_mode in augment_modes:\n",
        "    for arch_name, build_fn in densenet_variants.items():\n",
        "        print(f\"\\nTraining {arch_name} with augment = {augment_mode}\")\n",
        "\n",
        "        model = build_fn()\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.0),\n",
        "            metrics=metrics\n",
        "        )\n",
        "\n",
        "        # Carregamento dos datasets\n",
        "        train_ds, class_names = preprocess.load_img(\n",
        "            data_dir=\"data/rare_species/train\",\n",
        "            minority_class=minority_class,\n",
        "            augment=augment_mode if augment_mode != \"none\" else None,\n",
        "            oversampling=True,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        val_ds, _ = preprocess.load_img(\n",
        "            data_dir=\"data/rare_species/val\",\n",
        "            minority_class=minority_class,\n",
        "            augment=None,\n",
        "            oversampling=False\n",
        "        )\n",
        "\n",
        "        # Experimento\n",
        "        experiment = Experiment(\n",
        "            model=model,\n",
        "            train_ds=train_ds,\n",
        "            val_ds=val_ds,\n",
        "            experiment_name=f\"{arch_name}_{augment_mode}\",\n",
        "            batch_size=batch_size,\n",
        "            image_size=image_size,\n",
        "            save_model=False\n",
        "        )\n",
        "\n",
        "        history = experiment.run_experiment(\n",
        "            callbacks=callbacks,\n",
        "            epochs=num_epochs\n",
        "        )\n",
        "\n",
        "        # Avaliação\n",
        "        y_val_pred = np.argmax(model.predict(val_ds), axis=1)\n",
        "        y_val_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "        y_train_pred = np.argmax(model.predict(train_ds), axis=1)\n",
        "        y_train_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in train_ds])\n",
        "\n",
        "        f1_macro_train = f1_score(y_train_true, y_train_pred, average='macro')\n",
        "        f1_macro_val = f1_score(y_val_true, y_val_pred, average='macro')\n",
        "        f1_weighted_val = f1_score(y_val_true, y_val_pred, average='weighted')\n",
        "        precision_val = precision_score(y_val_true, y_val_pred, average='weighted')\n",
        "        recall_val = recall_score(y_val_true, y_val_pred, average='weighted')\n",
        "\n",
        "        best_epoch = int(np.argmin(history.history[\"val_loss\"]) + 1)\n",
        "\n",
        "        metric_names = [\"loss\", \"accuracy\", \"auc\", \"top5_accuracy\"]\n",
        "        train_metrics = dict(zip(metric_names, model.evaluate(train_ds, verbose=0)))\n",
        "        val_metrics = dict(zip(metric_names, model.evaluate(val_ds, verbose=0)))\n",
        "\n",
        "        all_results.append({\n",
        "            \"architecture\": arch_name,\n",
        "            \"augmentation\": augment_mode,\n",
        "            \"best_epoch\": best_epoch,\n",
        "            \"train_loss\": train_metrics[\"loss\"],\n",
        "            \"val_loss\": val_metrics[\"loss\"],\n",
        "            \"train_accuracy\": train_metrics[\"accuracy\"],\n",
        "            \"val_accuracy\": val_metrics[\"accuracy\"],\n",
        "            \"train_f1_macro\": f1_macro_train,\n",
        "            \"val_f1_macro\": f1_macro_val,\n",
        "            \"val_f1_weighted\": f1_weighted_val,\n",
        "            \"val_precision\": precision_val,\n",
        "            \"val_recall\": recall_val\n",
        "        })\n",
        "\n",
        "# Mostrar resultados finais\n",
        "results_df = pd.DataFrame(all_results)\n",
        "print(results_df.round(4))\n"
      ],
      "metadata": {
        "id": "3hYDgCe8E014",
        "outputId": "4b8f1611-3407-4afd-f46f-0463dc1a9f66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training DenseNet-Tiny with augment = none\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 186ms/step - accuracy: 0.0346 - auc: 0.6068 - f1_macro: 0.0071 - f1_weighted: 0.0159 - loss: 5.3961 - top5_accuracy: 0.0986 - val_accuracy: 0.0373 - val_auc: 0.6045 - val_f1_macro: 0.0041 - val_f1_weighted: 0.0153 - val_loss: 5.9274 - val_top5_accuracy: 0.1080 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.0592 - auc: 0.6970 - f1_macro: 0.0178 - f1_weighted: 0.0318 - loss: 4.9785 - top5_accuracy: 0.1566 - val_accuracy: 0.0356 - val_auc: 0.6355 - val_f1_macro: 0.0070 - val_f1_weighted: 0.0231 - val_loss: 5.6451 - val_top5_accuracy: 0.1219 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.0687 - auc: 0.7417 - f1_macro: 0.0236 - f1_weighted: 0.0389 - loss: 4.7589 - top5_accuracy: 0.1933 - val_accuracy: 0.0178 - val_auc: 0.5454 - val_f1_macro: 0.0072 - val_f1_weighted: 0.0178 - val_loss: 10.8315 - val_top5_accuracy: 0.0712 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0829 - auc: 0.7703 - f1_macro: 0.0338 - f1_weighted: 0.0517 - loss: 4.5997 - top5_accuracy: 0.2296 - val_accuracy: 0.0228 - val_auc: 0.5728 - val_f1_macro: 0.0096 - val_f1_weighted: 0.0201 - val_loss: 8.4459 - val_top5_accuracy: 0.0735 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0973 - auc: 0.7895 - f1_macro: 0.0458 - f1_weighted: 0.0644 - loss: 4.4730 - top5_accuracy: 0.2509 - val_accuracy: 0.0306 - val_auc: 0.6305 - val_f1_macro: 0.0102 - val_f1_weighted: 0.0270 - val_loss: 6.4533 - val_top5_accuracy: 0.1330 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1074 - auc: 0.8058 - f1_macro: 0.0580 - f1_weighted: 0.0768 - loss: 4.3647 - top5_accuracy: 0.2730 - val_accuracy: 0.0306 - val_auc: 0.6121 - val_f1_macro: 0.0110 - val_f1_weighted: 0.0285 - val_loss: 7.5800 - val_top5_accuracy: 0.1297 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.1165 - auc: 0.8208 - f1_macro: 0.0683 - f1_weighted: 0.0869 - loss: 4.2647 - top5_accuracy: 0.2914\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1165 - auc: 0.8208 - f1_macro: 0.0683 - f1_weighted: 0.0870 - loss: 4.2646 - top5_accuracy: 0.2914 - val_accuracy: 0.0401 - val_auc: 0.6198 - val_f1_macro: 0.0125 - val_f1_weighted: 0.0280 - val_loss: 7.3292 - val_top5_accuracy: 0.1341 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1459 - auc: 0.8429 - f1_macro: 0.0951 - f1_weighted: 0.1127 - loss: 4.0751 - top5_accuracy: 0.3303 - val_accuracy: 0.0779 - val_auc: 0.6840 - val_f1_macro: 0.0300 - val_f1_weighted: 0.0529 - val_loss: 5.8108 - val_top5_accuracy: 0.2003 - learning_rate: 5.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1644 - auc: 0.8603 - f1_macro: 0.1132 - f1_weighted: 0.1318 - loss: 3.9380 - top5_accuracy: 0.3671 - val_accuracy: 0.0879 - val_auc: 0.7216 - val_f1_macro: 0.0418 - val_f1_weighted: 0.0642 - val_loss: 5.1650 - val_top5_accuracy: 0.2365 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1780 - auc: 0.8708 - f1_macro: 0.1240 - f1_weighted: 0.1449 - loss: 3.8473 - top5_accuracy: 0.3906 - val_accuracy: 0.0946 - val_auc: 0.7098 - val_f1_macro: 0.0397 - val_f1_weighted: 0.0653 - val_loss: 5.5509 - val_top5_accuracy: 0.2348 - learning_rate: 5.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1879 - auc: 0.8781 - f1_macro: 0.1365 - f1_weighted: 0.1561 - loss: 3.7630 - top5_accuracy: 0.4124 - val_accuracy: 0.0985 - val_auc: 0.7304 - val_f1_macro: 0.0499 - val_f1_weighted: 0.0706 - val_loss: 5.3167 - val_top5_accuracy: 0.2538 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.2001 - auc: 0.8849 - f1_macro: 0.1512 - f1_weighted: 0.1707 - loss: 3.6774 - top5_accuracy: 0.4361 - val_accuracy: 0.1052 - val_auc: 0.7342 - val_f1_macro: 0.0496 - val_f1_weighted: 0.0768 - val_loss: 5.2148 - val_top5_accuracy: 0.2682 - learning_rate: 5.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.2142 - auc: 0.8907 - f1_macro: 0.1664 - f1_weighted: 0.1855 - loss: 3.5940 - top5_accuracy: 0.4596 - val_accuracy: 0.1057 - val_auc: 0.7351 - val_f1_macro: 0.0565 - val_f1_weighted: 0.0843 - val_loss: 5.3804 - val_top5_accuracy: 0.2521 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.2257 - auc: 0.8974 - f1_macro: 0.1822 - f1_weighted: 0.1989 - loss: 3.5086 - top5_accuracy: 0.4841\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.2257 - auc: 0.8974 - f1_macro: 0.1823 - f1_weighted: 0.1990 - loss: 3.5085 - top5_accuracy: 0.4841 - val_accuracy: 0.1007 - val_auc: 0.7270 - val_f1_macro: 0.0568 - val_f1_weighted: 0.0855 - val_loss: 5.3465 - val_top5_accuracy: 0.2543 - learning_rate: 5.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.2619 - auc: 0.9101 - f1_macro: 0.2259 - f1_weighted: 0.2388 - loss: 3.3678 - top5_accuracy: 0.5109 - val_accuracy: 0.1202 - val_auc: 0.7540 - val_f1_macro: 0.0775 - val_f1_weighted: 0.1073 - val_loss: 4.9283 - val_top5_accuracy: 0.2944 - learning_rate: 2.5000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.2809 - auc: 0.9163 - f1_macro: 0.2443 - f1_weighted: 0.2582 - loss: 3.2658 - top5_accuracy: 0.5358 - val_accuracy: 0.1130 - val_auc: 0.7464 - val_f1_macro: 0.0717 - val_f1_weighted: 0.1040 - val_loss: 5.0345 - val_top5_accuracy: 0.2894 - learning_rate: 2.5000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.2958 - auc: 0.9213 - f1_macro: 0.2597 - f1_weighted: 0.2725 - loss: 3.1889 - top5_accuracy: 0.5576 - val_accuracy: 0.1247 - val_auc: 0.7509 - val_f1_macro: 0.0824 - val_f1_weighted: 0.1150 - val_loss: 4.9924 - val_top5_accuracy: 0.2966 - learning_rate: 2.5000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.3101 - auc: 0.9249 - f1_macro: 0.2762 - f1_weighted: 0.2889 - loss: 3.1161 - top5_accuracy: 0.5763 - val_accuracy: 0.1241 - val_auc: 0.7499 - val_f1_macro: 0.0789 - val_f1_weighted: 0.1115 - val_loss: 5.0560 - val_top5_accuracy: 0.2883 - learning_rate: 2.5000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.3228 - auc: 0.9286 - f1_macro: 0.2895 - f1_weighted: 0.3029 - loss: 3.0529 - top5_accuracy: 0.5938 - val_accuracy: 0.1308 - val_auc: 0.7468 - val_f1_macro: 0.0862 - val_f1_weighted: 0.1190 - val_loss: 5.0667 - val_top5_accuracy: 0.2894 - learning_rate: 2.5000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3350 - auc: 0.9319 - f1_macro: 0.3026 - f1_weighted: 0.3148 - loss: 2.9829 - top5_accuracy: 0.6074\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.3351 - auc: 0.9319 - f1_macro: 0.3027 - f1_weighted: 0.3149 - loss: 2.9828 - top5_accuracy: 0.6074 - val_accuracy: 0.1263 - val_auc: 0.7458 - val_f1_macro: 0.0829 - val_f1_weighted: 0.1176 - val_loss: 5.1039 - val_top5_accuracy: 0.2927 - learning_rate: 2.5000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.3501 - auc: 0.9365 - f1_macro: 0.3192 - f1_weighted: 0.3312 - loss: 2.9131 - top5_accuracy: 0.6246 - val_accuracy: 0.1508 - val_auc: 0.7690 - val_f1_macro: 0.0991 - val_f1_weighted: 0.1371 - val_loss: 4.7534 - val_top5_accuracy: 0.3205 - learning_rate: 1.2500e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.3667 - auc: 0.9411 - f1_macro: 0.3358 - f1_weighted: 0.3470 - loss: 2.8458 - top5_accuracy: 0.6431 - val_accuracy: 0.1491 - val_auc: 0.7685 - val_f1_macro: 0.0983 - val_f1_weighted: 0.1340 - val_loss: 4.7779 - val_top5_accuracy: 0.3250 - learning_rate: 1.2500e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.3768 - auc: 0.9430 - f1_macro: 0.3481 - f1_weighted: 0.3585 - loss: 2.7949 - top5_accuracy: 0.6448 - val_accuracy: 0.1514 - val_auc: 0.7685 - val_f1_macro: 0.1026 - val_f1_weighted: 0.1381 - val_loss: 4.7856 - val_top5_accuracy: 0.3239 - learning_rate: 1.2500e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.3825 - auc: 0.9449 - f1_macro: 0.3540 - f1_weighted: 0.3637 - loss: 2.7493 - top5_accuracy: 0.6590 - val_accuracy: 0.1519 - val_auc: 0.7682 - val_f1_macro: 0.1040 - val_f1_weighted: 0.1388 - val_loss: 4.7992 - val_top5_accuracy: 0.3300 - learning_rate: 1.2500e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.3911 - auc: 0.9480 - f1_macro: 0.3628 - f1_weighted: 0.3735 - loss: 2.7054 - top5_accuracy: 0.6705 - val_accuracy: 0.1530 - val_auc: 0.7666 - val_f1_macro: 0.1063 - val_f1_weighted: 0.1413 - val_loss: 4.8313 - val_top5_accuracy: 0.3255 - learning_rate: 1.2500e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.4069 - auc: 0.9482 - f1_macro: 0.3793 - f1_weighted: 0.3899 - loss: 2.6648 - top5_accuracy: 0.6799\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.4070 - auc: 0.9482 - f1_macro: 0.3794 - f1_weighted: 0.3900 - loss: 2.6646 - top5_accuracy: 0.6799 - val_accuracy: 0.1530 - val_auc: 0.7660 - val_f1_macro: 0.1064 - val_f1_weighted: 0.1417 - val_loss: 4.8472 - val_top5_accuracy: 0.3267 - learning_rate: 1.2500e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.4126 - auc: 0.9518 - f1_macro: 0.3823 - f1_weighted: 0.3963 - loss: 2.6324 - top5_accuracy: 0.6819 - val_accuracy: 0.1686 - val_auc: 0.7780 - val_f1_macro: 0.1168 - val_f1_weighted: 0.1561 - val_loss: 4.7081 - val_top5_accuracy: 0.3534 - learning_rate: 6.2500e-05\n",
            "Epoch 28/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.4268 - auc: 0.9537 - f1_macro: 0.3989 - f1_weighted: 0.4107 - loss: 2.5893 - top5_accuracy: 0.6899 - val_accuracy: 0.1692 - val_auc: 0.7783 - val_f1_macro: 0.1180 - val_f1_weighted: 0.1560 - val_loss: 4.7145 - val_top5_accuracy: 0.3545 - learning_rate: 6.2500e-05\n",
            "Epoch 29/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.4329 - auc: 0.9556 - f1_macro: 0.4059 - f1_weighted: 0.4175 - loss: 2.5558 - top5_accuracy: 0.6971 - val_accuracy: 0.1642 - val_auc: 0.7773 - val_f1_macro: 0.1128 - val_f1_weighted: 0.1521 - val_loss: 4.7201 - val_top5_accuracy: 0.3528 - learning_rate: 6.2500e-05\n",
            "Epoch 30/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.4343 - auc: 0.9561 - f1_macro: 0.4099 - f1_weighted: 0.4197 - loss: 2.5313 - top5_accuracy: 0.7054 - val_accuracy: 0.1630 - val_auc: 0.7764 - val_f1_macro: 0.1118 - val_f1_weighted: 0.1498 - val_loss: 4.7444 - val_top5_accuracy: 0.3478 - learning_rate: 6.2500e-05\n",
            "Restoring model weights from the end of the best epoch: 27.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training DenseNet-S with augment = none\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 263ms/step - accuracy: 0.0775 - auc: 0.6713 - f1_macro: 0.0496 - f1_weighted: 0.0630 - loss: 5.8917 - top5_accuracy: 0.1827 - val_accuracy: 0.0467 - val_auc: 0.6364 - val_f1_macro: 0.0068 - val_f1_weighted: 0.0196 - val_loss: 5.9060 - val_top5_accuracy: 0.1430 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 148ms/step - accuracy: 0.0546 - auc: 0.7130 - f1_macro: 0.0188 - f1_weighted: 0.0305 - loss: 5.3908 - top5_accuracy: 0.1572 - val_accuracy: 0.0445 - val_auc: 0.6386 - val_f1_macro: 0.0105 - val_f1_weighted: 0.0275 - val_loss: 5.8905 - val_top5_accuracy: 0.1447 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 147ms/step - accuracy: 0.0651 - auc: 0.7524 - f1_macro: 0.0238 - f1_weighted: 0.0381 - loss: 5.1221 - top5_accuracy: 0.1958 - val_accuracy: 0.0312 - val_auc: 0.5744 - val_f1_macro: 0.0090 - val_f1_weighted: 0.0176 - val_loss: 14.7015 - val_top5_accuracy: 0.1035 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 146ms/step - accuracy: 0.0777 - auc: 0.7789 - f1_macro: 0.0359 - f1_weighted: 0.0515 - loss: 4.9326 - top5_accuracy: 0.2200 - val_accuracy: 0.0551 - val_auc: 0.6311 - val_f1_macro: 0.0123 - val_f1_weighted: 0.0289 - val_loss: 6.7314 - val_top5_accuracy: 0.1486 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 147ms/step - accuracy: 0.0895 - auc: 0.8001 - f1_macro: 0.0495 - f1_weighted: 0.0645 - loss: 4.7642 - top5_accuracy: 0.2483 - val_accuracy: 0.0551 - val_auc: 0.6422 - val_f1_macro: 0.0135 - val_f1_weighted: 0.0315 - val_loss: 6.7485 - val_top5_accuracy: 0.1503 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 148ms/step - accuracy: 0.1057 - auc: 0.8175 - f1_macro: 0.0644 - f1_weighted: 0.0805 - loss: 4.5955 - top5_accuracy: 0.2768 - val_accuracy: 0.0378 - val_auc: 0.6002 - val_f1_macro: 0.0062 - val_f1_weighted: 0.0206 - val_loss: 8.5591 - val_top5_accuracy: 0.1258 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.1173 - auc: 0.8311 - f1_macro: 0.0756 - f1_weighted: 0.0933 - loss: 4.4560 - top5_accuracy: 0.3049\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 146ms/step - accuracy: 0.1173 - auc: 0.8311 - f1_macro: 0.0756 - f1_weighted: 0.0934 - loss: 4.4558 - top5_accuracy: 0.3050 - val_accuracy: 0.0562 - val_auc: 0.6216 - val_f1_macro: 0.0159 - val_f1_weighted: 0.0329 - val_loss: 7.6289 - val_top5_accuracy: 0.1458 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 146ms/step - accuracy: 0.1566 - auc: 0.8610 - f1_macro: 0.1126 - f1_weighted: 0.1317 - loss: 4.1638 - top5_accuracy: 0.3733 - val_accuracy: 0.0629 - val_auc: 0.6281 - val_f1_macro: 0.0264 - val_f1_weighted: 0.0446 - val_loss: 7.8756 - val_top5_accuracy: 0.1547 - learning_rate: 5.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 147ms/step - accuracy: 0.1877 - auc: 0.8787 - f1_macro: 0.1384 - f1_weighted: 0.1619 - loss: 3.9480 - top5_accuracy: 0.4233 - val_accuracy: 0.0601 - val_auc: 0.6259 - val_f1_macro: 0.0202 - val_f1_weighted: 0.0403 - val_loss: 7.9742 - val_top5_accuracy: 0.1586 - learning_rate: 5.0000e-04\n",
            "Epoch 9: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 257ms/step\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training DenseNet-Tiny with augment = medium\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 294ms/step - accuracy: 0.0367 - auc: 0.6149 - f1_macro: 0.0083 - f1_weighted: 0.0199 - loss: 5.4143 - top5_accuracy: 0.1155 - val_accuracy: 0.0150 - val_auc: 0.5824 - val_f1_macro: 0.0022 - val_f1_weighted: 0.0065 - val_loss: 6.7246 - val_top5_accuracy: 0.0757 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0498 - auc: 0.6841 - f1_macro: 0.0132 - f1_weighted: 0.0256 - loss: 5.0337 - top5_accuracy: 0.1518 - val_accuracy: 0.0145 - val_auc: 0.5854 - val_f1_macro: 0.0039 - val_f1_weighted: 0.0081 - val_loss: 6.8713 - val_top5_accuracy: 0.0735 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0676 - auc: 0.7307 - f1_macro: 0.0223 - f1_weighted: 0.0397 - loss: 4.8116 - top5_accuracy: 0.1844 - val_accuracy: 0.0284 - val_auc: 0.6491 - val_f1_macro: 0.0087 - val_f1_weighted: 0.0202 - val_loss: 5.6017 - val_top5_accuracy: 0.1157 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0750 - auc: 0.7596 - f1_macro: 0.0275 - f1_weighted: 0.0463 - loss: 4.6618 - top5_accuracy: 0.2071 - val_accuracy: 0.0584 - val_auc: 0.7111 - val_f1_macro: 0.0199 - val_f1_weighted: 0.0368 - val_loss: 5.0144 - val_top5_accuracy: 0.1630 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0796 - auc: 0.7768 - f1_macro: 0.0323 - f1_weighted: 0.0513 - loss: 4.5592 - top5_accuracy: 0.2265 - val_accuracy: 0.0774 - val_auc: 0.7515 - val_f1_macro: 0.0275 - val_f1_weighted: 0.0480 - val_loss: 4.7634 - val_top5_accuracy: 0.2014 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0891 - auc: 0.7910 - f1_macro: 0.0417 - f1_weighted: 0.0604 - loss: 4.4656 - top5_accuracy: 0.2448 - val_accuracy: 0.0735 - val_auc: 0.7540 - val_f1_macro: 0.0300 - val_f1_weighted: 0.0508 - val_loss: 4.7502 - val_top5_accuracy: 0.2087 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0963 - auc: 0.8022 - f1_macro: 0.0509 - f1_weighted: 0.0688 - loss: 4.3863 - top5_accuracy: 0.2641 - val_accuracy: 0.0746 - val_auc: 0.7560 - val_f1_macro: 0.0393 - val_f1_weighted: 0.0577 - val_loss: 4.7330 - val_top5_accuracy: 0.2092 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1027 - auc: 0.8152 - f1_macro: 0.0600 - f1_weighted: 0.0772 - loss: 4.3024 - top5_accuracy: 0.2886 - val_accuracy: 0.0757 - val_auc: 0.7480 - val_f1_macro: 0.0461 - val_f1_weighted: 0.0616 - val_loss: 4.7774 - val_top5_accuracy: 0.2120 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1188 - auc: 0.8237 - f1_macro: 0.0715 - f1_weighted: 0.0916 - loss: 4.2292 - top5_accuracy: 0.3083 - val_accuracy: 0.0718 - val_auc: 0.7357 - val_f1_macro: 0.0404 - val_f1_weighted: 0.0575 - val_loss: 4.9674 - val_top5_accuracy: 0.1959 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.1230 - auc: 0.8352 - f1_macro: 0.0781 - f1_weighted: 0.0977 - loss: 4.1548 - top5_accuracy: 0.3227 - val_accuracy: 0.0523 - val_auc: 0.7171 - val_f1_macro: 0.0350 - val_f1_weighted: 0.0421 - val_loss: 5.2469 - val_top5_accuracy: 0.1925 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.1334 - auc: 0.8421 - f1_macro: 0.0911 - f1_weighted: 0.1099 - loss: 4.0897 - top5_accuracy: 0.3384 - val_accuracy: 0.0595 - val_auc: 0.7265 - val_f1_macro: 0.0391 - val_f1_weighted: 0.0484 - val_loss: 5.1059 - val_top5_accuracy: 0.2120 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.1435 - auc: 0.8510 - f1_macro: 0.1022 - f1_weighted: 0.1209 - loss: 4.0183 - top5_accuracy: 0.3579\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.1435 - auc: 0.8510 - f1_macro: 0.1022 - f1_weighted: 0.1209 - loss: 4.0183 - top5_accuracy: 0.3579 - val_accuracy: 0.0612 - val_auc: 0.7085 - val_f1_macro: 0.0386 - val_f1_weighted: 0.0504 - val_loss: 5.3406 - val_top5_accuracy: 0.1931 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.1768 - auc: 0.8666 - f1_macro: 0.1304 - f1_weighted: 0.1501 - loss: 3.8580 - top5_accuracy: 0.4101 - val_accuracy: 0.0902 - val_auc: 0.7405 - val_f1_macro: 0.0631 - val_f1_weighted: 0.0798 - val_loss: 4.9835 - val_top5_accuracy: 0.2454 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.1986 - auc: 0.8788 - f1_macro: 0.1522 - f1_weighted: 0.1732 - loss: 3.7400 - top5_accuracy: 0.4358 - val_accuracy: 0.0879 - val_auc: 0.7292 - val_f1_macro: 0.0605 - val_f1_weighted: 0.0785 - val_loss: 5.1144 - val_top5_accuracy: 0.2404 - learning_rate: 5.0000e-04\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training DenseNet-S with augment = medium\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 355ms/step - accuracy: 0.0443 - auc: 0.6556 - f1_macro: 0.0199 - f1_weighted: 0.0299 - loss: 5.9114 - top5_accuracy: 0.1356 - val_accuracy: 0.0378 - val_auc: 0.6272 - val_f1_macro: 0.0064 - val_f1_weighted: 0.0171 - val_loss: 6.1204 - val_top5_accuracy: 0.1169 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 150ms/step - accuracy: 0.0524 - auc: 0.6976 - f1_macro: 0.0145 - f1_weighted: 0.0277 - loss: 5.4287 - top5_accuracy: 0.1522 - val_accuracy: 0.0495 - val_auc: 0.6215 - val_f1_macro: 0.0114 - val_f1_weighted: 0.0306 - val_loss: 6.1072 - val_top5_accuracy: 0.1285 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 150ms/step - accuracy: 0.0636 - auc: 0.7400 - f1_macro: 0.0223 - f1_weighted: 0.0369 - loss: 5.1643 - top5_accuracy: 0.1850 - val_accuracy: 0.0490 - val_auc: 0.6563 - val_f1_macro: 0.0120 - val_f1_weighted: 0.0282 - val_loss: 5.9418 - val_top5_accuracy: 0.1586 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 150ms/step - accuracy: 0.0709 - auc: 0.7621 - f1_macro: 0.0295 - f1_weighted: 0.0442 - loss: 4.9983 - top5_accuracy: 0.2115 - val_accuracy: 0.0640 - val_auc: 0.6940 - val_f1_macro: 0.0225 - val_f1_weighted: 0.0364 - val_loss: 5.9508 - val_top5_accuracy: 0.1892 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 150ms/step - accuracy: 0.0800 - auc: 0.7828 - f1_macro: 0.0389 - f1_weighted: 0.0536 - loss: 4.8344 - top5_accuracy: 0.2343 - val_accuracy: 0.0618 - val_auc: 0.7119 - val_f1_macro: 0.0238 - val_f1_weighted: 0.0396 - val_loss: 5.3783 - val_top5_accuracy: 0.1898 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 151ms/step - accuracy: 0.0893 - auc: 0.7989 - f1_macro: 0.0475 - f1_weighted: 0.0624 - loss: 4.7070 - top5_accuracy: 0.2544 - val_accuracy: 0.0484 - val_auc: 0.6683 - val_f1_macro: 0.0170 - val_f1_weighted: 0.0318 - val_loss: 5.8080 - val_top5_accuracy: 0.1703 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 149ms/step - accuracy: 0.0992 - auc: 0.8093 - f1_macro: 0.0574 - f1_weighted: 0.0740 - loss: 4.5920 - top5_accuracy: 0.2709 - val_accuracy: 0.0690 - val_auc: 0.6844 - val_f1_macro: 0.0318 - val_f1_weighted: 0.0498 - val_loss: 5.7497 - val_top5_accuracy: 0.1697 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 150ms/step - accuracy: 0.1111 - auc: 0.8272 - f1_macro: 0.0716 - f1_weighted: 0.0869 - loss: 4.4618 - top5_accuracy: 0.2944 - val_accuracy: 0.0584 - val_auc: 0.7002 - val_f1_macro: 0.0284 - val_f1_weighted: 0.0461 - val_loss: 6.4919 - val_top5_accuracy: 0.1853 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 149ms/step - accuracy: 0.1218 - auc: 0.8395 - f1_macro: 0.0817 - f1_weighted: 0.0989 - loss: 4.3527 - top5_accuracy: 0.3144 - val_accuracy: 0.0712 - val_auc: 0.6823 - val_f1_macro: 0.0378 - val_f1_weighted: 0.0527 - val_loss: 6.2846 - val_top5_accuracy: 0.1859 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.1345 - auc: 0.8488 - f1_macro: 0.0966 - f1_weighted: 0.1131 - loss: 4.2525 - top5_accuracy: 0.3388\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 150ms/step - accuracy: 0.1345 - auc: 0.8488 - f1_macro: 0.0967 - f1_weighted: 0.1132 - loss: 4.2523 - top5_accuracy: 0.3389 - val_accuracy: 0.0935 - val_auc: 0.7180 - val_f1_macro: 0.0460 - val_f1_weighted: 0.0728 - val_loss: 5.4116 - val_top5_accuracy: 0.2231 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 150ms/step - accuracy: 0.1679 - auc: 0.8721 - f1_macro: 0.1276 - f1_weighted: 0.1451 - loss: 4.0124 - top5_accuracy: 0.4012 - val_accuracy: 0.0913 - val_auc: 0.7115 - val_f1_macro: 0.0407 - val_f1_weighted: 0.0666 - val_loss: 5.4959 - val_top5_accuracy: 0.2209 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 150ms/step - accuracy: 0.2010 - auc: 0.8920 - f1_macro: 0.1619 - f1_weighted: 0.1805 - loss: 3.7974 - top5_accuracy: 0.4501 - val_accuracy: 0.0890 - val_auc: 0.7019 - val_f1_macro: 0.0446 - val_f1_weighted: 0.0654 - val_loss: 5.7594 - val_top5_accuracy: 0.2248 - learning_rate: 5.0000e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 258ms/step\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training DenseNet-Tiny with augment = mixup\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 191ms/step - accuracy: 0.0449 - auc: 0.6142 - f1_macro: 0.0140 - f1_weighted: 0.0248 - loss: 5.4214 - top5_accuracy: 0.1332 - val_accuracy: 0.0384 - val_auc: 0.6280 - val_f1_macro: 0.0063 - val_f1_weighted: 0.0212 - val_loss: 5.2347 - val_top5_accuracy: 0.1091 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 78ms/step - accuracy: 0.0558 - auc: 0.6363 - f1_macro: 0.0101 - f1_weighted: 0.0220 - loss: 5.1072 - top5_accuracy: 0.1590 - val_accuracy: 0.0217 - val_auc: 0.5940 - val_f1_macro: 0.0043 - val_f1_weighted: 0.0129 - val_loss: 5.6139 - val_top5_accuracy: 0.0829 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 79ms/step - accuracy: 0.0650 - auc: 0.6606 - f1_macro: 0.0148 - f1_weighted: 0.0283 - loss: 4.9649 - top5_accuracy: 0.1832 - val_accuracy: 0.0417 - val_auc: 0.6756 - val_f1_macro: 0.0114 - val_f1_weighted: 0.0251 - val_loss: 5.2081 - val_top5_accuracy: 0.1391 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 78ms/step - accuracy: 0.0720 - auc: 0.6729 - f1_macro: 0.0206 - f1_weighted: 0.0345 - loss: 4.8750 - top5_accuracy: 0.2054 - val_accuracy: 0.0390 - val_auc: 0.6777 - val_f1_macro: 0.0135 - val_f1_weighted: 0.0244 - val_loss: 5.2411 - val_top5_accuracy: 0.1386 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0814 - auc: 0.6806 - f1_macro: 0.0263 - f1_weighted: 0.0410 - loss: 4.8033 - top5_accuracy: 0.2256 - val_accuracy: 0.0601 - val_auc: 0.7073 - val_f1_macro: 0.0201 - val_f1_weighted: 0.0360 - val_loss: 5.0063 - val_top5_accuracy: 0.1486 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0935 - auc: 0.6867 - f1_macro: 0.0322 - f1_weighted: 0.0484 - loss: 4.7424 - top5_accuracy: 0.2426 - val_accuracy: 0.0662 - val_auc: 0.7198 - val_f1_macro: 0.0231 - val_f1_weighted: 0.0419 - val_loss: 5.0432 - val_top5_accuracy: 0.1797 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.1010 - auc: 0.6936 - f1_macro: 0.0385 - f1_weighted: 0.0548 - loss: 4.6777 - top5_accuracy: 0.2655 - val_accuracy: 0.0662 - val_auc: 0.7164 - val_f1_macro: 0.0294 - val_f1_weighted: 0.0471 - val_loss: 5.0858 - val_top5_accuracy: 0.1781 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.1094 - auc: 0.7008 - f1_macro: 0.0459 - f1_weighted: 0.0616 - loss: 4.6201 - top5_accuracy: 0.2850 - val_accuracy: 0.0690 - val_auc: 0.7096 - val_f1_macro: 0.0307 - val_f1_weighted: 0.0491 - val_loss: 5.1107 - val_top5_accuracy: 0.1886 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.1187 - auc: 0.7074 - f1_macro: 0.0524 - f1_weighted: 0.0687 - loss: 4.5663 - top5_accuracy: 0.3035 - val_accuracy: 0.0634 - val_auc: 0.7043 - val_f1_macro: 0.0296 - val_f1_weighted: 0.0491 - val_loss: 5.0737 - val_top5_accuracy: 0.1764 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.1254 - auc: 0.7108 - f1_macro: 0.0610 - f1_weighted: 0.0768 - loss: 4.5201 - top5_accuracy: 0.3197\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.1254 - auc: 0.7108 - f1_macro: 0.0610 - f1_weighted: 0.0768 - loss: 4.5201 - top5_accuracy: 0.3197 - val_accuracy: 0.0640 - val_auc: 0.7156 - val_f1_macro: 0.0258 - val_f1_weighted: 0.0470 - val_loss: 5.0244 - val_top5_accuracy: 0.1809 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.1473 - auc: 0.7195 - f1_macro: 0.0783 - f1_weighted: 0.0933 - loss: 4.4254 - top5_accuracy: 0.3508 - val_accuracy: 0.0890 - val_auc: 0.7493 - val_f1_macro: 0.0440 - val_f1_weighted: 0.0696 - val_loss: 4.8194 - val_top5_accuracy: 0.2282 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.1623 - auc: 0.7262 - f1_macro: 0.0895 - f1_weighted: 0.1045 - loss: 4.3476 - top5_accuracy: 0.3726 - val_accuracy: 0.0840 - val_auc: 0.7399 - val_f1_macro: 0.0421 - val_f1_weighted: 0.0691 - val_loss: 4.9299 - val_top5_accuracy: 0.2154 - learning_rate: 5.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.1768 - auc: 0.7311 - f1_macro: 0.1016 - f1_weighted: 0.1167 - loss: 4.2902 - top5_accuracy: 0.3922 - val_accuracy: 0.0812 - val_auc: 0.7427 - val_f1_macro: 0.0450 - val_f1_weighted: 0.0674 - val_loss: 4.9144 - val_top5_accuracy: 0.2220 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.1851 - auc: 0.7350 - f1_macro: 0.1106 - f1_weighted: 0.1260 - loss: 4.2340 - top5_accuracy: 0.4149 - val_accuracy: 0.0824 - val_auc: 0.7513 - val_f1_macro: 0.0462 - val_f1_weighted: 0.0730 - val_loss: 4.9160 - val_top5_accuracy: 0.2204 - learning_rate: 5.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.2029 - auc: 0.7379 - f1_macro: 0.1245 - f1_weighted: 0.1408 - loss: 4.1816 - top5_accuracy: 0.4377 - val_accuracy: 0.0857 - val_auc: 0.7497 - val_f1_macro: 0.0503 - val_f1_weighted: 0.0751 - val_loss: 4.9420 - val_top5_accuracy: 0.2371 - learning_rate: 5.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.2124 - auc: 0.7430 - f1_macro: 0.1329 - f1_weighted: 0.1488 - loss: 4.1319 - top5_accuracy: 0.4532\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.2124 - auc: 0.7430 - f1_macro: 0.1330 - f1_weighted: 0.1488 - loss: 4.1319 - top5_accuracy: 0.4532 - val_accuracy: 0.0807 - val_auc: 0.7354 - val_f1_macro: 0.0491 - val_f1_weighted: 0.0703 - val_loss: 5.0655 - val_top5_accuracy: 0.2276 - learning_rate: 5.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.2326 - auc: 0.7469 - f1_macro: 0.1520 - f1_weighted: 0.1670 - loss: 4.0541 - top5_accuracy: 0.4839 - val_accuracy: 0.1213 - val_auc: 0.7665 - val_f1_macro: 0.0617 - val_f1_weighted: 0.1009 - val_loss: 4.6698 - val_top5_accuracy: 0.2860 - learning_rate: 2.5000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.2524 - auc: 0.7520 - f1_macro: 0.1670 - f1_weighted: 0.1830 - loss: 3.9881 - top5_accuracy: 0.5074 - val_accuracy: 0.1302 - val_auc: 0.7731 - val_f1_macro: 0.0680 - val_f1_weighted: 0.1063 - val_loss: 4.6196 - val_top5_accuracy: 0.3100 - learning_rate: 2.5000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.2608 - auc: 0.7534 - f1_macro: 0.1780 - f1_weighted: 0.1914 - loss: 3.9442 - top5_accuracy: 0.5216 - val_accuracy: 0.1347 - val_auc: 0.7812 - val_f1_macro: 0.0733 - val_f1_weighted: 0.1122 - val_loss: 4.5778 - val_top5_accuracy: 0.3100 - learning_rate: 2.5000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.2744 - auc: 0.7571 - f1_macro: 0.1884 - f1_weighted: 0.2029 - loss: 3.8976 - top5_accuracy: 0.5397 - val_accuracy: 0.1391 - val_auc: 0.7866 - val_f1_macro: 0.0798 - val_f1_weighted: 0.1199 - val_loss: 4.5402 - val_top5_accuracy: 0.3228 - learning_rate: 2.5000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.2834 - auc: 0.7583 - f1_macro: 0.1958 - f1_weighted: 0.2107 - loss: 3.8565 - top5_accuracy: 0.5566 - val_accuracy: 0.1402 - val_auc: 0.7921 - val_f1_macro: 0.0825 - val_f1_weighted: 0.1194 - val_loss: 4.5188 - val_top5_accuracy: 0.3261 - learning_rate: 2.5000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.2964 - auc: 0.7597 - f1_macro: 0.2069 - f1_weighted: 0.2214 - loss: 3.8169 - top5_accuracy: 0.5675 - val_accuracy: 0.1391 - val_auc: 0.7862 - val_f1_macro: 0.0790 - val_f1_weighted: 0.1182 - val_loss: 4.5783 - val_top5_accuracy: 0.3183 - learning_rate: 2.5000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.3071 - auc: 0.7632 - f1_macro: 0.2175 - f1_weighted: 0.2311 - loss: 3.7762 - top5_accuracy: 0.5806 - val_accuracy: 0.1452 - val_auc: 0.7884 - val_f1_macro: 0.0850 - val_f1_weighted: 0.1240 - val_loss: 4.5992 - val_top5_accuracy: 0.3216 - learning_rate: 2.5000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.3189 - auc: 0.7638 - f1_macro: 0.2277 - f1_weighted: 0.2406 - loss: 3.7371 - top5_accuracy: 0.5943 - val_accuracy: 0.1363 - val_auc: 0.7810 - val_f1_macro: 0.0755 - val_f1_weighted: 0.1121 - val_loss: 4.6525 - val_top5_accuracy: 0.3150 - learning_rate: 2.5000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.3417 - auc: 0.7650 - f1_macro: 0.2464 - f1_weighted: 0.2600 - loss: 3.6970 - top5_accuracy: 0.6065 - val_accuracy: 0.1391 - val_auc: 0.7765 - val_f1_macro: 0.0751 - val_f1_weighted: 0.1173 - val_loss: 4.7092 - val_top5_accuracy: 0.3111 - learning_rate: 2.5000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.3518 - auc: 0.7661 - f1_macro: 0.2538 - f1_weighted: 0.2705 - loss: 3.6577 - top5_accuracy: 0.6222\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.3518 - auc: 0.7661 - f1_macro: 0.2538 - f1_weighted: 0.2706 - loss: 3.6576 - top5_accuracy: 0.6222 - val_accuracy: 0.1313 - val_auc: 0.7695 - val_f1_macro: 0.0703 - val_f1_weighted: 0.1096 - val_loss: 4.7792 - val_top5_accuracy: 0.3050 - learning_rate: 2.5000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.3666 - auc: 0.7691 - f1_macro: 0.2697 - f1_weighted: 0.2827 - loss: 3.6116 - top5_accuracy: 0.6395 - val_accuracy: 0.1391 - val_auc: 0.7735 - val_f1_macro: 0.0802 - val_f1_weighted: 0.1188 - val_loss: 4.7415 - val_top5_accuracy: 0.3116 - learning_rate: 1.2500e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.3802 - auc: 0.7706 - f1_macro: 0.2828 - f1_weighted: 0.2949 - loss: 3.5650 - top5_accuracy: 0.6566 - val_accuracy: 0.1425 - val_auc: 0.7751 - val_f1_macro: 0.0865 - val_f1_weighted: 0.1252 - val_loss: 4.7209 - val_top5_accuracy: 0.3139 - learning_rate: 1.2500e-04\n",
            "Epoch 28: early stopping\n",
            "Restoring model weights from the end of the best epoch: 21.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training DenseNet-S with augment = mixup\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 276ms/step - accuracy: 0.0681 - auc: 0.6363 - f1_macro: 0.0360 - f1_weighted: 0.0488 - loss: 5.9102 - top5_accuracy: 0.1739 - val_accuracy: 0.0506 - val_auc: 0.6627 - val_f1_macro: 0.0060 - val_f1_weighted: 0.0228 - val_loss: 7.7309 - val_top5_accuracy: 0.1647 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 151ms/step - accuracy: 0.0535 - auc: 0.6414 - f1_macro: 0.0085 - f1_weighted: 0.0184 - loss: 5.4957 - top5_accuracy: 0.1552 - val_accuracy: 0.0440 - val_auc: 0.6043 - val_f1_macro: 0.0043 - val_f1_weighted: 0.0151 - val_loss: 5.7040 - val_top5_accuracy: 0.1063 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 150ms/step - accuracy: 0.0574 - auc: 0.6560 - f1_macro: 0.0107 - f1_weighted: 0.0224 - loss: 5.3251 - top5_accuracy: 0.1758 - val_accuracy: 0.0607 - val_auc: 0.6812 - val_f1_macro: 0.0085 - val_f1_weighted: 0.0236 - val_loss: 5.7155 - val_top5_accuracy: 0.1647 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 150ms/step - accuracy: 0.0677 - auc: 0.6689 - f1_macro: 0.0171 - f1_weighted: 0.0289 - loss: 5.1640 - top5_accuracy: 0.1957 - val_accuracy: 0.0668 - val_auc: 0.7041 - val_f1_macro: 0.0130 - val_f1_weighted: 0.0294 - val_loss: 5.3368 - val_top5_accuracy: 0.1742 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 151ms/step - accuracy: 0.0759 - auc: 0.6792 - f1_macro: 0.0230 - f1_weighted: 0.0360 - loss: 5.0427 - top5_accuracy: 0.2085 - val_accuracy: 0.0618 - val_auc: 0.7047 - val_f1_macro: 0.0126 - val_f1_weighted: 0.0284 - val_loss: 5.2093 - val_top5_accuracy: 0.1914 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 150ms/step - accuracy: 0.0795 - auc: 0.6845 - f1_macro: 0.0275 - f1_weighted: 0.0399 - loss: 4.9490 - top5_accuracy: 0.2265 - val_accuracy: 0.0595 - val_auc: 0.7208 - val_f1_macro: 0.0165 - val_f1_weighted: 0.0298 - val_loss: 5.1577 - val_top5_accuracy: 0.2053 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 151ms/step - accuracy: 0.0896 - auc: 0.6927 - f1_macro: 0.0333 - f1_weighted: 0.0471 - loss: 4.8522 - top5_accuracy: 0.2433 - val_accuracy: 0.0952 - val_auc: 0.7516 - val_f1_macro: 0.0330 - val_f1_weighted: 0.0516 - val_loss: 4.9232 - val_top5_accuracy: 0.2254 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 150ms/step - accuracy: 0.0977 - auc: 0.7001 - f1_macro: 0.0409 - f1_weighted: 0.0546 - loss: 4.7746 - top5_accuracy: 0.2646 - val_accuracy: 0.0612 - val_auc: 0.6997 - val_f1_macro: 0.0168 - val_f1_weighted: 0.0339 - val_loss: 5.3873 - val_top5_accuracy: 0.1797 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 150ms/step - accuracy: 0.1102 - auc: 0.7072 - f1_macro: 0.0509 - f1_weighted: 0.0650 - loss: 4.7000 - top5_accuracy: 0.2896 - val_accuracy: 0.0779 - val_auc: 0.7347 - val_f1_macro: 0.0291 - val_f1_weighted: 0.0494 - val_loss: 5.0637 - val_top5_accuracy: 0.2259 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 150ms/step - accuracy: 0.1216 - auc: 0.7146 - f1_macro: 0.0619 - f1_weighted: 0.0761 - loss: 4.6218 - top5_accuracy: 0.3137 - val_accuracy: 0.0712 - val_auc: 0.7454 - val_f1_macro: 0.0270 - val_f1_weighted: 0.0474 - val_loss: 4.9905 - val_top5_accuracy: 0.2376 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 150ms/step - accuracy: 0.1363 - auc: 0.7227 - f1_macro: 0.0736 - f1_weighted: 0.0891 - loss: 4.5433 - top5_accuracy: 0.3377 - val_accuracy: 0.0735 - val_auc: 0.7110 - val_f1_macro: 0.0309 - val_f1_weighted: 0.0499 - val_loss: 5.5710 - val_top5_accuracy: 0.2081 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.1554 - auc: 0.7288 - f1_macro: 0.0917 - f1_weighted: 0.1062 - loss: 4.4533 - top5_accuracy: 0.3741\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 150ms/step - accuracy: 0.1554 - auc: 0.7288 - f1_macro: 0.0917 - f1_weighted: 0.1063 - loss: 4.4533 - top5_accuracy: 0.3741 - val_accuracy: 0.0529 - val_auc: 0.6535 - val_f1_macro: 0.0288 - val_f1_weighted: 0.0362 - val_loss: 6.9926 - val_top5_accuracy: 0.1636 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 150ms/step - accuracy: 0.1885 - auc: 0.7388 - f1_macro: 0.1156 - f1_weighted: 0.1324 - loss: 4.3174 - top5_accuracy: 0.4226 - val_accuracy: 0.0885 - val_auc: 0.7379 - val_f1_macro: 0.0424 - val_f1_weighted: 0.0671 - val_loss: 5.1772 - val_top5_accuracy: 0.2410 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 150ms/step - accuracy: 0.2145 - auc: 0.7458 - f1_macro: 0.1429 - f1_weighted: 0.1570 - loss: 4.1893 - top5_accuracy: 0.4700 - val_accuracy: 0.0874 - val_auc: 0.7321 - val_f1_macro: 0.0502 - val_f1_weighted: 0.0719 - val_loss: 5.2798 - val_top5_accuracy: 0.2354 - learning_rate: 5.0000e-04\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 316ms/step\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    architecture augmentation  best_epoch  train_loss  val_loss  \\\n",
            "0  DenseNet-Tiny         none          27      3.2933    4.7081   \n",
            "1     DenseNet-S         none           2      5.8423    5.8905   \n",
            "2  DenseNet-Tiny       medium           7      4.5109    4.7330   \n",
            "3     DenseNet-S       medium           5      5.2824    5.3783   \n",
            "4  DenseNet-Tiny        mixup          21      4.2634    4.5188   \n",
            "5     DenseNet-S        mixup           7      4.9534    4.9232   \n",
            "\n",
            "   train_accuracy  val_accuracy  train_f1_macro  val_f1_macro  \\\n",
            "0          0.2886        0.1686          0.2622        0.1168   \n",
            "1          0.0446        0.0445          0.0112        0.0105   \n",
            "2          0.0866        0.0746          0.0501        0.0393   \n",
            "3          0.0656        0.0618          0.0314        0.0238   \n",
            "4          0.2091        0.1402          0.1665        0.0825   \n",
            "5          0.0947        0.0952          0.0460        0.0330   \n",
            "\n",
            "   val_f1_weighted  val_precision  val_recall  \n",
            "0           0.1561         0.1679      0.1686  \n",
            "1           0.0275         0.0328      0.0445  \n",
            "2           0.0577         0.0618      0.0746  \n",
            "3           0.0396         0.0394      0.0618  \n",
            "4           0.1194         0.1238      0.1402  \n",
            "5           0.0516         0.0458      0.0952  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df"
      ],
      "metadata": {
        "id": "GVKwjWo7FvEb",
        "outputId": "0d9b729d-30b3-4f3b-9be3-dc1f7372a295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    architecture augmentation  best_epoch  train_loss  val_loss  \\\n",
              "0  DenseNet-Tiny         none          27    3.293268  4.708080   \n",
              "1     DenseNet-S         none           2    5.842314  5.890521   \n",
              "2  DenseNet-Tiny       medium           7    4.510923  4.732995   \n",
              "3     DenseNet-S       medium           5    5.282403  5.378264   \n",
              "4  DenseNet-Tiny        mixup          21    4.263402  4.518836   \n",
              "5     DenseNet-S        mixup           7    4.953425  4.923228   \n",
              "\n",
              "   train_accuracy  val_accuracy  train_f1_macro  val_f1_macro  \\\n",
              "0        0.288571      0.168614        0.262226      0.116791   \n",
              "1        0.044554      0.044519        0.011210      0.010482   \n",
              "2        0.086607      0.074569        0.050137      0.039305   \n",
              "3        0.065625      0.061770        0.031445      0.023849   \n",
              "4        0.209107      0.140234        0.166490      0.082496   \n",
              "5        0.094732      0.095159        0.045951      0.033026   \n",
              "\n",
              "   val_f1_weighted  val_precision  val_recall  \n",
              "0         0.156082       0.167867    0.168614  \n",
              "1         0.027515       0.032779    0.044519  \n",
              "2         0.057711       0.061755    0.074569  \n",
              "3         0.039606       0.039440    0.061770  \n",
              "4         0.119393       0.123766    0.140234  \n",
              "5         0.051579       0.045831    0.095159  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9163ed62-2889-4636-b765-85167acb4c17\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>architecture</th>\n",
              "      <th>augmentation</th>\n",
              "      <th>best_epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>train_f1_macro</th>\n",
              "      <th>val_f1_macro</th>\n",
              "      <th>val_f1_weighted</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DenseNet-Tiny</td>\n",
              "      <td>none</td>\n",
              "      <td>27</td>\n",
              "      <td>3.293268</td>\n",
              "      <td>4.708080</td>\n",
              "      <td>0.288571</td>\n",
              "      <td>0.168614</td>\n",
              "      <td>0.262226</td>\n",
              "      <td>0.116791</td>\n",
              "      <td>0.156082</td>\n",
              "      <td>0.167867</td>\n",
              "      <td>0.168614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DenseNet-S</td>\n",
              "      <td>none</td>\n",
              "      <td>2</td>\n",
              "      <td>5.842314</td>\n",
              "      <td>5.890521</td>\n",
              "      <td>0.044554</td>\n",
              "      <td>0.044519</td>\n",
              "      <td>0.011210</td>\n",
              "      <td>0.010482</td>\n",
              "      <td>0.027515</td>\n",
              "      <td>0.032779</td>\n",
              "      <td>0.044519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DenseNet-Tiny</td>\n",
              "      <td>medium</td>\n",
              "      <td>7</td>\n",
              "      <td>4.510923</td>\n",
              "      <td>4.732995</td>\n",
              "      <td>0.086607</td>\n",
              "      <td>0.074569</td>\n",
              "      <td>0.050137</td>\n",
              "      <td>0.039305</td>\n",
              "      <td>0.057711</td>\n",
              "      <td>0.061755</td>\n",
              "      <td>0.074569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DenseNet-S</td>\n",
              "      <td>medium</td>\n",
              "      <td>5</td>\n",
              "      <td>5.282403</td>\n",
              "      <td>5.378264</td>\n",
              "      <td>0.065625</td>\n",
              "      <td>0.061770</td>\n",
              "      <td>0.031445</td>\n",
              "      <td>0.023849</td>\n",
              "      <td>0.039606</td>\n",
              "      <td>0.039440</td>\n",
              "      <td>0.061770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DenseNet-Tiny</td>\n",
              "      <td>mixup</td>\n",
              "      <td>21</td>\n",
              "      <td>4.263402</td>\n",
              "      <td>4.518836</td>\n",
              "      <td>0.209107</td>\n",
              "      <td>0.140234</td>\n",
              "      <td>0.166490</td>\n",
              "      <td>0.082496</td>\n",
              "      <td>0.119393</td>\n",
              "      <td>0.123766</td>\n",
              "      <td>0.140234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DenseNet-S</td>\n",
              "      <td>mixup</td>\n",
              "      <td>7</td>\n",
              "      <td>4.953425</td>\n",
              "      <td>4.923228</td>\n",
              "      <td>0.094732</td>\n",
              "      <td>0.095159</td>\n",
              "      <td>0.045951</td>\n",
              "      <td>0.033026</td>\n",
              "      <td>0.051579</td>\n",
              "      <td>0.045831</td>\n",
              "      <td>0.095159</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9163ed62-2889-4636-b765-85167acb4c17')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9163ed62-2889-4636-b765-85167acb4c17 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9163ed62-2889-4636-b765-85167acb4c17');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d9c1b68e-2e9d-4bee-8bb7-37b7ee5eaff4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d9c1b68e-2e9d-4bee-8bb7-37b7ee5eaff4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d9c1b68e-2e9d-4bee-8bb7-37b7ee5eaff4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_77416e2c-9c1b-4493-a204-b6411f9192ff\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_77416e2c-9c1b-4493-a204-b6411f9192ff button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"architecture\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"DenseNet-S\",\n          \"DenseNet-Tiny\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"augmentation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"none\",\n          \"medium\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 2,\n        \"max\": 27,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8846546363519724,\n        \"min\": 3.2932684421539307,\n        \"max\": 5.842313766479492,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3.2932684421539307,\n          5.842313766479492\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5150118348060628,\n        \"min\": 4.51883602142334,\n        \"max\": 5.890521049499512,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.708080291748047,\n          5.890521049499512\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09587568439830367,\n        \"min\": 0.044553570449352264,\n        \"max\": 0.28857141733169556,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.28857141733169556,\n          0.044553570449352264\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04795504178957415,\n        \"min\": 0.044518642127513885,\n        \"max\": 0.16861435770988464,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.16861435770988464,\n          0.044518642127513885\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09854239907331969,\n        \"min\": 0.011209574521992817,\n        \"max\": 0.26222644976952025,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.26222644976952025,\n          0.011209574521992817\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04039614670597333,\n        \"min\": 0.010481887958513576,\n        \"max\": 0.116791426488887,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.116791426488887,\n          0.010481887958513576\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_f1_weighted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0507925926378231,\n        \"min\": 0.027515253458999675,\n        \"max\": 0.15608210182463175,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.15608210182463175,\n          0.027515253458999675\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05477096829966365,\n        \"min\": 0.0327791707614393,\n        \"max\": 0.16786737454412726,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.16786737454412726,\n          0.0327791707614393\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04795504124584695,\n        \"min\": 0.044518642181413465,\n        \"max\": 0.1686143572621035,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.1686143572621035,\n          0.044518642181413465\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Warm up learning rate"
      ],
      "metadata": {
        "id": "I5GdpwhOyVjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "num_epochs = 30\n",
        "\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "augment_mode='mixup'\n",
        "\n",
        "# Carregamento dos datasets\n",
        "train_ds, class_names = preprocess.load_img(\n",
        "    data_dir=\"data/rare_species/train\",\n",
        "    minority_class=minority_class,\n",
        "    augment=augment_mode if augment_mode != \"none\" else None,\n",
        "    oversampling=True,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_ds, _ = preprocess.load_img(\n",
        "    data_dir=\"data/rare_species/val\",\n",
        "    minority_class=minority_class,\n",
        "    augment=None,\n",
        "    oversampling=False\n",
        ")\n",
        "\n",
        "\n",
        "steps_per_epoch = len(train_ds)\n",
        "print(f\"Number of batches per epoch: {steps_per_epoch}\")"
      ],
      "metadata": {
        "id": "qQ8JYVRxzFLj",
        "outputId": "d67224a6-045b-4a38-ac6b-630f074fc290",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Number of batches per epoch: 350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_densenet(\n",
        "        layers_per_block=[4, 8, 12, 8],\n",
        "        growth_rate=12,\n",
        "        compression=0.5,\n",
        "        dropout_rate=0.1,  # Menor dropout para baseline\n",
        "        bottleneck=False)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.0),\n",
        "            metrics=metrics)"
      ],
      "metadata": {
        "id": "tixrfMte0YIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define warmup_lr function\n",
        "def warmup_lr(step, initial_lr, warmup_steps):\n",
        "    \"\"\"\n",
        "    Linearly increases the learning rate from 0 to initial_lr during warmup_steps.\n",
        "    \"\"\"\n",
        "    if step < warmup_steps:\n",
        "        # Increase learning rate linearly\n",
        "        lr = initial_lr * (step + 1) / warmup_steps\n",
        "    else:\n",
        "        # After warm-up, keep the learning rate constant at initial_lr\n",
        "        lr = initial_lr\n",
        "    return lr\n",
        "\n",
        "# Training parameters\n",
        "initial_lr = 0.001  # Maximum learning rate after warm-up\n",
        "steps_per_epoch = 350  # Steps per epoch (depends on your dataset and batch size)\n",
        "warmup_steps = num_epochs*steps_per_epoch  # Number of steps for warm-up (can be epochs * steps_per_epoch)\n",
        "# total_steps = steps_per_epoch * 30  # Total steps for training (for 30 epochs)\n",
        "\n",
        "# Create LearningRateScheduler with warmup_lr function\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: warmup_lr(epoch * steps_per_epoch, initial_lr, warmup_steps)\n",
        ")\n",
        "\n",
        "callbacks=callbacks+[lr_scheduler]"
      ],
      "metadata": {
        "id": "1klqy-ylyZbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimento\n",
        "experiment = Experiment(\n",
        "    model=model,\n",
        "    train_ds=train_ds,\n",
        "    val_ds=val_ds,\n",
        "    experiment_name=f\"densenet_warm_up\",\n",
        "    batch_size=batch_size,\n",
        "    image_size=image_size\n",
        ")\n",
        "\n",
        "history = experiment.run_experiment(\n",
        "    callbacks=callbacks,\n",
        "    epochs=num_epochs\n",
        ")"
      ],
      "metadata": {
        "id": "5Mo0C8p80JKv",
        "outputId": "8852e10d-7cb1-4735-ef4b-dc386cfd7863",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m914s\u001b[0m 3s/step - accuracy: 0.0029 - auc: 0.5029 - f1_macro: 6.0274e-04 - f1_weighted: 6.1281e-04 - loss: 5.5287 - top5_accuracy: 0.0228 - val_accuracy: 0.0039 - val_auc: 0.5005 - val_f1_macro: 0.0022 - val_f1_weighted: 0.0011 - val_loss: 5.4933 - val_top5_accuracy: 0.0195 - learning_rate: 9.5238e-08\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - accuracy: 0.0255 - auc: 0.5457 - f1_macro: 0.0029 - f1_weighted: 0.0093 - loss: 5.3939 - top5_accuracy: 0.0748 - val_accuracy: 0.0601 - val_auc: 0.6658 - val_f1_macro: 0.0050 - val_f1_weighted: 0.0182 - val_loss: 5.0894 - val_top5_accuracy: 0.1592 - learning_rate: 3.3429e-05\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0548 - auc: 0.6103 - f1_macro: 0.0045 - f1_weighted: 0.0138 - loss: 5.1801 - top5_accuracy: 0.1506 - val_accuracy: 0.0607 - val_auc: 0.6824 - val_f1_macro: 0.0051 - val_f1_weighted: 0.0211 - val_loss: 5.0206 - val_top5_accuracy: 0.1853 - learning_rate: 6.6762e-05\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.0653 - auc: 0.6334 - f1_macro: 0.0066 - f1_weighted: 0.0185 - loss: 5.0706 - top5_accuracy: 0.1692 - val_accuracy: 0.0551 - val_auc: 0.6542 - val_f1_macro: 0.0100 - val_f1_weighted: 0.0279 - val_loss: 5.3862 - val_top5_accuracy: 0.1603 - learning_rate: 1.0010e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.0741 - auc: 0.6490 - f1_macro: 0.0114 - f1_weighted: 0.0248 - loss: 4.9714 - top5_accuracy: 0.1937 - val_accuracy: 0.0490 - val_auc: 0.6506 - val_f1_macro: 0.0116 - val_f1_weighted: 0.0252 - val_loss: 5.5999 - val_top5_accuracy: 0.1503 - learning_rate: 1.3343e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.0825 - auc: 0.6620 - f1_macro: 0.0182 - f1_weighted: 0.0322 - loss: 4.8882 - top5_accuracy: 0.2155 - val_accuracy: 0.0428 - val_auc: 0.6220 - val_f1_macro: 0.0138 - val_f1_weighted: 0.0227 - val_loss: 6.1661 - val_top5_accuracy: 0.1391 - learning_rate: 1.6676e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.0902 - auc: 0.6719 - f1_macro: 0.0257 - f1_weighted: 0.0398 - loss: 4.8196 - top5_accuracy: 0.2301 - val_accuracy: 0.0356 - val_auc: 0.6322 - val_f1_macro: 0.0111 - val_f1_weighted: 0.0192 - val_loss: 5.9598 - val_top5_accuracy: 0.1425 - learning_rate: 2.0010e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.0959 - auc: 0.6786 - f1_macro: 0.0293 - f1_weighted: 0.0449 - loss: 4.7579 - top5_accuracy: 0.2503\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.000116714283649344.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.0959 - auc: 0.6786 - f1_macro: 0.0293 - f1_weighted: 0.0449 - loss: 4.7579 - top5_accuracy: 0.2503 - val_accuracy: 0.0417 - val_auc: 0.6490 - val_f1_macro: 0.0122 - val_f1_weighted: 0.0190 - val_loss: 5.6505 - val_top5_accuracy: 0.1413 - learning_rate: 1.1671e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1005 - auc: 0.6860 - f1_macro: 0.0326 - f1_weighted: 0.0486 - loss: 4.7061 - top5_accuracy: 0.2623 - val_accuracy: 0.0512 - val_auc: 0.6544 - val_f1_macro: 0.0131 - val_f1_weighted: 0.0242 - val_loss: 5.5302 - val_top5_accuracy: 0.1464 - learning_rate: 2.6676e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.1081 - auc: 0.6906 - f1_macro: 0.0387 - f1_weighted: 0.0553 - loss: 4.6662 - top5_accuracy: 0.2777 - val_accuracy: 0.0373 - val_auc: 0.6346 - val_f1_macro: 0.0081 - val_f1_weighted: 0.0158 - val_loss: 5.8196 - val_top5_accuracy: 0.1157 - learning_rate: 3.0010e-04\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# Plotting Training and Validation Accuracy and Loss\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "# Plotting Accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_accuracy, label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "5Rp3z4f51_JB",
        "outputId": "9a36cbc2-968a-49fe-e884-0740b6529dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Tiny com mixup"
      ],
      "metadata": {
        "id": "LyHoJRDu3nJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "num_epochs = 30\n",
        "\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "augment_mode='mixup'\n",
        "\n",
        "# Carregamento dos datasets\n",
        "train_ds, class_names = preprocess.load_img(\n",
        "    data_dir=\"data/rare_species/train\",\n",
        "    minority_class=minority_class,\n",
        "    augment=augment_mode if augment_mode != \"none\" else None,\n",
        "    oversampling=True,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_ds, _ = preprocess.load_img(\n",
        "    data_dir=\"data/rare_species/val\",\n",
        "    minority_class=minority_class,\n",
        "    augment=None,\n",
        "    oversampling=False\n",
        ")\n",
        "\n",
        "\n",
        "steps_per_epoch = len(train_ds)\n",
        "print(f\"Number of batches per epoch: {steps_per_epoch}\")"
      ],
      "metadata": {
        "id": "33KrZ07u4auy",
        "outputId": "0345c78c-d32d-4a26-b6e4-b5b24a03a0e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "Number of batches per epoch: 350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_densenet(\n",
        "        layers_per_block=[4, 8, 12, 8],\n",
        "        growth_rate=12,\n",
        "        compression=0.5,\n",
        "        dropout_rate=0.1,  # Menor dropout para baseline\n",
        "        bottleneck=False)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.0),\n",
        "            metrics=metrics)"
      ],
      "metadata": {
        "id": "9A7oBp_j4fxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimento\n",
        "experiment = Experiment(\n",
        "    model=model,\n",
        "    train_ds=train_ds,\n",
        "    val_ds=val_ds,\n",
        "    experiment_name=f\"densenet_mix_tiny\",\n",
        "    batch_size=batch_size,\n",
        "    image_size=image_size,\n",
        "    save_model=False\n",
        ")\n",
        "\n",
        "history = experiment.run_experiment(\n",
        "    callbacks=callbacks,\n",
        "    epochs=num_epochs\n",
        ")"
      ],
      "metadata": {
        "id": "GulYe_rG43hX",
        "outputId": "9b102437-2115-430b-8ac5-771a31289f7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 168ms/step - accuracy: 0.0513 - auc: 0.6144 - f1_macro: 0.0208 - f1_weighted: 0.0318 - loss: 5.4194 - top5_accuracy: 0.1352 - val_accuracy: 0.0506 - val_auc: 0.6458 - val_f1_macro: 0.0058 - val_f1_weighted: 0.0183 - val_loss: 5.2003 - val_top5_accuracy: 0.1102 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.0588 - auc: 0.6358 - f1_macro: 0.0099 - f1_weighted: 0.0226 - loss: 5.0972 - top5_accuracy: 0.1586 - val_accuracy: 0.0161 - val_auc: 0.5563 - val_f1_macro: 0.0074 - val_f1_weighted: 0.0108 - val_loss: 6.9901 - val_top5_accuracy: 0.0668 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0698 - auc: 0.6577 - f1_macro: 0.0151 - f1_weighted: 0.0294 - loss: 4.9684 - top5_accuracy: 0.1845 - val_accuracy: 0.0278 - val_auc: 0.5969 - val_f1_macro: 0.0092 - val_f1_weighted: 0.0144 - val_loss: 6.7317 - val_top5_accuracy: 0.0913 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.0767 - auc: 0.6705 - f1_macro: 0.0207 - f1_weighted: 0.0353 - loss: 4.8834 - top5_accuracy: 0.2033 - val_accuracy: 0.0423 - val_auc: 0.6552 - val_f1_macro: 0.0157 - val_f1_weighted: 0.0301 - val_loss: 5.3970 - val_top5_accuracy: 0.1363 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.0809 - auc: 0.6794 - f1_macro: 0.0231 - f1_weighted: 0.0377 - loss: 4.8194 - top5_accuracy: 0.2234 - val_accuracy: 0.0451 - val_auc: 0.6372 - val_f1_macro: 0.0114 - val_f1_weighted: 0.0302 - val_loss: 5.6015 - val_top5_accuracy: 0.1402 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.0876 - auc: 0.6857 - f1_macro: 0.0287 - f1_weighted: 0.0434 - loss: 4.7639 - top5_accuracy: 0.2375\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.0876 - auc: 0.6857 - f1_macro: 0.0287 - f1_weighted: 0.0434 - loss: 4.7638 - top5_accuracy: 0.2375 - val_accuracy: 0.0684 - val_auc: 0.6669 - val_f1_macro: 0.0186 - val_f1_weighted: 0.0402 - val_loss: 5.2685 - val_top5_accuracy: 0.1608 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1099 - auc: 0.6966 - f1_macro: 0.0392 - f1_weighted: 0.0566 - loss: 4.6540 - top5_accuracy: 0.2712 - val_accuracy: 0.0751 - val_auc: 0.6955 - val_f1_macro: 0.0209 - val_f1_weighted: 0.0430 - val_loss: 5.1032 - val_top5_accuracy: 0.1925 - learning_rate: 5.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1212 - auc: 0.7032 - f1_macro: 0.0493 - f1_weighted: 0.0668 - loss: 4.5783 - top5_accuracy: 0.2977 - val_accuracy: 0.0662 - val_auc: 0.6703 - val_f1_macro: 0.0179 - val_f1_weighted: 0.0394 - val_loss: 5.4521 - val_top5_accuracy: 0.1786 - learning_rate: 5.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.1292 - auc: 0.7067 - f1_macro: 0.0561 - f1_weighted: 0.0746 - loss: 4.5247 - top5_accuracy: 0.3129 - val_accuracy: 0.0679 - val_auc: 0.6757 - val_f1_macro: 0.0189 - val_f1_weighted: 0.0409 - val_loss: 5.4214 - val_top5_accuracy: 0.1825 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.1418 - auc: 0.7114 - f1_macro: 0.0667 - f1_weighted: 0.0857 - loss: 4.4696 - top5_accuracy: 0.3304 - val_accuracy: 0.0657 - val_auc: 0.6756 - val_f1_macro: 0.0185 - val_f1_weighted: 0.0396 - val_loss: 5.4288 - val_top5_accuracy: 0.1825 - learning_rate: 5.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1537 - auc: 0.7154 - f1_macro: 0.0766 - f1_weighted: 0.0960 - loss: 4.4194 - top5_accuracy: 0.3511 - val_accuracy: 0.0623 - val_auc: 0.6712 - val_f1_macro: 0.0180 - val_f1_weighted: 0.0368 - val_loss: 5.5091 - val_top5_accuracy: 0.1764 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.1595 - auc: 0.7206 - f1_macro: 0.0837 - f1_weighted: 0.1020 - loss: 4.3676 - top5_accuracy: 0.3686\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1595 - auc: 0.7206 - f1_macro: 0.0838 - f1_weighted: 0.1020 - loss: 4.3675 - top5_accuracy: 0.3686 - val_accuracy: 0.0690 - val_auc: 0.6828 - val_f1_macro: 0.0255 - val_f1_weighted: 0.0478 - val_loss: 5.3813 - val_top5_accuracy: 0.1892 - learning_rate: 5.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1820 - auc: 0.7246 - f1_macro: 0.0994 - f1_weighted: 0.1190 - loss: 4.2900 - top5_accuracy: 0.3949 - val_accuracy: 0.0885 - val_auc: 0.7310 - val_f1_macro: 0.0468 - val_f1_weighted: 0.0706 - val_loss: 4.9746 - val_top5_accuracy: 0.2309 - learning_rate: 2.5000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1916 - auc: 0.7286 - f1_macro: 0.1102 - f1_weighted: 0.1293 - loss: 4.2324 - top5_accuracy: 0.4135 - val_accuracy: 0.0890 - val_auc: 0.7321 - val_f1_macro: 0.0481 - val_f1_weighted: 0.0709 - val_loss: 4.9874 - val_top5_accuracy: 0.2215 - learning_rate: 2.5000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.2044 - auc: 0.7327 - f1_macro: 0.1198 - f1_weighted: 0.1390 - loss: 4.1849 - top5_accuracy: 0.4353 - val_accuracy: 0.0885 - val_auc: 0.7239 - val_f1_macro: 0.0470 - val_f1_weighted: 0.0702 - val_loss: 5.0817 - val_top5_accuracy: 0.2270 - learning_rate: 2.5000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.2140 - auc: 0.7358 - f1_macro: 0.1287 - f1_weighted: 0.1475 - loss: 4.1390 - top5_accuracy: 0.4489 - val_accuracy: 0.0952 - val_auc: 0.7285 - val_f1_macro: 0.0494 - val_f1_weighted: 0.0771 - val_loss: 5.0659 - val_top5_accuracy: 0.2359 - learning_rate: 2.5000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.2219 - auc: 0.7383 - f1_macro: 0.1362 - f1_weighted: 0.1549 - loss: 4.1034 - top5_accuracy: 0.4646 - val_accuracy: 0.0991 - val_auc: 0.7368 - val_f1_macro: 0.0513 - val_f1_weighted: 0.0801 - val_loss: 4.9885 - val_top5_accuracy: 0.2432 - learning_rate: 2.5000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.2358 - auc: 0.7412 - f1_macro: 0.1466 - f1_weighted: 0.1661 - loss: 4.0585 - top5_accuracy: 0.4756 - val_accuracy: 0.1068 - val_auc: 0.7486 - val_f1_macro: 0.0513 - val_f1_weighted: 0.0897 - val_loss: 4.8786 - val_top5_accuracy: 0.2521 - learning_rate: 2.5000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.2445 - auc: 0.7432 - f1_macro: 0.1549 - f1_weighted: 0.1754 - loss: 4.0221 - top5_accuracy: 0.4919 - val_accuracy: 0.0996 - val_auc: 0.7508 - val_f1_macro: 0.0512 - val_f1_weighted: 0.0833 - val_loss: 4.8834 - val_top5_accuracy: 0.2515 - learning_rate: 2.5000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.2557 - auc: 0.7438 - f1_macro: 0.1667 - f1_weighted: 0.1852 - loss: 3.9836 - top5_accuracy: 0.5056 - val_accuracy: 0.0913 - val_auc: 0.7353 - val_f1_macro: 0.0461 - val_f1_weighted: 0.0726 - val_loss: 5.0722 - val_top5_accuracy: 0.2398 - learning_rate: 2.5000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.2645 - auc: 0.7472 - f1_macro: 0.1747 - f1_weighted: 0.1927 - loss: 3.9425 - top5_accuracy: 0.5161 - val_accuracy: 0.0996 - val_auc: 0.7403 - val_f1_macro: 0.0511 - val_f1_weighted: 0.0834 - val_loss: 4.9678 - val_top5_accuracy: 0.2504 - learning_rate: 2.5000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.2761 - auc: 0.7490 - f1_macro: 0.1858 - f1_weighted: 0.2045 - loss: 3.9032 - top5_accuracy: 0.5273 - val_accuracy: 0.1002 - val_auc: 0.7407 - val_f1_macro: 0.0557 - val_f1_weighted: 0.0839 - val_loss: 5.0034 - val_top5_accuracy: 0.2632 - learning_rate: 2.5000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.2862 - auc: 0.7524 - f1_macro: 0.1923 - f1_weighted: 0.2114 - loss: 3.8645 - top5_accuracy: 0.5400\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.2862 - auc: 0.7524 - f1_macro: 0.1923 - f1_weighted: 0.2114 - loss: 3.8644 - top5_accuracy: 0.5400 - val_accuracy: 0.1041 - val_auc: 0.7462 - val_f1_macro: 0.0610 - val_f1_weighted: 0.0910 - val_loss: 4.9231 - val_top5_accuracy: 0.2654 - learning_rate: 2.5000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.3093 - auc: 0.7540 - f1_macro: 0.2114 - f1_weighted: 0.2300 - loss: 3.8173 - top5_accuracy: 0.5633 - val_accuracy: 0.1252 - val_auc: 0.7795 - val_f1_macro: 0.0731 - val_f1_weighted: 0.1056 - val_loss: 4.6132 - val_top5_accuracy: 0.2949 - learning_rate: 1.2500e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.3188 - auc: 0.7563 - f1_macro: 0.2231 - f1_weighted: 0.2397 - loss: 3.7768 - top5_accuracy: 0.5749 - val_accuracy: 0.1302 - val_auc: 0.7784 - val_f1_macro: 0.0834 - val_f1_weighted: 0.1148 - val_loss: 4.6253 - val_top5_accuracy: 0.2994 - learning_rate: 1.2500e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.3222 - auc: 0.7587 - f1_macro: 0.2237 - f1_weighted: 0.2413 - loss: 3.7439 - top5_accuracy: 0.5913 - val_accuracy: 0.1297 - val_auc: 0.7815 - val_f1_macro: 0.0803 - val_f1_weighted: 0.1114 - val_loss: 4.6232 - val_top5_accuracy: 0.3044 - learning_rate: 1.2500e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.3309 - auc: 0.7595 - f1_macro: 0.2328 - f1_weighted: 0.2506 - loss: 3.7172 - top5_accuracy: 0.5960 - val_accuracy: 0.1363 - val_auc: 0.7812 - val_f1_macro: 0.0829 - val_f1_weighted: 0.1175 - val_loss: 4.5964 - val_top5_accuracy: 0.3072 - learning_rate: 1.2500e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.3418 - auc: 0.7613 - f1_macro: 0.2422 - f1_weighted: 0.2593 - loss: 3.6861 - top5_accuracy: 0.6056 - val_accuracy: 0.1380 - val_auc: 0.7837 - val_f1_macro: 0.0840 - val_f1_weighted: 0.1197 - val_loss: 4.5873 - val_top5_accuracy: 0.3166 - learning_rate: 1.2500e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 73ms/step - accuracy: 0.3449 - auc: 0.7619 - f1_macro: 0.2431 - f1_weighted: 0.2614 - loss: 3.6605 - top5_accuracy: 0.6158 - val_accuracy: 0.1402 - val_auc: 0.7783 - val_f1_macro: 0.0882 - val_f1_weighted: 0.1229 - val_loss: 4.6398 - val_top5_accuracy: 0.3055 - learning_rate: 1.2500e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.3552 - auc: 0.7638 - f1_macro: 0.2535 - f1_weighted: 0.2703 - loss: 3.6333 - top5_accuracy: 0.6277 - val_accuracy: 0.1475 - val_auc: 0.7815 - val_f1_macro: 0.0986 - val_f1_weighted: 0.1295 - val_loss: 4.6240 - val_top5_accuracy: 0.3161 - learning_rate: 1.2500e-04\n",
            "Restoring model weights from the end of the best epoch: 28.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# Plotting Training and Validation Accuracy and Loss\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "# Plotting Accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_accuracy, label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "BB1RL5qi4-Hh",
        "outputId": "81d732aa-3b30-45fe-e24c-d4a4b01da614",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('dense_tiny_mix.h5')"
      ],
      "metadata": {
        "id": "jM9vUTFOjhzs",
        "outputId": "e2943672-4c5d-4abe-c979-74c32110d834",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Increasing DropOut"
      ],
      "metadata": {
        "id": "p4SY0Y1C3rAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_densenet(\n",
        "        layers_per_block=[4, 8, 12, 8],\n",
        "        growth_rate=12,\n",
        "        compression=0.5,\n",
        "        dropout_rate=0.3,\n",
        "        bottleneck=False)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.0),\n",
        "            metrics=metrics)"
      ],
      "metadata": {
        "id": "rZwLV98a59eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimento\n",
        "experiment = Experiment(\n",
        "    model=model,\n",
        "    train_ds=train_ds,\n",
        "    val_ds=val_ds,\n",
        "    experiment_name=f\"densenet_mix_tiny_drop03\",\n",
        "    batch_size=batch_size,\n",
        "    image_size=image_size,\n",
        "    save_model=False\n",
        ")\n",
        "\n",
        "history = experiment.run_experiment(\n",
        "    callbacks=callbacks,\n",
        "    epochs=num_epochs\n",
        ")"
      ],
      "metadata": {
        "id": "SjepIREeke8K",
        "outputId": "2ee55949-5b70-414e-cd40-b342c997efe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 114ms/step - accuracy: 0.0709 - auc: 0.6324 - f1_macro: 0.0408 - f1_weighted: 0.0523 - loss: 5.4136 - top5_accuracy: 0.1707 - val_accuracy: 0.0501 - val_auc: 0.6580 - val_f1_macro: 0.0046 - val_f1_weighted: 0.0145 - val_loss: 5.1386 - val_top5_accuracy: 0.1575 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.0549 - auc: 0.6340 - f1_macro: 0.0075 - f1_weighted: 0.0200 - loss: 5.1190 - top5_accuracy: 0.1556 - val_accuracy: 0.0479 - val_auc: 0.6720 - val_f1_macro: 0.0066 - val_f1_weighted: 0.0228 - val_loss: 5.1145 - val_top5_accuracy: 0.1603 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.0641 - auc: 0.6574 - f1_macro: 0.0121 - f1_weighted: 0.0260 - loss: 4.9895 - top5_accuracy: 0.1783 - val_accuracy: 0.0595 - val_auc: 0.7119 - val_f1_macro: 0.0130 - val_f1_weighted: 0.0318 - val_loss: 4.9155 - val_top5_accuracy: 0.1848 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.0700 - auc: 0.6677 - f1_macro: 0.0167 - f1_weighted: 0.0310 - loss: 4.9126 - top5_accuracy: 0.1986 - val_accuracy: 0.0195 - val_auc: 0.5967 - val_f1_macro: 0.0098 - val_f1_weighted: 0.0154 - val_loss: 6.1785 - val_top5_accuracy: 0.1041 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.0776 - auc: 0.6762 - f1_macro: 0.0194 - f1_weighted: 0.0353 - loss: 4.8522 - top5_accuracy: 0.2160 - val_accuracy: 0.0401 - val_auc: 0.6859 - val_f1_macro: 0.0129 - val_f1_weighted: 0.0283 - val_loss: 5.0841 - val_top5_accuracy: 0.1341 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.0839 - auc: 0.6824 - f1_macro: 0.0250 - f1_weighted: 0.0410 - loss: 4.8006 - top5_accuracy: 0.2179 - val_accuracy: 0.0445 - val_auc: 0.6665 - val_f1_macro: 0.0164 - val_f1_weighted: 0.0323 - val_loss: 5.1921 - val_top5_accuracy: 0.1375 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.0935 - auc: 0.6873 - f1_macro: 0.0298 - f1_weighted: 0.0470 - loss: 4.7522 - top5_accuracy: 0.2339 - val_accuracy: 0.0417 - val_auc: 0.6402 - val_f1_macro: 0.0166 - val_f1_weighted: 0.0261 - val_loss: 6.2039 - val_top5_accuracy: 0.1263 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.1025 - auc: 0.6909 - f1_macro: 0.0353 - f1_weighted: 0.0532 - loss: 4.6995 - top5_accuracy: 0.2511\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.1025 - auc: 0.6909 - f1_macro: 0.0353 - f1_weighted: 0.0532 - loss: 4.6994 - top5_accuracy: 0.2511 - val_accuracy: 0.0573 - val_auc: 0.6494 - val_f1_macro: 0.0182 - val_f1_weighted: 0.0378 - val_loss: 5.7484 - val_top5_accuracy: 0.1514 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1181 - auc: 0.7002 - f1_macro: 0.0474 - f1_weighted: 0.0646 - loss: 4.5933 - top5_accuracy: 0.2893 - val_accuracy: 0.0940 - val_auc: 0.7290 - val_f1_macro: 0.0344 - val_f1_weighted: 0.0612 - val_loss: 4.8082 - val_top5_accuracy: 0.2159 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1289 - auc: 0.7048 - f1_macro: 0.0553 - f1_weighted: 0.0737 - loss: 4.5343 - top5_accuracy: 0.3130 - val_accuracy: 0.0857 - val_auc: 0.7269 - val_f1_macro: 0.0311 - val_f1_weighted: 0.0551 - val_loss: 4.8607 - val_top5_accuracy: 0.1998 - learning_rate: 5.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.1355 - auc: 0.7082 - f1_macro: 0.0614 - f1_weighted: 0.0798 - loss: 4.4878 - top5_accuracy: 0.3244 - val_accuracy: 0.0840 - val_auc: 0.7205 - val_f1_macro: 0.0329 - val_f1_weighted: 0.0593 - val_loss: 4.9198 - val_top5_accuracy: 0.2104 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1516 - auc: 0.7125 - f1_macro: 0.0733 - f1_weighted: 0.0923 - loss: 4.4401 - top5_accuracy: 0.3446 - val_accuracy: 0.0718 - val_auc: 0.6931 - val_f1_macro: 0.0312 - val_f1_weighted: 0.0526 - val_loss: 5.2229 - val_top5_accuracy: 0.1697 - learning_rate: 5.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1567 - auc: 0.7174 - f1_macro: 0.0780 - f1_weighted: 0.0967 - loss: 4.3943 - top5_accuracy: 0.3565 - val_accuracy: 0.0740 - val_auc: 0.6860 - val_f1_macro: 0.0293 - val_f1_weighted: 0.0480 - val_loss: 5.3401 - val_top5_accuracy: 0.1720 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.1661 - auc: 0.7204 - f1_macro: 0.0872 - f1_weighted: 0.1055 - loss: 4.3532 - top5_accuracy: 0.3732\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1661 - auc: 0.7204 - f1_macro: 0.0873 - f1_weighted: 0.1056 - loss: 4.3531 - top5_accuracy: 0.3732 - val_accuracy: 0.0579 - val_auc: 0.6710 - val_f1_macro: 0.0264 - val_f1_weighted: 0.0451 - val_loss: 5.5905 - val_top5_accuracy: 0.1725 - learning_rate: 5.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.1782 - auc: 0.7263 - f1_macro: 0.0996 - f1_weighted: 0.1162 - loss: 4.2882 - top5_accuracy: 0.3957 - val_accuracy: 0.1341 - val_auc: 0.7829 - val_f1_macro: 0.0734 - val_f1_weighted: 0.1071 - val_loss: 4.4782 - val_top5_accuracy: 0.2922 - learning_rate: 2.5000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.1901 - auc: 0.7290 - f1_macro: 0.1085 - f1_weighted: 0.1261 - loss: 4.2282 - top5_accuracy: 0.4161 - val_accuracy: 0.1297 - val_auc: 0.7787 - val_f1_macro: 0.0694 - val_f1_weighted: 0.1047 - val_loss: 4.4903 - val_top5_accuracy: 0.2866 - learning_rate: 2.5000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.2027 - auc: 0.7319 - f1_macro: 0.1183 - f1_weighted: 0.1355 - loss: 4.1931 - top5_accuracy: 0.4243 - val_accuracy: 0.1302 - val_auc: 0.7813 - val_f1_macro: 0.0735 - val_f1_weighted: 0.1080 - val_loss: 4.4959 - val_top5_accuracy: 0.2972 - learning_rate: 2.5000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.2063 - auc: 0.7346 - f1_macro: 0.1216 - f1_weighted: 0.1396 - loss: 4.1606 - top5_accuracy: 0.4371 - val_accuracy: 0.1319 - val_auc: 0.7854 - val_f1_macro: 0.0747 - val_f1_weighted: 0.1063 - val_loss: 4.4606 - val_top5_accuracy: 0.3016 - learning_rate: 2.5000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.2133 - auc: 0.7370 - f1_macro: 0.1261 - f1_weighted: 0.1445 - loss: 4.1187 - top5_accuracy: 0.4511 - val_accuracy: 0.1230 - val_auc: 0.7807 - val_f1_macro: 0.0686 - val_f1_weighted: 0.1004 - val_loss: 4.4938 - val_top5_accuracy: 0.2988 - learning_rate: 2.5000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.2263 - auc: 0.7383 - f1_macro: 0.1384 - f1_weighted: 0.1570 - loss: 4.0923 - top5_accuracy: 0.4607 - val_accuracy: 0.1352 - val_auc: 0.7793 - val_f1_macro: 0.0773 - val_f1_weighted: 0.1121 - val_loss: 4.5022 - val_top5_accuracy: 0.3050 - learning_rate: 2.5000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.2331 - auc: 0.7426 - f1_macro: 0.1437 - f1_weighted: 0.1626 - loss: 4.0566 - top5_accuracy: 0.4757 - val_accuracy: 0.1191 - val_auc: 0.7813 - val_f1_macro: 0.0659 - val_f1_weighted: 0.0967 - val_loss: 4.5125 - val_top5_accuracy: 0.3077 - learning_rate: 2.5000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.2398 - auc: 0.7431 - f1_macro: 0.1512 - f1_weighted: 0.1702 - loss: 4.0312 - top5_accuracy: 0.4765 - val_accuracy: 0.1196 - val_auc: 0.7767 - val_f1_macro: 0.0656 - val_f1_weighted: 0.0924 - val_loss: 4.5575 - val_top5_accuracy: 0.3088 - learning_rate: 2.5000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.2507 - auc: 0.7429 - f1_macro: 0.1585 - f1_weighted: 0.1786 - loss: 4.0018 - top5_accuracy: 0.4857\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.2507 - auc: 0.7429 - f1_macro: 0.1586 - f1_weighted: 0.1787 - loss: 4.0017 - top5_accuracy: 0.4857 - val_accuracy: 0.1219 - val_auc: 0.7784 - val_f1_macro: 0.0714 - val_f1_weighted: 0.0983 - val_loss: 4.5314 - val_top5_accuracy: 0.3150 - learning_rate: 2.5000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.2585 - auc: 0.7455 - f1_macro: 0.1682 - f1_weighted: 0.1869 - loss: 3.9582 - top5_accuracy: 0.5077 - val_accuracy: 0.1380 - val_auc: 0.7921 - val_f1_macro: 0.0719 - val_f1_weighted: 0.1073 - val_loss: 4.4430 - val_top5_accuracy: 0.3283 - learning_rate: 1.2500e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.2696 - auc: 0.7484 - f1_macro: 0.1760 - f1_weighted: 0.1958 - loss: 3.9264 - top5_accuracy: 0.5238 - val_accuracy: 0.1408 - val_auc: 0.7920 - val_f1_macro: 0.0717 - val_f1_weighted: 0.1105 - val_loss: 4.4242 - val_top5_accuracy: 0.3267 - learning_rate: 1.2500e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.2766 - auc: 0.7504 - f1_macro: 0.1831 - f1_weighted: 0.2031 - loss: 3.8939 - top5_accuracy: 0.5299 - val_accuracy: 0.1363 - val_auc: 0.7889 - val_f1_macro: 0.0703 - val_f1_weighted: 0.1064 - val_loss: 4.4407 - val_top5_accuracy: 0.3255 - learning_rate: 1.2500e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 74ms/step - accuracy: 0.2775 - auc: 0.7506 - f1_macro: 0.1849 - f1_weighted: 0.2042 - loss: 3.8791 - top5_accuracy: 0.5407 - val_accuracy: 0.1464 - val_auc: 0.7883 - val_f1_macro: 0.0764 - val_f1_weighted: 0.1165 - val_loss: 4.4673 - val_top5_accuracy: 0.3239 - learning_rate: 1.2500e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.2812 - auc: 0.7519 - f1_macro: 0.1860 - f1_weighted: 0.2062 - loss: 3.8574 - top5_accuracy: 0.5449 - val_accuracy: 0.1508 - val_auc: 0.7937 - val_f1_macro: 0.0795 - val_f1_weighted: 0.1188 - val_loss: 4.4188 - val_top5_accuracy: 0.3350 - learning_rate: 1.2500e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.2876 - auc: 0.7531 - f1_macro: 0.1926 - f1_weighted: 0.2111 - loss: 3.8399 - top5_accuracy: 0.5533 - val_accuracy: 0.1408 - val_auc: 0.7895 - val_f1_macro: 0.0746 - val_f1_weighted: 0.1118 - val_loss: 4.4729 - val_top5_accuracy: 0.3283 - learning_rate: 1.2500e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 76ms/step - accuracy: 0.2973 - auc: 0.7541 - f1_macro: 0.2005 - f1_weighted: 0.2200 - loss: 3.8167 - top5_accuracy: 0.5624 - val_accuracy: 0.1386 - val_auc: 0.7896 - val_f1_macro: 0.0718 - val_f1_weighted: 0.1103 - val_loss: 4.4801 - val_top5_accuracy: 0.3250 - learning_rate: 1.2500e-04\n",
            "Restoring model weights from the end of the best epoch: 28.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# Plotting Training and Validation Accuracy and Loss\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "# Plotting Accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_accuracy, label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "PG7ihRQ3ny_K",
        "outputId": "c7ce8737-e4d0-4696-e101-a4a18c7bffce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "xK-Zlw--n5nD",
        "outputId": "2dcad951-ef61-4363-a3f7-672a26b822f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperband tunner - DenseNet"
      ],
      "metadata": {
        "id": "QB0WGF52nrxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing:\n",
        "- Drop out (different percentages)\n",
        "- Growth rate\n",
        "- Compression\n",
        "- l2 weights\n",
        "- Activation function"
      ],
      "metadata": {
        "id": "TvhFd-pIju9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dense_layer(x, growth_rate, dropout_rate, bottleneck):\n",
        "    # ‑‑ Optionally add a 1×1 bottleneck (DenseNet‑B)\n",
        "    if bottleneck:\n",
        "        x1 = BatchNormalization()(x)\n",
        "        x1 = ReLU()(x1)\n",
        "        x1 = Conv2D(4 * growth_rate, (1, 1), padding='same',\n",
        "                    kernel_regularizer=l2(1e-4))(x1)\n",
        "        x1 = BatchNormalization()(x1)\n",
        "        x1 = ReLU()(x1)\n",
        "        x1 = Conv2D(growth_rate, (3, 3), padding='same',\n",
        "                    kernel_regularizer=l2(1e-4))(x1)\n",
        "    else:\n",
        "        x1 = BatchNormalization()(x)\n",
        "        x1 = ReLU()(x1)\n",
        "        x1 = Conv2D(growth_rate, (3, 3), padding='same',\n",
        "                    kernel_regularizer=l2(1e-4))(x1)\n",
        "\n",
        "    if dropout_rate:                    # dropout depois do conv\n",
        "        x1 = Dropout(dropout_rate)(x1)\n",
        "    return Concatenate()([x, x1])       # dense connection\n",
        "\n",
        "\n",
        "def dense_block(x, n_layers, growth_rate, dropout_rate, bottleneck):\n",
        "    for _ in range(n_layers):\n",
        "        x = dense_layer(x, growth_rate, dropout_rate, bottleneck)\n",
        "    return x\n",
        "\n",
        "\n",
        "def transition_layer(x, compression, dropout_rate):\n",
        "    filters = int(tf.keras.backend.int_shape(x)[-1] * compression)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(filters, (1, 1), padding='same',\n",
        "               kernel_regularizer=l2(1e-4))(x)\n",
        "    if dropout_rate:\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "    return AveragePooling2D((2, 2), strides=2)(x)\n",
        "\n",
        "\n",
        "def build_densenet(input_shape=(224, 224, 3),\n",
        "                   num_classes=202,\n",
        "                   layers_per_block=(6, 12, 24, 16),\n",
        "                   growth_rate=32,\n",
        "                   compression=0.5,\n",
        "                   bottleneck=True,\n",
        "                   dropout_rate=0.3):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Stem\n",
        "    x = Conv2D(64, (7, 7), strides=2, padding='same',\n",
        "               kernel_regularizer=l2(1e-4))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = AveragePooling2D((3, 3), strides=2, padding='same')(x)\n",
        "\n",
        "    # Dense blocks\n",
        "    for i, n_layers in enumerate(layers_per_block):\n",
        "        x = dense_block(x, n_layers, growth_rate, dropout_rate, bottleneck)\n",
        "        if i != len(layers_per_block) - 1:          # no transition after last\n",
        "            x = transition_layer(x, compression, dropout_rate)\n",
        "\n",
        "    # Classifier\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    return Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "X46ZDi-CAYKK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras_tuner"
      ],
      "metadata": {
        "id": "IKVHW4xpAtel",
        "outputId": "861f7ea9-c35c-4463-bc36-ff29f541d42f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras_tuner) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras_tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras_tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_tuner import Hyperband, Objective"
      ],
      "metadata": {
        "id": "F13bTR-NkccH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define OverfitStopper callback\n",
        "class OverfitStopper(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, threshold=0.1):\n",
        "        super().__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        train_f1 = logs.get(\"f1_macro\")  # adjust if your training metric has another name\n",
        "        val_f1 = logs.get(\"val_f1_macro\")\n",
        "        if train_f1 is not None and val_f1 is not None:\n",
        "            gap = train_f1 - val_f1\n",
        "            if gap > self.threshold:\n",
        "                print(f\"[Early stop] Overfitting detected: train_f1={train_f1:.3f}, val_f1={val_f1:.3f}\")\n",
        "                self.model.stop_training = True"
      ],
      "metadata": {
        "id": "CggMxPqgeSJ6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model builder\n",
        "def build_model_tiny_densenet(hp):\n",
        "    learning_rate = hp.Choice(\"learning_rate\", [1e-4, 5e-5])\n",
        "    l2_weight = hp.Choice(\"l2_weight\", [1e-5, 1e-4, 5e-4])\n",
        "    growth_rate = hp.Choice('growth_rate', [])\n",
        "    compression = hp.Choice('compression', [])\n",
        "    head_activation = hp.Choice(\"head_activation\", [\"relu\", \"leaky_relu\"])\n",
        "    dropout_rate = hp.Choice(\"dropout_rate\", [0.3, 0.4, 0.5])\n",
        "\n",
        "      \"DenseNet-S\": lambda: build_densenet(\n",
        "        layers_per_block=[6, 12, 24, 16],\n",
        "        growth_rate=12,\n",
        "        compression=0.5,\n",
        "        dropout_rate=0.1,\n",
        "        bottleneck=True\n",
        "    )\n",
        "\n",
        "    model = build_resnet18(\n",
        "        num_blocks=num_blocks,\n",
        "        l2_weight=l2_weight,\n",
        "        head_units=head_units,\n",
        "        head_activation=head_activation,\n",
        "        dropout_rate=dropout_rate\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.01),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "3up1ivrbkS85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model builder\n",
        "def build_model_S_densenet(hp):\n",
        "    growth_rate = hp.Choice('growth_rate', [12, 24, 32])\n",
        "    compression = hp.Choice('compression', [0.5, 0.7, 1.0])\n",
        "    dropout_rate = hp.Float('dropout_rate', 0.1, 0.5, step=0.1)\n",
        "    learning_rate = hp.Float('lr', 1e-5, 1e-2, sampling='log')\n",
        "    use_extra_dense = hp.Boolean('use_extra_dense')\n",
        "    head_activation = hp.Choice(\"head_activation\", [\"relu\", \"leaky_relu\"])\n",
        "\n",
        "    print(f\"[HP] growth_rate={growth_rate}, compression={compression}, dropout={dropout_rate}, \"\n",
        "          f\"lr={learning_rate}, extra_dense={use_extra_dense}, activation={head_activation}\")\n",
        "\n",
        "    base_model = build_densenet(\n",
        "        layers_per_block=[6, 12, 24, 16],\n",
        "        growth_rate=growth_rate,\n",
        "        compression=compression,\n",
        "        dropout_rate=dropout_rate,\n",
        "        bottleneck=True\n",
        "    )\n",
        "\n",
        "    inputs = keras.Input(shape=(224, 224, 3))\n",
        "    x = base_model(inputs, training=True)\n",
        "\n",
        "    # Head com ativação escolhida\n",
        "\n",
        "    if use_extra_dense:\n",
        "        x = layers.Dense(256)(x)\n",
        "        if head_activation == 'leaky_relu':\n",
        "            x = layers.LeakyReLU()(x)\n",
        "        else:\n",
        "            x = layers.ReLU()(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)  # regularização também aqui\n",
        "\n",
        "    outputs = layers.Dense(202, activation=\"softmax\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "im8ZFVOqEumx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom tuner with augmentation and overfit control\n",
        "class MyAugTuner(Hyperband):\n",
        "    def run_trial(self, trial, *args, **kwargs):\n",
        "        hp = trial.hyperparameters\n",
        "        aug = \"mixup\"\n",
        "        oversample = True\n",
        "\n",
        "        train_ds, _ = preprocess.load_img(\n",
        "            data_dir=\"data/rare_species/train\",\n",
        "            minority_class=minority_class,\n",
        "            augment=aug,\n",
        "            oversampling=oversample,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        val_ds, _ = preprocess.load_img(\n",
        "            data_dir=\"data/rare_species/val\",\n",
        "            minority_class=minority_class,\n",
        "            augment=None,\n",
        "            oversampling=False\n",
        "        )\n",
        "\n",
        "        model = build_model_S_densenet(hp)\n",
        "        epochs = trial.hyperparameters.get('tuner/epochs')\n",
        "\n",
        "        return model.fit(\n",
        "            train_ds,\n",
        "            validation_data=val_ds,\n",
        "            callbacks=callbacks,\n",
        "            epochs=epochs,\n",
        "            verbose=1\n",
        "        )"
      ],
      "metadata": {
        "id": "QCJ1pvFM_Fn9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "callbacks = callbacks + [OverfitStopper()]\n",
        "\n",
        "# Tuner\n",
        "tuner = MyAugTuner(\n",
        "    hypermodel=build_model_S_densenet,\n",
        "    objective=Objective(\"val_f1_macro\", direction=\"max\"),\n",
        "    max_epochs=20,\n",
        "    factor=3,\n",
        "    directory=\"tuner_dir\",\n",
        "    project_name=\"densenet_S_mixup_control_overfit\"\n",
        ")\n",
        "\n",
        "# Search\n",
        "tuner.search(callbacks=callbacks)"
      ],
      "metadata": {
        "id": "55GUeicY_UO1",
        "outputId": "50aeee37-ca8d-414a-9e42-125a8490cfb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 15 Complete [00h 11m 59s]\n",
            "val_f1_macro: 0.0017770847771316767\n",
            "\n",
            "Best val_f1_macro So Far: 0.0017770847771316767\n",
            "Total elapsed time: 02h 43m 02s\n",
            "\n",
            "Search: Running Trial #16\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "12                |12                |growth_rate\n",
            "0.7               |1                 |compression\n",
            "0.1               |0.3               |dropout_rate\n",
            "0.0098992         |2.0807e-05        |lr\n",
            "False             |False             |use_extra_dense\n",
            "relu              |relu              |head_activation\n",
            "7                 |7                 |tuner/epochs\n",
            "3                 |3                 |tuner/initial_epoch\n",
            "2                 |2                 |tuner/bracket\n",
            "1                 |1                 |tuner/round\n",
            "0000              |0009              |tuner/trial_id\n",
            "\n",
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n",
            "[HP] growth_rate=12, compression=0.7, dropout=0.1, lr=0.009899233148540992, extra_dense=False, activation=relu\n",
            "Epoch 1/7\n",
            "\u001b[1m237/350\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 198ms/step - accuracy: 0.0240 - auc: 0.5629 - f1_macro: 9.6757e-04 - f1_weighted: 0.0042 - loss: 5.3617 - top5_accuracy: 0.0945"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the top N trials and print their results\n",
        "top_n = 10\n",
        "top_hps = tuner.get_best_hyperparameters(top_n)\n",
        "\n",
        "for i, hp in enumerate(top_hps):\n",
        "    matched_trial = None\n",
        "    for trial in tuner.oracle.trials.values():\n",
        "        if trial.hyperparameters.values == hp.values:\n",
        "            matched_trial = trial\n",
        "            break\n",
        "\n",
        "    if matched_trial is None:\n",
        "        print(f\"\\n No trial found for top {i+1}\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n🔹 Top {i+1} trial (Score: {matched_trial.score:.4f}):\")\n",
        "\n",
        "    print(\"  Growth Rate:\", hp.get(\"growth_rate\"))\n",
        "    print(\"  Compression:\", hp.get(\"compression\"))\n",
        "    print(\"  Dropout Rate:\", hp.get(\"dropout_rate\"))\n",
        "    print(\"  Learning Rate:\", hp.get(\"lr\"))\n",
        "    print(\"  Extra Dense:\", hp.get(\"use_extra_dense\"))\n",
        "    print(\"  Head Activation:\", hp.get(\"head_activation\"))\n"
      ],
      "metadata": {
        "id": "ihVvk0DeAEtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet S - trial 30 epochs"
      ],
      "metadata": {
        "id": "fxNzSLJqoKgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=build_densenet(\n",
        "    layers_per_block=[6, 12, 24, 16],\n",
        "    growth_rate=12,\n",
        "    compression=1,\n",
        "    dropout_rate=0.3,\n",
        "    bottleneck=True\n",
        ")\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2.0807e-05),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.0),\n",
        "        metrics=metrics)"
      ],
      "metadata": {
        "id": "d7H6ptKBoJiV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparâmetros\n",
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "num_epochs = 30\n",
        "augment_mode = \"mixup\"\n",
        "\n",
        "# Preprocessador\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "all_results = []\n",
        "\n",
        "\n",
        "# Carregamento dos datasets\n",
        "train_ds, class_names = preprocess.load_img(\n",
        "    data_dir=\"data/rare_species/train\",\n",
        "    minority_class=minority_class,\n",
        "    augment=augment_mode if augment_mode != \"none\" else None,\n",
        "    oversampling=True,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_ds, _ = preprocess.load_img(\n",
        "    data_dir=\"data/rare_species/val\",\n",
        "    minority_class=minority_class,\n",
        "    augment=None,\n",
        "    oversampling=False\n",
        ")"
      ],
      "metadata": {
        "id": "IzUOe9CfpB6P",
        "outputId": "832d67ff-c32e-4b6e-f6d9-cc7070e007eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimento\n",
        "experiment = Experiment(\n",
        "    model=model,\n",
        "    train_ds=train_ds,\n",
        "    val_ds=val_ds,\n",
        "    experiment_name=f\"densenet_mix_S_test1\",\n",
        "    batch_size=batch_size,\n",
        "    image_size=image_size,\n",
        "    save_model=False\n",
        ")\n",
        "\n",
        "history = experiment.run_experiment(\n",
        "    callbacks=callbacks,\n",
        "    epochs=num_epochs\n",
        ")"
      ],
      "metadata": {
        "id": "Eo4P_E-CoZkJ",
        "outputId": "ac5d5d1e-da0f-4426-cfd1-a4f0d3eadd2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m782s\u001b[0m 2s/step - accuracy: 0.0185 - auc: 0.5399 - f1_macro: 0.0020 - f1_weighted: 0.0058 - loss: 6.0166 - top5_accuracy: 0.0639 - val_accuracy: 0.0345 - val_auc: 0.5975 - val_f1_macro: 0.0021 - val_f1_weighted: 0.0099 - val_loss: 5.8590 - val_top5_accuracy: 0.1196 - learning_rate: 2.0807e-05\n",
            "Epoch 2/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 176ms/step - accuracy: 0.0579 - auc: 0.6214 - f1_macro: 0.0036 - f1_weighted: 0.0129 - loss: 5.7835 - top5_accuracy: 0.1393 - val_accuracy: 0.0607 - val_auc: 0.6770 - val_f1_macro: 0.0051 - val_f1_weighted: 0.0208 - val_loss: 5.6214 - val_top5_accuracy: 0.1758 - learning_rate: 2.0807e-05\n",
            "Epoch 3/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 177ms/step - accuracy: 0.0599 - auc: 0.6370 - f1_macro: 0.0040 - f1_weighted: 0.0137 - loss: 5.7276 - top5_accuracy: 0.1507 - val_accuracy: 0.0634 - val_auc: 0.6982 - val_f1_macro: 0.0089 - val_f1_weighted: 0.0251 - val_loss: 5.5609 - val_top5_accuracy: 0.1853 - learning_rate: 2.0807e-05\n",
            "Epoch 4/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 179ms/step - accuracy: 0.0630 - auc: 0.6493 - f1_macro: 0.0054 - f1_weighted: 0.0159 - loss: 5.6848 - top5_accuracy: 0.1589 - val_accuracy: 0.0718 - val_auc: 0.7104 - val_f1_macro: 0.0101 - val_f1_weighted: 0.0292 - val_loss: 5.5101 - val_top5_accuracy: 0.1920 - learning_rate: 2.0807e-05\n",
            "Epoch 5/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.0635 - auc: 0.6586 - f1_macro: 0.0055 - f1_weighted: 0.0164 - loss: 5.6475 - top5_accuracy: 0.1657 - val_accuracy: 0.0740 - val_auc: 0.7210 - val_f1_macro: 0.0106 - val_f1_weighted: 0.0296 - val_loss: 5.4589 - val_top5_accuracy: 0.2042 - learning_rate: 2.0807e-05\n",
            "Epoch 6/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.0682 - auc: 0.6670 - f1_macro: 0.0064 - f1_weighted: 0.0189 - loss: 5.6162 - top5_accuracy: 0.1727 - val_accuracy: 0.0740 - val_auc: 0.7321 - val_f1_macro: 0.0111 - val_f1_weighted: 0.0313 - val_loss: 5.4192 - val_top5_accuracy: 0.2142 - learning_rate: 2.0807e-05\n",
            "Epoch 7/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.0660 - auc: 0.6734 - f1_macro: 0.0069 - f1_weighted: 0.0186 - loss: 5.5878 - top5_accuracy: 0.1797 - val_accuracy: 0.0740 - val_auc: 0.7347 - val_f1_macro: 0.0142 - val_f1_weighted: 0.0332 - val_loss: 5.3879 - val_top5_accuracy: 0.2215 - learning_rate: 2.0807e-05\n",
            "Epoch 8/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.0682 - auc: 0.6781 - f1_macro: 0.0080 - f1_weighted: 0.0205 - loss: 5.5625 - top5_accuracy: 0.1869 - val_accuracy: 0.0751 - val_auc: 0.7381 - val_f1_macro: 0.0142 - val_f1_weighted: 0.0342 - val_loss: 5.3613 - val_top5_accuracy: 0.2226 - learning_rate: 2.0807e-05\n",
            "Epoch 9/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.0689 - auc: 0.6818 - f1_macro: 0.0092 - f1_weighted: 0.0220 - loss: 5.5423 - top5_accuracy: 0.1887 - val_accuracy: 0.0746 - val_auc: 0.7416 - val_f1_macro: 0.0179 - val_f1_weighted: 0.0355 - val_loss: 5.3491 - val_top5_accuracy: 0.2165 - learning_rate: 2.0807e-05\n",
            "Epoch 10/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.0718 - auc: 0.6860 - f1_macro: 0.0098 - f1_weighted: 0.0234 - loss: 5.5194 - top5_accuracy: 0.1912 - val_accuracy: 0.0768 - val_auc: 0.7493 - val_f1_macro: 0.0195 - val_f1_weighted: 0.0388 - val_loss: 5.3332 - val_top5_accuracy: 0.2209 - learning_rate: 2.0807e-05\n",
            "Epoch 11/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.0719 - auc: 0.6905 - f1_macro: 0.0106 - f1_weighted: 0.0237 - loss: 5.5016 - top5_accuracy: 0.1968 - val_accuracy: 0.0790 - val_auc: 0.7460 - val_f1_macro: 0.0201 - val_f1_weighted: 0.0400 - val_loss: 5.3304 - val_top5_accuracy: 0.2254 - learning_rate: 2.0807e-05\n",
            "Epoch 12/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.0740 - auc: 0.6933 - f1_macro: 0.0109 - f1_weighted: 0.0246 - loss: 5.4826 - top5_accuracy: 0.1986 - val_accuracy: 0.0807 - val_auc: 0.7499 - val_f1_macro: 0.0209 - val_f1_weighted: 0.0405 - val_loss: 5.3024 - val_top5_accuracy: 0.2315 - learning_rate: 2.0807e-05\n",
            "Epoch 13/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 182ms/step - accuracy: 0.0766 - auc: 0.6966 - f1_macro: 0.0119 - f1_weighted: 0.0257 - loss: 5.4656 - top5_accuracy: 0.2026 - val_accuracy: 0.0818 - val_auc: 0.7578 - val_f1_macro: 0.0217 - val_f1_weighted: 0.0447 - val_loss: 5.2732 - val_top5_accuracy: 0.2326 - learning_rate: 2.0807e-05\n",
            "Epoch 14/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.0788 - auc: 0.6998 - f1_macro: 0.0123 - f1_weighted: 0.0265 - loss: 5.4505 - top5_accuracy: 0.2062 - val_accuracy: 0.0807 - val_auc: 0.7556 - val_f1_macro: 0.0218 - val_f1_weighted: 0.0424 - val_loss: 5.2873 - val_top5_accuracy: 0.2298 - learning_rate: 2.0807e-05\n",
            "Epoch 15/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.0794 - auc: 0.7010 - f1_macro: 0.0133 - f1_weighted: 0.0274 - loss: 5.4366 - top5_accuracy: 0.2097 - val_accuracy: 0.0868 - val_auc: 0.7571 - val_f1_macro: 0.0244 - val_f1_weighted: 0.0472 - val_loss: 5.2575 - val_top5_accuracy: 0.2348 - learning_rate: 2.0807e-05\n",
            "Epoch 16/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.0830 - auc: 0.7051 - f1_macro: 0.0144 - f1_weighted: 0.0295 - loss: 5.4170 - top5_accuracy: 0.2168 - val_accuracy: 0.0851 - val_auc: 0.7546 - val_f1_macro: 0.0268 - val_f1_weighted: 0.0469 - val_loss: 5.2524 - val_top5_accuracy: 0.2293 - learning_rate: 2.0807e-05\n",
            "Epoch 17/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.0829 - auc: 0.7075 - f1_macro: 0.0146 - f1_weighted: 0.0293 - loss: 5.4043 - top5_accuracy: 0.2185 - val_accuracy: 0.0846 - val_auc: 0.7559 - val_f1_macro: 0.0246 - val_f1_weighted: 0.0447 - val_loss: 5.2337 - val_top5_accuracy: 0.2354 - learning_rate: 2.0807e-05\n",
            "Epoch 18/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.0879 - auc: 0.7098 - f1_macro: 0.0163 - f1_weighted: 0.0322 - loss: 5.3894 - top5_accuracy: 0.2238 - val_accuracy: 0.0863 - val_auc: 0.7599 - val_f1_macro: 0.0253 - val_f1_weighted: 0.0462 - val_loss: 5.2253 - val_top5_accuracy: 0.2365 - learning_rate: 2.0807e-05\n",
            "Epoch 19/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.0877 - auc: 0.7106 - f1_macro: 0.0161 - f1_weighted: 0.0316 - loss: 5.3750 - top5_accuracy: 0.2257 - val_accuracy: 0.0824 - val_auc: 0.7595 - val_f1_macro: 0.0232 - val_f1_weighted: 0.0414 - val_loss: 5.2343 - val_top5_accuracy: 0.2376 - learning_rate: 2.0807e-05\n",
            "Epoch 20/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.0901 - auc: 0.7131 - f1_macro: 0.0182 - f1_weighted: 0.0337 - loss: 5.3628 - top5_accuracy: 0.2303 - val_accuracy: 0.0851 - val_auc: 0.7590 - val_f1_macro: 0.0256 - val_f1_weighted: 0.0465 - val_loss: 5.2241 - val_top5_accuracy: 0.2315 - learning_rate: 2.0807e-05\n",
            "Epoch 21/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.0924 - auc: 0.7160 - f1_macro: 0.0186 - f1_weighted: 0.0346 - loss: 5.3478 - top5_accuracy: 0.2353 - val_accuracy: 0.0863 - val_auc: 0.7592 - val_f1_macro: 0.0292 - val_f1_weighted: 0.0498 - val_loss: 5.2186 - val_top5_accuracy: 0.2321 - learning_rate: 2.0807e-05\n",
            "Epoch 22/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 179ms/step - accuracy: 0.0939 - auc: 0.7172 - f1_macro: 0.0192 - f1_weighted: 0.0355 - loss: 5.3347 - top5_accuracy: 0.2396 - val_accuracy: 0.0851 - val_auc: 0.7531 - val_f1_macro: 0.0286 - val_f1_weighted: 0.0468 - val_loss: 5.2339 - val_top5_accuracy: 0.2332 - learning_rate: 2.0807e-05\n",
            "Epoch 23/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.0929 - auc: 0.7177 - f1_macro: 0.0210 - f1_weighted: 0.0361 - loss: 5.3230 - top5_accuracy: 0.2430 - val_accuracy: 0.0879 - val_auc: 0.7539 - val_f1_macro: 0.0282 - val_f1_weighted: 0.0500 - val_loss: 5.2191 - val_top5_accuracy: 0.2354 - learning_rate: 2.0807e-05\n",
            "Epoch 24/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.0990 - auc: 0.7205 - f1_macro: 0.0224 - f1_weighted: 0.0394 - loss: 5.3096 - top5_accuracy: 0.2498 - val_accuracy: 0.0863 - val_auc: 0.7553 - val_f1_macro: 0.0302 - val_f1_weighted: 0.0486 - val_loss: 5.2223 - val_top5_accuracy: 0.2421 - learning_rate: 2.0807e-05\n",
            "Epoch 25/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.0982 - auc: 0.7230 - f1_macro: 0.0233 - f1_weighted: 0.0396 - loss: 5.2958 - top5_accuracy: 0.2524 - val_accuracy: 0.0835 - val_auc: 0.7553 - val_f1_macro: 0.0286 - val_f1_weighted: 0.0473 - val_loss: 5.2197 - val_top5_accuracy: 0.2376 - learning_rate: 2.0807e-05\n",
            "Epoch 26/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.1008 - auc: 0.7247 - f1_macro: 0.0245 - f1_weighted: 0.0408 - loss: 5.2840 - top5_accuracy: 0.2545\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 1.0403499800304417e-05.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.1008 - auc: 0.7247 - f1_macro: 0.0245 - f1_weighted: 0.0408 - loss: 5.2840 - top5_accuracy: 0.2545 - val_accuracy: 0.0874 - val_auc: 0.7536 - val_f1_macro: 0.0294 - val_f1_weighted: 0.0504 - val_loss: 5.2223 - val_top5_accuracy: 0.2387 - learning_rate: 2.0807e-05\n",
            "Epoch 27/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.1007 - auc: 0.7276 - f1_macro: 0.0252 - f1_weighted: 0.0411 - loss: 5.2630 - top5_accuracy: 0.2624 - val_accuracy: 0.0929 - val_auc: 0.7613 - val_f1_macro: 0.0354 - val_f1_weighted: 0.0566 - val_loss: 5.1789 - val_top5_accuracy: 0.2482 - learning_rate: 1.0403e-05\n",
            "Epoch 28/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.1058 - auc: 0.7302 - f1_macro: 0.0274 - f1_weighted: 0.0442 - loss: 5.2528 - top5_accuracy: 0.2646 - val_accuracy: 0.0952 - val_auc: 0.7632 - val_f1_macro: 0.0361 - val_f1_weighted: 0.0595 - val_loss: 5.1761 - val_top5_accuracy: 0.2493 - learning_rate: 1.0403e-05\n",
            "Epoch 29/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.1048 - auc: 0.7319 - f1_macro: 0.0275 - f1_weighted: 0.0448 - loss: 5.2445 - top5_accuracy: 0.2712 - val_accuracy: 0.0946 - val_auc: 0.7590 - val_f1_macro: 0.0364 - val_f1_weighted: 0.0589 - val_loss: 5.1850 - val_top5_accuracy: 0.2482 - learning_rate: 1.0403e-05\n",
            "Epoch 30/30\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.1086 - auc: 0.7318 - f1_macro: 0.0301 - f1_weighted: 0.0467 - loss: 5.2380 - top5_accuracy: 0.2694 - val_accuracy: 0.0952 - val_auc: 0.7588 - val_f1_macro: 0.0369 - val_f1_weighted: 0.0596 - val_loss: 5.1834 - val_top5_accuracy: 0.2471 - learning_rate: 1.0403e-05\n",
            "Restoring model weights from the end of the best epoch: 28.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# Plotting Training and Validation Accuracy and Loss\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "# Plotting Accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_accuracy, label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "m1wDZL5uolCS",
        "outputId": "852ddefe-d5c5-4f94-d9f3-f685b4ec86ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('densenet_s_test1.h5')"
      ],
      "metadata": {
        "id": "nVVkT-1eolVO",
        "outputId": "baed6385-33f2-4d67-a7a4-1a70db304f2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet trial - 100 epochs\n"
      ],
      "metadata": {
        "id": "jgDHv-wdfU7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=build_densenet(\n",
        "    layers_per_block=[6, 12, 24, 16],\n",
        "    growth_rate=12,\n",
        "    compression=1,\n",
        "    dropout_rate=0.3,\n",
        "    bottleneck=True\n",
        ")\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2.0807e-05),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.0),\n",
        "        metrics=metrics)"
      ],
      "metadata": {
        "id": "IBgdz2vVgBiD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparâmetros\n",
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "num_epochs = 100\n",
        "augment_mode = \"mixup\"\n",
        "\n",
        "# Preprocessador\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "all_results = []\n",
        "\n",
        "\n",
        "# Carregamento dos datasets\n",
        "train_ds, class_names = preprocess.load_img(\n",
        "    data_dir=\"data/rare_species/train\",\n",
        "    minority_class=minority_class,\n",
        "    augment=augment_mode if augment_mode != \"none\" else None,\n",
        "    oversampling=True,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_ds, _ = preprocess.load_img(\n",
        "    data_dir=\"data/rare_species/val\",\n",
        "    minority_class=minority_class,\n",
        "    augment=None,\n",
        "    oversampling=False\n",
        ")"
      ],
      "metadata": {
        "id": "iXiRHfYIgE7C",
        "outputId": "23333284-f022-47ae-9d5c-03960b1e3058",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimento\n",
        "experiment = Experiment(\n",
        "    model=model,\n",
        "    train_ds=train_ds,\n",
        "    val_ds=val_ds,\n",
        "    experiment_name=f\"densenet_mix_S_test2\",\n",
        "    batch_size=batch_size,\n",
        "    image_size=image_size,\n",
        "    save_model=False\n",
        ")\n",
        "\n",
        "history = experiment.run_experiment(\n",
        "    callbacks=callbacks,\n",
        "    epochs=num_epochs\n",
        ")"
      ],
      "metadata": {
        "id": "8ixbCqkUgK4h",
        "outputId": "56821a61-f347-429f-9ec8-d55dfaf034fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No checkpoint found, starting from scratch.\n",
            "Epoch 1/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m572s\u001b[0m 1s/step - accuracy: 0.0214 - auc: 0.5417 - f1_macro: 0.0026 - f1_weighted: 0.0076 - loss: 6.0062 - top5_accuracy: 0.0629 - val_accuracy: 0.0273 - val_auc: 0.6036 - val_f1_macro: 0.0026 - val_f1_weighted: 0.0112 - val_loss: 5.8677 - val_top5_accuracy: 0.0902 - learning_rate: 2.0807e-05\n",
            "Epoch 2/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.0558 - auc: 0.6254 - f1_macro: 0.0040 - f1_weighted: 0.0129 - loss: 5.7461 - top5_accuracy: 0.1441 - val_accuracy: 0.0768 - val_auc: 0.6994 - val_f1_macro: 0.0108 - val_f1_weighted: 0.0276 - val_loss: 5.5287 - val_top5_accuracy: 0.1964 - learning_rate: 2.0807e-05\n",
            "Epoch 3/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.0624 - auc: 0.6427 - f1_macro: 0.0065 - f1_weighted: 0.0177 - loss: 5.6622 - top5_accuracy: 0.1608 - val_accuracy: 0.0818 - val_auc: 0.7188 - val_f1_macro: 0.0140 - val_f1_weighted: 0.0360 - val_loss: 5.4295 - val_top5_accuracy: 0.2142 - learning_rate: 2.0807e-05\n",
            "Epoch 4/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.0664 - auc: 0.6518 - f1_macro: 0.0081 - f1_weighted: 0.0207 - loss: 5.5984 - top5_accuracy: 0.1754 - val_accuracy: 0.0812 - val_auc: 0.7271 - val_f1_macro: 0.0159 - val_f1_weighted: 0.0368 - val_loss: 5.3798 - val_top5_accuracy: 0.2215 - learning_rate: 2.0807e-05\n",
            "Epoch 5/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.0693 - auc: 0.6593 - f1_macro: 0.0096 - f1_weighted: 0.0230 - loss: 5.5458 - top5_accuracy: 0.1846 - val_accuracy: 0.0874 - val_auc: 0.7365 - val_f1_macro: 0.0175 - val_f1_weighted: 0.0405 - val_loss: 5.3343 - val_top5_accuracy: 0.2298 - learning_rate: 2.0807e-05\n",
            "Epoch 6/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.0734 - auc: 0.6659 - f1_macro: 0.0118 - f1_weighted: 0.0258 - loss: 5.5067 - top5_accuracy: 0.1917 - val_accuracy: 0.0929 - val_auc: 0.7431 - val_f1_macro: 0.0204 - val_f1_weighted: 0.0456 - val_loss: 5.2949 - val_top5_accuracy: 0.2371 - learning_rate: 2.0807e-05\n",
            "Epoch 7/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.0759 - auc: 0.6692 - f1_macro: 0.0130 - f1_weighted: 0.0277 - loss: 5.4653 - top5_accuracy: 0.2016 - val_accuracy: 0.0902 - val_auc: 0.7492 - val_f1_macro: 0.0204 - val_f1_weighted: 0.0432 - val_loss: 5.2643 - val_top5_accuracy: 0.2437 - learning_rate: 2.0807e-05\n",
            "Epoch 8/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.0812 - auc: 0.6738 - f1_macro: 0.0160 - f1_weighted: 0.0316 - loss: 5.4326 - top5_accuracy: 0.2085 - val_accuracy: 0.0996 - val_auc: 0.7553 - val_f1_macro: 0.0260 - val_f1_weighted: 0.0507 - val_loss: 5.2389 - val_top5_accuracy: 0.2476 - learning_rate: 2.0807e-05\n",
            "Epoch 9/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.0823 - auc: 0.6779 - f1_macro: 0.0159 - f1_weighted: 0.0314 - loss: 5.4017 - top5_accuracy: 0.2180 - val_accuracy: 0.1002 - val_auc: 0.7597 - val_f1_macro: 0.0251 - val_f1_weighted: 0.0500 - val_loss: 5.2140 - val_top5_accuracy: 0.2521 - learning_rate: 2.0807e-05\n",
            "Epoch 10/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.0866 - auc: 0.6817 - f1_macro: 0.0193 - f1_weighted: 0.0347 - loss: 5.3722 - top5_accuracy: 0.2285 - val_accuracy: 0.1041 - val_auc: 0.7611 - val_f1_macro: 0.0283 - val_f1_weighted: 0.0553 - val_loss: 5.2114 - val_top5_accuracy: 0.2487 - learning_rate: 2.0807e-05\n",
            "Epoch 11/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 177ms/step - accuracy: 0.0865 - auc: 0.6853 - f1_macro: 0.0197 - f1_weighted: 0.0355 - loss: 5.3460 - top5_accuracy: 0.2364 - val_accuracy: 0.1035 - val_auc: 0.7675 - val_f1_macro: 0.0288 - val_f1_weighted: 0.0553 - val_loss: 5.1730 - val_top5_accuracy: 0.2532 - learning_rate: 2.0807e-05\n",
            "Epoch 12/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 177ms/step - accuracy: 0.0899 - auc: 0.6879 - f1_macro: 0.0235 - f1_weighted: 0.0388 - loss: 5.3224 - top5_accuracy: 0.2459 - val_accuracy: 0.0935 - val_auc: 0.7674 - val_f1_macro: 0.0256 - val_f1_weighted: 0.0491 - val_loss: 5.1860 - val_top5_accuracy: 0.2621 - learning_rate: 2.0807e-05\n",
            "Epoch 13/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.0943 - auc: 0.6904 - f1_macro: 0.0268 - f1_weighted: 0.0423 - loss: 5.2959 - top5_accuracy: 0.2541 - val_accuracy: 0.1080 - val_auc: 0.7722 - val_f1_macro: 0.0298 - val_f1_weighted: 0.0587 - val_loss: 5.1369 - val_top5_accuracy: 0.2738 - learning_rate: 2.0807e-05\n",
            "Epoch 14/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 177ms/step - accuracy: 0.0995 - auc: 0.6941 - f1_macro: 0.0291 - f1_weighted: 0.0455 - loss: 5.2710 - top5_accuracy: 0.2616 - val_accuracy: 0.0963 - val_auc: 0.7685 - val_f1_macro: 0.0299 - val_f1_weighted: 0.0523 - val_loss: 5.1568 - val_top5_accuracy: 0.2643 - learning_rate: 2.0807e-05\n",
            "Epoch 15/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 177ms/step - accuracy: 0.0996 - auc: 0.6967 - f1_macro: 0.0306 - f1_weighted: 0.0461 - loss: 5.2485 - top5_accuracy: 0.2700 - val_accuracy: 0.1002 - val_auc: 0.7721 - val_f1_macro: 0.0298 - val_f1_weighted: 0.0540 - val_loss: 5.1433 - val_top5_accuracy: 0.2654 - learning_rate: 2.0807e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1038 - auc: 0.6991 - f1_macro: 0.0337 - f1_weighted: 0.0496 - loss: 5.2255 - top5_accuracy: 0.2749 - val_accuracy: 0.1113 - val_auc: 0.7766 - val_f1_macro: 0.0403 - val_f1_weighted: 0.0657 - val_loss: 5.0959 - val_top5_accuracy: 0.2721 - learning_rate: 2.0807e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1061 - auc: 0.7004 - f1_macro: 0.0346 - f1_weighted: 0.0509 - loss: 5.2043 - top5_accuracy: 0.2763 - val_accuracy: 0.1002 - val_auc: 0.7725 - val_f1_macro: 0.0367 - val_f1_weighted: 0.0575 - val_loss: 5.1337 - val_top5_accuracy: 0.2705 - learning_rate: 2.0807e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1081 - auc: 0.7029 - f1_macro: 0.0371 - f1_weighted: 0.0529 - loss: 5.1833 - top5_accuracy: 0.2863 - val_accuracy: 0.1024 - val_auc: 0.7763 - val_f1_macro: 0.0399 - val_f1_weighted: 0.0605 - val_loss: 5.0917 - val_top5_accuracy: 0.2794 - learning_rate: 2.0807e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 177ms/step - accuracy: 0.1124 - auc: 0.7028 - f1_macro: 0.0396 - f1_weighted: 0.0556 - loss: 5.1642 - top5_accuracy: 0.2902 - val_accuracy: 0.1035 - val_auc: 0.7805 - val_f1_macro: 0.0392 - val_f1_weighted: 0.0619 - val_loss: 5.0835 - val_top5_accuracy: 0.2799 - learning_rate: 2.0807e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1134 - auc: 0.7062 - f1_macro: 0.0413 - f1_weighted: 0.0572 - loss: 5.1418 - top5_accuracy: 0.2992 - val_accuracy: 0.1063 - val_auc: 0.7793 - val_f1_macro: 0.0441 - val_f1_weighted: 0.0658 - val_loss: 5.0628 - val_top5_accuracy: 0.2721 - learning_rate: 2.0807e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1201 - auc: 0.7066 - f1_macro: 0.0432 - f1_weighted: 0.0611 - loss: 5.1240 - top5_accuracy: 0.3042 - val_accuracy: 0.1230 - val_auc: 0.7819 - val_f1_macro: 0.0506 - val_f1_weighted: 0.0767 - val_loss: 5.0362 - val_top5_accuracy: 0.2794 - learning_rate: 2.0807e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1235 - auc: 0.7095 - f1_macro: 0.0457 - f1_weighted: 0.0632 - loss: 5.1042 - top5_accuracy: 0.3092 - val_accuracy: 0.1263 - val_auc: 0.7823 - val_f1_macro: 0.0497 - val_f1_weighted: 0.0805 - val_loss: 5.0235 - val_top5_accuracy: 0.2810 - learning_rate: 2.0807e-05\n",
            "Epoch 23/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1250 - auc: 0.7104 - f1_macro: 0.0481 - f1_weighted: 0.0657 - loss: 5.0855 - top5_accuracy: 0.3190 - val_accuracy: 0.1280 - val_auc: 0.7813 - val_f1_macro: 0.0552 - val_f1_weighted: 0.0836 - val_loss: 5.0043 - val_top5_accuracy: 0.2877 - learning_rate: 2.0807e-05\n",
            "Epoch 24/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1301 - auc: 0.7133 - f1_macro: 0.0519 - f1_weighted: 0.0696 - loss: 5.0675 - top5_accuracy: 0.3205 - val_accuracy: 0.1274 - val_auc: 0.7889 - val_f1_macro: 0.0514 - val_f1_weighted: 0.0832 - val_loss: 4.9898 - val_top5_accuracy: 0.2883 - learning_rate: 2.0807e-05\n",
            "Epoch 25/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 177ms/step - accuracy: 0.1351 - auc: 0.7149 - f1_macro: 0.0558 - f1_weighted: 0.0735 - loss: 5.0477 - top5_accuracy: 0.3258 - val_accuracy: 0.1302 - val_auc: 0.7845 - val_f1_macro: 0.0532 - val_f1_weighted: 0.0858 - val_loss: 4.9931 - val_top5_accuracy: 0.2938 - learning_rate: 2.0807e-05\n",
            "Epoch 26/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1388 - auc: 0.7151 - f1_macro: 0.0593 - f1_weighted: 0.0768 - loss: 5.0329 - top5_accuracy: 0.3303 - val_accuracy: 0.1324 - val_auc: 0.7859 - val_f1_macro: 0.0587 - val_f1_weighted: 0.0893 - val_loss: 4.9809 - val_top5_accuracy: 0.2955 - learning_rate: 2.0807e-05\n",
            "Epoch 27/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 177ms/step - accuracy: 0.1381 - auc: 0.7174 - f1_macro: 0.0586 - f1_weighted: 0.0761 - loss: 5.0113 - top5_accuracy: 0.3361 - val_accuracy: 0.1324 - val_auc: 0.7873 - val_f1_macro: 0.0554 - val_f1_weighted: 0.0896 - val_loss: 4.9945 - val_top5_accuracy: 0.2849 - learning_rate: 2.0807e-05\n",
            "Epoch 28/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 177ms/step - accuracy: 0.1421 - auc: 0.7197 - f1_macro: 0.0616 - f1_weighted: 0.0787 - loss: 4.9925 - top5_accuracy: 0.3424 - val_accuracy: 0.1330 - val_auc: 0.7867 - val_f1_macro: 0.0591 - val_f1_weighted: 0.0928 - val_loss: 4.9898 - val_top5_accuracy: 0.2860 - learning_rate: 2.0807e-05\n",
            "Epoch 29/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1481 - auc: 0.7203 - f1_macro: 0.0682 - f1_weighted: 0.0847 - loss: 4.9752 - top5_accuracy: 0.3506 - val_accuracy: 0.1302 - val_auc: 0.7856 - val_f1_macro: 0.0552 - val_f1_weighted: 0.0883 - val_loss: 4.9871 - val_top5_accuracy: 0.2821 - learning_rate: 2.0807e-05\n",
            "Epoch 30/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 177ms/step - accuracy: 0.1532 - auc: 0.7207 - f1_macro: 0.0738 - f1_weighted: 0.0903 - loss: 4.9576 - top5_accuracy: 0.3535 - val_accuracy: 0.1352 - val_auc: 0.7878 - val_f1_macro: 0.0590 - val_f1_weighted: 0.0958 - val_loss: 4.9666 - val_top5_accuracy: 0.2916 - learning_rate: 2.0807e-05\n",
            "Epoch 31/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1538 - auc: 0.7227 - f1_macro: 0.0725 - f1_weighted: 0.0901 - loss: 4.9440 - top5_accuracy: 0.3529 - val_accuracy: 0.1375 - val_auc: 0.7891 - val_f1_macro: 0.0619 - val_f1_weighted: 0.0981 - val_loss: 4.9599 - val_top5_accuracy: 0.2955 - learning_rate: 2.0807e-05\n",
            "Epoch 32/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1585 - auc: 0.7226 - f1_macro: 0.0786 - f1_weighted: 0.0952 - loss: 4.9263 - top5_accuracy: 0.3642 - val_accuracy: 0.1258 - val_auc: 0.7854 - val_f1_macro: 0.0545 - val_f1_weighted: 0.0902 - val_loss: 5.0004 - val_top5_accuracy: 0.2888 - learning_rate: 2.0807e-05\n",
            "Epoch 33/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 177ms/step - accuracy: 0.1579 - auc: 0.7238 - f1_macro: 0.0763 - f1_weighted: 0.0943 - loss: 4.9117 - top5_accuracy: 0.3709 - val_accuracy: 0.1324 - val_auc: 0.7869 - val_f1_macro: 0.0604 - val_f1_weighted: 0.0951 - val_loss: 4.9730 - val_top5_accuracy: 0.2922 - learning_rate: 2.0807e-05\n",
            "Epoch 34/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1620 - auc: 0.7251 - f1_macro: 0.0817 - f1_weighted: 0.0979 - loss: 4.8963 - top5_accuracy: 0.3722 - val_accuracy: 0.1291 - val_auc: 0.7872 - val_f1_macro: 0.0595 - val_f1_weighted: 0.0920 - val_loss: 4.9727 - val_top5_accuracy: 0.2972 - learning_rate: 2.0807e-05\n",
            "Epoch 35/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1666 - auc: 0.7266 - f1_macro: 0.0831 - f1_weighted: 0.1016 - loss: 4.8764 - top5_accuracy: 0.3803 - val_accuracy: 0.1336 - val_auc: 0.7892 - val_f1_macro: 0.0647 - val_f1_weighted: 0.0954 - val_loss: 4.9553 - val_top5_accuracy: 0.2994 - learning_rate: 2.0807e-05\n",
            "Epoch 36/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 179ms/step - accuracy: 0.1724 - auc: 0.7273 - f1_macro: 0.0888 - f1_weighted: 0.1064 - loss: 4.8625 - top5_accuracy: 0.3850 - val_accuracy: 0.1363 - val_auc: 0.7914 - val_f1_macro: 0.0646 - val_f1_weighted: 0.0997 - val_loss: 4.9440 - val_top5_accuracy: 0.3016 - learning_rate: 2.0807e-05\n",
            "Epoch 37/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 179ms/step - accuracy: 0.1730 - auc: 0.7289 - f1_macro: 0.0889 - f1_weighted: 0.1073 - loss: 4.8448 - top5_accuracy: 0.3897 - val_accuracy: 0.1324 - val_auc: 0.7874 - val_f1_macro: 0.0639 - val_f1_weighted: 0.0960 - val_loss: 4.9648 - val_top5_accuracy: 0.2972 - learning_rate: 2.0807e-05\n",
            "Epoch 38/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 179ms/step - accuracy: 0.1764 - auc: 0.7302 - f1_macro: 0.0920 - f1_weighted: 0.1094 - loss: 4.8308 - top5_accuracy: 0.3936 - val_accuracy: 0.1291 - val_auc: 0.7868 - val_f1_macro: 0.0628 - val_f1_weighted: 0.0946 - val_loss: 4.9758 - val_top5_accuracy: 0.2988 - learning_rate: 2.0807e-05\n",
            "Epoch 39/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1788 - auc: 0.7303 - f1_macro: 0.0955 - f1_weighted: 0.1130 - loss: 4.8119 - top5_accuracy: 0.4010 - val_accuracy: 0.1369 - val_auc: 0.7892 - val_f1_macro: 0.0700 - val_f1_weighted: 0.1025 - val_loss: 4.9529 - val_top5_accuracy: 0.2977 - learning_rate: 2.0807e-05\n",
            "Epoch 40/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1816 - auc: 0.7316 - f1_macro: 0.0975 - f1_weighted: 0.1153 - loss: 4.7974 - top5_accuracy: 0.4052 - val_accuracy: 0.1297 - val_auc: 0.7887 - val_f1_macro: 0.0642 - val_f1_weighted: 0.0965 - val_loss: 4.9660 - val_top5_accuracy: 0.2999 - learning_rate: 2.0807e-05\n",
            "Epoch 41/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.1836 - auc: 0.7327 - f1_macro: 0.1010 - f1_weighted: 0.1182 - loss: 4.7818 - top5_accuracy: 0.4118\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 1.0403499800304417e-05.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.1836 - auc: 0.7327 - f1_macro: 0.1010 - f1_weighted: 0.1182 - loss: 4.7818 - top5_accuracy: 0.4118 - val_accuracy: 0.1280 - val_auc: 0.7876 - val_f1_macro: 0.0635 - val_f1_weighted: 0.0943 - val_loss: 4.9652 - val_top5_accuracy: 0.2999 - learning_rate: 2.0807e-05\n",
            "Epoch 42/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1888 - auc: 0.7347 - f1_macro: 0.1052 - f1_weighted: 0.1223 - loss: 4.7593 - top5_accuracy: 0.4223 - val_accuracy: 0.1397 - val_auc: 0.7939 - val_f1_macro: 0.0725 - val_f1_weighted: 0.1042 - val_loss: 4.9361 - val_top5_accuracy: 0.3105 - learning_rate: 1.0403e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 177ms/step - accuracy: 0.1938 - auc: 0.7351 - f1_macro: 0.1090 - f1_weighted: 0.1261 - loss: 4.7475 - top5_accuracy: 0.4245 - val_accuracy: 0.1341 - val_auc: 0.7912 - val_f1_macro: 0.0688 - val_f1_weighted: 0.0997 - val_loss: 4.9543 - val_top5_accuracy: 0.3061 - learning_rate: 1.0403e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1989 - auc: 0.7358 - f1_macro: 0.1134 - f1_weighted: 0.1307 - loss: 4.7377 - top5_accuracy: 0.4276 - val_accuracy: 0.1386 - val_auc: 0.7931 - val_f1_macro: 0.0722 - val_f1_weighted: 0.1006 - val_loss: 4.9323 - val_top5_accuracy: 0.3105 - learning_rate: 1.0403e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.1975 - auc: 0.7358 - f1_macro: 0.1109 - f1_weighted: 0.1291 - loss: 4.7283 - top5_accuracy: 0.4277 - val_accuracy: 0.1391 - val_auc: 0.7937 - val_f1_macro: 0.0714 - val_f1_weighted: 0.1031 - val_loss: 4.9344 - val_top5_accuracy: 0.3111 - learning_rate: 1.0403e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.2020 - auc: 0.7383 - f1_macro: 0.1150 - f1_weighted: 0.1326 - loss: 4.7182 - top5_accuracy: 0.4355 - val_accuracy: 0.1386 - val_auc: 0.7940 - val_f1_macro: 0.0709 - val_f1_weighted: 0.1017 - val_loss: 4.9299 - val_top5_accuracy: 0.3166 - learning_rate: 1.0403e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 177ms/step - accuracy: 0.2018 - auc: 0.7372 - f1_macro: 0.1175 - f1_weighted: 0.1337 - loss: 4.7123 - top5_accuracy: 0.4385 - val_accuracy: 0.1386 - val_auc: 0.7958 - val_f1_macro: 0.0723 - val_f1_weighted: 0.1018 - val_loss: 4.9273 - val_top5_accuracy: 0.3127 - learning_rate: 1.0403e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.2026 - auc: 0.7381 - f1_macro: 0.1153 - f1_weighted: 0.1338 - loss: 4.7014 - top5_accuracy: 0.4411 - val_accuracy: 0.1402 - val_auc: 0.7927 - val_f1_macro: 0.0731 - val_f1_weighted: 0.1045 - val_loss: 4.9400 - val_top5_accuracy: 0.3077 - learning_rate: 1.0403e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.2013 - auc: 0.7386 - f1_macro: 0.1160 - f1_weighted: 0.1335 - loss: 4.6950 - top5_accuracy: 0.4469 - val_accuracy: 0.1386 - val_auc: 0.7954 - val_f1_macro: 0.0722 - val_f1_weighted: 0.1006 - val_loss: 4.9372 - val_top5_accuracy: 0.3072 - learning_rate: 1.0403e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 177ms/step - accuracy: 0.2052 - auc: 0.7380 - f1_macro: 0.1184 - f1_weighted: 0.1357 - loss: 4.6892 - top5_accuracy: 0.4388 - val_accuracy: 0.1380 - val_auc: 0.7944 - val_f1_macro: 0.0711 - val_f1_weighted: 0.1003 - val_loss: 4.9283 - val_top5_accuracy: 0.3094 - learning_rate: 1.0403e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.2139 - auc: 0.7399 - f1_macro: 0.1244 - f1_weighted: 0.1432 - loss: 4.6773 - top5_accuracy: 0.4477 - val_accuracy: 0.1430 - val_auc: 0.7953 - val_f1_macro: 0.0741 - val_f1_weighted: 0.1054 - val_loss: 4.9300 - val_top5_accuracy: 0.3155 - learning_rate: 1.0403e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.2074 - auc: 0.7404 - f1_macro: 0.1201 - f1_weighted: 0.1382 - loss: 4.6701 - top5_accuracy: 0.4509\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 5.201749900152208e-06.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.2074 - auc: 0.7404 - f1_macro: 0.1201 - f1_weighted: 0.1382 - loss: 4.6701 - top5_accuracy: 0.4509 - val_accuracy: 0.1430 - val_auc: 0.7954 - val_f1_macro: 0.0739 - val_f1_weighted: 0.1050 - val_loss: 4.9273 - val_top5_accuracy: 0.3122 - learning_rate: 1.0403e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 177ms/step - accuracy: 0.2148 - auc: 0.7406 - f1_macro: 0.1248 - f1_weighted: 0.1429 - loss: 4.6585 - top5_accuracy: 0.4546 - val_accuracy: 0.1413 - val_auc: 0.7946 - val_f1_macro: 0.0762 - val_f1_weighted: 0.1048 - val_loss: 4.9227 - val_top5_accuracy: 0.3189 - learning_rate: 5.2017e-06\n",
            "Epoch 54/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 177ms/step - accuracy: 0.2139 - auc: 0.7405 - f1_macro: 0.1261 - f1_weighted: 0.1443 - loss: 4.6529 - top5_accuracy: 0.4625 - val_accuracy: 0.1391 - val_auc: 0.7952 - val_f1_macro: 0.0751 - val_f1_weighted: 0.1035 - val_loss: 4.9254 - val_top5_accuracy: 0.3205 - learning_rate: 5.2017e-06\n",
            "Epoch 55/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 182ms/step - accuracy: 0.2140 - auc: 0.7416 - f1_macro: 0.1260 - f1_weighted: 0.1434 - loss: 4.6489 - top5_accuracy: 0.4655 - val_accuracy: 0.1413 - val_auc: 0.7957 - val_f1_macro: 0.0764 - val_f1_weighted: 0.1051 - val_loss: 4.9227 - val_top5_accuracy: 0.3178 - learning_rate: 5.2017e-06\n",
            "Epoch 56/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 183ms/step - accuracy: 0.2154 - auc: 0.7414 - f1_macro: 0.1261 - f1_weighted: 0.1447 - loss: 4.6475 - top5_accuracy: 0.4530 - val_accuracy: 0.1402 - val_auc: 0.7961 - val_f1_macro: 0.0752 - val_f1_weighted: 0.1041 - val_loss: 4.9208 - val_top5_accuracy: 0.3228 - learning_rate: 5.2017e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.2213 - auc: 0.7420 - f1_macro: 0.1310 - f1_weighted: 0.1496 - loss: 4.6397 - top5_accuracy: 0.4609 - val_accuracy: 0.1391 - val_auc: 0.7943 - val_f1_macro: 0.0741 - val_f1_weighted: 0.1031 - val_loss: 4.9277 - val_top5_accuracy: 0.3200 - learning_rate: 5.2017e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.2201 - auc: 0.7422 - f1_macro: 0.1294 - f1_weighted: 0.1477 - loss: 4.6363 - top5_accuracy: 0.4623 - val_accuracy: 0.1413 - val_auc: 0.7947 - val_f1_macro: 0.0756 - val_f1_weighted: 0.1047 - val_loss: 4.9223 - val_top5_accuracy: 0.3222 - learning_rate: 5.2017e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 182ms/step - accuracy: 0.2189 - auc: 0.7429 - f1_macro: 0.1279 - f1_weighted: 0.1480 - loss: 4.6298 - top5_accuracy: 0.4679 - val_accuracy: 0.1408 - val_auc: 0.7942 - val_f1_macro: 0.0750 - val_f1_weighted: 0.1042 - val_loss: 4.9176 - val_top5_accuracy: 0.3244 - learning_rate: 5.2017e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.2239 - auc: 0.7429 - f1_macro: 0.1343 - f1_weighted: 0.1524 - loss: 4.6273 - top5_accuracy: 0.4655 - val_accuracy: 0.1402 - val_auc: 0.7954 - val_f1_macro: 0.0753 - val_f1_weighted: 0.1046 - val_loss: 4.9229 - val_top5_accuracy: 0.3233 - learning_rate: 5.2017e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 179ms/step - accuracy: 0.2231 - auc: 0.7428 - f1_macro: 0.1331 - f1_weighted: 0.1514 - loss: 4.6195 - top5_accuracy: 0.4746 - val_accuracy: 0.1447 - val_auc: 0.7933 - val_f1_macro: 0.0793 - val_f1_weighted: 0.1077 - val_loss: 4.9278 - val_top5_accuracy: 0.3211 - learning_rate: 5.2017e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.2194 - auc: 0.7431 - f1_macro: 0.1289 - f1_weighted: 0.1479 - loss: 4.6184 - top5_accuracy: 0.4723 - val_accuracy: 0.1447 - val_auc: 0.7945 - val_f1_macro: 0.0796 - val_f1_weighted: 0.1071 - val_loss: 4.9143 - val_top5_accuracy: 0.3250 - learning_rate: 5.2017e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 178ms/step - accuracy: 0.2245 - auc: 0.7435 - f1_macro: 0.1354 - f1_weighted: 0.1536 - loss: 4.6120 - top5_accuracy: 0.4738 - val_accuracy: 0.1464 - val_auc: 0.7935 - val_f1_macro: 0.0796 - val_f1_weighted: 0.1091 - val_loss: 4.9231 - val_top5_accuracy: 0.3216 - learning_rate: 5.2017e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.2228 - auc: 0.7432 - f1_macro: 0.1327 - f1_weighted: 0.1511 - loss: 4.6091 - top5_accuracy: 0.4736 - val_accuracy: 0.1447 - val_auc: 0.7948 - val_f1_macro: 0.0787 - val_f1_weighted: 0.1081 - val_loss: 4.9187 - val_top5_accuracy: 0.3228 - learning_rate: 5.2017e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.2268 - auc: 0.7432 - f1_macro: 0.1382 - f1_weighted: 0.1560 - loss: 4.6054 - top5_accuracy: 0.4795 - val_accuracy: 0.1458 - val_auc: 0.7927 - val_f1_macro: 0.0795 - val_f1_weighted: 0.1078 - val_loss: 4.9215 - val_top5_accuracy: 0.3222 - learning_rate: 5.2017e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 179ms/step - accuracy: 0.2275 - auc: 0.7432 - f1_macro: 0.1353 - f1_weighted: 0.1546 - loss: 4.6028 - top5_accuracy: 0.4749 - val_accuracy: 0.1469 - val_auc: 0.7951 - val_f1_macro: 0.0805 - val_f1_weighted: 0.1102 - val_loss: 4.9168 - val_top5_accuracy: 0.3255 - learning_rate: 5.2017e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.2274 - auc: 0.7442 - f1_macro: 0.1383 - f1_weighted: 0.1567 - loss: 4.5982 - top5_accuracy: 0.4773\n",
            "Epoch 67: ReduceLROnPlateau reducing learning rate to 2.600874950076104e-06.\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 179ms/step - accuracy: 0.2274 - auc: 0.7442 - f1_macro: 0.1383 - f1_weighted: 0.1567 - loss: 4.5982 - top5_accuracy: 0.4773 - val_accuracy: 0.1436 - val_auc: 0.7944 - val_f1_macro: 0.0788 - val_f1_weighted: 0.1076 - val_loss: 4.9230 - val_top5_accuracy: 0.3233 - learning_rate: 5.2017e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.2276 - auc: 0.7444 - f1_macro: 0.1369 - f1_weighted: 0.1565 - loss: 4.5907 - top5_accuracy: 0.4822 - val_accuracy: 0.1475 - val_auc: 0.7989 - val_f1_macro: 0.0781 - val_f1_weighted: 0.1084 - val_loss: 4.9045 - val_top5_accuracy: 0.3228 - learning_rate: 2.6009e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.2325 - auc: 0.7444 - f1_macro: 0.1414 - f1_weighted: 0.1602 - loss: 4.5902 - top5_accuracy: 0.4847 - val_accuracy: 0.1475 - val_auc: 0.7968 - val_f1_macro: 0.0782 - val_f1_weighted: 0.1088 - val_loss: 4.9056 - val_top5_accuracy: 0.3228 - learning_rate: 2.6009e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.2287 - auc: 0.7450 - f1_macro: 0.1385 - f1_weighted: 0.1565 - loss: 4.5890 - top5_accuracy: 0.4836 - val_accuracy: 0.1491 - val_auc: 0.7974 - val_f1_macro: 0.0783 - val_f1_weighted: 0.1097 - val_loss: 4.9061 - val_top5_accuracy: 0.3255 - learning_rate: 2.6009e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 181ms/step - accuracy: 0.2296 - auc: 0.7440 - f1_macro: 0.1393 - f1_weighted: 0.1576 - loss: 4.5829 - top5_accuracy: 0.4833 - val_accuracy: 0.1486 - val_auc: 0.7963 - val_f1_macro: 0.0780 - val_f1_weighted: 0.1095 - val_loss: 4.9047 - val_top5_accuracy: 0.3250 - learning_rate: 2.6009e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.2328 - auc: 0.7444 - f1_macro: 0.1413 - f1_weighted: 0.1602 - loss: 4.5842 - top5_accuracy: 0.4860 - val_accuracy: 0.1475 - val_auc: 0.7970 - val_f1_macro: 0.0784 - val_f1_weighted: 0.1088 - val_loss: 4.8980 - val_top5_accuracy: 0.3250 - learning_rate: 2.6009e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 182ms/step - accuracy: 0.2344 - auc: 0.7455 - f1_macro: 0.1418 - f1_weighted: 0.1615 - loss: 4.5801 - top5_accuracy: 0.4879 - val_accuracy: 0.1486 - val_auc: 0.7968 - val_f1_macro: 0.0790 - val_f1_weighted: 0.1094 - val_loss: 4.8999 - val_top5_accuracy: 0.3255 - learning_rate: 2.6009e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.2308 - auc: 0.7448 - f1_macro: 0.1386 - f1_weighted: 0.1577 - loss: 4.5775 - top5_accuracy: 0.4901 - val_accuracy: 0.1486 - val_auc: 0.7963 - val_f1_macro: 0.0794 - val_f1_weighted: 0.1100 - val_loss: 4.9050 - val_top5_accuracy: 0.3244 - learning_rate: 2.6009e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.2375 - auc: 0.7456 - f1_macro: 0.1451 - f1_weighted: 0.1638 - loss: 4.5758 - top5_accuracy: 0.4898 - val_accuracy: 0.1480 - val_auc: 0.7964 - val_f1_macro: 0.0793 - val_f1_weighted: 0.1098 - val_loss: 4.9084 - val_top5_accuracy: 0.3250 - learning_rate: 2.6009e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 180ms/step - accuracy: 0.2358 - auc: 0.7460 - f1_macro: 0.1411 - f1_weighted: 0.1620 - loss: 4.5728 - top5_accuracy: 0.4877 - val_accuracy: 0.1486 - val_auc: 0.7969 - val_f1_macro: 0.0797 - val_f1_weighted: 0.1095 - val_loss: 4.9063 - val_top5_accuracy: 0.3233 - learning_rate: 2.6009e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m134/350\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 173ms/step - accuracy: 0.2387 - auc: 0.7467 - f1_macro: 0.1317 - f1_weighted: 0.1636 - loss: 4.5658 - top5_accuracy: 0.4875"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-a89932370028>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m history = experiment.run_experiment(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/FACULDADE/mestrado/classes.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, epochs, callbacks)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         history = self.model.fit(\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[1;32m    219\u001b[0m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\u001b[0m in \u001b[0;36mhas_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       return gen_optional_ops.optional_has_value(\n\u001b[0m\u001b[1;32m    177\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\u001b[0m in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    173\u001b[0m         _ctx, \"OptionalHasValue\", name, optional)\n\u001b[1;32m    174\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('densenet_s_test2.h5')"
      ],
      "metadata": {
        "id": "F9p44GTF0ygZ",
        "outputId": "900cbbae-bbf4-4c22-89b1-341880cf6cde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('densenet_s_test2.h5')"
      ],
      "metadata": {
        "id": "mRGs2BUu1CLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# Plotting Training and Validation Accuracy and Loss\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "# Plotting Accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_accuracy, label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ulFTVQLWgN-K",
        "outputId": "11f6e43d-0240-46b1-c66b-a38ee7bac01d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-d9bc1519c7e6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Plotting Training and Validation Accuracy and Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('densenet_s_test2.h5')"
      ],
      "metadata": {
        "id": "xkojNGcWg9xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet Grayscale Augmentation - With Oversampling"
      ],
      "metadata": {
        "id": "H6uPhf0RTocm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def dense_layer(x, growth_rate):\n",
        "#     \"\"\"Single layer inside a dense block.\"\"\"\n",
        "#     out = BatchNormalization()(x)\n",
        "#     out = ReLU()(out)\n",
        "#     out = Conv2D(growth_rate, (3, 3), padding='same', kernel_regularizer=l2(1e-4))(out)\n",
        "#     x = Concatenate()([x, out])  # Concatenate input and output (dense connection)\n",
        "#     return x\n",
        "\n",
        "# def dense_block(x, num_layers, growth_rate):\n",
        "#     \"\"\"Dense block with several dense layers.\"\"\"\n",
        "#     for _ in range(num_layers):\n",
        "#         x = dense_layer(x, growth_rate)\n",
        "#     return x\n",
        "\n",
        "# def transition_layer(x, reduction=0.5):\n",
        "#     \"\"\"Reduces spatial size and number of filters.\"\"\"\n",
        "#     filters = int(tf.keras.backend.int_shape(x)[-1] * reduction)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = ReLU()(x)\n",
        "#     x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=l2(1e-4))(x)\n",
        "#     x = AveragePooling2D((2, 2), strides=2)(x)\n",
        "#     return x\n",
        "\n",
        "# def build_densenet(input_shape=(224, 224, 3), num_classes=202, growth_rate=32):\n",
        "#     inputs = Input(shape=input_shape)\n",
        "\n",
        "#     # Initial conv\n",
        "#     x = Conv2D(64, (7, 7), strides=2, padding='same', kernel_regularizer=l2(1e-4))(inputs)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = ReLU()(x)\n",
        "#     x = AveragePooling2D((3, 3), strides=2, padding='same')(x)\n",
        "\n",
        "#     # Dense Block 1\n",
        "#     x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "#     x = transition_layer(x)\n",
        "\n",
        "#     # Dense Block 2\n",
        "#     x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "#     x = transition_layer(x)\n",
        "\n",
        "#     # Dense Block 3\n",
        "#     x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "#     x = transition_layer(x)\n",
        "\n",
        "#     # Dense Block 4\n",
        "#     x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "\n",
        "#     # Classification\n",
        "#     x = GlobalAveragePooling2D()(x)\n",
        "#     outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "#     return Model(inputs, outputs)\n",
        "\n",
        "# model = build_densenet()\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "#     loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "#     metrics=metrics\n",
        "# )\n",
        "\n",
        "# model.summary()\n"
      ],
      "metadata": {
        "id": "f6abK5wCTqtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Initialize the preprocessor\n",
        "# batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "# image_size = (224, 224)\n",
        "\n",
        "# preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# # Store results\n",
        "# results = {}\n",
        "\n",
        "# print(f\"\\nTraining with augmentation: greysclae\")\n",
        "\n",
        "# model = build_densenet()\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "#     loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "#     metrics=metrics\n",
        "# )\n",
        "\n",
        "# train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment='grayscale_plus', oversampling=True, shuffle=True)\n",
        "# train_ds_sampled, class_names = preprocess.load_img(data_dir=\"data/rare_species/train_sampled\", minority_class=minority_class, augment='grayscale_plus', oversampling=True, shuffle=True)\n",
        "# val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment='grayscale', oversampling=False)\n",
        "# test_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/test\", minority_class=minority_class, augment='grayscale', oversampling=False)\n",
        "\n",
        "# # Initialize the experiment\n",
        "# experiment = Experiment(\n",
        "#     model=model,\n",
        "#     train_ds=train_ds_sampled,\n",
        "#     val_ds=val_ds,\n",
        "#     experiment_name=f\"densenet_with_gray_scale_oversampling_2\", # MUDAR NOME!!!!!!!!!!!!\n",
        "#     batch_size=32,\n",
        "#     image_size=(224, 224),\n",
        "#     save_model = False\n",
        "# )\n",
        "\n",
        "# # Run the experiment\n",
        "# history = experiment.run_experiment(callbacks=callbacks, epochs=40)\n",
        "\n",
        "# # Predict entire validation set at once\n",
        "# preds = model.predict(val_ds)\n",
        "# y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "# # Extract true labels in order\n",
        "# y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "# # Compute metrics\n",
        "# f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "# f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "# precision = precision_score(y_true, y_pred, average='weighted')\n",
        "# recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# # Store in results\n",
        "# results['grayscale'] = {\n",
        "#     \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "#     \"f1_macro\": f1_macro,\n",
        "#     \"f1_weighted\": f1_weighted,\n",
        "#     \"precision\": precision,\n",
        "#     \"recall\": recall\n",
        "# }\n",
        "\n",
        "# print(f\"Finished '{'grayscale'}'\")\n",
        "# print(f\"  Accuracy:      {results['grayscale']['accuracy']:.4f}\")\n",
        "# print(f\"  F1 (macro):    {results['grayscale']['f1_macro']:.4f}\")\n",
        "# print(f\"  F1 (weighted): {results['grayscale']['f1_weighted']:.4f}\")\n",
        "# print(f\"  Precision:     {results['garyscale']['precision']:.4f}\")\n",
        "# print(f\"  Recall:        {results['grayscale']['recall']:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "BCoYtu8UTwhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Store in results\n",
        "# results['grayscale'] = {\n",
        "#     \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "#     \"f1_macro\": f1_macro,\n",
        "#     \"f1_weighted\": f1_weighted,\n",
        "#     \"precision\": precision,\n",
        "#     \"recall\": recall\n",
        "# }\n",
        "\n",
        "# print(f\"Finished '{'grayscale'}'\")\n",
        "# print(f\"  Accuracy:      {results['grayscale']['accuracy']:.4f}\")\n",
        "# print(f\"  F1 (macro):    {results['grayscale']['f1_macro']:.4f}\")\n",
        "# print(f\"  F1 (weighted): {results['grayscale']['f1_weighted']:.4f}\")\n",
        "# print(f\"  Precision:     {results['grayscale']['precision']:.4f}\")\n",
        "# print(f\"  Recall:        {results['grayscale']['recall']:.4f}\")\n",
        "\n",
        "# # Clear memory to avoid OOM\n",
        "# del model\n",
        "# del experiment\n",
        "# K.clear_session()\n",
        "# gc.collect()"
      ],
      "metadata": {
        "id": "tdVoJStTWkF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet Medium Augmentation - With Oversampling"
      ],
      "metadata": {
        "id": "iai7uSJwXBY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def dense_layer(x, growth_rate):\n",
        "#     \"\"\"Single layer inside a dense block.\"\"\"\n",
        "#     out = BatchNormalization()(x)\n",
        "#     out = ReLU()(out)\n",
        "#     out = Conv2D(growth_rate, (3, 3), padding='same', kernel_regularizer=l2(1e-4))(out)\n",
        "#     x = Concatenate()([x, out])  # Concatenate input and output (dense connection)\n",
        "#     return x\n",
        "\n",
        "# def dense_block(x, num_layers, growth_rate):\n",
        "#     \"\"\"Dense block with several -dense layers.\"\"\"\n",
        "#     for _ in range(num_layers):\n",
        "#         x = dense_layer(x, growth_rate)\n",
        "#     return x\n",
        "\n",
        "# def transition_layer(x, reduction=0.5):\n",
        "#     \"\"\"Reduces spatial size and number of filters.\"\"\"\n",
        "#     filters = int(tf.keras.backend.int_shape(x)[-1] * reduction)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = ReLU()(x)\n",
        "#     x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=l2(1e-4))(x)\n",
        "#     x = AveragePooling2D((2, 2), strides=2)(x)\n",
        "#     return x\n",
        "\n",
        "# def build_densenet(input_shape=(224, 224, 3), num_classes=202, growth_rate=32):\n",
        "#     inputs = Input(shape=input_shape)\n",
        "\n",
        "#     # Initial conv\n",
        "#     x = Conv2D(64, (7, 7), strides=2, padding='same', kernel_regularizer=l2(1e-4))(inputs)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = ReLU()(x)\n",
        "#     x = AveragePooling2D((3, 3), strides=2, padding='same')(x)\n",
        "\n",
        "#     # Dense Block 1\n",
        "#     x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "#     x = transition_layer(x)\n",
        "\n",
        "#     # Dense Block 2\n",
        "#     x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "#     x = transition_layer(x)\n",
        "\n",
        "#     # Dense Block 3\n",
        "#     x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "#     x = transition_layer(x)\n",
        "\n",
        "#     # Dense Block 4\n",
        "#     x = dense_block(x, num_layers=4, growth_rate=growth_rate)\n",
        "\n",
        "#     # Classification\n",
        "#     x = GlobalAveragePooling2D()(x)\n",
        "#     outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "#     return Model(inputs, outputs)\n",
        "\n",
        "# model = build_densenet()\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "#     loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "#     metrics=metrics\n",
        "# )\n",
        "\n",
        "# model.summary()\n"
      ],
      "metadata": {
        "id": "JjXUDvfdXEXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Initialize the preprocessor\n",
        "# batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "# image_size = (224, 224)\n",
        "\n",
        "# preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "# # Store results\n",
        "# results = {}\n",
        "\n",
        "# print(f\"\\nTraining with augmentation: medium\")\n",
        "\n",
        "# model = build_densenet()\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "#     loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "#     metrics=metrics\n",
        "# )\n",
        "\n",
        "# train_ds, class_names = preprocess.load_img(data_dir=\"data/rare_species/train\", minority_class=minority_class, augment='medium', oversampling=True, shuffle=True)\n",
        "# train_ds_sampled, class_names = preprocess.load_img(data_dir=\"data/rare_species/train_sampled\", minority_class=minority_class, augment='medium', oversampling=True, shuffle=True)\n",
        "# val_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/val\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "# test_ds, _ = preprocess.load_img(data_dir=\"data/rare_species/test\", minority_class=minority_class, augment=None, oversampling=False)\n",
        "\n",
        "# # Initialize the experiment\n",
        "# experiment = Experiment(\n",
        "#     model=model,\n",
        "#     train_ds=train_ds_sampled,\n",
        "#     val_ds=val_ds,\n",
        "#     experiment_name=f\"densenet_with_medium_oversampling_2\", # MUDAR NOME!!!!!!!!!!!!\n",
        "#     batch_size=32,\n",
        "#     image_size=(224, 224),\n",
        "#     save_model = False\n",
        "# )\n",
        "\n",
        "# # Run the experiment\n",
        "# history = experiment.run_experiment(callbacks=callbacks, epochs=40)\n",
        "\n",
        "# # Predict entire validation set at once\n",
        "# preds = model.predict(val_ds)\n",
        "# y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "# # Extract true labels in order\n",
        "# y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in val_ds])\n",
        "\n",
        "# # Compute metrics\n",
        "# f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "# f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "# precision = precision_score(y_true, y_pred, average='weighted')\n",
        "# recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# # Store in results\n",
        "# results['medium'] = {\n",
        "#     \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "#     \"f1_macro\": f1_macro,\n",
        "#     \"f1_weighted\": f1_weighted,\n",
        "#     \"precision\": precision,\n",
        "#     \"recall\": recall\n",
        "# }\n",
        "\n",
        "# print(f\"Finished '{'medium'}'\")\n",
        "# print(f\"  Accuracy:      {results['medium']['accuracy']:.4f}\")\n",
        "# print(f\"  F1 (macro):    {results['medium']['f1_macro']:.4f}\")\n",
        "# print(f\"  F1 (weighted): {results['medium']['f1_weighted']:.4f}\")\n",
        "# print(f\"  Precision:     {results['medium']['precision']:.4f}\")\n",
        "# print(f\"  Recall:        {results['medium']['recall']:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9uS1-SFqXJr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'augmentation'})\n",
        "\n",
        "# Display the table\n",
        "display(results_df.round(4))"
      ],
      "metadata": {
        "id": "TS3MRTMvXfnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# acc = history.history['acc']\n",
        "# val_acc = history.history['val_acc']\n",
        "# loss = history.history['loss']\n",
        "# val_loss = history.history['val_loss']\n",
        "\n",
        "# epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "# plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "# plt.title('Training and validation accuracy')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.figure()\n",
        "\n",
        "# plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "# plt.title('Training and validation loss')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "AoWaQSjNeBIp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}