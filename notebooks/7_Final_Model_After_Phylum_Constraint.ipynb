{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "02e283f2",
      "metadata": {
        "id": "02e283f2"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "# **1.** Environment Setup\n",
        "\n",
        "<div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d815d3b",
      "metadata": {
        "id": "3d815d3b"
      },
      "source": [
        "## 1.1 Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2f08c574",
      "metadata": {},
      "outputs": [],
      "source": [
        "base_path = \"../\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "89ef556b",
      "metadata": {
        "id": "89ef556b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/brunasimoes/Desktop/nova_ims/2_semester/Trimestral/deep_learning/deep-learning-project/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from keras import regularizers\n",
        "from classes import *\n",
        "from functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "55268a9a",
      "metadata": {
        "id": "55268a9a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Dropout, Input, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.metrics import AUC, F1Score, CategoricalAccuracy, TopKCategoricalAccuracy\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0hMHy4gsBGa-",
      "metadata": {
        "id": "0hMHy4gsBGa-"
      },
      "outputs": [],
      "source": [
        "#Load the DataFrames from the .pkl files\n",
        "with open(os.path.join(base_path,\"data/train_df.pkl\"), \"rb\") as f:\n",
        "     train_df = pickle.load(f)\n",
        "\n",
        "with open(os.path.join(base_path,\"data/val_df.pkl\"), \"rb\") as f:\n",
        "     val_df = pickle.load(f)\n",
        "\n",
        "with open(os.path.join(base_path,\"data/test_df.pkl\"), \"rb\") as f:\n",
        "     test_df = pickle.load(f)\n",
        "\n",
        "with open(os.path.join(base_path,\"data/train_df_sampled.pkl\"), \"rb\") as f:\n",
        "     train_df_sampled = pickle.load(f)\n",
        "\n",
        "with open(os.path.join(base_path,\"data/family_encoder.pkl\"), \"rb\") as f:\n",
        "     family_encoder = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "TyiaZbJsBvxM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyiaZbJsBvxM",
        "outputId": "4bb0f9bb-c342-439d-be25-d6ec518a219d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['accipitridae', 'acipenseridae', 'acroporidae', 'agamidae',\n",
              "       'agariciidae', 'albulidae', 'alcedinidae', 'alligatoridae',\n",
              "       'alopiidae', 'ambystomatidae', 'anatidae', 'anguidae', 'aotidae',\n",
              "       'apidae', 'ardeidae', 'arthroleptidae', 'atelidae', 'attelabidae',\n",
              "       'balaenicipitidae', 'balaenidae', 'balaenopteridae', 'balistidae',\n",
              "       'bombycillidae', 'bovidae', 'brachypteraciidae', 'bucerotidae',\n",
              "       'bufonidae', 'burhinidae', 'cacatuidae', 'callitrichidae',\n",
              "       'callorhinchidae', 'caprimulgidae', 'carabidae', 'carcharhinidae',\n",
              "       'cardiidae', 'carettochelyidae', 'cebidae', 'cerambycidae',\n",
              "       'cercopithecidae', 'cervidae', 'cetorhinidae', 'chaetodontidae',\n",
              "       'chamaeleonidae', 'charadriidae', 'cheirogaleidae', 'chelidae',\n",
              "       'cheloniidae', 'chelydridae', 'ciconiidae', 'coenagrionidae',\n",
              "       'colubridae', 'columbidae', 'conidae', 'cracidae', 'cricetidae',\n",
              "       'crocodylidae', 'cryptobranchidae', 'ctenomyidae', 'cuculidae',\n",
              "       'cyprinodontidae', 'dactyloidae', 'dalatiidae', 'dasyatidae',\n",
              "       'dasypodidae', 'dasyuridae', 'daubentoniidae', 'delphinidae',\n",
              "       'dendrobatidae', 'dendrophylliidae', 'diomedeidae',\n",
              "       'diploastraeidae', 'diplodactylidae', 'elapidae', 'emydidae',\n",
              "       'equidae', 'estrildidae', 'euphylliidae', 'falconidae', 'faviidae',\n",
              "       'formicidae', 'fringillidae', 'fungiidae', 'gavialidae',\n",
              "       'gekkonidae', 'geoemydidae', 'giraffidae', 'glareolidae',\n",
              "       'gliridae', 'gomphidae', 'goodeidae', 'gymnuridae', 'haliotidae',\n",
              "       'helioporidae', 'hemiscylliidae', 'hexanchidae', 'hominidae',\n",
              "       'hyaenidae', 'hylobatidae', 'hynobiidae', 'iguanidae', 'indriidae',\n",
              "       'labridae', 'lacertidae', 'lamnidae', 'laridae', 'latimeriidae',\n",
              "       'lemuridae', 'leporidae', 'lobophylliidae', 'lucanidae',\n",
              "       'lutjanidae', 'manidae', 'mantellidae', 'meandrinidae',\n",
              "       'megapodiidae', 'merlucciidae', 'merulinidae', 'mesitornithidae',\n",
              "       'mimidae', 'motacillidae', 'muscicapidae', 'mustelidae',\n",
              "       'myliobatidae', 'nesospingidae', 'nymphalidae', 'odontophoridae',\n",
              "       'otariidae', 'otididae', 'palinuridae', 'pangasiidae',\n",
              "       'papilionidae', 'paradisaeidae', 'pardalotidae', 'parulidae',\n",
              "       'percidae', 'phasianidae', 'phrynosomatidae', 'phyllomedusidae',\n",
              "       'phyllostomidae', 'pisauridae', 'pittidae', 'platystictidae',\n",
              "       'plethodontidae', 'pleuronectidae', 'pocilloporidae',\n",
              "       'podocnemididae', 'polyprionidae', 'pontoporiidae', 'potoroidae',\n",
              "       'pristidae', 'procellariidae', 'pseudophasmatidae', 'psittacidae',\n",
              "       'psittaculidae', 'pythonidae', 'rajidae', 'rallidae',\n",
              "       'ramphastidae', 'ranidae', 'recurvirostridae', 'rhacophoridae',\n",
              "       'rhinodermatidae', 'rhyacotritonidae', 'salamandridae',\n",
              "       'salmonidae', 'scincidae', 'sciuridae', 'scolopacidae',\n",
              "       'scombridae', 'serranidae', 'siderastreidae', 'siluridae',\n",
              "       'somniosidae', 'soricidae', 'sparidae', 'spheniscidae',\n",
              "       'sphyrnidae', 'squalidae', 'squatinidae', 'stichopodidae',\n",
              "       'strigidae', 'strigopidae', 'syngnathidae', 'testudinidae',\n",
              "       'tettigoniidae', 'theraphosidae', 'thraupidae', 'trionychidae',\n",
              "       'triopsidae', 'trochilidae', 'trogonidae', 'tropiduridae',\n",
              "       'turdidae', 'unionidae', 'urolophidae', 'ursidae', 'vangidae',\n",
              "       'vespertilionidae', 'viperidae', 'vireonidae', 'vombatidae',\n",
              "       'zonitidae'], dtype=object)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_names = family_encoder.classes_\n",
        "\n",
        "class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "803176e3",
      "metadata": {
        "id": "803176e3"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "# **2.** Preprocessing\n",
        "\n",
        "<div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a7ca1ca0",
      "metadata": {
        "id": "a7ca1ca0"
      },
      "outputs": [],
      "source": [
        "minority_class = train_df['family'].value_counts()[train_df['family'].value_counts() < 25].index\n",
        "minority_class=minority_class.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9020e1ec",
      "metadata": {
        "id": "9020e1ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-01 19:46:40.544139: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
            "2025-05-01 19:46:40.544298: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
            "2025-05-01 19:46:40.544303: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
            "2025-05-01 19:46:40.544331: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2025-05-01 19:46:40.544340: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32 ## the less the better because in each epoch the model sees N / batch_size images\n",
        "image_size = (224, 224)\n",
        "\n",
        "preprocess = Preprocessor(image_size=image_size, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58bae18c",
      "metadata": {
        "id": "58bae18c"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "# **3.** Results Analysis\n",
        "\n",
        "<div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c51bd5d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c51bd5d0",
        "outputId": "066ebd59-ee71-40ad-cda6-4392bbce2490"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/brunasimoes/Desktop/nova_ims/2_semester/Trimestral/deep_learning/deep-learning-project/.venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 34 variables whereas the saved optimizer has 6 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "# Load model keras\\\n",
        "model = load_model(os.path.join(base_path,\"project/efficient_net_finetuned_final.keras\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b9376929",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9376929",
        "outputId": "07bdce52-d4f1-46b9-b40f-7b8d35cadd54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8388 files belonging to 202 classes.\n",
            "Found 1797 files belonging to 202 classes.\n"
          ]
        }
      ],
      "source": [
        "# load datasets with efficientnets preprocessing\n",
        "train_ds, _ = preprocess.load_img(\n",
        "    data_dir=os.path.join(base_path,\"data/rare_species/train\"),\n",
        "    minority_class=minority_class,\n",
        "    augment=\"mixup\",\n",
        "    oversampling=False,\n",
        "    shuffle= True,\n",
        "    preprocessing_function=preprocess_input)\n",
        "\n",
        "val_ds, _ = preprocess.load_img(\n",
        "    data_dir=os.path.join(base_path,\"data/rare_species/val\"),\n",
        "    minority_class=[],\n",
        "    augment=None,\n",
        "    shuffle= False,\n",
        "    preprocessing_function=preprocess_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9d22e293",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d22e293",
        "outputId": "becb6f93-7895-4ce4-efe7-63166aa7a730"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-01 19:46:43.737763: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 224ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eaecb56d",
      "metadata": {
        "id": "eaecb56d"
      },
      "source": [
        "### Classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1a7452f6",
      "metadata": {
        "id": "1a7452f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating model: ../project/efficient_net_finetuned_final.keras\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7391    0.9444    0.8293        18\n",
            "           1     0.6429    0.6923    0.6667        13\n",
            "           2     0.6579    0.8065    0.7246        31\n",
            "           3     0.7143    0.5556    0.6250         9\n",
            "           4     0.6364    0.7778    0.7000        18\n",
            "           5     0.6000    0.6000    0.6000         5\n",
            "           6     0.0000    0.0000    0.0000         4\n",
            "           7     0.6667    0.4000    0.5000         5\n",
            "           8     1.0000    0.1111    0.2000         9\n",
            "           9     1.0000    0.3333    0.5000         9\n",
            "          10     0.6364    0.7778    0.7000        27\n",
            "          11     0.7500    0.6667    0.7059         9\n",
            "          12     1.0000    0.5556    0.7143         9\n",
            "          13     1.0000    1.0000    1.0000        22\n",
            "          14     0.7143    0.5556    0.6250         9\n",
            "          15     1.0000    0.5000    0.6667         4\n",
            "          16     0.5909    0.5909    0.5909        22\n",
            "          17     1.0000    0.8000    0.8889         5\n",
            "          18     1.0000    0.5000    0.6667         4\n",
            "          19     0.0000    0.0000    0.0000         5\n",
            "          20     1.0000    0.5000    0.6667         4\n",
            "          21     0.8889    0.8889    0.8889         9\n",
            "          22     1.0000    0.6000    0.7500         5\n",
            "          23     0.6000    0.8333    0.6977        36\n",
            "          24     0.6667    0.4000    0.5000         5\n",
            "          25     0.6512    0.9032    0.7568        31\n",
            "          26     0.7143    0.6818    0.6977        22\n",
            "          27     1.0000    0.6667    0.8000         9\n",
            "          28     0.8000    0.8000    0.8000         5\n",
            "          29     0.7059    0.6667    0.6857        18\n",
            "          30     1.0000    0.4000    0.5714         5\n",
            "          31     1.0000    0.2000    0.3333         5\n",
            "          32     1.0000    0.8889    0.9412         9\n",
            "          33     0.5538    0.9000    0.6857        40\n",
            "          34     0.7000    0.7778    0.7368         9\n",
            "          35     0.6000    0.7500    0.6667         4\n",
            "          36     0.7500    0.6923    0.7200        13\n",
            "          37     1.0000    1.0000    1.0000         4\n",
            "          38     0.6538    0.7556    0.7010        45\n",
            "          39     1.0000    0.2000    0.3333         5\n",
            "          40     0.3333    0.2000    0.2500         5\n",
            "          41     0.8889    0.8889    0.8889         9\n",
            "          42     0.6667    1.0000    0.8000         8\n",
            "          43     0.9000    1.0000    0.9474         9\n",
            "          44     1.0000    0.7500    0.8571         4\n",
            "          45     0.7500    0.7500    0.7500         8\n",
            "          46     0.2000    0.2000    0.2000         5\n",
            "          47     0.4000    0.4000    0.4000         5\n",
            "          48     0.7692    0.7692    0.7692        13\n",
            "          49     0.6667    0.8000    0.7273         5\n",
            "          50     0.6923    0.6923    0.6923        13\n",
            "          51     1.0000    1.0000    1.0000         5\n",
            "          52     1.0000    1.0000    1.0000         5\n",
            "          53     0.7143    0.5556    0.6250         9\n",
            "          54     1.0000    1.0000    1.0000         4\n",
            "          55     0.6364    0.7778    0.7000         9\n",
            "          56     0.3333    0.4444    0.3810         9\n",
            "          57     0.6250    1.0000    0.7692         5\n",
            "          58     0.8000    1.0000    0.8889         4\n",
            "          59     1.0000    0.6000    0.7500         5\n",
            "          60     0.7000    0.7778    0.7368        45\n",
            "          61     0.5000    0.4000    0.4444         5\n",
            "          62     0.5625    0.8182    0.6667        22\n",
            "          63     0.6667    0.5000    0.5714         4\n",
            "          64     1.0000    0.4000    0.5714         5\n",
            "          65     0.5000    0.2000    0.2857         5\n",
            "          66     0.5000    0.7222    0.5909        18\n",
            "          67     1.0000    0.8000    0.8889         5\n",
            "          68     1.0000    0.4000    0.5714         5\n",
            "          69     0.7500    0.7778    0.7636        27\n",
            "          70     0.8000    1.0000    0.8889         4\n",
            "          71     0.5455    0.6667    0.6000         9\n",
            "          72     0.6667    1.0000    0.8000         4\n",
            "          73     0.8000    0.4444    0.5714         9\n",
            "          74     1.0000    0.5000    0.6667         4\n",
            "          75     1.0000    1.0000    1.0000         5\n",
            "          76     0.5714    0.6154    0.5926        13\n",
            "          77     0.5000    0.3333    0.4000         9\n",
            "          78     0.7000    0.7778    0.7368         9\n",
            "          79     0.8571    0.9767    0.9130        43\n",
            "          80     0.7778    0.7778    0.7778         9\n",
            "          81     1.0000    0.8000    0.8889         5\n",
            "          82     1.0000    0.4000    0.5714         5\n",
            "          83     0.8000    1.0000    0.8889         4\n",
            "          84     0.5294    0.6923    0.6000        13\n",
            "          85     1.0000    1.0000    1.0000         4\n",
            "          86     0.5000    0.6000    0.5455         5\n",
            "          87     0.5000    0.4000    0.4444         5\n",
            "          88     1.0000    0.8889    0.9412         9\n",
            "          89     0.6667    1.0000    0.8000         4\n",
            "          90     0.3333    0.2500    0.2857         4\n",
            "          91     0.7500    0.6000    0.6667         5\n",
            "          92     0.3333    0.2500    0.2857         4\n",
            "          93     0.5000    0.2500    0.3333         4\n",
            "          94     0.6667    0.2222    0.3333         9\n",
            "          95     1.0000    1.0000    1.0000         5\n",
            "          96     1.0000    0.7500    0.8571         4\n",
            "          97     0.6667    0.4615    0.5455        13\n",
            "          98     0.0000    0.0000    0.0000         5\n",
            "          99     0.8750    0.7778    0.8235        18\n",
            "         100     1.0000    0.8000    0.8889         5\n",
            "         101     0.6000    0.6667    0.6316         9\n",
            "         102     0.7000    0.7778    0.7368         9\n",
            "         103     0.8000    1.0000    0.8889         4\n",
            "         104     0.8077    0.9545    0.8750        22\n",
            "         105     0.6667    0.5000    0.5714         4\n",
            "         106     0.7778    0.7778    0.7778         9\n",
            "         107     0.8333    0.5556    0.6667         9\n",
            "         108     0.8000    0.8000    0.8000         5\n",
            "         109     1.0000    0.8000    0.8889         5\n",
            "         110     1.0000    0.2000    0.3333         5\n",
            "         111     1.0000    0.5556    0.7143         9\n",
            "         112     1.0000    0.8000    0.8889         5\n",
            "         113     1.0000    0.4000    0.5714         5\n",
            "         114     1.0000    1.0000    1.0000         4\n",
            "         115     0.6667    0.8000    0.7273         5\n",
            "         116     0.3333    0.3333    0.3333         9\n",
            "         117     0.8000    1.0000    0.8889         4\n",
            "         118     0.7500    0.7500    0.7500         4\n",
            "         119     1.0000    0.6000    0.7500         5\n",
            "         120     0.8000    0.8000    0.8000         5\n",
            "         121     0.7273    0.6154    0.6667        13\n",
            "         122     0.5000    0.3077    0.3810        13\n",
            "         123     0.5000    0.8000    0.6154         5\n",
            "         124     1.0000    0.8000    0.8889         5\n",
            "         125     1.0000    1.0000    1.0000         5\n",
            "         126     0.8571    0.6667    0.7500         9\n",
            "         127     1.0000    0.4000    0.5714         5\n",
            "         128     1.0000    0.8000    0.8889         5\n",
            "         129     0.3333    0.2500    0.2857         4\n",
            "         130     1.0000    1.0000    1.0000         4\n",
            "         131     0.8000    0.8000    0.8000         5\n",
            "         132     0.7500    0.7500    0.7500         4\n",
            "         133     0.6000    0.6000    0.6000         5\n",
            "         134     1.0000    1.0000    1.0000         5\n",
            "         135     1.0000    0.8000    0.8889         5\n",
            "         136     1.0000    0.5000    0.6667         4\n",
            "         137     0.7500    0.6000    0.6667         5\n",
            "         138     0.7500    0.7500    0.7500         4\n",
            "         139     0.2500    0.2500    0.2500         4\n",
            "         140     1.0000    1.0000    1.0000         5\n",
            "         141     1.0000    0.4000    0.5714         5\n",
            "         142     0.5763    0.8500    0.6869        40\n",
            "         143     1.0000    1.0000    1.0000         4\n",
            "         144     0.6667    0.4444    0.5333         9\n",
            "         145     0.6667    0.4000    0.5000         5\n",
            "         146     1.0000    0.4000    0.5714         5\n",
            "         147     0.8000    1.0000    0.8889         4\n",
            "         148     0.6667    0.8000    0.7273         5\n",
            "         149     0.6667    0.4000    0.5000         5\n",
            "         150     0.5000    0.3846    0.4348        13\n",
            "         151     0.7500    0.7500    0.7500         4\n",
            "         152     0.6667    0.8889    0.7619        18\n",
            "         153     0.8571    0.6667    0.7500         9\n",
            "         154     1.0000    0.8889    0.9412         9\n",
            "         155     0.7143    0.3846    0.5000        13\n",
            "         156     1.0000    0.8000    0.8889         5\n",
            "         157     0.6667    0.5000    0.5714         4\n",
            "         158     0.5385    0.5385    0.5385        13\n",
            "         159     1.0000    1.0000    1.0000         4\n",
            "         160     0.7000    0.7778    0.7368         9\n",
            "         161     1.0000    0.7500    0.8571         4\n",
            "         162     0.0000    0.0000    0.0000         9\n",
            "         163     0.5082    0.7750    0.6139        40\n",
            "         164     0.3333    0.2000    0.2500         5\n",
            "         165     0.7500    0.6000    0.6667         5\n",
            "         166     0.7143    1.0000    0.8333         5\n",
            "         167     0.8750    0.7778    0.8235         9\n",
            "         168     0.6667    0.8000    0.7273         5\n",
            "         169     0.6667    0.7692    0.7143        13\n",
            "         170     0.6667    0.8000    0.7273         5\n",
            "         171     0.4000    0.5000    0.4444         4\n",
            "         172     1.0000    0.6000    0.7500         5\n",
            "         173     0.6667    0.8000    0.7273         5\n",
            "         174     0.6667    0.6667    0.6667         9\n",
            "         175     0.7000    0.7778    0.7368        18\n",
            "         176     0.0000    0.0000    0.0000        13\n",
            "         177     0.0000    0.0000    0.0000         4\n",
            "         178     1.0000    0.6000    0.7500         5\n",
            "         179     0.7778    0.7778    0.7778         9\n",
            "         180     1.0000    0.4000    0.5714         5\n",
            "         181     1.0000    0.8000    0.8889         5\n",
            "         182     0.7500    0.6667    0.7059         9\n",
            "         183     0.8000    0.8889    0.8421         9\n",
            "         184     0.8000    1.0000    0.8889         4\n",
            "         185     1.0000    1.0000    1.0000         5\n",
            "         186     0.5882    0.7692    0.6667        13\n",
            "         187     0.7500    0.6000    0.6667         5\n",
            "         188     1.0000    0.4000    0.5714         5\n",
            "         189     0.8000    0.9231    0.8571        13\n",
            "         190     1.0000    0.7500    0.8571         4\n",
            "         191     0.6000    0.6000    0.6000         5\n",
            "         192     0.8333    0.5556    0.6667         9\n",
            "         193     0.5294    1.0000    0.6923         9\n",
            "         194     0.4286    0.7500    0.5455         4\n",
            "         195     1.0000    0.7778    0.8750         9\n",
            "         196     0.6000    0.7500    0.6667         4\n",
            "         197     0.5714    0.4444    0.5000         9\n",
            "         198     0.8000    0.8000    0.8000         5\n",
            "         199     0.6000    0.6000    0.6000         5\n",
            "         200     0.5000    0.5000    0.5000         4\n",
            "         201     0.8000    1.0000    0.8889         4\n",
            "\n",
            "    accuracy                         0.7006      1797\n",
            "   macro avg     0.7439    0.6621    0.6770      1797\n",
            "weighted avg     0.7132    0.7006    0.6859      1797\n",
            "\n",
            "Accuracy     : 0.7006121313299944\n",
            "F1 (macro)   : 0.677013335354349\n",
            "Precision    : 0.7438634419993236\n",
            "Recall       : 0.6620633202018337\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-01 19:47:15.636311: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "/Users/brunasimoes/Desktop/nova_ims/2_semester/Trimestral/deep_learning/deep-learning-project/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/brunasimoes/Desktop/nova_ims/2_semester/Trimestral/deep_learning/deep-learning-project/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/brunasimoes/Desktop/nova_ims/2_semester/Trimestral/deep_learning/deep-learning-project/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/brunasimoes/Desktop/nova_ims/2_semester/Trimestral/deep_learning/deep-learning-project/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([  0,   0,   0, ..., 201, 201, 201]),\n",
              " array([  0,   0,   0, ..., 201, 201, 201]))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_metric(val_ds, os.path.join(base_path,\"project/efficient_net_finetuned_final.keras\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9197a567",
      "metadata": {},
      "source": [
        "### Incorporate phylum"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dade6ad",
      "metadata": {
        "id": "8dade6ad"
      },
      "source": [
        "#### Histogram of model confidence, divided by correctly and incorrectly classified images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e38640ab",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-01 19:47:49.690728: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8388, 224, 224, 3)\n",
            "(8388, 202)\n"
          ]
        }
      ],
      "source": [
        "# Create a list of all images and labels\n",
        "train_images = []\n",
        "train_labels = []\n",
        "\n",
        "for batch in train_ds:\n",
        "    images_batch, labels_batch = batch\n",
        "    train_images.append(images_batch.numpy())\n",
        "    train_labels.append(labels_batch.numpy())\n",
        "\n",
        "# Stack properly\n",
        "train_images = np.vstack(train_images)\n",
        "train_labels = np.vstack(train_labels)\n",
        "\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bb06c8d1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 299ms/step\n"
          ]
        }
      ],
      "source": [
        "# Predict all train images\n",
        "pred_probs_all = model.predict(train_ds, verbose=1)\n",
        "y_pred = np.argmax(pred_probs_all, axis=1)\n",
        "y_true = train_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d20e6c8",
      "metadata": {
        "id": "1d20e6c8"
      },
      "source": [
        "#### Trying to incorporate phylum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e51884f0",
      "metadata": {
        "id": "e51884f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-01 19:49:39.489082: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 379ms/step\n"
          ]
        }
      ],
      "source": [
        "# Unbatch train_ds into list\n",
        "val_images = []\n",
        "val_labels = []\n",
        "\n",
        "for img, label in val_ds.unbatch():\n",
        "    val_images.append(img.numpy())\n",
        "    val_labels.append(label.numpy())\n",
        "\n",
        "val_images = np.array(val_images)\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "# Predict all val images\n",
        "pred_probs_all_val = model.predict(val_images, verbose=1)\n",
        "y_pred = np.argmax(pred_probs_all, axis=1)\n",
        "y_true = val_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3182fc5e",
      "metadata": {
        "id": "3182fc5e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# create family:phylum dicionary\n",
        "meta = pd.read_csv('../data/rare_species/metadata.csv')\n",
        "dup = meta.groupby('family')['phylum'].nunique()\n",
        "family_to_phylum = dict(zip(meta['family'], meta['phylum']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5c182f96",
      "metadata": {
        "id": "5c182f96"
      },
      "outputs": [],
      "source": [
        "# --- 2) Prepare true labels & names ---\n",
        "# train_labels: your true labels, shape (11200,) or one-hot (11200,202)\n",
        "# class_names: list of length 202 mapping index→family string\n",
        "labels = np.argmax(val_labels, axis=1) # family# prediction, not one-hot-encoded\n",
        "y_true_fam   = np.array([class_names[i] for i in labels])\n",
        "y_true_phyl  = np.array([family_to_phylum[f] for f in y_true_fam])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5238f7c4",
      "metadata": {
        "id": "5238f7c4"
      },
      "outputs": [],
      "source": [
        "# --- 3) Baseline predictions & phylum check ---\n",
        "y_pred       = np.argmax(pred_probs_all_val, axis=1)\n",
        "y_pred_fam   = np.array([class_names[i] for i in y_pred])\n",
        "y_pred_phyl  = np.array([family_to_phylum[f] for f in y_pred_fam])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "49c97d0f",
      "metadata": {
        "id": "49c97d0f"
      },
      "outputs": [],
      "source": [
        "# a dictionary phylum:[list of indices of classes that belong to that phylum]\n",
        "phylum_to_inds = {}\n",
        "for idx, fam in enumerate(class_names):\n",
        "    ph = family_to_phylum[fam]\n",
        "    phylum_to_inds.setdefault(ph, []).append(idx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "a924cea4",
      "metadata": {
        "id": "a924cea4"
      },
      "outputs": [],
      "source": [
        "# --- 4) Hierarchical override logic ---\n",
        "y_pred_hier = y_pred.copy()\n",
        "for i, probs in enumerate(pred_probs_all_val):\n",
        "    # if predicted phylum ≠ true phylum, force to best within true phylum\n",
        "    if y_pred_phyl[i] != y_true_phyl[i]:\n",
        "        valid_idx = phylum_to_inds[y_true_phyl[i]]\n",
        "        y_pred_hier[i] = valid_idx[np.argmax(probs[valid_idx])]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6535eee7",
      "metadata": {
        "id": "6535eee7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline overall accuracy:     0.7006\n",
            "Hierarchical override accuracy:0.7101\n"
          ]
        }
      ],
      "source": [
        "# --- 5) Overall accuracy comparison ---\n",
        "acc_base  = accuracy_score(labels, y_pred)\n",
        "acc_hier  = accuracy_score(labels, y_pred_hier)\n",
        "print(f\"Baseline overall accuracy:     {acc_base:.4f}\")\n",
        "print(f\"Hierarchical override accuracy:{acc_hier:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "fd706552",
      "metadata": {
        "id": "fd706552"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report with original predictions:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7391    0.9444    0.8293        18\n",
            "           1     0.6429    0.6923    0.6667        13\n",
            "           2     0.6842    0.8387    0.7536        31\n",
            "           3     0.7143    0.5556    0.6250         9\n",
            "           4     0.6667    0.7778    0.7179        18\n",
            "           5     0.6000    0.6000    0.6000         5\n",
            "           6     0.0000    0.0000    0.0000         4\n",
            "           7     0.6667    0.4000    0.5000         5\n",
            "           8     1.0000    0.1111    0.2000         9\n",
            "           9     1.0000    0.3333    0.5000         9\n",
            "          10     0.6562    0.7778    0.7119        27\n",
            "          11     0.7500    0.6667    0.7059         9\n",
            "          12     1.0000    0.5556    0.7143         9\n",
            "          13     1.0000    1.0000    1.0000        22\n",
            "          14     0.8333    0.5556    0.6667         9\n",
            "          15     1.0000    0.5000    0.6667         4\n",
            "          16     0.5909    0.5909    0.5909        22\n",
            "          17     1.0000    1.0000    1.0000         5\n",
            "          18     1.0000    0.5000    0.6667         4\n",
            "          19     0.0000    0.0000    0.0000         5\n",
            "          20     1.0000    0.5000    0.6667         4\n",
            "          21     0.8889    0.8889    0.8889         9\n",
            "          22     1.0000    0.6000    0.7500         5\n",
            "          23     0.5882    0.8333    0.6897        36\n",
            "          24     0.6667    0.4000    0.5000         5\n",
            "          25     0.6512    0.9032    0.7568        31\n",
            "          26     0.6522    0.6818    0.6667        22\n",
            "          27     1.0000    0.6667    0.8000         9\n",
            "          28     0.8000    0.8000    0.8000         5\n",
            "          29     0.7059    0.6667    0.6857        18\n",
            "          30     1.0000    0.4000    0.5714         5\n",
            "          31     1.0000    0.2000    0.3333         5\n",
            "          32     1.0000    0.8889    0.9412         9\n",
            "          33     0.5455    0.9000    0.6792        40\n",
            "          34     1.0000    1.0000    1.0000         9\n",
            "          35     0.6000    0.7500    0.6667         4\n",
            "          36     0.7500    0.6923    0.7200        13\n",
            "          37     1.0000    1.0000    1.0000         4\n",
            "          38     0.6538    0.7556    0.7010        45\n",
            "          39     1.0000    0.2000    0.3333         5\n",
            "          40     0.3333    0.2000    0.2500         5\n",
            "          41     0.8889    0.8889    0.8889         9\n",
            "          42     0.6667    1.0000    0.8000         8\n",
            "          43     0.9000    1.0000    0.9474         9\n",
            "          44     1.0000    0.7500    0.8571         4\n",
            "          45     0.7500    0.7500    0.7500         8\n",
            "          46     0.3333    0.2000    0.2500         5\n",
            "          47     0.4000    0.4000    0.4000         5\n",
            "          48     0.7692    0.7692    0.7692        13\n",
            "          49     0.6667    0.8000    0.7273         5\n",
            "          50     0.6923    0.6923    0.6923        13\n",
            "          51     1.0000    1.0000    1.0000         5\n",
            "          52     1.0000    1.0000    1.0000         5\n",
            "          53     0.7143    0.5556    0.6250         9\n",
            "          54     1.0000    1.0000    1.0000         4\n",
            "          55     0.6364    0.7778    0.7000         9\n",
            "          56     0.3333    0.4444    0.3810         9\n",
            "          57     0.6250    1.0000    0.7692         5\n",
            "          58     0.8000    1.0000    0.8889         4\n",
            "          59     1.0000    0.6000    0.7500         5\n",
            "          60     0.6863    0.7778    0.7292        45\n",
            "          61     0.4000    0.4000    0.4000         5\n",
            "          62     0.5625    0.8182    0.6667        22\n",
            "          63     0.6667    0.5000    0.5714         4\n",
            "          64     1.0000    0.4000    0.5714         5\n",
            "          65     0.5000    0.2000    0.2857         5\n",
            "          66     0.4815    0.7222    0.5778        18\n",
            "          67     1.0000    0.8000    0.8889         5\n",
            "          68     1.0000    0.4000    0.5714         5\n",
            "          69     0.7500    0.7778    0.7636        27\n",
            "          70     0.8000    1.0000    0.8889         4\n",
            "          71     0.5455    0.6667    0.6000         9\n",
            "          72     0.6667    1.0000    0.8000         4\n",
            "          73     0.8333    0.5556    0.6667         9\n",
            "          74     1.0000    0.5000    0.6667         4\n",
            "          75     1.0000    1.0000    1.0000         5\n",
            "          76     0.6154    0.6154    0.6154        13\n",
            "          77     0.4286    0.3333    0.3750         9\n",
            "          78     0.7000    0.7778    0.7368         9\n",
            "          79     0.9130    0.9767    0.9438        43\n",
            "          80     0.7000    0.7778    0.7368         9\n",
            "          81     1.0000    0.8000    0.8889         5\n",
            "          82     1.0000    0.4000    0.5714         5\n",
            "          83     0.8000    1.0000    0.8889         4\n",
            "          84     0.5294    0.6923    0.6000        13\n",
            "          85     1.0000    1.0000    1.0000         4\n",
            "          86     0.5000    0.6000    0.5455         5\n",
            "          87     0.5000    0.4000    0.4444         5\n",
            "          88     1.0000    1.0000    1.0000         9\n",
            "          89     0.6667    1.0000    0.8000         4\n",
            "          90     0.3333    0.2500    0.2857         4\n",
            "          91     1.0000    0.6000    0.7500         5\n",
            "          92     0.2500    0.2500    0.2500         4\n",
            "          93     0.5000    0.2500    0.3333         4\n",
            "          94     0.6667    0.2222    0.3333         9\n",
            "          95     1.0000    1.0000    1.0000         5\n",
            "          96     0.7500    0.7500    0.7500         4\n",
            "          97     0.6667    0.4615    0.5455        13\n",
            "          98     0.0000    0.0000    0.0000         5\n",
            "          99     0.8235    0.7778    0.8000        18\n",
            "         100     1.0000    0.8000    0.8889         5\n",
            "         101     0.6000    0.6667    0.6316         9\n",
            "         102     0.7000    0.7778    0.7368         9\n",
            "         103     0.8000    1.0000    0.8889         4\n",
            "         104     0.8077    0.9545    0.8750        22\n",
            "         105     0.6667    0.5000    0.5714         4\n",
            "         106     0.7778    0.7778    0.7778         9\n",
            "         107     0.8333    0.5556    0.6667         9\n",
            "         108     1.0000    0.8000    0.8889         5\n",
            "         109     0.8000    0.8000    0.8000         5\n",
            "         110     1.0000    0.2000    0.3333         5\n",
            "         111     0.8333    0.5556    0.6667         9\n",
            "         112     1.0000    0.8000    0.8889         5\n",
            "         113     1.0000    0.4000    0.5714         5\n",
            "         114     1.0000    1.0000    1.0000         4\n",
            "         115     0.6667    0.8000    0.7273         5\n",
            "         116     0.3333    0.3333    0.3333         9\n",
            "         117     0.8000    1.0000    0.8889         4\n",
            "         118     0.7500    0.7500    0.7500         4\n",
            "         119     1.0000    0.6000    0.7500         5\n",
            "         120     0.8000    0.8000    0.8000         5\n",
            "         121     0.7273    0.6154    0.6667        13\n",
            "         122     0.4444    0.3077    0.3636        13\n",
            "         123     0.5000    0.8000    0.6154         5\n",
            "         124     1.0000    1.0000    1.0000         5\n",
            "         125     1.0000    1.0000    1.0000         5\n",
            "         126     0.8571    0.6667    0.7500         9\n",
            "         127     1.0000    0.4000    0.5714         5\n",
            "         128     1.0000    0.8000    0.8889         5\n",
            "         129     0.5000    0.2500    0.3333         4\n",
            "         130     1.0000    1.0000    1.0000         4\n",
            "         131     0.8000    0.8000    0.8000         5\n",
            "         132     0.7500    0.7500    0.7500         4\n",
            "         133     0.6000    0.6000    0.6000         5\n",
            "         134     1.0000    1.0000    1.0000         5\n",
            "         135     1.0000    0.8000    0.8889         5\n",
            "         136     1.0000    0.5000    0.6667         4\n",
            "         137     0.7500    0.6000    0.6667         5\n",
            "         138     0.7500    0.7500    0.7500         4\n",
            "         139     0.5000    0.5000    0.5000         4\n",
            "         140     1.0000    1.0000    1.0000         5\n",
            "         141     1.0000    0.6000    0.7500         5\n",
            "         142     0.5763    0.8500    0.6869        40\n",
            "         143     1.0000    1.0000    1.0000         4\n",
            "         144     1.0000    0.4444    0.6154         9\n",
            "         145     0.6667    0.4000    0.5000         5\n",
            "         146     1.0000    0.4000    0.5714         5\n",
            "         147     0.8000    1.0000    0.8889         4\n",
            "         148     0.6667    0.8000    0.7273         5\n",
            "         149     0.6667    0.4000    0.5000         5\n",
            "         150     0.5455    0.4615    0.5000        13\n",
            "         151     0.7500    0.7500    0.7500         4\n",
            "         152     0.6400    0.8889    0.7442        18\n",
            "         153     0.8571    0.6667    0.7500         9\n",
            "         154     1.0000    0.8889    0.9412         9\n",
            "         155     0.7143    0.3846    0.5000        13\n",
            "         156     1.0000    0.8000    0.8889         5\n",
            "         157     0.6667    0.5000    0.5714         4\n",
            "         158     0.5000    0.5385    0.5185        13\n",
            "         159     1.0000    1.0000    1.0000         4\n",
            "         160     0.7000    0.7778    0.7368         9\n",
            "         161     1.0000    0.7500    0.8571         4\n",
            "         162     0.0000    0.0000    0.0000         9\n",
            "         163     0.5439    0.7750    0.6392        40\n",
            "         164     0.3333    0.2000    0.2500         5\n",
            "         165     0.7500    0.6000    0.6667         5\n",
            "         166     0.7143    1.0000    0.8333         5\n",
            "         167     0.8750    0.7778    0.8235         9\n",
            "         168     0.6667    0.8000    0.7273         5\n",
            "         169     0.7059    0.9231    0.8000        13\n",
            "         170     0.6667    0.8000    0.7273         5\n",
            "         171     0.4000    0.5000    0.4444         4\n",
            "         172     1.0000    0.6000    0.7500         5\n",
            "         173     0.6667    0.8000    0.7273         5\n",
            "         174     0.6667    0.6667    0.6667         9\n",
            "         175     0.7000    0.7778    0.7368        18\n",
            "         176     0.0000    0.0000    0.0000        13\n",
            "         177     0.0000    0.0000    0.0000         4\n",
            "         178     1.0000    0.6000    0.7500         5\n",
            "         179     1.0000    1.0000    1.0000         9\n",
            "         180     1.0000    0.4000    0.5714         5\n",
            "         181     1.0000    0.8000    0.8889         5\n",
            "         182     0.8750    0.7778    0.8235         9\n",
            "         183     0.8000    0.8889    0.8421         9\n",
            "         184     0.8000    1.0000    0.8889         4\n",
            "         185     1.0000    1.0000    1.0000         5\n",
            "         186     0.6250    0.7692    0.6897        13\n",
            "         187     0.7500    0.6000    0.6667         5\n",
            "         188     1.0000    0.8000    0.8889         5\n",
            "         189     0.8571    0.9231    0.8889        13\n",
            "         190     1.0000    0.7500    0.8571         4\n",
            "         191     0.6000    0.6000    0.6000         5\n",
            "         192     0.8333    0.5556    0.6667         9\n",
            "         193     0.8182    1.0000    0.9000         9\n",
            "         194     0.3750    0.7500    0.5000         4\n",
            "         195     1.0000    0.7778    0.8750         9\n",
            "         196     0.6000    0.7500    0.6667         4\n",
            "         197     0.5714    0.4444    0.5000         9\n",
            "         198     0.8000    0.8000    0.8000         5\n",
            "         199     0.6000    0.6000    0.6000         5\n",
            "         200     0.5000    0.5000    0.5000         4\n",
            "         201     1.0000    1.0000    1.0000         4\n",
            "\n",
            "    accuracy                         0.7101      1797\n",
            "   macro avg     0.7524    0.6734    0.6879      1797\n",
            "weighted avg     0.7217    0.7101    0.6957      1797\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/brunasimoes/Desktop/nova_ims/2_semester/Trimestral/deep_learning/deep-learning-project/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/brunasimoes/Desktop/nova_ims/2_semester/Trimestral/deep_learning/deep-learning-project/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/brunasimoes/Desktop/nova_ims/2_semester/Trimestral/deep_learning/deep-learning-project/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "print(\"Classification report with original predictions:\")\n",
        "print(classification_report(labels,y_pred_hier,digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "209f9b80",
      "metadata": {
        "id": "209f9b80"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- 6) Per-phylum accuracy improvement ---\n",
        "phyla = np.unique(y_true_phyl)\n",
        "base_scores = []\n",
        "hier_scores = []\n",
        "for ph in phyla:\n",
        "    idxs = np.where(y_true_phyl == ph)[0]\n",
        "    base_scores.append( accuracy_score(labels[idxs], y_pred[idxs]) )\n",
        "    hier_scores.append( accuracy_score(labels[idxs], y_pred_hier[idxs]) )\n",
        "\n",
        "x = np.arange(len(phyla))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.bar(x - width/2, base_scores, width, label='Baseline')\n",
        "plt.bar(x + width/2, hier_scores, width, label='Hierarchical')\n",
        "plt.xticks(x, phyla, rotation=45, ha='right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy by Phylum')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
